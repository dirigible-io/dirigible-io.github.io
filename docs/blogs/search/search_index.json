{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to Eclipse Dirigible \u2122 Blog Hi, friends! Here, we share our vision, opinions, and experience on cloud development and, in particular, Eclipse Dirigible. We hope you'll enjoy reading these blog posts. Add more content whenever you feel like it! Here's a link to our contributor guide for your reference.","title":"Blog"},{"location":"#welcome-to-eclipse-dirigible-blog","text":"Hi, friends! Here, we share our vision, opinions, and experience on cloud development and, in particular, Eclipse Dirigible. We hope you'll enjoy reading these blog posts. Add more content whenever you feel like it! Here's a link to our contributor guide for your reference.","title":"Welcome to Eclipse Dirigible&trade; Blog"},{"location":"2014/03/21/blogs-start-of-journey/","text":"The initial idea was to make use of the very promising Eclipse RAP technology https://eclipse.org/rap/ in our development, related to Service Adaptation (part of SOA tools). The question was: - Can we build Web-based tooling for Web Services simplification (i.e. enterprise services in SAP language)? Started as a POC and evolved to a TGiF project, the Dirigible first and foremost impressed us ourselves. Full Article Here: Start of Journey","title":"Start of Journey"},{"location":"2014/03/24/blogs-dirigible-on-sap-hana/","text":"Have you ever wondered if it is possible to develop end to end your next cloud application directly via the browser? What language should you use? What kind of other tools should you need for the database management, authorization definitions, testing, life-cycle management, monitoring\u2026? What if you can: write the whole application in JavaScript? You like Ruby? What about Groovy as well? And still in the same environment? run directly Apache Camel's Routes as simplified integration services and scheduled jobs? browse your database schema or catalog and execute your query and update scripts again in the same environment? Full Article Here: Dirigible on SAP HANA Cloud Platform","title":"Dirigible on SAP HANA Cloud Platform"},{"location":"2014/06/11/blogs-dirigible-extensions-configs/","text":"If somebody asks you just right now \" What do you require most from your business software in general? \", what will pop up in your mind first? To be ...reliable, secure, feature rich? ... Cheaper? \u2013 Noo!... What about being configurable, flexible, or extendable? Well, it is clear that for business applications, in comparison to other types of software bundles like HTTP Servers, Databases, Office Packages, etc., it is vital to be adaptable to the particular business processes within a given company. Full Article Here: Dirigible - Extensions vs Configurations","title":"Dirigible - Extensions vs Configurations"},{"location":"2014/08/04/blogs-dirigible-fast-track-to-hcp/","text":"Just recently I was on site with a customer with the task to develop an HCP extension to their Successfactors subscription. The timelines were very tight and the team had zero experience with HCP and its related toolset and entry points. One option was to block some time to learn how to make use of HCP cockpit and tools and essentially halt the development during this period. On the other hand there is Dirigible http://www.dirigible.io/ . Full Article Here: Dirigible is the fast track to your HCP HANA DB instance","title":"Dirigible is the fast track to your HCP HANA DB instance"},{"location":"2014/08/19/blogs-dirigible-to-replicate-or-not-to-replicate/","text":"The existential question, which only seems to offer two equal and yet feasible options. The first time we face such a question in a distributed environment (typical in the context of cloud applications) we\u2019ll have a hard time finding the \u201cright\u201d answer \u2026hmm the second time as well? The actual problem is that we cannot give a universal solution just by definition, but have to go through case by case each time. Such scenarios could be transferring data between two legacy or 3-thd party systems, between a legacy system and our custom extension, even between the different extension applications that we could have. There could be different boundary conditions depending mainly on the source and target systems\u2019 capabilities for external communication. Sometimes, additional intermediate component could be required to cope with the integration between the systems. Hence, we need to deeply investigate the pros & cons for the given scenario, personas and components and to take concrete conscious decisions for the architectural patterns, which can be used. We have to consider also aspects like the performance for direct synchronous calls between remote systems, scalability of the source system itself, lack of tailored interfaces for our brand new use-cases, preserving the security model e.g. identity propagation, need of preliminary cache and other non-functional requirements, we often reach to the well-known situation (after taking the red pill) when \u2013 \u201cthe choice has already been made, and now you have to understand it\u201d. Full Article Here: Dirigible - To Replicate or Not To Replicate","title":"Dirigible - To Replicate or Not To Replicate"},{"location":"2014/10/15/blogs-dirigible-terminal-services/","text":"In response of the great interest related to Shellshock , Dirigible provided several possibilities to use low level OS commands. After going to the well known trial instance at http://trial.dirigible.io from the menu, go to Window->Show View->Other open the Other tree-node and choose Terminal. Full Article Here: Dirigible - Terminal Services","title":"Dirigible - Terminal Services"},{"location":"2014/10/22/blogs-dirigible-java-runtime/","text":"In attempt to attract the 9 million happy Java developers to the Dirigible community, we have introduced Java as runtime language. Yes, finally we can run our Java code in the cloud the way we like it, with Dirigible. To explore the new \" Java Services \" features, we\u2019ll create a simple \"gamification\" project. It will contain only one service and a couple of helper classes. We\u2019ll take advantage of Java by using some of the most popular classes and capabilities in the language, such as Collections Comparable , and of course Generics . The service will be responsible for calculating and distributing the results of the gamification. We\u2019ll deliver the scores in two manners \u2013 displaying them to the user, or sending them via e-mail. Full Article Here: Dirigible enables dynamic in-memory Java runtime","title":"Dirigible enables dynamic in-memory Java runtime"},{"location":"2014/10/27/news-dirigible-founders-of-cdi/","text":"Dirigible - one of the founders of Cloud Development Initiative at Eclipse together with Orion, Che and Flux - Eclipse Announces Cloud Development Industry Initiative","title":"Dirigible - one of the founders of Cloud Development Initiative at Eclipse together with Orion, Che and Flux"},{"location":"2015/01/21/news-new-release-osgiruntime-flowengine/","text":"New Release 2.0.150121 OSGi-fied Runtime, new Flow Engine, support for Markdown, Textile, TracWiki, TWiki and many more...","title":"Release 2.0.150121"},{"location":"2015/02/23/news-new-release-rcp-native-eclipse-plugins/","text":"New Release 2.0.150223 - RCP native Eclipse plugins, Repository impl for FS, Server-less RT","title":"Release 2.0.150223"},{"location":"2015/03/09/news-introduction-to-the-team/","text":"Dirigible at EclipseCon NA 2015 - Introduction to Eclipse Cloud Developer Tooling all together Martin, Nedelcho, John, Tyler and Simon","title":"Introduction to Eclipse Cloud Developer Tooling"},{"location":"2015/03/16/news-new-release-root-package/","text":"New Release 2.0.150316 - the first one with org.eclipse.dirigible root package and EPL v1.0 license","title":"Release 2.0.150316"},{"location":"2015/04/24/news-new-release-orion-as-editor/","text":"New Release 2.0.150424 - Orion as editor in Dirigible","title":"Release 2.0.150424"},{"location":"2015/05/08/news-dirigible-eclipse-project/","text":"Initial contribution has been approved 9548 . Dirigible officially became Eclipse Project - part of the Eclipse Cloud Development","title":"Dirigible officially became Eclipse Project"},{"location":"2015/08/24/news-dirigible-new-trial-instance/","text":"Trial instance of Dirigible has been moved to Eclipse.org - http://dirigible.eclipse.org . The old link http://trial.dirigible.io redirects to the same new location. The first screen asks for selection of a nickname for instant anonymous access to Dirigible. This is required for the further workspace creation. After accessing, the users have full access to all capabilities in a shared mode, hence do not be constructive in destruction, which will not be counted at this instance. Instead of this you can try the new feature - injected API code-completion in Orion editor: Enjoy!","title":"New Trial Instance at Eclipse.org"},{"location":"2015/09/23/news-2-1-m1/","text":"The M1 for Release 2.1 is ready for test. You can download it locally from http://download.dirigible.io or test it on-line at http://trial.dirigible.io","title":"Milestone 2.1 M1"},{"location":"2015/09/23/news-bof-eclipsecon-eu-2015/","text":"We are happy to announce that a BoF session at EclipseCon Europe 2015 is scheduled for Tuesday, November 3, 2015 - 20:00 to 21:00, in Seminarr\u00e4ume 1-3 https://www.eclipsecon.org/europe2015/bof-session/dirigible-powered-orion-cloud-development Join us to discuss the current state as well as the future plans and to be able to shape the project to serve best your needs.","title":"BoF at EclipseCon Europe 2015 scheduled"},{"location":"2015/09/24/blogs-dirigible-tools-for-vertical-scenarios/","text":"What does vertical scenario mean? Why building applications covering such scenarios need special toolkit and why all these relates to Dirigible? Starting the work on your next cloud application, you have to set the key concepts, architecture, boundary conditions, dependencies, development model, language, tools and many more aspects, which can lead you up to either fast delivery or fail-fast situation. If you do not ask your-self questions about these aspects every time starting a project, in these turbulent times you will not be agile enough, hence not innovative enough, hence - dull coward. Assuming that - you are here and read these article, this means you are agile, innovative, devoted to be perfect each time, so let's continue - what do you need to start and where from? Let's distinguish four major application categories in the cloud applications domain: user interface only user interface and services user interface, services and data user interface, services, data and integration User Interface Only In this category fall the static sites, reports, analytical dash-boards and all the client side only applications, which rely on existing already available services. User Interface and Services These kind of applications require some server-side logic. Mostly transformation, simplification and adaptation use-cases, where there is already an existing service which provide some data in a given scope and format, but the user interface should use only part of these data in different format. User Interface, Services and Data Here fall the set of well known atomic applications consisting of the standard building blocks - data model and its persistence, business logic in web services and user interface on top of these services. User Interface, Services, Data and Integrations Following the natural process of application evolution, sooner or later the applications from the above category start requiring integrations with some 3td party services, regular replication of data from external sources, scheduled or real-time synchronizations of events, etc. Progress Gravity Based on the above categorization, the question is: in which category does my application fall? Depending on the use-case that you have to cover and the level of understanding of this use-case, you can choose one of four. Are you ready? Good! Which one did you choose? Next question is what happens after the initial demo with some mocked data, hard-coded configurations and dummy business logic? You have to add some real services with real end-points? You have to create a real persistence, hopefully reliable, eventually consistent and as for the cloud - scalable? Step by step shaping the product adding more and more features mostly based on the key requirements, not just nice to have, you will recognize that your tiny, simple and sweet show-case application became full-fledged yet powerful beast from the last category. How did this happen?! We call this - \"progress gravity\". No matter how do you start at the beginning, maturity process pulls your application down through the category stack and finally it ends up at the last one. End-to-End Coverage with Tools Now you have an idea what we do mean with the term \"vertical scenario\", right? Once you have a real problem you have to solve it completely - partial doesn't count. Who can help you in this situation - usually you need a single instrument for every single task in the chain. What if, all the instruments are packed in one toolkit? This would be perfect, right? You do not need to jump around every time you need to change the instrument. This very simple and naive explanation shows how do we look at the problem and how do we strive to solve it - to provide you with a full-fledged toolkit, where you can find all the single \"instruments\" you need to build and operate your application for a vertical scenario - completely . Feedback and Requests If you miss an \"instrument\" in the current version of Dirigible, you can always request such via: http://forum.dirigible.io","title":"Dirigible - Toolkit for Vertical Scenarios"},{"location":"2015/09/24/blogs-dirigible-tools-for-vertical-scenarios/#user-interface-only","text":"In this category fall the static sites, reports, analytical dash-boards and all the client side only applications, which rely on existing already available services.","title":"User Interface Only"},{"location":"2015/09/24/blogs-dirigible-tools-for-vertical-scenarios/#user-interface-and-services","text":"These kind of applications require some server-side logic. Mostly transformation, simplification and adaptation use-cases, where there is already an existing service which provide some data in a given scope and format, but the user interface should use only part of these data in different format.","title":"User Interface and Services"},{"location":"2015/09/24/blogs-dirigible-tools-for-vertical-scenarios/#user-interface-services-and-data","text":"Here fall the set of well known atomic applications consisting of the standard building blocks - data model and its persistence, business logic in web services and user interface on top of these services.","title":"User Interface, Services and Data"},{"location":"2015/09/24/blogs-dirigible-tools-for-vertical-scenarios/#user-interface-services-data-and-integrations","text":"Following the natural process of application evolution, sooner or later the applications from the above category start requiring integrations with some 3td party services, regular replication of data from external sources, scheduled or real-time synchronizations of events, etc.","title":"User Interface, Services, Data and Integrations"},{"location":"2015/09/24/blogs-dirigible-tools-for-vertical-scenarios/#progress-gravity","text":"Based on the above categorization, the question is: in which category does my application fall? Depending on the use-case that you have to cover and the level of understanding of this use-case, you can choose one of four. Are you ready? Good! Which one did you choose? Next question is what happens after the initial demo with some mocked data, hard-coded configurations and dummy business logic? You have to add some real services with real end-points? You have to create a real persistence, hopefully reliable, eventually consistent and as for the cloud - scalable? Step by step shaping the product adding more and more features mostly based on the key requirements, not just nice to have, you will recognize that your tiny, simple and sweet show-case application became full-fledged yet powerful beast from the last category. How did this happen?! We call this - \"progress gravity\". No matter how do you start at the beginning, maturity process pulls your application down through the category stack and finally it ends up at the last one.","title":"Progress Gravity"},{"location":"2015/09/24/blogs-dirigible-tools-for-vertical-scenarios/#end-to-end-coverage-with-tools","text":"Now you have an idea what we do mean with the term \"vertical scenario\", right? Once you have a real problem you have to solve it completely - partial doesn't count. Who can help you in this situation - usually you need a single instrument for every single task in the chain. What if, all the instruments are packed in one toolkit? This would be perfect, right? You do not need to jump around every time you need to change the instrument. This very simple and naive explanation shows how do we look at the problem and how do we strive to solve it - to provide you with a full-fledged toolkit, where you can find all the single \"instruments\" you need to build and operate your application for a vertical scenario - completely .","title":"End-to-End Coverage with Tools"},{"location":"2015/09/24/blogs-dirigible-tools-for-vertical-scenarios/#feedback-and-requests","text":"If you miss an \"instrument\" in the current version of Dirigible, you can always request such via: http://forum.dirigible.io","title":"Feedback and Requests"},{"location":"2015/09/24/news-ecd-in-cio-bg/","text":"Development of applications in the Cloud environment is gaining more and more popularity among companies as producers of business software and foundations in supporting open source software. To reinforce this initiative Eclipse Foundation created at the end of last year a private area comprising several existing project (Orion and Flux), and two new (Che and Dirigible ). Companies that stand behind the support for this initiative originally IBM, SAP, Pivotal, Codenvy, WSO2 and Redhat. Later the initiative Eclipse Cloud Development (ECD) include another new project connected with tools for working with CloudFoundry. Full article in Bulgarian here: http://cio.bg/7439_eclipse_cloud_development__fokus_varhu_razrabotkata_v_oblaka and translated by Google here","title":"Eclipse Cloud Development - focusing on development in the Cloud"},{"location":"2015/10/06/news-dirigible-in-cio-bg/","text":"The project started its development more than five years ago in the local unit to SAP in Bulgaria, as the prototype related to the processes of adaptation and integration of web services offered by business systems. Over time, because of the increasing number of scenarios have been added various new features. This leads to the formation of discursive product development and operation of business applications based on open source technologies. Full article in Bulgarian here: http://cio.bg/7478_dirigible__integrirana_sreda_za_razrabotka_na_prilozheniya_v_oblaka and translated by Google here","title":"Dirigible - integrated environment for developing applications in the Cloud"},{"location":"2015/10/07/news-new-release-2-1/","text":"New Release 2.1.151007 first official release at Eclipse Foundation! It contains all the major features for database management, workspace management, source code editing, runtime engines and registry/repository life-cycle management. The full list of bug-fixes and enhancements can be found here The instant trial is updated accordingly with the released version here . The source code is available at GitHub repository . Congratulations for this great achievement!","title":"Release 2.1.151007"},{"location":"2015/10/07/news-new-release-2-1/#congratulations-for-this-great-achievement","text":"","title":"Congratulations for this great achievement!"},{"location":"2015/10/09/news-dirigible-workshop-codeweek/","text":"The workshop aims to achieve the dream of every developer in the cloud \u2013 building a full-fledged vertical scenario application in the fastest and yet cheapest way possible. The whole development process will be in the cloud so our turn-around time will be faster than a mouse click. For the workshop we will be using Dirigible. It is an open source project that provides Integrated Development Environment as a Service (IDEaaS), as well as integrated runtime execution engines. Currently Dirigible is a part of the Eclipse Cloud Development initiative. Organized by: SAP Labs Bulgaria Contact email: dirigible-dev@eclipse.org Happening at: bul. \"Tsar Boris III\" 136, 1618 Sofia, Bulgaria From Saturday, October 17, 2015 at 10:00 to Saturday, October 17, 2015 at 16:00 http://events.codeweek.eu/view/6000/eclipse-dirigible-cloud-dev-workshop/","title":"Dirigible Workshop CodeWeek"},{"location":"2015/10/09/news-dirigible-workshop-codeweek/#organized-by","text":"SAP Labs Bulgaria","title":"Organized by:"},{"location":"2015/10/09/news-dirigible-workshop-codeweek/#contact-email","text":"dirigible-dev@eclipse.org","title":"Contact email:"},{"location":"2015/10/09/news-dirigible-workshop-codeweek/#happening-at","text":"bul. \"Tsar Boris III\" 136, 1618 Sofia, Bulgaria From Saturday, October 17, 2015 at 10:00 to Saturday, October 17, 2015 at 16:00 http://events.codeweek.eu/view/6000/eclipse-dirigible-cloud-dev-workshop/","title":"Happening at:"},{"location":"2015/10/17/news-dirigible-workshop-codeweek-feedback/","text":"Great event! We are looking forward for the next one... There were various group of participants - students, teachers, evangelists, junior and senior experts from commercial companies and geeks. First we gave an overview about the project - history, building blocks, concepts and architecture. Then step by step the participants have created their first Dirigible project. We gathered tons of feedback about the future capabilities, which can be useful for cloud developers. It is collected in the forum's topic: https://www.eclipse.org/forums/index.php/t/1071310/ The mailing list dirigible-dev @ eclipse.org is always open to receive new ideas as well. The presentation (in Bulgarian language) can be found here http://events.codeweek.eu/view/6000/eclipse-dirigible-cloud-dev-workshop/","title":"Dirigible Workshop CodeWeek - Feedback"},{"location":"2015/10/21/blogs-dirigible-impl-sql-plugin/","text":"How to implement a custom plugin for Dirigible, which brings custom execution engine for a custom development language? Hmmm ... why at all you would need this? In general you do not. You can rely on the standard JavaScript, supported by default as a primary language for services in Dirigible. If you prefer Java you are still in the supported default options. But, what if you want to use your preferred language like Ruby, Groovy, Pyton, Scala and many other JVM and non-JVM modern languages? The good news - it's not so difficult. In this tutorial we will give you the major steps and directions, which can guide you throughout such integrations. Let's take something simple e.g. SQL script. The engine, which executes this language is the underlying RDBMS itself, but from Dirigible's point of view the database is abstracted via JDBC interface. So, let's create a new feature - 'SQL Services' support. It will provide the following: Editor for SQL script with highlighting of the keywords Icon in Workspace and Repository views showing that *.sql files are recognized Activator/Publisher, which will take care of the transfer of the SQL artifacts to Sandbox/Registry Runtime dispatcher, which will provide the endpoint for access for these services Runtime executor, which will take the artifact and will do the processing Infrastructure - pom.xml, config.ini, feature.xml User interface for endpoints in Registry Sample template for SQL Service If you are Eclipse RCP/RAP and OSGi developer, you can skip this blog and go directly by cloning the sources and looking for the Java and JavaScript plugins as example. Let's start... Editor for SQL Luckily we support two web editors in Dirigible - Orion and ACE. The later has good support for SQL Language, hence we can use it directly. Be sure that you enable the support of your language in the corresponding editor by adding the file extension to the editor's 'extensions' parameter in the plugin.xml. In this case in plugin org.eclipse.dirigible.ide.editor.ace , extension point org.eclipse.ui.editors , class org.eclipse.dirigible.ide.editor.ace.AceEditor . Icon for *.sql files Add an icon in the resources folder of the org.eclipse.dirigible.ide.repository.ui plugin, e.g. icon-sql.png . Add a reference of the icon and the necessary file extension in org.eclipse.dirigible.ide.repository.ui.viewer.AbstractArtifactLabelProvider similar like the other cases. Publisher adaptation There are a few adaptation that can enable *.sql artifact to be considered as supported scripting services. To do that: Add the corresponding constant for SQL extension in ARTIFACT_EXTENSION in the class org.eclipse.dirigible.repository.api.ICommonConstants e.g. public static final String SQL = \".sql\"; Add SQL_CONTAINER_MAPPING and SQL_SANDBOX_MAPPING in class org.eclipse.dirigible.ide.common.CommonParameters in similar way like the others. Add the corresponding artifact extension and mappings in the static list and maps in class org.eclipse.dirigible.ide.scripts.publish.ScriptsPublisher in similar way like the others. We are done at the IDE side! Now we go to the Runtime to implement the execution engine. Engine for SQL Create a new plugin which will contain all the execution engine related artifacts for the SQL support. As a template you can use already available for Java org.eclipse.dirigible.runtime.java - e.g. org.eclipse.dirigible.runtime.sql Add corresponding ENGINE_TYPE public static final String SQL = \"sql\"; in org.eclipse.dirigible.repository.api.ICommonConstants Do the same for ENGINE_ALIAS Modify/check: .project file MANIFEST.MF file names, dependencies, exported packages In OSGi-INF folder create a sql-executor.xml with corresponding references plugin.xml fill the corresponding servlets and filters pom.xml Add the module definition in the parent's pom.xml, e.g. < module>org.eclipse.dirigible.runtime.sql< /module> In the source folder ( src ), you should finally have at least: org.eclipse.dirigible.runtime.filter.SQLRegistrySecureFilter.java package org.eclipse.dirigible.runtime.filter ; public class SQLRegistrySecureFilter extends AbstractRegistrySecureFilter { private static final String SQL_SECURED_MAPPING = \"/services/sql-secured\" ; //$NON-NLS-1$ @Override protected String getSecuredMapping () { return SQL_SECURED_MAPPING ; } } org.eclipse.dirigible.runtime.registry.SQLRegistryServlet.java package org.eclipse.dirigible.runtime.registry ; public class SQLRegistryServlet extends AbstractRegistryServiceServlet { private static final long serialVersionUID = - 7292896045277229573L ; @Override protected String getServletMapping () { return \"/sql/\" ; } @Override protected String getFileExtension () { return \".sql\" ; } @Override protected String getRequestProcessingFailedMessage () { return Messages . getString ( \"JavascriptRegistryServlet.REQUEST_PROCESSING_FAILED_S\" ); } } org.eclipse.dirigible.runtime.sql.SQLExecutor.java package org.eclipse.dirigible.runtime.sql ; import java.io.IOException ; import java.sql.Connection ; import java.sql.PreparedStatement ; import java.sql.ResultSet ; import java.sql.ResultSetMetaData ; import java.util.ArrayList ; import java.util.HashMap ; import java.util.List ; import java.util.Map ; import javax.servlet.http.HttpServletRequest ; import javax.servlet.http.HttpServletResponse ; import javax.sql.DataSource ; import org.eclipse.dirigible.repository.api.ICommonConstants ; import org.eclipse.dirigible.repository.api.IRepository ; import org.eclipse.dirigible.repository.logging.Logger ; import org.eclipse.dirigible.runtime.repository.RepositoryFacade ; import org.eclipse.dirigible.runtime.scripting.AbstractScriptExecutor ; import com.google.gson.Gson ; import com.google.gson.JsonArray ; import com.google.gson.JsonObject ; import com.google.gson.JsonPrimitive ; public class SQLExecutor extends AbstractScriptExecutor { private static final String SQL_MODULE_NAME_CANNOT_BE_NULL = \"SQL module name cannot be null.\" ; private static final Logger logger = Logger . getLogger ( SQLExecutor . class ); private IRepository repository ; private String [] rootPaths ; private Map < String , Object > defaultVariables ; private String classpath ; public SQLExecutor ( IRepository repository , String ... rootPaths ) { this . repository = repository ; this . rootPaths = rootPaths ; this . defaultVariables = new HashMap < String , Object > (); this . classpath = classpath ; } @Override public Object executeServiceModule ( HttpServletRequest request , HttpServletResponse response , Object input , String module , Map < Object , Object > executionContext ) throws IOException { String result = null ; try { logger . debug ( \"entering: executeServiceModule()\" ); //$NON-NLS-1$ logger . debug ( \"module=\" + module ); //$NON-NLS-1$ if ( module == null ) { throw new IOException ( SQL_MODULE_NAME_CANNOT_BE_NULL ); } String sqlSource = new String ( retrieveModule ( repository , module , \"\" , rootPaths ). getContent ()); DataSource dataSource = RepositoryFacade . getInstance (). getDataSource (); Connection connection = null ; try { connection = dataSource . getConnection (); PreparedStatement pstmt = connection . prepareStatement ( sqlSource ); ResultSet rs = pstmt . executeQuery (); // get column names ResultSetMetaData rsmd = rs . getMetaData (); int columnCnt = rsmd . getColumnCount (); List < String > columnNames = new ArrayList < String > (); for ( int i = 1 ; i <= columnCnt ; i ++ ) { columnNames . add ( rsmd . getColumnName ( i ). toUpperCase ()); } JsonArray array = new JsonArray (); while ( rs . next ()) { JsonObject obj = new JsonObject (); for ( int i = 1 ; i <= columnCnt ; i ++ ) { String key = columnNames . get ( i - 1 ); String value = rs . getString ( i ); obj . add ( key , new JsonPrimitive ( value != null ? value : \"\" )); } array . add ( obj ); } result = new Gson (). toJson ( array ); rs . close (); pstmt . close (); } finally { if ( connection != null ) { connection . close (); } } } catch ( Exception e ) { logger . error ( e . getMessage (), e ); throw new IOException ( e ); } return result ; } @Override protected void registerDefaultVariable ( Object scope , String name , Object value ) { defaultVariables . put ( name , value ); } @Override protected String getModuleType ( String path ) { return ICommonConstants . ARTIFACT_TYPE . SCRIPTING_SERVICES ; } } org.eclipse.dirigible.runtime.sql.SQLServlet.java org.eclipse.dirigible.runtime.sql.SQLSandboxServlet.java org.eclipse.dirigible.runtime.sql.SQLSecuredServlet.java org.eclipse.dirigible.runtime.sql.SQLScriptExecutorProvider.java Include the Plugin as a Feature There is a feature for the runtime plugins in the project p2.runtime.feature Add the SQL plugin to the feature.xml accordingly Include the Plugin for Packaging You have to include just created plugin into the configuration files for Equinox OSGi: In the project releng/dirigible-all-tomcat > sub-folder src/main/webapp/WEB-INF/configuration > file config.ini In the project releng/dirigible-runtime-tomcat > sub-folder src/main/webapp/WEB-INF/configuration > file config.ini be very careful with the white spaces in the beginning of the line Security Constrains in web.xml In the project releng/dirigible-all-tomcat > sub-folder src/web/ > all files web.xml excluding trial In the project releng/dirigible-runtime-tomcat > sub-folder src/web/ > all files web.xml excluding trial Flows and Jobs Integration Luckily we have already implemented the extensibility in a way that SQLScriptExecutorProvider from above is automatically registered and can be used in Flows. Registry Section for SQL Services The plugin containing the registry user interface is org.eclipse.dirigible.runtime.ui Create a file sql.html in the sub-folder resources/ui/templates/scripting/sql < div id = \"content\" ng-include = \"'templates/default.html'\" ></ div > Adapt $routeProvider in the app.js file by adding routing for sql pages In the same file add a corresponding section in $scope.homeData Add the controller itself in default.js defaultControllers.controller('SQLCtrl', function($scope, $resource) { $scope.restService = $resource('../scripting/sql'); }); Do not forget to add some image file also Add a manu item in the main menu - menu.json Template for SQL Scripting Service To complete the SQL support we can add at least one template to be available in the New->ScriptinService wizard. To do that, in the plugin org.eclipse.dirigible.ide.template.ui.js Create file sql-service.sql under the folder src/org/eclipse/dirigible/ide/template/ui/js/templates SELECT * FROM DGB_FILES Add the definition in the plugin.xml accordingly <template category= \"ScriptingServices\" image= \"/icons/sql-service.png\" location= \"/org/eclipse/dirigible/ide/template/ui/js/templates/sql-service.sql\" text= \"SQL Sample Query Service\" > </template> Do not forget the icon as well Add the default extension file recognition in org.eclipse.dirigible.ide.template.ui.js.wizard.JavascriptServiceTemplateTargetLocationPage ... } else if ( \"/org/eclipse/dirigible/ide/template/ui/js/templates/sql-service.sql\" //$NON-NLS-1$ . equals ( model . getTemplate (). getLocation ())) { jsOrLibExt = \"sql\" ; //$NON-NLS-1$ } ... Congratulations! If you managed to follow all this - you are a hero! The git commit for reference is here","title":"Tutorial - How to implement a plugin for SQL language support"},{"location":"2015/10/21/blogs-dirigible-impl-sql-plugin/#editor-for-sql","text":"Luckily we support two web editors in Dirigible - Orion and ACE. The later has good support for SQL Language, hence we can use it directly. Be sure that you enable the support of your language in the corresponding editor by adding the file extension to the editor's 'extensions' parameter in the plugin.xml. In this case in plugin org.eclipse.dirigible.ide.editor.ace , extension point org.eclipse.ui.editors , class org.eclipse.dirigible.ide.editor.ace.AceEditor .","title":"Editor for SQL"},{"location":"2015/10/21/blogs-dirigible-impl-sql-plugin/#icon-for-sql-files","text":"Add an icon in the resources folder of the org.eclipse.dirigible.ide.repository.ui plugin, e.g. icon-sql.png . Add a reference of the icon and the necessary file extension in org.eclipse.dirigible.ide.repository.ui.viewer.AbstractArtifactLabelProvider similar like the other cases.","title":"Icon for *.sql files"},{"location":"2015/10/21/blogs-dirigible-impl-sql-plugin/#publisher-adaptation","text":"There are a few adaptation that can enable *.sql artifact to be considered as supported scripting services. To do that: Add the corresponding constant for SQL extension in ARTIFACT_EXTENSION in the class org.eclipse.dirigible.repository.api.ICommonConstants e.g. public static final String SQL = \".sql\"; Add SQL_CONTAINER_MAPPING and SQL_SANDBOX_MAPPING in class org.eclipse.dirigible.ide.common.CommonParameters in similar way like the others. Add the corresponding artifact extension and mappings in the static list and maps in class org.eclipse.dirigible.ide.scripts.publish.ScriptsPublisher in similar way like the others. We are done at the IDE side! Now we go to the Runtime to implement the execution engine.","title":"Publisher adaptation"},{"location":"2015/10/21/blogs-dirigible-impl-sql-plugin/#engine-for-sql","text":"Create a new plugin which will contain all the execution engine related artifacts for the SQL support. As a template you can use already available for Java org.eclipse.dirigible.runtime.java - e.g. org.eclipse.dirigible.runtime.sql Add corresponding ENGINE_TYPE public static final String SQL = \"sql\"; in org.eclipse.dirigible.repository.api.ICommonConstants Do the same for ENGINE_ALIAS Modify/check: .project file MANIFEST.MF file names, dependencies, exported packages In OSGi-INF folder create a sql-executor.xml with corresponding references plugin.xml fill the corresponding servlets and filters pom.xml Add the module definition in the parent's pom.xml, e.g. < module>org.eclipse.dirigible.runtime.sql< /module> In the source folder ( src ), you should finally have at least: org.eclipse.dirigible.runtime.filter.SQLRegistrySecureFilter.java package org.eclipse.dirigible.runtime.filter ; public class SQLRegistrySecureFilter extends AbstractRegistrySecureFilter { private static final String SQL_SECURED_MAPPING = \"/services/sql-secured\" ; //$NON-NLS-1$ @Override protected String getSecuredMapping () { return SQL_SECURED_MAPPING ; } } org.eclipse.dirigible.runtime.registry.SQLRegistryServlet.java package org.eclipse.dirigible.runtime.registry ; public class SQLRegistryServlet extends AbstractRegistryServiceServlet { private static final long serialVersionUID = - 7292896045277229573L ; @Override protected String getServletMapping () { return \"/sql/\" ; } @Override protected String getFileExtension () { return \".sql\" ; } @Override protected String getRequestProcessingFailedMessage () { return Messages . getString ( \"JavascriptRegistryServlet.REQUEST_PROCESSING_FAILED_S\" ); } } org.eclipse.dirigible.runtime.sql.SQLExecutor.java package org.eclipse.dirigible.runtime.sql ; import java.io.IOException ; import java.sql.Connection ; import java.sql.PreparedStatement ; import java.sql.ResultSet ; import java.sql.ResultSetMetaData ; import java.util.ArrayList ; import java.util.HashMap ; import java.util.List ; import java.util.Map ; import javax.servlet.http.HttpServletRequest ; import javax.servlet.http.HttpServletResponse ; import javax.sql.DataSource ; import org.eclipse.dirigible.repository.api.ICommonConstants ; import org.eclipse.dirigible.repository.api.IRepository ; import org.eclipse.dirigible.repository.logging.Logger ; import org.eclipse.dirigible.runtime.repository.RepositoryFacade ; import org.eclipse.dirigible.runtime.scripting.AbstractScriptExecutor ; import com.google.gson.Gson ; import com.google.gson.JsonArray ; import com.google.gson.JsonObject ; import com.google.gson.JsonPrimitive ; public class SQLExecutor extends AbstractScriptExecutor { private static final String SQL_MODULE_NAME_CANNOT_BE_NULL = \"SQL module name cannot be null.\" ; private static final Logger logger = Logger . getLogger ( SQLExecutor . class ); private IRepository repository ; private String [] rootPaths ; private Map < String , Object > defaultVariables ; private String classpath ; public SQLExecutor ( IRepository repository , String ... rootPaths ) { this . repository = repository ; this . rootPaths = rootPaths ; this . defaultVariables = new HashMap < String , Object > (); this . classpath = classpath ; } @Override public Object executeServiceModule ( HttpServletRequest request , HttpServletResponse response , Object input , String module , Map < Object , Object > executionContext ) throws IOException { String result = null ; try { logger . debug ( \"entering: executeServiceModule()\" ); //$NON-NLS-1$ logger . debug ( \"module=\" + module ); //$NON-NLS-1$ if ( module == null ) { throw new IOException ( SQL_MODULE_NAME_CANNOT_BE_NULL ); } String sqlSource = new String ( retrieveModule ( repository , module , \"\" , rootPaths ). getContent ()); DataSource dataSource = RepositoryFacade . getInstance (). getDataSource (); Connection connection = null ; try { connection = dataSource . getConnection (); PreparedStatement pstmt = connection . prepareStatement ( sqlSource ); ResultSet rs = pstmt . executeQuery (); // get column names ResultSetMetaData rsmd = rs . getMetaData (); int columnCnt = rsmd . getColumnCount (); List < String > columnNames = new ArrayList < String > (); for ( int i = 1 ; i <= columnCnt ; i ++ ) { columnNames . add ( rsmd . getColumnName ( i ). toUpperCase ()); } JsonArray array = new JsonArray (); while ( rs . next ()) { JsonObject obj = new JsonObject (); for ( int i = 1 ; i <= columnCnt ; i ++ ) { String key = columnNames . get ( i - 1 ); String value = rs . getString ( i ); obj . add ( key , new JsonPrimitive ( value != null ? value : \"\" )); } array . add ( obj ); } result = new Gson (). toJson ( array ); rs . close (); pstmt . close (); } finally { if ( connection != null ) { connection . close (); } } } catch ( Exception e ) { logger . error ( e . getMessage (), e ); throw new IOException ( e ); } return result ; } @Override protected void registerDefaultVariable ( Object scope , String name , Object value ) { defaultVariables . put ( name , value ); } @Override protected String getModuleType ( String path ) { return ICommonConstants . ARTIFACT_TYPE . SCRIPTING_SERVICES ; } } org.eclipse.dirigible.runtime.sql.SQLServlet.java org.eclipse.dirigible.runtime.sql.SQLSandboxServlet.java org.eclipse.dirigible.runtime.sql.SQLSecuredServlet.java org.eclipse.dirigible.runtime.sql.SQLScriptExecutorProvider.java","title":"Engine for SQL"},{"location":"2015/10/21/blogs-dirigible-impl-sql-plugin/#include-the-plugin-as-a-feature","text":"There is a feature for the runtime plugins in the project p2.runtime.feature Add the SQL plugin to the feature.xml accordingly","title":"Include the Plugin as a Feature"},{"location":"2015/10/21/blogs-dirigible-impl-sql-plugin/#include-the-plugin-for-packaging","text":"You have to include just created plugin into the configuration files for Equinox OSGi: In the project releng/dirigible-all-tomcat > sub-folder src/main/webapp/WEB-INF/configuration > file config.ini In the project releng/dirigible-runtime-tomcat > sub-folder src/main/webapp/WEB-INF/configuration > file config.ini be very careful with the white spaces in the beginning of the line","title":"Include the Plugin for Packaging"},{"location":"2015/10/21/blogs-dirigible-impl-sql-plugin/#security-constrains-in-webxml","text":"In the project releng/dirigible-all-tomcat > sub-folder src/web/ > all files web.xml excluding trial In the project releng/dirigible-runtime-tomcat > sub-folder src/web/ > all files web.xml excluding trial","title":"Security Constrains in web.xml"},{"location":"2015/10/21/blogs-dirigible-impl-sql-plugin/#flows-and-jobs-integration","text":"Luckily we have already implemented the extensibility in a way that SQLScriptExecutorProvider from above is automatically registered and can be used in Flows.","title":"Flows and Jobs Integration"},{"location":"2015/10/21/blogs-dirigible-impl-sql-plugin/#registry-section-for-sql-services","text":"The plugin containing the registry user interface is org.eclipse.dirigible.runtime.ui Create a file sql.html in the sub-folder resources/ui/templates/scripting/sql < div id = \"content\" ng-include = \"'templates/default.html'\" ></ div > Adapt $routeProvider in the app.js file by adding routing for sql pages In the same file add a corresponding section in $scope.homeData Add the controller itself in default.js defaultControllers.controller('SQLCtrl', function($scope, $resource) { $scope.restService = $resource('../scripting/sql'); }); Do not forget to add some image file also Add a manu item in the main menu - menu.json","title":"Registry Section for SQL Services"},{"location":"2015/10/21/blogs-dirigible-impl-sql-plugin/#template-for-sql-scripting-service","text":"To complete the SQL support we can add at least one template to be available in the New->ScriptinService wizard. To do that, in the plugin org.eclipse.dirigible.ide.template.ui.js Create file sql-service.sql under the folder src/org/eclipse/dirigible/ide/template/ui/js/templates SELECT * FROM DGB_FILES Add the definition in the plugin.xml accordingly <template category= \"ScriptingServices\" image= \"/icons/sql-service.png\" location= \"/org/eclipse/dirigible/ide/template/ui/js/templates/sql-service.sql\" text= \"SQL Sample Query Service\" > </template> Do not forget the icon as well Add the default extension file recognition in org.eclipse.dirigible.ide.template.ui.js.wizard.JavascriptServiceTemplateTargetLocationPage ... } else if ( \"/org/eclipse/dirigible/ide/template/ui/js/templates/sql-service.sql\" //$NON-NLS-1$ . equals ( model . getTemplate (). getLocation ())) { jsOrLibExt = \"sql\" ; //$NON-NLS-1$ } ... Congratulations! If you managed to follow all this - you are a hero! The git commit for reference is here","title":"Template for SQL Scripting Service"},{"location":"2015/10/28/blogs-dirigible-branding/","text":"Being a cloud platform provider or development tools provider company, most probably you would like to have your own logo and a name following your products naming convention instead of Dirigible's ones. It is very easy following the Eclipse RAP Branding approach. Create a plugin for your theme You can use the existing plugin org.eclipse.rap.design.example as a template: https://github.com/eclipse/rap/tree/master/examples/org.eclipse.rap.design.example . Create an entry point Let's assume that we just use the existing example plugin with the existing sample theme with id org.eclipse.rap.design.example.business.branding or org.eclipse.rap.design.example.fancy.branding . The new entrypoint declaration in the plugin.xml in the project org.eclipse.dirigible.ide.ui.rap should look like: ... <extension point= \"org.eclipse.rap.ui.entrypoint\" > <entrypoint brandingId= \"org.eclipse.rap.design.example.business.branding\" class= \"org.eclipse.dirigible.ide.ui.rap.entry.DirigibleWorkbench\" id= \"org.eclipse.dirigible.ide.ui.rap.entry.DefaultEntrypoint\" path= \"/business\" > </entrypoint> </extension> ... Add the branding plugin to parent's pom.xml Do not forget to add the branding plugin as a module definition in the parent's pom.xml Include the branding plugin as a feature There is a feature for the ide plugins in the project p2.ide.feature Add your branding plugin to the feature.xml accordingly Include the branding plugin for packaging You have to include branding plugin into the configuration files for Equinox OSGi: In the project releng/dirigible-all-tomcat > sub-folder src/main/webapp/WEB-INF/configuration > file config.ini be very careful with the white spaces in the beginning of the line Below you can get an impression what is achievable. Business Theme - /business Fancy Theme - /fancy Enjoy Branding!","title":"Tutorial - How to re-brand Dirigible workbench"},{"location":"2015/10/28/blogs-dirigible-branding/#create-a-plugin-for-your-theme","text":"You can use the existing plugin org.eclipse.rap.design.example as a template: https://github.com/eclipse/rap/tree/master/examples/org.eclipse.rap.design.example .","title":"Create a plugin for your theme"},{"location":"2015/10/28/blogs-dirigible-branding/#create-an-entry-point","text":"Let's assume that we just use the existing example plugin with the existing sample theme with id org.eclipse.rap.design.example.business.branding or org.eclipse.rap.design.example.fancy.branding . The new entrypoint declaration in the plugin.xml in the project org.eclipse.dirigible.ide.ui.rap should look like: ... <extension point= \"org.eclipse.rap.ui.entrypoint\" > <entrypoint brandingId= \"org.eclipse.rap.design.example.business.branding\" class= \"org.eclipse.dirigible.ide.ui.rap.entry.DirigibleWorkbench\" id= \"org.eclipse.dirigible.ide.ui.rap.entry.DefaultEntrypoint\" path= \"/business\" > </entrypoint> </extension> ...","title":"Create an entry point"},{"location":"2015/10/28/blogs-dirigible-branding/#add-the-branding-plugin-to-parents-pomxml","text":"Do not forget to add the branding plugin as a module definition in the parent's pom.xml","title":"Add the branding plugin to parent's pom.xml"},{"location":"2015/10/28/blogs-dirigible-branding/#include-the-branding-plugin-as-a-feature","text":"There is a feature for the ide plugins in the project p2.ide.feature Add your branding plugin to the feature.xml accordingly","title":"Include the branding plugin as a feature"},{"location":"2015/10/28/blogs-dirigible-branding/#include-the-branding-plugin-for-packaging","text":"You have to include branding plugin into the configuration files for Equinox OSGi: In the project releng/dirigible-all-tomcat > sub-folder src/main/webapp/WEB-INF/configuration > file config.ini be very careful with the white spaces in the beginning of the line Below you can get an impression what is achievable.","title":"Include the branding plugin for packaging"},{"location":"2015/10/28/blogs-dirigible-branding/#business-theme-business","text":"","title":"Business Theme - /business"},{"location":"2015/10/28/blogs-dirigible-branding/#fancy-theme-fancy","text":"Enjoy Branding!","title":"Fancy Theme - /fancy"},{"location":"2015/10/28/blogs-dirigible-orion-editor/","text":"Why Orion? How the code-completion is achieved? How the Orion editor is integrated with RAP? Why Orion? Our choice for using the Orion editor as the primary editor in Dirigible is bases on that it is has the best support and tooling for JavaScript. Also JavaScript is the language of choice for writing services with Dirigible. Beyond these arguments, Dirigible and Orion are part of the Eclipse Cloud Development iniciative , that strives to set up the standarts and the best practices for \"developing in the cloud for the cloud\" . Taking advantage of the open source eco system is key mindset, layed in the foundations of the project. Why Tern.js? Tern.js is a code-analysis and code-completion library for JavaScript. It can run both on client-side and on server-side. In order to achive real time proposals and to remove the overhead from server communication, in Dirigible we use Tern.js as a client-side library. In addition to the JavaScript code-completion, Tern.js allows to introduce custom suggestions - the way to integrate and allow code-completion for Dirigible API . How is the Injected API integrated in Orion? We use the standard Tern.js approach leveraged by Orion, by declaring objects and functions for code-completion as a JavaScript plugin. You can find the plugin here . After the build of Orion itself, there is a generated dirigible.json file out of the declarations. To use and package the embedded Orion editor in Dirigible we need to go over the following steps: Build the json definition with: npm install tern git clone orion.client git reset --hard origin/stable_20150817 Add your declaration file in ternWorkerCore.js orion.client/bundles/org.eclipse.orion.client.javascript/web/node_modules/tern/bin/condense --name dirigible --no-spans --plugin doc_comment --def ecma5 --def browser dirigible.js > orion.client/bundles/org.eclipse.orion.client.javascript/web/tern/defs/dirigible.json mvn clean install copy orion.client/build-js/codeEdit > resources How it is integrated with RAP? By using RAP scripting capabilities for callbacks, we have client and backend sides communicating via the standard RAP chanel. Thanks to functions like getText() , setText() , setDirty() , setDebugRow() , etc., we are on the half of the way. To glue to whole thing to works as one, we have in the backend EditorWidget.java and its coresponding client-side controller editor.html . What about Debugging? Last but not least, here comes the integrated debuggier in Dirigible. This was not so easy and trivial part, but finally the Dirigible's debugger uses the Orion editor. Client-side integration ... function getBreakpointsEnabled () { return breakpointsEnabled ; } function setBreakpointsEnabled ( status ) { breakpointsEnabled = status ; } function loadBreakpoint ( breakpoint ) { handleAddRemoveBreakpoint ( breakpoint ); } function setDebugRow ( row ) { editor . setCaretOffset ( editor . getLineStart ( row )); } function handleAddRemoveBreakpoint ( lineIndex ) { if ( typeof ( Storage ) === \"undefined\" ) { alert ( \"Session storage is not available!\" ) } else if ( getBreakpointsEnabled ()) { var breakpointsArray ; if ( sessionStorage . breakpoints ) { breakpointsArray = JSON . parse ( sessionStorage . breakpoints ); var index = breakpointsArray . indexOf ( lineIndex ); if ( index > - 1 ) { breakpointsArray . splice ( index , 1 ); clearBreakpoint ( lineIndex ); } else { breakpointsArray . push ( lineIndex ); setBreakpoint ( lineIndex ); } } else { breakpointsArray = [] ; breakpointsArray . push ( lineIndex ); setBreakpoint ( lineIndex ); } sessionStorage . breakpoints = JSON . stringify ( breakpointsArray ); } } ... The whole file can be found here . Server-side ... new BrowserFunction ( browser , \"setBreakpoint\" ) { @Override public Object function ( final Object [] arguments ) { if (( listener != null ) && ( arguments [ 0 ] != null ) && ( arguments [ 0 ] instanceof Number )) { listener . setBreakpoint ((( Number ) arguments [ 0 ] ). intValue ()); } return null ; } }; new BrowserFunction ( browser , \"clearBreakpoint\" ) { @Override public Object function ( final Object [] arguments ) { if (( listener != null ) && ( arguments [ 0 ] != null ) && ( arguments [ 0 ] instanceof Number )) { listener . clearBreakpoint ((( Number ) arguments [ 0 ] ). intValue ()); } return null ; } }; ... public void setDebugRow ( final int row ) { execute ( \"setDebugRow\" , row ); } public void loadBreakpoints ( final int [] breakpoints ) { for ( final int breakpoint : breakpoints ) { execute ( \"loadBreakpoint\" , breakpoint ); } } private void execute ( final String function , final Object ... arguments ) { browser . execute ( buildFunctionCall ( function , arguments )); } ... The whole file can be found here . Special thanks to Libing Wang and the orion-dev team for helping us with the integration between the debugger and the Orion editor. You can find the whole conversation here .","title":"How the Orion editor is integrated in Dirigible"},{"location":"2015/10/28/blogs-dirigible-orion-editor/#why-orion","text":"Our choice for using the Orion editor as the primary editor in Dirigible is bases on that it is has the best support and tooling for JavaScript. Also JavaScript is the language of choice for writing services with Dirigible. Beyond these arguments, Dirigible and Orion are part of the Eclipse Cloud Development iniciative , that strives to set up the standarts and the best practices for \"developing in the cloud for the cloud\" . Taking advantage of the open source eco system is key mindset, layed in the foundations of the project.","title":"Why Orion?"},{"location":"2015/10/28/blogs-dirigible-orion-editor/#why-ternjs","text":"Tern.js is a code-analysis and code-completion library for JavaScript. It can run both on client-side and on server-side. In order to achive real time proposals and to remove the overhead from server communication, in Dirigible we use Tern.js as a client-side library. In addition to the JavaScript code-completion, Tern.js allows to introduce custom suggestions - the way to integrate and allow code-completion for Dirigible API .","title":"Why Tern.js?"},{"location":"2015/10/28/blogs-dirigible-orion-editor/#how-is-the-injected-api-integrated-in-orion","text":"We use the standard Tern.js approach leveraged by Orion, by declaring objects and functions for code-completion as a JavaScript plugin. You can find the plugin here . After the build of Orion itself, there is a generated dirigible.json file out of the declarations. To use and package the embedded Orion editor in Dirigible we need to go over the following steps:","title":"How is the Injected API integrated in Orion?"},{"location":"2015/10/28/blogs-dirigible-orion-editor/#build-the-json-definition-with","text":"npm install tern git clone orion.client git reset --hard origin/stable_20150817","title":"Build the json definition with:"},{"location":"2015/10/28/blogs-dirigible-orion-editor/#add-your-declaration-file-in-ternworkercorejs","text":"orion.client/bundles/org.eclipse.orion.client.javascript/web/node_modules/tern/bin/condense --name dirigible --no-spans --plugin doc_comment --def ecma5 --def browser dirigible.js > orion.client/bundles/org.eclipse.orion.client.javascript/web/tern/defs/dirigible.json mvn clean install copy orion.client/build-js/codeEdit > resources","title":"Add your declaration file in ternWorkerCore.js"},{"location":"2015/10/28/blogs-dirigible-orion-editor/#how-it-is-integrated-with-rap","text":"By using RAP scripting capabilities for callbacks, we have client and backend sides communicating via the standard RAP chanel. Thanks to functions like getText() , setText() , setDirty() , setDebugRow() , etc., we are on the half of the way. To glue to whole thing to works as one, we have in the backend EditorWidget.java and its coresponding client-side controller editor.html .","title":"How it is integrated with RAP?"},{"location":"2015/10/28/blogs-dirigible-orion-editor/#what-about-debugging","text":"Last but not least, here comes the integrated debuggier in Dirigible. This was not so easy and trivial part, but finally the Dirigible's debugger uses the Orion editor.","title":"What about Debugging?"},{"location":"2015/10/28/blogs-dirigible-orion-editor/#client-side-integration","text":"... function getBreakpointsEnabled () { return breakpointsEnabled ; } function setBreakpointsEnabled ( status ) { breakpointsEnabled = status ; } function loadBreakpoint ( breakpoint ) { handleAddRemoveBreakpoint ( breakpoint ); } function setDebugRow ( row ) { editor . setCaretOffset ( editor . getLineStart ( row )); } function handleAddRemoveBreakpoint ( lineIndex ) { if ( typeof ( Storage ) === \"undefined\" ) { alert ( \"Session storage is not available!\" ) } else if ( getBreakpointsEnabled ()) { var breakpointsArray ; if ( sessionStorage . breakpoints ) { breakpointsArray = JSON . parse ( sessionStorage . breakpoints ); var index = breakpointsArray . indexOf ( lineIndex ); if ( index > - 1 ) { breakpointsArray . splice ( index , 1 ); clearBreakpoint ( lineIndex ); } else { breakpointsArray . push ( lineIndex ); setBreakpoint ( lineIndex ); } } else { breakpointsArray = [] ; breakpointsArray . push ( lineIndex ); setBreakpoint ( lineIndex ); } sessionStorage . breakpoints = JSON . stringify ( breakpointsArray ); } } ... The whole file can be found here .","title":"Client-side integration"},{"location":"2015/10/28/blogs-dirigible-orion-editor/#server-side","text":"... new BrowserFunction ( browser , \"setBreakpoint\" ) { @Override public Object function ( final Object [] arguments ) { if (( listener != null ) && ( arguments [ 0 ] != null ) && ( arguments [ 0 ] instanceof Number )) { listener . setBreakpoint ((( Number ) arguments [ 0 ] ). intValue ()); } return null ; } }; new BrowserFunction ( browser , \"clearBreakpoint\" ) { @Override public Object function ( final Object [] arguments ) { if (( listener != null ) && ( arguments [ 0 ] != null ) && ( arguments [ 0 ] instanceof Number )) { listener . clearBreakpoint ((( Number ) arguments [ 0 ] ). intValue ()); } return null ; } }; ... public void setDebugRow ( final int row ) { execute ( \"setDebugRow\" , row ); } public void loadBreakpoints ( final int [] breakpoints ) { for ( final int breakpoint : breakpoints ) { execute ( \"loadBreakpoint\" , breakpoint ); } } private void execute ( final String function , final Object ... arguments ) { browser . execute ( buildFunctionCall ( function , arguments )); } ... The whole file can be found here . Special thanks to Libing Wang and the orion-dev team for helping us with the integration between the debugger and the Orion editor. You can find the whole conversation here .","title":"Server-side"},{"location":"2015/11/17/news-new-milestone-2-2-1/","text":"New Milestone 2.2.151117 released. Local (File System based) Repository added. SQL Services added as part of the tutorial . The full list of bug-fixes and enhancements can be found here . The source code is available at GitHub repository . Enjoy!","title":"Milestone 2.2.151117-M1"},{"location":"2015/11/17/news-new-milestone-2-2-1/#enjoy","text":"","title":"Enjoy!"},{"location":"2015/12/10/blogs-dirigible-remote-debugging/","text":"While a significant part of the Dirigible development can be conveniently supported by in-Eclipse debugging using the generated 'dirigible-local' OSGi Framework launch configuration, there is also a couple of use cases that cannot be implemented using this approach. More specifically, this is the case when Dirigible is deployed in a web container and you need to debug it remotely e.g. from Eclipse. This very much affects both supportability but also partially development process too. Wrt supportability , being able to debug remotely is very important so that issues can be inspected directly in the defective deployments. Wrt development process , it is the only valid way to debug components that rely on external components and their execution environment. One such example is the configurable database access in the repository services. To set the scene in brief, suppose that one needs to integrate yet another database and debug end-to-end if it worked out (or why exactly it didn't work) in a real setup with Dirigible deployed in Tomcat with the DB drivers provisioned by Tomcat and exposed as a JNDI-bound DataSource in web.xml. Currently, you can't do this in OSGi-only environment. You could think that setting up remote debugging is as trivial as with any other web application and mostly it is with a few caveats that can ruin your day. The two important specific steps that i needed to perform before i had remote debugging working for me were: 1.Build Dirigible with debug info <plugin> <groupId> org.apache.maven.plugins </groupId> <artifactId> maven-compiler-plugin </artifactId> <version> 2.4 </version> <configuration> <source> 1.7 </source> <target> 1.7 </target> <debug> true </debug> <debuglevel> lines,vars,source </debuglevel> </configuration> </plugin> 2.Clear the work directory in Tomcat (!) ...because in my case I had previously deployed Dirigible. OSGi is using it for its bundles and it will interfere with fresh deployments Summing up the steps: 1.Build Dirigible with debug info 2.Clear previous deployments if any and make sure the work directory is clear (very important!), and deploy 3.Start Tomcat in debug mode: catalina jpda start 4.In Eclipse, launch a Debug launch configuration with default settings. Set breakpoints and debug happily. It would be lovely to have some shortcut for the first two steps (and particularly the second) but I can't figure out anything more suitable than manual work for now. Enjoy!","title":"Developer - Remote debugging Dirigible source code"},{"location":"2015/12/10/blogs-dirigible-remote-debugging/#1build-dirigible-with-debug-info","text":"<plugin> <groupId> org.apache.maven.plugins </groupId> <artifactId> maven-compiler-plugin </artifactId> <version> 2.4 </version> <configuration> <source> 1.7 </source> <target> 1.7 </target> <debug> true </debug> <debuglevel> lines,vars,source </debuglevel> </configuration> </plugin>","title":"1.Build Dirigible with debug info"},{"location":"2015/12/10/blogs-dirigible-remote-debugging/#2clear-the-work-directory-in-tomcat","text":"...because in my case I had previously deployed Dirigible. OSGi is using it for its bundles and it will interfere with fresh deployments","title":"2.Clear the work directory in Tomcat (!)"},{"location":"2015/12/10/blogs-dirigible-remote-debugging/#summing-up-the-steps","text":"1.Build Dirigible with debug info 2.Clear previous deployments if any and make sure the work directory is clear (very important!), and deploy 3.Start Tomcat in debug mode: catalina jpda start 4.In Eclipse, launch a Debug launch configuration with default settings. Set breakpoints and debug happily. It would be lovely to have some shortcut for the first two steps (and particularly the second) but I can't figure out anything more suitable than manual work for now. Enjoy!","title":"Summing up the steps:"},{"location":"2015/12/16/news-vlado-session-eclipsecon-na-2016/","text":"In this session we'll discuss how development of cloud applications and services with Dirigible looks like - in the eyes of a hard-core veteran Java guy. We'll draw some analogies to the Java (EE) development model and also explore how the two models differ. Which Dirigible concepts look smarter and could ease development of cloud applications and increase productivity, and in which aspects Java is still stronger and continues to strengthen its positions... Eclipse Con Congrats!","title":"Session by Vladimir Pavlov about Dirigible has been accepted for EclipseCon NA 2016!"},{"location":"2015/12/16/news-vlado-session-eclipsecon-na-2016/#congrats","text":"","title":"Congrats!"},{"location":"2015/12/17/blogs-how-to-install-dirigible-on-sap-hana-cloud-platform/","text":"You can try HTML, CSS, Java Script, Java, and SQL without installing anything on your computer. Just start it in HCP (SAP Hana Cloud Platform) and access from anywhere and create your own project. It could be very useful for learners, or for teachers as an online educational tool for full stack web development... Full Article Here: How to install Dirigible on SAP HANA Cloud Platform","title":"Tutorial - How to install Dirigible on SAP HANA Cloud Platform"},{"location":"2015/12/17/news-new-milestone-2-2-2/","text":"New Milestone 2.2.151217 released. Multiple DataSources support + Injected API + Code Completion + Preferences Integration of MongoDB as NoSQL datasource Local File System based Repository stabilisation and setting as default Templating Service (Velocity syntax) + Injected API + Code Completion Master Repository Provider concept Git based Master Repository implementation RDBMS based Master Repository implementation File System (Shared FS) based Master Repository implementation Hiding Activate (sandboxing) functionality by default Bugfixes and Refactoring... Remote debugging Dirigible source code developer tutorial . The full list of bug-fixes and enhancements can be found here . The source code is available at GitHub repository . Enjoy!","title":"Milestone 2.2.151217-M2"},{"location":"2015/12/17/news-new-milestone-2-2-2/#enjoy","text":"","title":"Enjoy!"},{"location":"2015/12/21/blogs-groovy-is-back/","text":"Groovy Dev Platform powered by Eclipse Dirigible is back! The fork of the Eclipse Dirigible project with the add-ons for Groovy Developers can be found at EclipseLabs Disclaimer This is not an official Eclipse project, but rather an example how to build your own Dev Platform based on Eclipse Dirigible. Download There is also a download section, where you can found the pre-built artifacts: Trial self executable Jar file War file for Apache Tomcat","title":"Developer - Groovy is back"},{"location":"2015/12/21/blogs-groovy-is-back/#disclaimer","text":"This is not an official Eclipse project, but rather an example how to build your own Dev Platform based on Eclipse Dirigible.","title":"Disclaimer"},{"location":"2015/12/21/blogs-groovy-is-back/#download","text":"There is also a download section, where you can found the pre-built artifacts: Trial self executable Jar file War file for Apache Tomcat","title":"Download"},{"location":"2016/01/07/blogs-dirigible-custom-ds-1/","text":"Starting with version Dirigible 2.2 M3, it is possible to register multiple custom data sources alongside with the default, system one. This feature allows keeping Dirigible system data completely separate from application data. And now application developers can create applications that span across multiple data sources. Both of these bring much more sense of production-readiness than ever before. In this Part I of our series dedicated to the new feature, we explore in details how a Service Provider would setup Dirigible for multiple data sources and how Operators and App Developers would benefit using Dirigible\u2019s database related tools and programming model. In the next parts of the series, we are going to see more topics related to custom data sources in Dirigible, such as how to extend the set of supported data sources, which currently consists of MySQL, PostgreSQL, Derby, SAPDB, SAP HANA DB and MongoDB, and more. Part I: Custom Data Sources setup A zero-to-hero, complete setup of a new Data Source in Dirigible consists of the following simple steps: Provision JDBC driver and Data Source classes to the runtime Bind a configured Data Source to JNDI Configure a reference to the JNDI-bound Data Source resource in Dirigible Register the Data Source with Dirigible IDE to make it available to its features This is the short story. Let us follow this process in details step-by-step and in more detail. Our setup will be a Dirigible web application deployed in a Tomcat web container and a PostgreSQL data source that will be provisioned along with the default Derby data source. Step 1: Provision JDBC drivers classes Supply a copy of PostgreSQL JDBC drivers jar into the <TOMCAT_HOME>/lib directory of the Tomcat hosting Dirigible. On this stage : The PostgreSQL JDBC driver classes can be loaded by web applications, including Dirigible deployment on this Tomcat instance. Step 2: Bind a Data Source to JNDI This is a web container and JDBC driver specific step. Modify <TOMCAT_HOME>/conf/context.xml to add a Resource tag: <Context> \u2026 <Resource name= \"jdbc/PostgreSQL\" auth= \"Container\" type= \"javax.sql.DataSource\" driverClassName= \"org.postgresql.Driver\" url= \"jdbc:postgresql://127.0.0.1:5432/<DB_NAME_HERE>\" username= \"<YOUR_USER_HERE>\" password= \"<YOUR_PASSWORD_HERE>\" /> \u2026 </Context> Note : Remember to change the placeholders in this example with actual values. must be changed to a valid database in your PostgreSQL instance at this URL. and are respectively the user name and password for a valid user of the database. Consult with the Postgre JDBC driver documentation for further details including on setting up for Tomcat . Tomcat\u2019s documentation also has a dedicated section on setting up a JDNI javax.sql.DataSource with PostgreSQL. On this stage : We have setup a JNDI javax.sql.DataSource instance named jdbc/PostgreSQL that can be looked up and is fully capable of producing connections to a PostgreSQL database as defined by its parameters. Step 3: Configure an application reference to the JNDI-bound Data Source resource There are two approaches at this goal serving different use cases. One of the use cases is when Dirigible\u2019s runtime environment is not managed. In that case, the required configuration details are entered in Dirigible\u2019s web.xml and this is the case that we shall review in more detail here. The other case is when the runtime environment is managed for e.g. automatic system provisioning. In that case the required configuration can be provided with environment variables (and of course this approach can be used also for unmanaged environments). We shall dedicate a blog on this in future. Locate Dirigible\u2019s web.xml descriptor file and open it for edit. In web.xml, locate the section with the tag <servlet id=\"bridge\"> and scroll down to its set of init-param tags. Add the following block: <init-param> <param-name> jndiCustomDataSource-postgre </param-name> <param-value> java:comp/env/jdbc/PostgreSQL </param-value> </init-param> Make sure to use the prefix \u201cjndiCustomDataSource-\u201c in param-name exactly as is, case sensitive. The suffix postgre will be used as identity for this resource in the next step. Notice, the construction of the string in the param-value. The pattern is to add the prefix java:comp/env to the name of the JNDI javax.sql.DataSource resource we defined in the previous step in context.xml . In our case this is the string jdbc/PostgreSQL . On this stage : We have setup Dirigible to lookup a named javax.sql.DataSource from JDNI and make it available to its features. Step 4: Register the Data Source in Dirigible injected API Note : Before proceeding, make sure that Tomcat is restarted if it was online when previous steps were accomplished, or start it now if it was offline. Open Dirigible IDE and select Window > Preferences from its menu: In the dialog that pops up, locate Data Sources in the list on the left, and then click the button New\u2026 Fill in the pop up as suggested by the screenshot below: Finally, confirm all dialogs. On this stage : The PostgreSQL javax.sql.DataSource is available for the Dirigible Injected API and Database tools. Verify results It is time to reap what we sow now. We shall now step in the shoes of an Operator or a Developer and use Dirigible\u2019s Database perspective tools with our new data source. Click to expand the dropdown in the Database Browser view and voil\u00e0, we\u2019ve got a brand new additional data source called postgre : Let\u2019s explore it like we do with the default one. Drill down its contents and select the table information_schema.sql_languages . Right-click on it and choose Open Definition from the context menu: Find the result in Table Details : Now right-click on the table again and select Show Content from the context menu. Find the result in SQL Console : Now, let\u2019s try how we can benefit from the new data source programmatically. Follow the implementation steps described in this dirigible sample to create a scripting service that uses the InjectedAPI to get a reference to our custom data source and print some results. Use the following source for the service: /* globals $ */ /* eslint-env node, dirigible */ $ . getResponse (). setContentType ( \"text/html; charset=UTF-8\" ); $ . getResponse (). setCharacterEncoding ( \"UTF-8\" ); var ds = $ . getNamedDatasources (). get ( \"postgre\" ); var conn = ds . getConnection (); try { var stmt = conn . createStatement (); var rs = stmt . executeQuery ( \"select * from \\\"information_schema\\\".\\\"sql_languages\\\"\" ); $ . getResponse (). getWriter (). println ( 'SQL language variants<br>' ); while ( rs . next ()) { $ . getResponse (). getWriter (). println ( rs . getString ( 1 ) + '-' + rs . getString ( 2 ) + '<br>' ); } } finally { conn . close (); } $ . getResponse (). getWriter (). flush (); $ . getResponse (). getWriter (). close (); The printed results look like that: What is next? Now that you know how to quickly onboard a data source for a database supported by Dirigible out-of-the-box, you might want learn how to approach the rest that are available out there. That is the topic of the next blog in the series.","title":"BYODS (Bring Your Own Data Source) in Dirigible - Part I: Custom Data Sources setup"},{"location":"2016/01/07/blogs-dirigible-custom-ds-1/#part-i-custom-data-sources-setup","text":"A zero-to-hero, complete setup of a new Data Source in Dirigible consists of the following simple steps: Provision JDBC driver and Data Source classes to the runtime Bind a configured Data Source to JNDI Configure a reference to the JNDI-bound Data Source resource in Dirigible Register the Data Source with Dirigible IDE to make it available to its features This is the short story. Let us follow this process in details step-by-step and in more detail. Our setup will be a Dirigible web application deployed in a Tomcat web container and a PostgreSQL data source that will be provisioned along with the default Derby data source.","title":"Part I: Custom Data Sources setup"},{"location":"2016/01/07/blogs-dirigible-custom-ds-1/#step-1-provision-jdbc-drivers-classes","text":"Supply a copy of PostgreSQL JDBC drivers jar into the <TOMCAT_HOME>/lib directory of the Tomcat hosting Dirigible. On this stage : The PostgreSQL JDBC driver classes can be loaded by web applications, including Dirigible deployment on this Tomcat instance.","title":"Step 1: Provision JDBC drivers classes"},{"location":"2016/01/07/blogs-dirigible-custom-ds-1/#step-2-bind-a-data-source-to-jndi","text":"This is a web container and JDBC driver specific step. Modify <TOMCAT_HOME>/conf/context.xml to add a Resource tag: <Context> \u2026 <Resource name= \"jdbc/PostgreSQL\" auth= \"Container\" type= \"javax.sql.DataSource\" driverClassName= \"org.postgresql.Driver\" url= \"jdbc:postgresql://127.0.0.1:5432/<DB_NAME_HERE>\" username= \"<YOUR_USER_HERE>\" password= \"<YOUR_PASSWORD_HERE>\" /> \u2026 </Context> Note : Remember to change the placeholders in this example with actual values. must be changed to a valid database in your PostgreSQL instance at this URL. and are respectively the user name and password for a valid user of the database. Consult with the Postgre JDBC driver documentation for further details including on setting up for Tomcat . Tomcat\u2019s documentation also has a dedicated section on setting up a JDNI javax.sql.DataSource with PostgreSQL. On this stage : We have setup a JNDI javax.sql.DataSource instance named jdbc/PostgreSQL that can be looked up and is fully capable of producing connections to a PostgreSQL database as defined by its parameters.","title":"Step 2: Bind a Data Source to JNDI"},{"location":"2016/01/07/blogs-dirigible-custom-ds-1/#step-3-configure-an-application-reference-to-the-jndi-bound-data-source-resource","text":"There are two approaches at this goal serving different use cases. One of the use cases is when Dirigible\u2019s runtime environment is not managed. In that case, the required configuration details are entered in Dirigible\u2019s web.xml and this is the case that we shall review in more detail here. The other case is when the runtime environment is managed for e.g. automatic system provisioning. In that case the required configuration can be provided with environment variables (and of course this approach can be used also for unmanaged environments). We shall dedicate a blog on this in future. Locate Dirigible\u2019s web.xml descriptor file and open it for edit. In web.xml, locate the section with the tag <servlet id=\"bridge\"> and scroll down to its set of init-param tags. Add the following block: <init-param> <param-name> jndiCustomDataSource-postgre </param-name> <param-value> java:comp/env/jdbc/PostgreSQL </param-value> </init-param> Make sure to use the prefix \u201cjndiCustomDataSource-\u201c in param-name exactly as is, case sensitive. The suffix postgre will be used as identity for this resource in the next step. Notice, the construction of the string in the param-value. The pattern is to add the prefix java:comp/env to the name of the JNDI javax.sql.DataSource resource we defined in the previous step in context.xml . In our case this is the string jdbc/PostgreSQL . On this stage : We have setup Dirigible to lookup a named javax.sql.DataSource from JDNI and make it available to its features.","title":"Step 3: Configure an application reference to the JNDI-bound Data Source resource"},{"location":"2016/01/07/blogs-dirigible-custom-ds-1/#step-4-register-the-data-source-in-dirigible-injected-api","text":"Note : Before proceeding, make sure that Tomcat is restarted if it was online when previous steps were accomplished, or start it now if it was offline. Open Dirigible IDE and select Window > Preferences from its menu: In the dialog that pops up, locate Data Sources in the list on the left, and then click the button New\u2026 Fill in the pop up as suggested by the screenshot below: Finally, confirm all dialogs. On this stage : The PostgreSQL javax.sql.DataSource is available for the Dirigible Injected API and Database tools.","title":"Step 4: Register the Data Source in Dirigible injected API"},{"location":"2016/01/07/blogs-dirigible-custom-ds-1/#verify-results","text":"It is time to reap what we sow now. We shall now step in the shoes of an Operator or a Developer and use Dirigible\u2019s Database perspective tools with our new data source. Click to expand the dropdown in the Database Browser view and voil\u00e0, we\u2019ve got a brand new additional data source called postgre : Let\u2019s explore it like we do with the default one. Drill down its contents and select the table information_schema.sql_languages . Right-click on it and choose Open Definition from the context menu: Find the result in Table Details : Now right-click on the table again and select Show Content from the context menu. Find the result in SQL Console : Now, let\u2019s try how we can benefit from the new data source programmatically. Follow the implementation steps described in this dirigible sample to create a scripting service that uses the InjectedAPI to get a reference to our custom data source and print some results. Use the following source for the service: /* globals $ */ /* eslint-env node, dirigible */ $ . getResponse (). setContentType ( \"text/html; charset=UTF-8\" ); $ . getResponse (). setCharacterEncoding ( \"UTF-8\" ); var ds = $ . getNamedDatasources (). get ( \"postgre\" ); var conn = ds . getConnection (); try { var stmt = conn . createStatement (); var rs = stmt . executeQuery ( \"select * from \\\"information_schema\\\".\\\"sql_languages\\\"\" ); $ . getResponse (). getWriter (). println ( 'SQL language variants<br>' ); while ( rs . next ()) { $ . getResponse (). getWriter (). println ( rs . getString ( 1 ) + '-' + rs . getString ( 2 ) + '<br>' ); } } finally { conn . close (); } $ . getResponse (). getWriter (). flush (); $ . getResponse (). getWriter (). close (); The printed results look like that:","title":"Verify results"},{"location":"2016/01/07/blogs-dirigible-custom-ds-1/#what-is-next","text":"Now that you know how to quickly onboard a data source for a database supported by Dirigible out-of-the-box, you might want learn how to approach the rest that are available out there. That is the topic of the next blog in the series.","title":"What is next?"},{"location":"2016/01/11/blogs-dirigible-custom-ds-2/","text":"Dirigible supports multiple database products by means of dialect adapters that can be used to extend the support to new ones In the previous Part I of our series, dedicated to the new multiple custom data sources feature, we introduced you to the routines required to setup a new custom data source representing one of the database brands that Dirigible supports out-of-the-box, and use it. In this Part II of the series we are going to explore what it takes to onboard a new, not yet supported database and make use of data sources configured for it, as discussed in Part I . One of the setup steps requires a minimal development and integration effort and in this Part II, we explore in details this particular task that is necessary to accomplish the integration of a new data source kind in Dirigible. It is a one-time job per database product that can then be reused for any concrete instance. Part II: Extending supported databases for custom data sources The relational database world enjoy the standard query language SQL for ages. However, database systems are often not entirely compliant with the standard. For example, it happens that they implement subset or extensions of it and ultimately end up with variants of SQL. We call these variants database (SQL) dialects . An optimal and correct use of a database requires to take this into account. This is why Dirigible and alike tools need to \u2018know\u2019 dialects to be able to truly support the corresponding database. And since the list of databases and applicable dialects out there is quite big, and it grows, it is reasonable to support some sensible, popular minimum of these and provide a mechanism to extend the support. The databases that are currently supported in Dirigible (in version 2.2 M3) are MySQL, PostgreSQL, Derby, SAPDB, SAP HANA DB, Sybase and MongoDB. Dirigible speaks their dialects already and you can create custom data sources configured for running instances of these databases as discussed in Part I . Let us now explore what is how to extend this list to support also H2 database and be able to create custom data sources for it too. Hitting the wall Let us first try to employ the routine from Part I with H2 and see what happens. Step 1: Provision the drivers Supply a copy of the database JDBC drivers in Tomcat\u2019s lib directory. H2 JDBC drivers are bundled together with the DB code so this means the database jar needs to be put there. Step 2: Bind to JNDI Edit Tomcat\u2019s conf/context.xml to add a resource: <Resource name= \"jdbc/H2\" auth= \"Container\" type= \"javax.sql.DataSource\" username= \"sa\" password= \"\" driverClassName= \"org.h2.Driver\" url= \"jdbc:h2:mem: \" /> Step 3: Configure application reference Add the following init parameter to the bridge servlet in the web.xml <init-param> <param-name> jndiCustomDataSource-h2 </param-name> <param-value> java:comp/env/jdbc/H2 </param-value> </init-param> Step 4: Register the data source Verify results Let\u2019s go now and check our H2 database in the Database perspective in Dirigible\u2019s IDE. Ooops: What happened? Yep! Dirigible clearly doesn\u2019t speak H2 dialect. Let\u2019s see what we can do to teach it. A new dialect onboard We need to accomplish the following steps in order to achieve our goal: Provide a class implementing the IDialectSpecifier interface Include the class in an OSGi bundle Declare an OSGi Service in XML descriptor with the new class and the IDialectSpecifier interface Register the XML descriptor in its container bundle MANIFEST.MF Except for the first task that is purely development and requires mostly domain knowledge for Dirigible APIs and H2 database, the rest of the tasks are a standard wiring mechanism and component model in OSGi. Let\u2019s focus on each part now. Implementation Technologies such as Dirigible delegate to concrete dialects the handling of database-specific statements and the interface IDialectSpecifier defines this contract. In addition, the interface also specifies some more generic characteristics of a database product kind, such as if it is a schemaless database or not (Yes, we look at you NoSQL! But more on that in a future blog). To make things easier and reduce redundant code to the minimum, Dirigible provides an out-of-the-box, convenience, common implementation for relational databases called RDBGenericDialectSpecifier . An absolutely minimal implementation of a dialect is the following public class H2DBSpecifier extends RDBGenericDialectSpecifier { private static final String PRODUCT_NAME = \"H2\" ; @Override public boolean isDialectForName ( String productName ) { return PRODUCT_NAME . equalsIgnoreCase ( productName ); } } It doesn\u2019t do much but is just enough to get us going. We will leave it as it is for now and proceed with some plumbing. Later, we shall come back to the class for a more elaborate insight and implementation. Bundling What we need to achieve on this stage is to declare a new OSGi (declarative) service so that Dirigible can find and use it. Each out-of-the-box dialect is declared as a service component, with its service interface ( IDialectSpecifier ) physically residing in its own bundle (org.eclipse.dirigible.repository.datasource), and an implementation class in another (org.eclipse.dirigible.repository.datasource.dialects). Detaching the interface and its implementations allows seamless, dynamic discovery of available dialects at runtime without disruption when new dialects are onboarded. Let\u2019s get down to it. First, we need to declare our service component in a XML descriptor file. Normally, such XMLs reside in an OSGI-INF directory. For example, OSGI-INF/h2-dialect.xml: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <scr:component xmlns:scr= \"http://www.osgi.org/xmlns/scr/v1.1.0\" immediate= \"true\" name= \"H2Dialect\" > <service> <provide interface= \"org.eclipse.dirigible.repository.datasource.db.dialect.IDialectSpecifier\" /> </service> <implementation class= \"org.eclipse.dirigible.repository.datasource.db.dialect.H2DBSpecifier\" /> </scr:component> Here the important variables are the component name and the implementation class. See, the OSGI-INF directory in org.eclipse.dirigible.repository.datasource.dialects for other examples. Next, we need to register the new service component in its bundle MANIFETS.MF in a Service-Component header. Another option that comes in handy is to use a pattern instead (e.g. Service-Component: OSGi-INF/*.xml). See for example the MANIFEST.MF in the bundle with the out-of-the-box dialects. And that\u2019s all folks! If you follow this routine, rebuild Dirigible with a bundle that contains your correctly registered dialect and deploy it, you will be able to happily explore the H2 database: Dissecting IDialectSpecifier Now, as promised, let\u2019s get back to the main interface for dialects. Its methods can be grouped according to their purpose. We shall review the more important of each one here. SQL statement construction callbacks There are a number of methods that are invoked during the construction of statements (queries and updates) by the Dirigible database related tools: String specify(String sql); String createLimitAndOffset(int limit, int offset); String createTopAndStart(int limit, int offset); String getAlterAddOpen(); String getAlterAddOpenEach(); String getAlterAddClose(); String getAlterAddCloseEach(); The specify method is concerned with transforming SQL statements into dialect-specific strings, by replacing a set of predefined variables from the input string with database-specific values. The variables are defined as constants in IDIalectSpecifier : public static final String DIALECT_TIMESTAMP = \"$TIMESTAMP$\"; public static final String DIALECT_BLOB = \"$BLOB$\"; public static final String DIALECT_CLOB = \"$CLOB$\"; public static final String DIALECT_CURRENT_TIMESTAMP = \"$CURRENT_TIMESTAMP$\"; public static final String DIALECT_KEY_VARCHAR = \"$KEY_VARCHAR$\"; public static final String DIALECT_BIG_VARCHAR = \"$BIG_VARCHAR$\"; The createLimitAndOffset and createTopAndStart methods are concerned with two alternative SQL syntax constructs that \"page\" results (return a subset form specified cursor position) The set of getAlter* methods are handling the ALTER <table-name> TABLE ADD construct in dialect specific manner. There are actually two pairs of methods, each pair concerned with a variant of handling the column ADD syntax. In each pair there is a method handling the opening part of the construction and there is one for the closing part. ResultSet iteration callbacks The following methods are used by Dirigible while iterating a query ResultSet: InputStream getBinaryStream(ResultSet resultSet, String columnName) throws SQLException; Common data type model translation String getSpecificType(String commonType); The getSpecificType method is responsible to translate between the common types used in Dirigible and database-specific ones. Query templates Dirigible tools such as the SQLConsole and the Database browser collaborate with the action Show Content to set a generic query, listing the contents a table and execute it. It is the following method that is invoked to provision that generic query: String getContentQueryScript(String catalogName, String schemaName, String tableName); Another one is concerned with provisioning a query that will perform database specific filtering of schemas and show only the applicable for Dirigible: String getSchemaFilterScript(); Database Metadata There are also methods concerned with the general description of the data base: boolean isSchemaFilterSupported(); boolean isCatalogForSchema(); boolean isSchemaless(); isDialectForName(productName); These methods are mostly used to decide on the composition of UI or process. For example, isSchemaless is used to determine whether the Open Definition action in the Database Browser context menu for tables is presented to end user or not. Obviously, it doesn\u2019t make a lot of sense for schemaless databases, at least not with the current view that deals with it. Similarly isSchemaFilterSupported is used by the Database Browser to invoke upon availability the getSchemaFilter method (discussed in previsous section) and reduce the schemas exhibited in the view to the applicable ones. And isCatalogForSchema instructs the UI how to handle database layouts of database products that have specific, non-standard handling of catalogs and schemas. But above all it's worth mentioning here the isDialectForName method. As you probably noted, this was the only one that was part of the minimal implementation of a dialect. What it does essentially is to assess the dialect where it is declared is applicable for the database product name supplied as argument for the productName parameter of the method. The value of the productName parameter is the string supplied by JDBC drivers implementation of DatabaseMetaData#getDatabaseProductName API. Dirigible uses this to determine, which of the available service implementations of IDialectSpecifier is applicable for a given database. Wrapping up Summing up what we already know about the IDialectSpecifier interface, here is a slightly more elaborated variant of the minimal dialect implementation that we started with: public class H2DBSpecifier extends RDBGenericDialectSpecifier { private static final String PRODUCT_NAME = \"H2\" ; private static final String H2_TIMESTAMP = \"TIMESTAMP\" ; private static final String H2_CLOB = \"CLOB\" ; private static final String H2_BLOB = \"BLOB\" ; private static final String H2_CURRENT_TIMESTAMP = \"CURRENT_TIMESTAMP\" ; private static final String H2_BIG_VARCHAR = \"VARCHAR(1000)\" ; private static final String H2_KEY_VARCHAR = \"VARCHAR(4000)\" ; private static final String LIMIT_D_D = \"LIMIT %d OFFSET %d\" ; @Override public boolean isDialectForName ( String productName ) { return PRODUCT_NAME . equalsIgnoreCase ( productName ); } @Override public String specify ( String sql ) { if ( sql == null || sql . length () < 1 ) return sql ; return sql . replace ( DIALECT_TIMESTAMP , H2_TIMESTAMP ) . replace ( DIALECT_CLOB , H2_CLOB ) . replace ( DIALECT_BLOB , H2_BLOB ) . replace ( DIALECT_CURRENT_TIMESTAMP , H2_CURRENT_TIMESTAMP ) . replace ( DIALECT_BIG_VARCHAR , H2_BIG_VARCHAR ) . replace ( DIALECT_KEY_VARCHAR , H2_KEY_VARCHAR ); } @Override public String createLimitAndOffset ( int limit , int offset ) { return String . format ( LIMIT_D_D , offset , limit ); } @Override public String getAlterAddOpen () { return \" ADD( \" ; } @Override public String getAlterAddClose () { return \")\" ; } }","title":"BYODS (Bring Your Own Data Source) in Dirigible - Part II: Extending supported databases for custom data sources"},{"location":"2016/01/11/blogs-dirigible-custom-ds-2/#part-ii-extending-supported-databases-for-custom-data-sources","text":"The relational database world enjoy the standard query language SQL for ages. However, database systems are often not entirely compliant with the standard. For example, it happens that they implement subset or extensions of it and ultimately end up with variants of SQL. We call these variants database (SQL) dialects . An optimal and correct use of a database requires to take this into account. This is why Dirigible and alike tools need to \u2018know\u2019 dialects to be able to truly support the corresponding database. And since the list of databases and applicable dialects out there is quite big, and it grows, it is reasonable to support some sensible, popular minimum of these and provide a mechanism to extend the support. The databases that are currently supported in Dirigible (in version 2.2 M3) are MySQL, PostgreSQL, Derby, SAPDB, SAP HANA DB, Sybase and MongoDB. Dirigible speaks their dialects already and you can create custom data sources configured for running instances of these databases as discussed in Part I . Let us now explore what is how to extend this list to support also H2 database and be able to create custom data sources for it too.","title":"Part II: Extending supported databases for custom data sources"},{"location":"2016/01/11/blogs-dirigible-custom-ds-2/#hitting-the-wall","text":"Let us first try to employ the routine from Part I with H2 and see what happens.","title":"Hitting the wall"},{"location":"2016/01/11/blogs-dirigible-custom-ds-2/#step-1-provision-the-drivers","text":"Supply a copy of the database JDBC drivers in Tomcat\u2019s lib directory. H2 JDBC drivers are bundled together with the DB code so this means the database jar needs to be put there.","title":"Step 1: Provision the drivers"},{"location":"2016/01/11/blogs-dirigible-custom-ds-2/#step-2-bind-to-jndi","text":"Edit Tomcat\u2019s conf/context.xml to add a resource: <Resource name= \"jdbc/H2\" auth= \"Container\" type= \"javax.sql.DataSource\" username= \"sa\" password= \"\" driverClassName= \"org.h2.Driver\" url= \"jdbc:h2:mem: \" />","title":"Step 2: Bind to JNDI"},{"location":"2016/01/11/blogs-dirigible-custom-ds-2/#step-3-configure-application-reference","text":"Add the following init parameter to the bridge servlet in the web.xml <init-param> <param-name> jndiCustomDataSource-h2 </param-name> <param-value> java:comp/env/jdbc/H2 </param-value> </init-param>","title":"Step 3: Configure application reference"},{"location":"2016/01/11/blogs-dirigible-custom-ds-2/#step-4-register-the-data-source","text":"","title":"Step 4: Register the data source"},{"location":"2016/01/11/blogs-dirigible-custom-ds-2/#verify-results","text":"Let\u2019s go now and check our H2 database in the Database perspective in Dirigible\u2019s IDE. Ooops: What happened? Yep! Dirigible clearly doesn\u2019t speak H2 dialect. Let\u2019s see what we can do to teach it.","title":"Verify results"},{"location":"2016/01/11/blogs-dirigible-custom-ds-2/#a-new-dialect-onboard","text":"We need to accomplish the following steps in order to achieve our goal: Provide a class implementing the IDialectSpecifier interface Include the class in an OSGi bundle Declare an OSGi Service in XML descriptor with the new class and the IDialectSpecifier interface Register the XML descriptor in its container bundle MANIFEST.MF Except for the first task that is purely development and requires mostly domain knowledge for Dirigible APIs and H2 database, the rest of the tasks are a standard wiring mechanism and component model in OSGi. Let\u2019s focus on each part now.","title":"A new dialect onboard"},{"location":"2016/01/11/blogs-dirigible-custom-ds-2/#implementation","text":"Technologies such as Dirigible delegate to concrete dialects the handling of database-specific statements and the interface IDialectSpecifier defines this contract. In addition, the interface also specifies some more generic characteristics of a database product kind, such as if it is a schemaless database or not (Yes, we look at you NoSQL! But more on that in a future blog). To make things easier and reduce redundant code to the minimum, Dirigible provides an out-of-the-box, convenience, common implementation for relational databases called RDBGenericDialectSpecifier . An absolutely minimal implementation of a dialect is the following public class H2DBSpecifier extends RDBGenericDialectSpecifier { private static final String PRODUCT_NAME = \"H2\" ; @Override public boolean isDialectForName ( String productName ) { return PRODUCT_NAME . equalsIgnoreCase ( productName ); } } It doesn\u2019t do much but is just enough to get us going. We will leave it as it is for now and proceed with some plumbing. Later, we shall come back to the class for a more elaborate insight and implementation.","title":"Implementation"},{"location":"2016/01/11/blogs-dirigible-custom-ds-2/#bundling","text":"What we need to achieve on this stage is to declare a new OSGi (declarative) service so that Dirigible can find and use it. Each out-of-the-box dialect is declared as a service component, with its service interface ( IDialectSpecifier ) physically residing in its own bundle (org.eclipse.dirigible.repository.datasource), and an implementation class in another (org.eclipse.dirigible.repository.datasource.dialects). Detaching the interface and its implementations allows seamless, dynamic discovery of available dialects at runtime without disruption when new dialects are onboarded. Let\u2019s get down to it. First, we need to declare our service component in a XML descriptor file. Normally, such XMLs reside in an OSGI-INF directory. For example, OSGI-INF/h2-dialect.xml: <?xml version=\"1.0\" encoding=\"UTF-8\"?> <scr:component xmlns:scr= \"http://www.osgi.org/xmlns/scr/v1.1.0\" immediate= \"true\" name= \"H2Dialect\" > <service> <provide interface= \"org.eclipse.dirigible.repository.datasource.db.dialect.IDialectSpecifier\" /> </service> <implementation class= \"org.eclipse.dirigible.repository.datasource.db.dialect.H2DBSpecifier\" /> </scr:component> Here the important variables are the component name and the implementation class. See, the OSGI-INF directory in org.eclipse.dirigible.repository.datasource.dialects for other examples. Next, we need to register the new service component in its bundle MANIFETS.MF in a Service-Component header. Another option that comes in handy is to use a pattern instead (e.g. Service-Component: OSGi-INF/*.xml). See for example the MANIFEST.MF in the bundle with the out-of-the-box dialects. And that\u2019s all folks! If you follow this routine, rebuild Dirigible with a bundle that contains your correctly registered dialect and deploy it, you will be able to happily explore the H2 database:","title":"Bundling"},{"location":"2016/01/11/blogs-dirigible-custom-ds-2/#dissecting-idialectspecifier","text":"Now, as promised, let\u2019s get back to the main interface for dialects. Its methods can be grouped according to their purpose. We shall review the more important of each one here.","title":"Dissecting IDialectSpecifier"},{"location":"2016/01/11/blogs-dirigible-custom-ds-2/#sql-statement-construction-callbacks","text":"There are a number of methods that are invoked during the construction of statements (queries and updates) by the Dirigible database related tools: String specify(String sql); String createLimitAndOffset(int limit, int offset); String createTopAndStart(int limit, int offset); String getAlterAddOpen(); String getAlterAddOpenEach(); String getAlterAddClose(); String getAlterAddCloseEach(); The specify method is concerned with transforming SQL statements into dialect-specific strings, by replacing a set of predefined variables from the input string with database-specific values. The variables are defined as constants in IDIalectSpecifier : public static final String DIALECT_TIMESTAMP = \"$TIMESTAMP$\"; public static final String DIALECT_BLOB = \"$BLOB$\"; public static final String DIALECT_CLOB = \"$CLOB$\"; public static final String DIALECT_CURRENT_TIMESTAMP = \"$CURRENT_TIMESTAMP$\"; public static final String DIALECT_KEY_VARCHAR = \"$KEY_VARCHAR$\"; public static final String DIALECT_BIG_VARCHAR = \"$BIG_VARCHAR$\"; The createLimitAndOffset and createTopAndStart methods are concerned with two alternative SQL syntax constructs that \"page\" results (return a subset form specified cursor position) The set of getAlter* methods are handling the ALTER <table-name> TABLE ADD construct in dialect specific manner. There are actually two pairs of methods, each pair concerned with a variant of handling the column ADD syntax. In each pair there is a method handling the opening part of the construction and there is one for the closing part.","title":"SQL statement construction callbacks"},{"location":"2016/01/11/blogs-dirigible-custom-ds-2/#resultset-iteration-callbacks","text":"The following methods are used by Dirigible while iterating a query ResultSet: InputStream getBinaryStream(ResultSet resultSet, String columnName) throws SQLException;","title":"ResultSet iteration callbacks"},{"location":"2016/01/11/blogs-dirigible-custom-ds-2/#common-data-type-model-translation","text":"String getSpecificType(String commonType); The getSpecificType method is responsible to translate between the common types used in Dirigible and database-specific ones.","title":"Common data type model translation"},{"location":"2016/01/11/blogs-dirigible-custom-ds-2/#query-templates","text":"Dirigible tools such as the SQLConsole and the Database browser collaborate with the action Show Content to set a generic query, listing the contents a table and execute it. It is the following method that is invoked to provision that generic query: String getContentQueryScript(String catalogName, String schemaName, String tableName); Another one is concerned with provisioning a query that will perform database specific filtering of schemas and show only the applicable for Dirigible: String getSchemaFilterScript();","title":"Query templates"},{"location":"2016/01/11/blogs-dirigible-custom-ds-2/#database-metadata","text":"There are also methods concerned with the general description of the data base: boolean isSchemaFilterSupported(); boolean isCatalogForSchema(); boolean isSchemaless(); isDialectForName(productName); These methods are mostly used to decide on the composition of UI or process. For example, isSchemaless is used to determine whether the Open Definition action in the Database Browser context menu for tables is presented to end user or not. Obviously, it doesn\u2019t make a lot of sense for schemaless databases, at least not with the current view that deals with it. Similarly isSchemaFilterSupported is used by the Database Browser to invoke upon availability the getSchemaFilter method (discussed in previsous section) and reduce the schemas exhibited in the view to the applicable ones. And isCatalogForSchema instructs the UI how to handle database layouts of database products that have specific, non-standard handling of catalogs and schemas. But above all it's worth mentioning here the isDialectForName method. As you probably noted, this was the only one that was part of the minimal implementation of a dialect. What it does essentially is to assess the dialect where it is declared is applicable for the database product name supplied as argument for the productName parameter of the method. The value of the productName parameter is the string supplied by JDBC drivers implementation of DatabaseMetaData#getDatabaseProductName API. Dirigible uses this to determine, which of the available service implementations of IDialectSpecifier is applicable for a given database.","title":"Database Metadata"},{"location":"2016/01/11/blogs-dirigible-custom-ds-2/#wrapping-up","text":"Summing up what we already know about the IDialectSpecifier interface, here is a slightly more elaborated variant of the minimal dialect implementation that we started with: public class H2DBSpecifier extends RDBGenericDialectSpecifier { private static final String PRODUCT_NAME = \"H2\" ; private static final String H2_TIMESTAMP = \"TIMESTAMP\" ; private static final String H2_CLOB = \"CLOB\" ; private static final String H2_BLOB = \"BLOB\" ; private static final String H2_CURRENT_TIMESTAMP = \"CURRENT_TIMESTAMP\" ; private static final String H2_BIG_VARCHAR = \"VARCHAR(1000)\" ; private static final String H2_KEY_VARCHAR = \"VARCHAR(4000)\" ; private static final String LIMIT_D_D = \"LIMIT %d OFFSET %d\" ; @Override public boolean isDialectForName ( String productName ) { return PRODUCT_NAME . equalsIgnoreCase ( productName ); } @Override public String specify ( String sql ) { if ( sql == null || sql . length () < 1 ) return sql ; return sql . replace ( DIALECT_TIMESTAMP , H2_TIMESTAMP ) . replace ( DIALECT_CLOB , H2_CLOB ) . replace ( DIALECT_BLOB , H2_BLOB ) . replace ( DIALECT_CURRENT_TIMESTAMP , H2_CURRENT_TIMESTAMP ) . replace ( DIALECT_BIG_VARCHAR , H2_BIG_VARCHAR ) . replace ( DIALECT_KEY_VARCHAR , H2_KEY_VARCHAR ); } @Override public String createLimitAndOffset ( int limit , int offset ) { return String . format ( LIMIT_D_D , offset , limit ); } @Override public String getAlterAddOpen () { return \" ADD( \" ; } @Override public String getAlterAddClose () { return \")\" ; } }","title":"Wrapping up"},{"location":"2016/01/19/news-new-milestone-2-2-3/","text":"New Milestone 2.2.160119-M3 released. Features Adaptation of UI templates to use the widget types meta-data - date, integer and float Custom templates feature in generation wizards Java services isolation by root package Datasources dialiects optimization Bugfixes and refactoring... Blogs How to install Dirigible on SAP HANA Cloud Platform tutorial Groovy is back developer tutorial BYODS (Bring Your Own Data Source) in Dirigible I developer tutorial BYODS (Bring Your Own Data Source) in Dirigible II developer tutorial Operational The full list of bug-fixes and enhancements can be found here . The source code is available at GitHub repository here . The instant trial is updated accordingly with the released version here . Enjoy!","title":"Milestone 2.2.160119-M3"},{"location":"2016/01/19/news-new-milestone-2-2-3/#features","text":"Adaptation of UI templates to use the widget types meta-data - date, integer and float Custom templates feature in generation wizards Java services isolation by root package Datasources dialiects optimization Bugfixes and refactoring...","title":"Features"},{"location":"2016/01/19/news-new-milestone-2-2-3/#blogs","text":"How to install Dirigible on SAP HANA Cloud Platform tutorial Groovy is back developer tutorial BYODS (Bring Your Own Data Source) in Dirigible I developer tutorial BYODS (Bring Your Own Data Source) in Dirigible II developer tutorial","title":"Blogs"},{"location":"2016/01/19/news-new-milestone-2-2-3/#operational","text":"The full list of bug-fixes and enhancements can be found here . The source code is available at GitHub repository here . The instant trial is updated accordingly with the released version here .","title":"Operational"},{"location":"2016/01/19/news-new-milestone-2-2-3/#enjoy","text":"","title":"Enjoy!"},{"location":"2016/01/21/blogs-dirigible-custom-ds-3/","text":"Dirigible welcomes Mongo DB onboard! Starting with version 2.2 Mongo DB is supported out-of-the-box In previous blogs in the \"BYODS in Dirigible\" series we explored how data sources are integrated in general with most examples focusing on relational databases as options. But what about NoSQL ? Dirigible welcomes Mongo DB onboard! Starting with version 2.2 Mongo DB is supported out-of-the-box. You can explore it in the IDE and develop scripting services for it. Taking advantage of NoSQL document storage is now an entirely viable option. This is the first stage of our roadmap for onboarding NoSQL development. It uses JDBC as standard communication protocol and API. We are well aware that it is not native to NoSql development and is rather a \u201cquick way in\u201d. On next stage, we plan to explore the options to provision Apache TinkerPop as a well-recognized standard Graph API (to which Mongo DB also complies) to scripting services via the Injected API . We shall seek also for convenient ways to provide access to native Graph APIs of NoSql data stores with all pros and cons that go along with that. But first things first. We shall now explore what we\u2019ve got for Mongo DB developers in Dirigible 2.2. Part III: MongoDB custom data source What\u2019s in the box? With a Mongo DB custom data source integrated in Dirigible Database tools, you can explore the related database instance list of collections and examine collection documents: <img src=\"/img/posts/20160121-0/3-0.png\"/> As with any other relational data source, you can also execute queries and updates but hence, using Mongo\u2019s native BSON-based query language: <img src=\"/img/posts/20160121-0/3-1.png\"/> It is integrated also into the InjectedAPI and therefore in your scripting service you can request the data source by its name, get a connection and execute a statement using Mongo\u2019s native query language, and iterate the result set (here, using the JDBC API. Read below for more options): var ds = $ . getNamedDatasources (). get ( \u2018 mongodb \u2019 ); var conn = ds . getConnection (); try { var stmt = conn . createStatement (); var rs = stmt . executeQuery ( \u2018 { \u201c find \u201d : \u201d testCollection \u201d } \u2019 ); while ( rs . next ()) { $ . getResponse (). getWriter (). println ( rs . getString ( 1 ) + ':' + rs . getString ( \u201c name \u201d ) + '<br>' ); } } finally { conn . close (); } Key design notes Onboarding a Mongo DB data source leverages exactly the same integration mechanism in Dirigible as any other (relational) data source. This feature has been discussed in detail in the previous BYODS blog series. The obvious advantage of this approach is that it follows an established path. That simplicity comes at the cost of a few reasonable prerequisites listed below. JDBC API JDBC is the standard API used by Dirigible internally to integrate data sources and by developers to use them. Therefore, you will need a JDBC compliant driver to provision access to a Mongo database. Its role is to reconcile the conceptual differences between the relational model centric JDBC API and the NoSQL document store world. In Mongo, despite the name \u201c Java driver \u201d that you will find on Mongo DB\u2019s site concerning Java clients, this has nothing to do with JDBC drivers. It is a Java client API. If you look around for available JDBC drivers for Mongo DB, they are not exactly abundant either. What\u2019s more troublesome here is that virtually all available drivers actually try to translate between Mongo DB\u2019s native query language and SQL. While this works perfectly well for us in terms of technical integration, it does not comply with our goal to make Mongo DB\u2019s developers feel at home in Dirigible, because it would be fairly weird for them to write SQL to query a document database. To fill this gap and for the sake of this example we\u2019ve prototyped a driver that can send native queries encoded as BSON to Mongo DB. It is available on Github . The fine print? Once again, this driver is a prototype and as of the time of this writing there\u2019s still nothing comparable (Meaning happily abusing the JDBC API as a standard protocol for Mongo DB but reusing its own query language). Show some love for it and we will further enhance it. The rest of the drivers out there translate to/from SQL, which will work for the InjectedAPI if you are happy with this approach, but not with the Dirigible database tools in the IDE\u2019s Database perspective. Query language In order to execute query or update statements from Dirigible, your back-end needs to be able to interpret a formal language that can be encoded in strings because that\u2019s the input it will get. There are options here, but it would be best to re-use a query language if your database already has one. Developers who are already used to it will feel at home and make the best use of the database capabilities. Other options, but less desirable for the same reasons, are to translate to and from SQL or other suitable language. MongoDB has a concept of query language. Queries are BSON encoded documents that are input to the operation find . Our JDBC driver takes documents in that format as string input to its query operations in the JDBC API, converts internally to BSON documents and invokes the operation find on the Mongo DB Java client. The JDBC query operations string input therefore needs to be compliant with Mongo's find operation input parameter specification . Result sets Results are returned as JDBC ResultSet , i.e. in a table form. The driver of choice should be capable of transforming internally to this form of results presentation from Mongo's documents format. Row data. Here is the nice part. The Mongo DB JDBC driver we introduced above is capable of a nice trick that can limit greatly your relation to JDBC and keep you more in the real Mongo world. While iterating the result set, and quite frankly slightly abusing the API for java.sql.ResultSet#getObject(int) method, if you pass -100 as argument, you will get the native Mongo document for the current iteration, the result of the MongoCursor #next() method. Standard? No. Convenient? Yes. Of course, the JDBC driver still provides you with the option to stick to the JDBC API to explore a row contents if you wanted that. So you have these two options here to choose from. ResultSetMetadata. A major difference between Mongo DB and relational databases is that Mongo DB is schemaless. Although it is not encouraged, the documents that constitute the model do not necessarily follow the same scheme and their properties may vary. One consequence is that the ResultSetMetadata should be handled with care. Since it is the content that defines the schema, first it is possible to deliver some insight on the ResultSetMetadata only if there are some documents stored, and second the metadata concerning the schema change with every new document so it is completely known only at the end of the iteration of the result set and is valid only until the data changes. The get (int index) methods. Our JDBC driver makes a best effort to return stable value by index, relying on the ordering of the results as provided by Mongo DB. Note that Mongo's documentation states the following: \" Starting in version 2.6, MongoDB actively attempts to preserve the field order in a document. Before version 2.6, MongoDB did not actively preserve the order of the fields in a document. \". The bottom line is that index-based value extraction from a ResultSet row is not working for Mongo DB versions earlier than 2.6, and for 2.6 and newer, the document fields will be as reliably ordered as Mongo DB can do it. These are all important considerations when implementing and using the result sets returned by queries. Provisioning The setup of a Mongo DB data source is no different from what we already did in Part I , so here we shall cut short and focus only on the details that you need to provide. Step 1: Provision JDBC drivers classes Get the JDBC driver source from Github and use Maven to build. Copy the build result in Tomcat\u2019s lib directory. Step 2: Bind a Data Source to JNDI Edit Tomcat\u2019s conf/context.xml to add a resource: <Resource name= \"jdbc/MongoDB\" auth= \"Container\" type= \"javax.sql.DataSource\" driverClassName= \"io.dirigible.mongodb.jdbcMongodbJdbcDriver\" url= \"jdbc:mongodb://127.0.0.1:5432\" username= \"<YOUR_USER_HERE>\" password= \"<YOUR_PASSWORD_HERE>\" /> Note: Remember to change the placeholders in this example with actual values. and are respectively the user name and password for a valid user of the database. Step 3: Configure application reference Add the following init parameter to the bridge servlet in the web.xml <init-param> <param-name> jndiCustomDataSource-mongodb </param-name> <param-value> java:comp/env/jdbc/MongoDB </param-value> </init-param> Step 4: Register the data source Go to Dirigible IDE Preferences, locate Data Sources and create a new one. Fill in the following details in dialog that pops up: Id: mongodb Name: MongoDB Type: JNDI Location: java:comp/env/jdbc/MongoDB Finally, confirm all dialogs. And that\u2019s pretty much it. You should have a new data source by the name mongodb by now. Putting it to use Now that we\u2019ve got a Mongo DB data source in Dirigible, put it to some good use. /* globals $ */ /* eslint-env node, dirigible */ $ . getResponse (). setContentType ( \"text/html; charset=UTF-8\" ); $ . getResponse (). setCharacterEncoding ( \"UTF-8\" ); var out = $ . getResponse (). getWriter (); var ds = $ . getNamedDatasources (). get ( \"mongodb\" ); var conn = ds . getConnection (); try { var stmt = conn . createStatement (); var rs = stmt . executeQuery ( \u2018 { find : \"testCollection\" } \u2019 ); while ( rs . next ()) { var rsDoc = rs . getObject ( - 100 ); for ( var prop in rsDoc ){ out . println ( prop + ': ' + rsDoc [ prop ] + '<br>' ); } } } finally { conn . close (); } out . flush (); out . close (); In this code snippet we have several semantic blocks. First we open a writer to output some data from the service: $ . getResponse (). setContentType ( \"text/html; charset=UTF-8\" ); $ . getResponse (). setCharacterEncoding ( \"UTF-8\" ); var out = $ . getResponse (). getWriter (); Next, we get a connection to the Mongo DB data source that we setup on previous stage: var ds = $ . getNamedDatasources (). get ( \"mongodb\" ); var conn = ds . getConnection (); Then, we create a statement and execute it using the standard JDBC API but the native Mongo DB query language: var stmt = conn . createStatement (); var rs = stmt . executeQuery ( \u2018 { find : \"testCollection\" } \u2019 ); Now we are ready to iterate on the result set and output some results. Note how we use the standard JDBC API for iteration and the little trick that our Mongo DB JDBC driver is capable of with the rs.getObject(-100); statement. Once we get hold of the JSON document for the current iteration we use pure JavaScript and no JDBC to make some use of it: while ( rs . next ()) { var rsDoc = rs . getObject ( - 100 ); for ( var prop in rsDoc ){ out . println ( prop + ': ' + rsDoc [ prop ] + '<br>' ); } } Finally, as good citizens we close all open resource streams.","title":"BYODS (Bring Your Own Data Source) in Dirigible - Part III: MongoDB custom data source"},{"location":"2016/01/21/blogs-dirigible-custom-ds-3/#part-iii-mongodb-custom-data-source","text":"What\u2019s in the box? With a Mongo DB custom data source integrated in Dirigible Database tools, you can explore the related database instance list of collections and examine collection documents: <img src=\"/img/posts/20160121-0/3-0.png\"/> As with any other relational data source, you can also execute queries and updates but hence, using Mongo\u2019s native BSON-based query language: <img src=\"/img/posts/20160121-0/3-1.png\"/> It is integrated also into the InjectedAPI and therefore in your scripting service you can request the data source by its name, get a connection and execute a statement using Mongo\u2019s native query language, and iterate the result set (here, using the JDBC API. Read below for more options): var ds = $ . getNamedDatasources (). get ( \u2018 mongodb \u2019 ); var conn = ds . getConnection (); try { var stmt = conn . createStatement (); var rs = stmt . executeQuery ( \u2018 { \u201c find \u201d : \u201d testCollection \u201d } \u2019 ); while ( rs . next ()) { $ . getResponse (). getWriter (). println ( rs . getString ( 1 ) + ':' + rs . getString ( \u201c name \u201d ) + '<br>' ); } } finally { conn . close (); }","title":"Part III: MongoDB custom data source"},{"location":"2016/01/21/blogs-dirigible-custom-ds-3/#key-design-notes","text":"Onboarding a Mongo DB data source leverages exactly the same integration mechanism in Dirigible as any other (relational) data source. This feature has been discussed in detail in the previous BYODS blog series. The obvious advantage of this approach is that it follows an established path. That simplicity comes at the cost of a few reasonable prerequisites listed below.","title":"Key design notes"},{"location":"2016/01/21/blogs-dirigible-custom-ds-3/#jdbc-api","text":"JDBC is the standard API used by Dirigible internally to integrate data sources and by developers to use them. Therefore, you will need a JDBC compliant driver to provision access to a Mongo database. Its role is to reconcile the conceptual differences between the relational model centric JDBC API and the NoSQL document store world. In Mongo, despite the name \u201c Java driver \u201d that you will find on Mongo DB\u2019s site concerning Java clients, this has nothing to do with JDBC drivers. It is a Java client API. If you look around for available JDBC drivers for Mongo DB, they are not exactly abundant either. What\u2019s more troublesome here is that virtually all available drivers actually try to translate between Mongo DB\u2019s native query language and SQL. While this works perfectly well for us in terms of technical integration, it does not comply with our goal to make Mongo DB\u2019s developers feel at home in Dirigible, because it would be fairly weird for them to write SQL to query a document database. To fill this gap and for the sake of this example we\u2019ve prototyped a driver that can send native queries encoded as BSON to Mongo DB. It is available on Github . The fine print? Once again, this driver is a prototype and as of the time of this writing there\u2019s still nothing comparable (Meaning happily abusing the JDBC API as a standard protocol for Mongo DB but reusing its own query language). Show some love for it and we will further enhance it. The rest of the drivers out there translate to/from SQL, which will work for the InjectedAPI if you are happy with this approach, but not with the Dirigible database tools in the IDE\u2019s Database perspective.","title":"JDBC API"},{"location":"2016/01/21/blogs-dirigible-custom-ds-3/#query-language","text":"In order to execute query or update statements from Dirigible, your back-end needs to be able to interpret a formal language that can be encoded in strings because that\u2019s the input it will get. There are options here, but it would be best to re-use a query language if your database already has one. Developers who are already used to it will feel at home and make the best use of the database capabilities. Other options, but less desirable for the same reasons, are to translate to and from SQL or other suitable language. MongoDB has a concept of query language. Queries are BSON encoded documents that are input to the operation find . Our JDBC driver takes documents in that format as string input to its query operations in the JDBC API, converts internally to BSON documents and invokes the operation find on the Mongo DB Java client. The JDBC query operations string input therefore needs to be compliant with Mongo's find operation input parameter specification .","title":"Query language"},{"location":"2016/01/21/blogs-dirigible-custom-ds-3/#result-sets","text":"Results are returned as JDBC ResultSet , i.e. in a table form. The driver of choice should be capable of transforming internally to this form of results presentation from Mongo's documents format. Row data. Here is the nice part. The Mongo DB JDBC driver we introduced above is capable of a nice trick that can limit greatly your relation to JDBC and keep you more in the real Mongo world. While iterating the result set, and quite frankly slightly abusing the API for java.sql.ResultSet#getObject(int) method, if you pass -100 as argument, you will get the native Mongo document for the current iteration, the result of the MongoCursor #next() method. Standard? No. Convenient? Yes. Of course, the JDBC driver still provides you with the option to stick to the JDBC API to explore a row contents if you wanted that. So you have these two options here to choose from. ResultSetMetadata. A major difference between Mongo DB and relational databases is that Mongo DB is schemaless. Although it is not encouraged, the documents that constitute the model do not necessarily follow the same scheme and their properties may vary. One consequence is that the ResultSetMetadata should be handled with care. Since it is the content that defines the schema, first it is possible to deliver some insight on the ResultSetMetadata only if there are some documents stored, and second the metadata concerning the schema change with every new document so it is completely known only at the end of the iteration of the result set and is valid only until the data changes. The get (int index) methods. Our JDBC driver makes a best effort to return stable value by index, relying on the ordering of the results as provided by Mongo DB. Note that Mongo's documentation states the following: \" Starting in version 2.6, MongoDB actively attempts to preserve the field order in a document. Before version 2.6, MongoDB did not actively preserve the order of the fields in a document. \". The bottom line is that index-based value extraction from a ResultSet row is not working for Mongo DB versions earlier than 2.6, and for 2.6 and newer, the document fields will be as reliably ordered as Mongo DB can do it. These are all important considerations when implementing and using the result sets returned by queries.","title":"Result sets"},{"location":"2016/01/21/blogs-dirigible-custom-ds-3/#provisioning","text":"The setup of a Mongo DB data source is no different from what we already did in Part I , so here we shall cut short and focus only on the details that you need to provide.","title":"Provisioning"},{"location":"2016/01/21/blogs-dirigible-custom-ds-3/#step-1-provision-jdbc-drivers-classes","text":"Get the JDBC driver source from Github and use Maven to build. Copy the build result in Tomcat\u2019s lib directory.","title":"Step 1: Provision JDBC drivers classes"},{"location":"2016/01/21/blogs-dirigible-custom-ds-3/#step-2-bind-a-data-source-to-jndi","text":"Edit Tomcat\u2019s conf/context.xml to add a resource: <Resource name= \"jdbc/MongoDB\" auth= \"Container\" type= \"javax.sql.DataSource\" driverClassName= \"io.dirigible.mongodb.jdbcMongodbJdbcDriver\" url= \"jdbc:mongodb://127.0.0.1:5432\" username= \"<YOUR_USER_HERE>\" password= \"<YOUR_PASSWORD_HERE>\" /> Note: Remember to change the placeholders in this example with actual values. and are respectively the user name and password for a valid user of the database.","title":"Step 2: Bind a Data Source to JNDI"},{"location":"2016/01/21/blogs-dirigible-custom-ds-3/#step-3-configure-application-reference","text":"Add the following init parameter to the bridge servlet in the web.xml <init-param> <param-name> jndiCustomDataSource-mongodb </param-name> <param-value> java:comp/env/jdbc/MongoDB </param-value> </init-param>","title":"Step 3: Configure application reference"},{"location":"2016/01/21/blogs-dirigible-custom-ds-3/#step-4-register-the-data-source","text":"Go to Dirigible IDE Preferences, locate Data Sources and create a new one. Fill in the following details in dialog that pops up: Id: mongodb Name: MongoDB Type: JNDI Location: java:comp/env/jdbc/MongoDB Finally, confirm all dialogs. And that\u2019s pretty much it. You should have a new data source by the name mongodb by now.","title":"Step 4: Register the data source"},{"location":"2016/01/21/blogs-dirigible-custom-ds-3/#putting-it-to-use","text":"Now that we\u2019ve got a Mongo DB data source in Dirigible, put it to some good use. /* globals $ */ /* eslint-env node, dirigible */ $ . getResponse (). setContentType ( \"text/html; charset=UTF-8\" ); $ . getResponse (). setCharacterEncoding ( \"UTF-8\" ); var out = $ . getResponse (). getWriter (); var ds = $ . getNamedDatasources (). get ( \"mongodb\" ); var conn = ds . getConnection (); try { var stmt = conn . createStatement (); var rs = stmt . executeQuery ( \u2018 { find : \"testCollection\" } \u2019 ); while ( rs . next ()) { var rsDoc = rs . getObject ( - 100 ); for ( var prop in rsDoc ){ out . println ( prop + ': ' + rsDoc [ prop ] + '<br>' ); } } } finally { conn . close (); } out . flush (); out . close (); In this code snippet we have several semantic blocks. First we open a writer to output some data from the service: $ . getResponse (). setContentType ( \"text/html; charset=UTF-8\" ); $ . getResponse (). setCharacterEncoding ( \"UTF-8\" ); var out = $ . getResponse (). getWriter (); Next, we get a connection to the Mongo DB data source that we setup on previous stage: var ds = $ . getNamedDatasources (). get ( \"mongodb\" ); var conn = ds . getConnection (); Then, we create a statement and execute it using the standard JDBC API but the native Mongo DB query language: var stmt = conn . createStatement (); var rs = stmt . executeQuery ( \u2018 { find : \"testCollection\" } \u2019 ); Now we are ready to iterate on the result set and output some results. Note how we use the standard JDBC API for iteration and the little trick that our Mongo DB JDBC driver is capable of with the rs.getObject(-100); statement. Once we get hold of the JSON document for the current iteration we use pure JavaScript and no JDBC to make some use of it: while ( rs . next ()) { var rsDoc = rs . getObject ( - 100 ); for ( var prop in rsDoc ){ out . println ( prop + ': ' + rsDoc [ prop ] + '<br>' ); } } Finally, as good citizens we close all open resource streams.","title":"Putting it to use"},{"location":"2016/01/21/blogs-repositories/","text":"What exactly the term Repository means in the context of Dirigible? How it is related to my projects' life-cycle management? Is there a benefit to have the whole content in a single place? What is the difference between the Local and Master Repositories, and when to use them? The Repository In Dirigible all projects artefacts, including the configurations are stored in a single file system like structure. This content can be easily transported from one instance to another as an archive file in ZIP format, using import/export capabilities. In addition there is a secured RESTful service, which can be used for external updates of the repository content from outside remotely via HTTP. Local Repository The Repository running in a given instance of Dirigible is often referred as 'Local Repository' and plays the role of an operational source code storage. The analogy is the workspace directory in many desktop IDEs, such as Eclipse. When you create a project with files and folders inside, they are immediately reflected in the Local Repository. Having in mind this, the Local Repository has to be above all - fast. The default implementation used in Dirigible is File System based one. It means that Dirigible stores the projects artefacts in some root directory (default or pre-configured) on the very same instance where it runs. There is also a relational database backed implementation for a Local Repository, which can be useful in one of the deployment options described later. Master Repository Another kind of Repository is the so called Master Repository. This is an immutable (read-only) content provider compliant with the IRepository API. The role of this repository is to supply the initial content comprising configurations and public registry (and also workspaces if any) during the bootstrap step of Dirigble's instance. This is actually a pull transfer, where the Dirigible is the active party. This approach gives the flexibility the Master Repository itself (as a passive party) to be implemented based on file system, Git repository or any relational database. Deployment Options Single Persistent Instance This is the simplest option from the operations point of view deployment option. It includes a VM with persistent state, Java Web Container (e.g. Tomcat) and Dirigible \"All-In-One\" product (WAR file) deployed on it. It uses a file system based Local Repository and no Master Repository is configured in this case. This option applies to trial and local development scenarios. Still interaction with Git, as well as import/export functions are available and can be used. Single non-Persistence Instance In this case we have a VM which doesn't keep its state after restart. We either have to mount a persistent file system to the image and configure a Local Repository, or we have to use a RDBMS based Local Repository connected to a remote (most likely \"managed\") relational database. Multiple non-Persistence Instances In this case we have multiple transient VMs connected via the RDBMS based Local Repository to a single database schema. Changes to the content (e.g. during development) can be made from any of the VM instances. After the start of a new VM image it gets the most recent content like all the others in the pool and can be used right away for development or production. The load optimisation here is based only on the in-memory cache built-in the Local Repository. Single Master Instance and Multiple Slave Instances If you want to have immutable production instances and a single or a few instances for development or support, you can choose this option. In this case the \"development/support\" instance(s) have direct connection (their Local Repository) to the \"master\" database schema or the \"master\" root directory (in case of a shared file system). All the other \"production\" instances have configured a Master Repository to the \"master\" source on one hand and a Local Repository configured as local file system based one on the other hand. This option gives the flexibility to have secure \"production\" instances where nobody has even theoretical possibility to break the \"master\" code base. At the same time to have a special instance(s) can be still accessed by different network access rules (e.g. internal access) for quick debugging and bug-fixing on the fly and on the very same environment. Multiple Instances with Git Another option similar to the previous one, is that you can configure the Master Repository to retrieve the content from a Git repository. This can be useful for \"production-only\u201d instances, which have to be immutable on one hand, and versioned on the other. Configurations Configurations parameters for the Repository components can be provided either as initial parameters for the DirigibleBridge servlet in the web.xml or as environment variables. For example to enable the default file-based Local Repository you can use the following snippet: <!-- Default Repository Provider --> <init-param> <param-name> repositoryProvider </param-name> <param-value> org.eclipse.dirigible.repository.local.LocalRepositoryProvider </param-value> </init-param> In case you want to use the database Local Repository you can use the following provider instead: org . eclipse . dirigible . repository . db . DBRepositoryProvider The corresponding database Master Repository can be enabled by: <!-- Default Repository Provider Master (used for Initial Load or Reset) --> <init-param> <param-name> repositoryProviderMaster </param-name> <param-value> org.eclipse.dirigible.repository.db.DBMasterRepositoryProvider </param-value> </init-param> and with Git-based Mater Repository: <!-- Default Repository Provider Master (used for Initial Load or Reset) --> <init-param> <param-name> repositoryProviderMaster </param-name> <param-value> org.eclipse.dirigible.repository.db.GitMasterRepositoryProvider </param-value> </init-param> <!-- Master Repository parameters - Git based --> <init-param> <param-name> masterRepositoryGitTarget </param-name> <param-value> master_git_repository </param-value> </init-param> <init-param> <param-name> masterRepositoryGitLocation </param-name> <param-value> https://xxx </param-value> </init-param> <init-param> <param-name> masterRepositoryGitUser </param-name> <param-value> {git.user} </param-value> </init-param> <init-param> <param-name> masterRepositoryGitPassword </param-name> <param-value> {git.password} </param-value> </init-param> <init-param> <param-name> masterRepositoryGitBranch </param-name> <param-value> {git.branch} </param-value> </init-param> Outlook Following the concepts of Repositories - Local and Master ones, the obvious path ahead is implementation of more production-ready connectors to different data storages e.g. NoSQL such as MongoDB or OrientDB, Cloud storage services e.g. Amazon S3, Google Cloud Storage, etc. Of course, this leaves somehow the responsibility of the security, integrity, high-availability, disaster recovery and the other important capabilities of the content Repository to the low level implementation of the data storage, but at the end this is how it should be, isn't it?","title":"Developer - Repositories, repositories, repositories..."},{"location":"2016/01/21/blogs-repositories/#the-repository","text":"In Dirigible all projects artefacts, including the configurations are stored in a single file system like structure. This content can be easily transported from one instance to another as an archive file in ZIP format, using import/export capabilities. In addition there is a secured RESTful service, which can be used for external updates of the repository content from outside remotely via HTTP.","title":"The Repository"},{"location":"2016/01/21/blogs-repositories/#local-repository","text":"The Repository running in a given instance of Dirigible is often referred as 'Local Repository' and plays the role of an operational source code storage. The analogy is the workspace directory in many desktop IDEs, such as Eclipse. When you create a project with files and folders inside, they are immediately reflected in the Local Repository. Having in mind this, the Local Repository has to be above all - fast. The default implementation used in Dirigible is File System based one. It means that Dirigible stores the projects artefacts in some root directory (default or pre-configured) on the very same instance where it runs. There is also a relational database backed implementation for a Local Repository, which can be useful in one of the deployment options described later.","title":"Local Repository"},{"location":"2016/01/21/blogs-repositories/#master-repository","text":"Another kind of Repository is the so called Master Repository. This is an immutable (read-only) content provider compliant with the IRepository API. The role of this repository is to supply the initial content comprising configurations and public registry (and also workspaces if any) during the bootstrap step of Dirigble's instance. This is actually a pull transfer, where the Dirigible is the active party. This approach gives the flexibility the Master Repository itself (as a passive party) to be implemented based on file system, Git repository or any relational database.","title":"Master Repository"},{"location":"2016/01/21/blogs-repositories/#deployment-options","text":"","title":"Deployment Options"},{"location":"2016/01/21/blogs-repositories/#single-persistent-instance","text":"This is the simplest option from the operations point of view deployment option. It includes a VM with persistent state, Java Web Container (e.g. Tomcat) and Dirigible \"All-In-One\" product (WAR file) deployed on it. It uses a file system based Local Repository and no Master Repository is configured in this case. This option applies to trial and local development scenarios. Still interaction with Git, as well as import/export functions are available and can be used.","title":"Single Persistent Instance"},{"location":"2016/01/21/blogs-repositories/#single-non-persistence-instance","text":"In this case we have a VM which doesn't keep its state after restart. We either have to mount a persistent file system to the image and configure a Local Repository, or we have to use a RDBMS based Local Repository connected to a remote (most likely \"managed\") relational database.","title":"Single non-Persistence Instance"},{"location":"2016/01/21/blogs-repositories/#multiple-non-persistence-instances","text":"In this case we have multiple transient VMs connected via the RDBMS based Local Repository to a single database schema. Changes to the content (e.g. during development) can be made from any of the VM instances. After the start of a new VM image it gets the most recent content like all the others in the pool and can be used right away for development or production. The load optimisation here is based only on the in-memory cache built-in the Local Repository.","title":"Multiple non-Persistence Instances"},{"location":"2016/01/21/blogs-repositories/#single-master-instance-and-multiple-slave-instances","text":"If you want to have immutable production instances and a single or a few instances for development or support, you can choose this option. In this case the \"development/support\" instance(s) have direct connection (their Local Repository) to the \"master\" database schema or the \"master\" root directory (in case of a shared file system). All the other \"production\" instances have configured a Master Repository to the \"master\" source on one hand and a Local Repository configured as local file system based one on the other hand. This option gives the flexibility to have secure \"production\" instances where nobody has even theoretical possibility to break the \"master\" code base. At the same time to have a special instance(s) can be still accessed by different network access rules (e.g. internal access) for quick debugging and bug-fixing on the fly and on the very same environment.","title":"Single Master Instance and Multiple Slave Instances"},{"location":"2016/01/21/blogs-repositories/#multiple-instances-with-git","text":"Another option similar to the previous one, is that you can configure the Master Repository to retrieve the content from a Git repository. This can be useful for \"production-only\u201d instances, which have to be immutable on one hand, and versioned on the other.","title":"Multiple Instances with Git"},{"location":"2016/01/21/blogs-repositories/#configurations","text":"Configurations parameters for the Repository components can be provided either as initial parameters for the DirigibleBridge servlet in the web.xml or as environment variables. For example to enable the default file-based Local Repository you can use the following snippet: <!-- Default Repository Provider --> <init-param> <param-name> repositoryProvider </param-name> <param-value> org.eclipse.dirigible.repository.local.LocalRepositoryProvider </param-value> </init-param> In case you want to use the database Local Repository you can use the following provider instead: org . eclipse . dirigible . repository . db . DBRepositoryProvider The corresponding database Master Repository can be enabled by: <!-- Default Repository Provider Master (used for Initial Load or Reset) --> <init-param> <param-name> repositoryProviderMaster </param-name> <param-value> org.eclipse.dirigible.repository.db.DBMasterRepositoryProvider </param-value> </init-param> and with Git-based Mater Repository: <!-- Default Repository Provider Master (used for Initial Load or Reset) --> <init-param> <param-name> repositoryProviderMaster </param-name> <param-value> org.eclipse.dirigible.repository.db.GitMasterRepositoryProvider </param-value> </init-param> <!-- Master Repository parameters - Git based --> <init-param> <param-name> masterRepositoryGitTarget </param-name> <param-value> master_git_repository </param-value> </init-param> <init-param> <param-name> masterRepositoryGitLocation </param-name> <param-value> https://xxx </param-value> </init-param> <init-param> <param-name> masterRepositoryGitUser </param-name> <param-value> {git.user} </param-value> </init-param> <init-param> <param-name> masterRepositoryGitPassword </param-name> <param-value> {git.password} </param-value> </init-param> <init-param> <param-name> masterRepositoryGitBranch </param-name> <param-value> {git.branch} </param-value> </init-param>","title":"Configurations"},{"location":"2016/01/21/blogs-repositories/#outlook","text":"Following the concepts of Repositories - Local and Master ones, the obvious path ahead is implementation of more production-ready connectors to different data storages e.g. NoSQL such as MongoDB or OrientDB, Cloud storage services e.g. Amazon S3, Google Cloud Storage, etc. Of course, this leaves somehow the responsibility of the security, integrity, high-availability, disaster recovery and the other important capabilities of the content Repository to the low level implementation of the data storage, but at the end this is how it should be, isn't it?","title":"Outlook"},{"location":"2016/01/26/news-docker/","text":"Docker image for Dirigible is created ... finally. Dockerfile can be found here . Ready to use image supported by Quay.io can be used as follows: docker pull quay.io/delchevn/dirigible223 docker run -p 8888:8080 -p quay.io/delchevn/dirigible223 Resources Installation Builder Enjoy!","title":"Docker image for Dirigible"},{"location":"2016/01/26/news-docker/#resources","text":"Installation Builder","title":"Resources"},{"location":"2016/01/26/news-docker/#enjoy","text":"","title":"Enjoy!"},{"location":"2016/02/03/news-new-release-2-2/","text":"New Release 2.2.160203-R released. Features Integrate tabris.js for mobile applications support Lightweight Web IDE - for easy code editing only Run on Dirigible Button (e.g. GitHub) Themes support for Registry UI Docker image for Dirigible on Tomcat Bugfixes and refactoring... Blogs Repositories, repositories, repositories... architecture Operational The full list of bug-fixes and enhancements can be found here . The source code is available at GitHub repository here . The instant trial is updated accordingly with the released version here . Milestones release notes 2.2 M1 2.2 M2 2.2 M3 Enjoy!","title":"Release 2.2.160203-R"},{"location":"2016/02/03/news-new-release-2-2/#features","text":"Integrate tabris.js for mobile applications support Lightweight Web IDE - for easy code editing only Run on Dirigible Button (e.g. GitHub) Themes support for Registry UI Docker image for Dirigible on Tomcat Bugfixes and refactoring...","title":"Features"},{"location":"2016/02/03/news-new-release-2-2/#blogs","text":"Repositories, repositories, repositories... architecture","title":"Blogs"},{"location":"2016/02/03/news-new-release-2-2/#operational","text":"The full list of bug-fixes and enhancements can be found here . The source code is available at GitHub repository here . The instant trial is updated accordingly with the released version here .","title":"Operational"},{"location":"2016/02/03/news-new-release-2-2/#milestones-release-notes","text":"2.2 M1 2.2 M2 2.2 M3","title":"Milestones release notes"},{"location":"2016/02/03/news-new-release-2-2/#enjoy","text":"","title":"Enjoy!"},{"location":"2016/02/05/blogs-develop-from-mobile-for-mobile/","text":"or what will be the next big breakthrough in the way native mobile applications are developed. Innovations Before starting with the \"Develop from Mobile for Mobile\" topic, let's say few words about the innovations. There are two types of innovations: Sustaining innovation Disruptive innovation Sustaining innovation is innovation that leads to improvement of an existing technology, product or service. Example of sustaining innovation is the electrical bulb - the evolution from the incandescent bulb to an energy saving bulb and then to the LED bulb. Through that evolution process the function of the electrical bulb didn't change, it became more energy efficient, emitting more light and having longer life. This sustaining innovation improved the existing \"bulb business\", but didn't create new business opportunities. The second type of innovations - the disruptive innovation , is so powerful that it can develop new markets, re-shape existing ones, create industries that did not exist before and have an enormous effect over the \"way the things are done\" . Examples for innovations of such scale are: Ford model T - the first serial produced automobile for mass consumption Cellular phones - Nokia gives to the market the cellular phones that soon replaced the fixed line telephones iPhone - wipe out the regular cellular phones from the market and open the doors for the smart phones Netflix and iTunes - drives out of the business most video and audio stores around the globe airbnb and booking.com - re-shapes the market for the tourist and the hotel industries Almost all industries and lines of business have suffered disruptive innovations based on software through the last 10 years. Overview It is time to go back to our topic and \"Develop from Mobile for Mobile\" . What do we mean by this and how the native mobile application development is related in the context of the Dirigible? First of all, let's introduce Tabris.js . It is a mobile framework that allows you to develop native iOS and Android mobile applications, written entirely in JavaScript. This framework is the right choice when native performance, native look and feel and single code-base (JavaScript) is wanted. Last but not least, it is possible to use existing JavaScript libraries and native extensions to extend the core functionality, when needed. Unlike other frameworks that use webviews or cross-platform intermediate runtimes, Tabris.js executes the JavaScript directly on the device and renders everything using native widgets. Thanks to the framework capabilities, the developers now can focus more on the mobile application development and less on the platform specifics (iOS and Android). Demo Now let's see how you can \"Develop from Mobile for Mobile\" with Dirigible. Prerequisites Have installed the tabris mobile client on a iOS or Android device from here Have account at https://tabrisjs.com (not mandatory) Have deployed your own instance of Dirigible as described here (not mandatory) Steps Launch your own Dirigible instance or use the free trial . From the home screen click the \"Develop\" tile and then launch the IDE from the \"Web IDE\" tile. Close the \"Get Started\" wizard if you don't have projects in the Dirigible instance. Create new project. Right click->New->Project . Give it some name (in the demo, for name is used \"tabris\"). From the list of available project templates select \"Blank Application\" . Create new \"Hello World\" native mobile application. Right click on the project->New->Mobile App . From the list of available templates select \"Tabris.js Hello World\" . Expand your project and navigate to the \"package.json\" file under the \"MobileApplications\" folder. Select the file and open the \"Preview\" tab. Copy from the \"Preview\" tab the URL to the application. (Optional) Login into your https://tabrisjs.com account and select the \"My Scripts\" tab. From there \"Link Script\" that we've created with the Dirigible. Open the \"Tabris.js\" mobile client from your device. If you've linked the script from your tabris.js account, the application can be found under the \"MY SCRIPTS\" tab, if not, then type the URL in the \"URL\" tab. Now let's take the most from the \"In-System Development\" concept and apply it on the native mobile application. Switch back to the Dirigible IDE and update the application. Back to the device, it is time to refresh the content of the application. Whoah, that is a real \"zero time to market\" . The changes were applied immediately and the content of application was updated. But what abot the \"Develop from Mobile for Mobile\" concept and more precisely the first part of the moto \"Develop from Mobile...\" ? While you are on the device, luanch the web browser and open the \"Dirigible Registry\" (the home screen). Click on the \"Develop\" tile, on the next page select the \"Light IDE\" and you are ready to go. Navigate down to the application sources and apply some changes. Hit the \"Publish\" button, so the applied changes will be available immediately. Convince yourself, that the \"Develop from Mobile for Mobile\" is real, available right now, applicable and easy to use. Conclusion We've seen that a cross platform (iOS and Android) native mobile applications can be developed only with the help of a web browser and nothing more. The integration between Dirigible and Tabris.js enables the developers to reach all their customers and make changes to the product with a \"zero time to market\" speed. The bottom line is this: \"By teaching ourselves to look through the lens of the theory to the future, we can actually see the future very clearly!\" Additional Resources What is a \"Disruptive Innovation\" by Clayton Christensen","title":"Develop from Mobile for Mobile"},{"location":"2016/02/05/blogs-develop-from-mobile-for-mobile/#innovations","text":"Before starting with the \"Develop from Mobile for Mobile\" topic, let's say few words about the innovations. There are two types of innovations: Sustaining innovation Disruptive innovation Sustaining innovation is innovation that leads to improvement of an existing technology, product or service. Example of sustaining innovation is the electrical bulb - the evolution from the incandescent bulb to an energy saving bulb and then to the LED bulb. Through that evolution process the function of the electrical bulb didn't change, it became more energy efficient, emitting more light and having longer life. This sustaining innovation improved the existing \"bulb business\", but didn't create new business opportunities. The second type of innovations - the disruptive innovation , is so powerful that it can develop new markets, re-shape existing ones, create industries that did not exist before and have an enormous effect over the \"way the things are done\" . Examples for innovations of such scale are: Ford model T - the first serial produced automobile for mass consumption Cellular phones - Nokia gives to the market the cellular phones that soon replaced the fixed line telephones iPhone - wipe out the regular cellular phones from the market and open the doors for the smart phones Netflix and iTunes - drives out of the business most video and audio stores around the globe airbnb and booking.com - re-shapes the market for the tourist and the hotel industries Almost all industries and lines of business have suffered disruptive innovations based on software through the last 10 years.","title":"Innovations"},{"location":"2016/02/05/blogs-develop-from-mobile-for-mobile/#overview","text":"It is time to go back to our topic and \"Develop from Mobile for Mobile\" . What do we mean by this and how the native mobile application development is related in the context of the Dirigible? First of all, let's introduce Tabris.js . It is a mobile framework that allows you to develop native iOS and Android mobile applications, written entirely in JavaScript. This framework is the right choice when native performance, native look and feel and single code-base (JavaScript) is wanted. Last but not least, it is possible to use existing JavaScript libraries and native extensions to extend the core functionality, when needed. Unlike other frameworks that use webviews or cross-platform intermediate runtimes, Tabris.js executes the JavaScript directly on the device and renders everything using native widgets. Thanks to the framework capabilities, the developers now can focus more on the mobile application development and less on the platform specifics (iOS and Android).","title":"Overview"},{"location":"2016/02/05/blogs-develop-from-mobile-for-mobile/#demo","text":"Now let's see how you can \"Develop from Mobile for Mobile\" with Dirigible.","title":"Demo"},{"location":"2016/02/05/blogs-develop-from-mobile-for-mobile/#prerequisites","text":"Have installed the tabris mobile client on a iOS or Android device from here Have account at https://tabrisjs.com (not mandatory) Have deployed your own instance of Dirigible as described here (not mandatory)","title":"Prerequisites"},{"location":"2016/02/05/blogs-develop-from-mobile-for-mobile/#steps","text":"Launch your own Dirigible instance or use the free trial . From the home screen click the \"Develop\" tile and then launch the IDE from the \"Web IDE\" tile. Close the \"Get Started\" wizard if you don't have projects in the Dirigible instance. Create new project. Right click->New->Project . Give it some name (in the demo, for name is used \"tabris\"). From the list of available project templates select \"Blank Application\" . Create new \"Hello World\" native mobile application. Right click on the project->New->Mobile App . From the list of available templates select \"Tabris.js Hello World\" . Expand your project and navigate to the \"package.json\" file under the \"MobileApplications\" folder. Select the file and open the \"Preview\" tab. Copy from the \"Preview\" tab the URL to the application. (Optional) Login into your https://tabrisjs.com account and select the \"My Scripts\" tab. From there \"Link Script\" that we've created with the Dirigible. Open the \"Tabris.js\" mobile client from your device. If you've linked the script from your tabris.js account, the application can be found under the \"MY SCRIPTS\" tab, if not, then type the URL in the \"URL\" tab. Now let's take the most from the \"In-System Development\" concept and apply it on the native mobile application. Switch back to the Dirigible IDE and update the application. Back to the device, it is time to refresh the content of the application. Whoah, that is a real \"zero time to market\" . The changes were applied immediately and the content of application was updated. But what abot the \"Develop from Mobile for Mobile\" concept and more precisely the first part of the moto \"Develop from Mobile...\" ? While you are on the device, luanch the web browser and open the \"Dirigible Registry\" (the home screen). Click on the \"Develop\" tile, on the next page select the \"Light IDE\" and you are ready to go. Navigate down to the application sources and apply some changes. Hit the \"Publish\" button, so the applied changes will be available immediately. Convince yourself, that the \"Develop from Mobile for Mobile\" is real, available right now, applicable and easy to use.","title":"Steps"},{"location":"2016/02/05/blogs-develop-from-mobile-for-mobile/#conclusion","text":"We've seen that a cross platform (iOS and Android) native mobile applications can be developed only with the help of a web browser and nothing more. The integration between Dirigible and Tabris.js enables the developers to reach all their customers and make changes to the product with a \"zero time to market\" speed. The bottom line is this: \"By teaching ourselves to look through the lens of the theory to the future, we can actually see the future very clearly!\"","title":"Conclusion"},{"location":"2016/02/05/blogs-develop-from-mobile-for-mobile/#additional-resources","text":"What is a \"Disruptive Innovation\" by Clayton Christensen","title":"Additional Resources"},{"location":"2016/02/26/blogs-understanding-dirigible/","text":"During the past couple of years Dirigible evolved from an RAP based Web IDE for simplification and adaptation of SOAP based Web services to a full fledged Dev Platform with its own yet unique to some extents architecture and features. Besides the main driving principles like In-System Development Model, Dynamic Alteration, Content Centric LM, Toolset Completeness, Vertical Scenarios Coverage and the other concepts that can be found easily at the front pages at the Web site, here we will give you more detailed insights of how Dirigible compares to the other similar frameworks and platforms. We will explain the current focus, priorities and future vision. Blocking vs. non-Blocking There are tons of discussions about the significant improvements in the performance, using the non-blocking a.k.a asynchronous programming model. It is quite successfully used in Node.js, Netty and other frameworks. We believe it is useful for many specific scenarios, especially for long running tasks and complex event processing cases. On the other hand, the main target application archetype for Dirigible is the one, that consists of a database backed RESTful services exposed to the end user via HTML5 interface. This type of applications aim at managing the entities from a business derived domain model. In this case the \"traditional\" i.e. synchronous structuring of the source code is much easier for Java, PHP, ABAP programmers and the all others with the similar background. Following this de-facto standard development style of writing business applications, we decided not to teach you how to develop in a new way, but simply to stick to the synchronous model - no matter that the default language in Dirigible is JavaScript. It could be strange to write JavaScript services in the \"Java\" way, but this is the case in Dirigible and will remain in the future as a primary target. All the current Injected APIs are synchronous. Events and Flows Following the above statements, in Dirigible we highly encourage the you to use the declarative Flows services to achieve the non-blocking processing of the long running tasks. The underlying flow engine will be responsible for the distribution and parallelization of the execution of the given task in the best possible way. Of course, you can code such asynchronous algorithms in JavaScript by using callbacks, or any other scripting language by using its own capabilities, but in this case the responsibility of the optimization, debugging and bug-fixing remains entirely yours. Dependency Management There are plenty of package management tools and dependency management descriptor files out there. Starting with the fact that the major Linux distributions use their own package managers such as APT, RPM, YUM, Zipper, throughout the language specific \"default\" descriptors such as MANIFEST.MF, package.json, gemspec, etc. and even the build tools dependency descriptors such as pom.xml, build.xml, bower.json, etc. it seems that there is no a silver bullet solution for this problem... obviously. What is for sure - the problem is complex and as much as one tries to fix it completely with very descriptive manifest files and complicated algorithms for strict dependency resolutions, the outcome is that the manifest files become too hard to be maintained. This leads to incorrect content and at the end leads to the fact that it is quite difficult to have such systems, based on such strict dependencies up and running at all. The \"global install\" has its drawbacks e.g. with version conflicts via transitive dependencies, but to go to the 'npm' style that leads to duplications is simply unacceptable. Another unacceptable decision is the strongest OSGi approach, which could prevent a plugin or even the whole application from starting, if there is an unsatisfied dependencies issues. The standard Java way so far, with no explicit dependencies check at all at run time, beats them all. Yes, you ever face such a problem, it will happen at the worst possible time - when somebody actually start using the chain, which has a dependency issue - Class Not Found case. In the same time you can work with all the other chains, which do not have any issue. In theory this is wrong because it is not perfect, but in the reality this is the only working model for the large scale applications combining huge set of components contributed by the teams that are distributed and diverse. Hence, in Dirigible we choose the \"non-blocking\" approach - the dependencies declarations are only to help you to navigate and pull the right components, without stopping you if a single dependency is not present at the moment. JavaScript vs. Java vs. ? The scripting languages are the ones chosen in Dirigible by several reasons. The project's ultimate driving force - shortest development turn-around time, requires the time between \"coding\" and \"testing\" to be zero or near to zero. Complex and time consuming build and deploy processes are just unacceptable. Fact. Scripting languages perfectly matches in this case and the whole architecture of Dirigible is built around this concept. Why at the same time do we support Java? The simple answer is - as an arbitrary scripting language. The detailed one - with in-memory compilation. Why JavaScript is the \"chosen\" one? First class citizen in the scripting languages group, widely used already for client and server side components, etc. Also important thing, which to some extents depends on the same factors, there is already available comprehensive source code web based editors, with highlighting, code analysis and code completion - such as Orion. Domain Driven Design vs. Model Driven Architecture Domain Driven Design (DDD) is the natural choice of what Dirigible aims to provide - the dev platform for business services. The starting point of the development of a business application is the definition of the domain model entities. At this phase nothing else matters - only the players and theirs interactions. The ultimate goal of any toolkit is after this design and definition phase to generate and run a full-fledged application auto-magically. We are not there yet, although you can in just a couple of seconds expose your entity from a database table, thru the RESTful service with pattern-based HTML5 user interface. But the important point here is that we know this kind of automatic generation is just to have a scaffold as a preview quickly. In this way we can have an idea how the real application will look like eventually, when it is ready. The real work on customizations based on the consumer's requirements just begins. What happens if you have to change the model, but you have already made lots of changes in the generated code? Bad news, you have to do them again after the generation of the new artefacts or you can skip the generation step and go and apply the needed modifications derived from the model changes on your own. Can Model Driven Architecture (MDA) help here? If yes, do we see MDA as an essential part of Dirigible? In short - yes for both. Sometimes the \"preview\" state is good enough to be used \"in the time being\". But we have to be clear here, such a \"magic\" that can solve this problem completely - does not exist. MDA approach comes with performance degradation it is never optimized enough for your specific case. User interface is never fancy enough nor extensible enough. The behavior that comes from the MDA framework doesn't necessarily match your need, but it is hard or impossible to change. Hence, in Dirigible we see DDD with one-time generation as a primary approach and MDA as just an option. Microservices vs. Monoliths There is a big noise related to the Microservices concepts although they are neither new nor unknown in the technology space until now. How do they reflect on Dirigible? How can we build a business application in the Cloud following the Microservices architecture? First of all it is possible to do this. What\u2019s more, in Dirigible this style of componentization is even kind of enforced. But here comes the major difference - in Dirigible we leverage an unified platform, which the services can run on - the Dev Platform. Hence, whether you decide to divide your components to run on separate instances (to scale separately) or to have them all in a single instance - this is entirely your choice. We keep the unified approach, because in the most of the cases the performance of the local communication channel between the components, for example, is the only acceptable choice. To be fair here, the Microservices architecture does not come because it is the best option - that is because this is an approach to solve the current situation, where many different components are written in different languages, run on different platforms, hence the unification for the deployment of all these can be done only at a very low level - OS, VM, containers and the communication channel can be established on a very high (and expensive) level - TCP/HTTP/File System. Roles Separation vs. One Man Army Depending on the project scale, there is a common suggestion, which constantly appears - separation of roles. This leads to the implied conclusion that the different roles (personas) mean different persons. And this, on the other hand, means that the different persons can use different tools during the development process of a single solution, doesn't it? In Dirigible we take this very seriously - we strive to provide the full set of tools as well as runtime foundation required by all the roles concerning a given project. Whether you will decide to bring the whole crew to work on the project or you will do it alone - it is your decision - you can do both. Dirigible claims to cover all your needs, with the appropriate tooling and runtime engines to develop your next generation business application. Open Source vs. Proprietary Dirigible is an open source project. It is based on a huge set of the open source frameworks. If there weren't such open source methodologies and initiatives, our world would never be the same, that's for sure. Dirigible would have never appeared. The collective intelligence - the major benefit of the open source, proved already many times that it can beat any other proprietary yet closed way of innovations. This leads us to the natural evolution of the Dev Platform concept - Dirigible to be used as the unified foundation for open source business services and utilities. Stay tuned for the exiting news in the next couple of weeks. Enjoy!","title":"Understanding Dirigible"},{"location":"2016/02/26/blogs-understanding-dirigible/#blocking-vs-non-blocking","text":"There are tons of discussions about the significant improvements in the performance, using the non-blocking a.k.a asynchronous programming model. It is quite successfully used in Node.js, Netty and other frameworks. We believe it is useful for many specific scenarios, especially for long running tasks and complex event processing cases. On the other hand, the main target application archetype for Dirigible is the one, that consists of a database backed RESTful services exposed to the end user via HTML5 interface. This type of applications aim at managing the entities from a business derived domain model. In this case the \"traditional\" i.e. synchronous structuring of the source code is much easier for Java, PHP, ABAP programmers and the all others with the similar background. Following this de-facto standard development style of writing business applications, we decided not to teach you how to develop in a new way, but simply to stick to the synchronous model - no matter that the default language in Dirigible is JavaScript. It could be strange to write JavaScript services in the \"Java\" way, but this is the case in Dirigible and will remain in the future as a primary target. All the current Injected APIs are synchronous.","title":"Blocking vs. non-Blocking"},{"location":"2016/02/26/blogs-understanding-dirigible/#events-and-flows","text":"Following the above statements, in Dirigible we highly encourage the you to use the declarative Flows services to achieve the non-blocking processing of the long running tasks. The underlying flow engine will be responsible for the distribution and parallelization of the execution of the given task in the best possible way. Of course, you can code such asynchronous algorithms in JavaScript by using callbacks, or any other scripting language by using its own capabilities, but in this case the responsibility of the optimization, debugging and bug-fixing remains entirely yours.","title":"Events and Flows"},{"location":"2016/02/26/blogs-understanding-dirigible/#dependency-management","text":"There are plenty of package management tools and dependency management descriptor files out there. Starting with the fact that the major Linux distributions use their own package managers such as APT, RPM, YUM, Zipper, throughout the language specific \"default\" descriptors such as MANIFEST.MF, package.json, gemspec, etc. and even the build tools dependency descriptors such as pom.xml, build.xml, bower.json, etc. it seems that there is no a silver bullet solution for this problem... obviously. What is for sure - the problem is complex and as much as one tries to fix it completely with very descriptive manifest files and complicated algorithms for strict dependency resolutions, the outcome is that the manifest files become too hard to be maintained. This leads to incorrect content and at the end leads to the fact that it is quite difficult to have such systems, based on such strict dependencies up and running at all. The \"global install\" has its drawbacks e.g. with version conflicts via transitive dependencies, but to go to the 'npm' style that leads to duplications is simply unacceptable. Another unacceptable decision is the strongest OSGi approach, which could prevent a plugin or even the whole application from starting, if there is an unsatisfied dependencies issues. The standard Java way so far, with no explicit dependencies check at all at run time, beats them all. Yes, you ever face such a problem, it will happen at the worst possible time - when somebody actually start using the chain, which has a dependency issue - Class Not Found case. In the same time you can work with all the other chains, which do not have any issue. In theory this is wrong because it is not perfect, but in the reality this is the only working model for the large scale applications combining huge set of components contributed by the teams that are distributed and diverse. Hence, in Dirigible we choose the \"non-blocking\" approach - the dependencies declarations are only to help you to navigate and pull the right components, without stopping you if a single dependency is not present at the moment.","title":"Dependency Management"},{"location":"2016/02/26/blogs-understanding-dirigible/#javascript-vs-java-vs","text":"The scripting languages are the ones chosen in Dirigible by several reasons. The project's ultimate driving force - shortest development turn-around time, requires the time between \"coding\" and \"testing\" to be zero or near to zero. Complex and time consuming build and deploy processes are just unacceptable. Fact. Scripting languages perfectly matches in this case and the whole architecture of Dirigible is built around this concept. Why at the same time do we support Java? The simple answer is - as an arbitrary scripting language. The detailed one - with in-memory compilation. Why JavaScript is the \"chosen\" one? First class citizen in the scripting languages group, widely used already for client and server side components, etc. Also important thing, which to some extents depends on the same factors, there is already available comprehensive source code web based editors, with highlighting, code analysis and code completion - such as Orion.","title":"JavaScript vs. Java vs. ?"},{"location":"2016/02/26/blogs-understanding-dirigible/#domain-driven-design-vs-model-driven-architecture","text":"Domain Driven Design (DDD) is the natural choice of what Dirigible aims to provide - the dev platform for business services. The starting point of the development of a business application is the definition of the domain model entities. At this phase nothing else matters - only the players and theirs interactions. The ultimate goal of any toolkit is after this design and definition phase to generate and run a full-fledged application auto-magically. We are not there yet, although you can in just a couple of seconds expose your entity from a database table, thru the RESTful service with pattern-based HTML5 user interface. But the important point here is that we know this kind of automatic generation is just to have a scaffold as a preview quickly. In this way we can have an idea how the real application will look like eventually, when it is ready. The real work on customizations based on the consumer's requirements just begins. What happens if you have to change the model, but you have already made lots of changes in the generated code? Bad news, you have to do them again after the generation of the new artefacts or you can skip the generation step and go and apply the needed modifications derived from the model changes on your own. Can Model Driven Architecture (MDA) help here? If yes, do we see MDA as an essential part of Dirigible? In short - yes for both. Sometimes the \"preview\" state is good enough to be used \"in the time being\". But we have to be clear here, such a \"magic\" that can solve this problem completely - does not exist. MDA approach comes with performance degradation it is never optimized enough for your specific case. User interface is never fancy enough nor extensible enough. The behavior that comes from the MDA framework doesn't necessarily match your need, but it is hard or impossible to change. Hence, in Dirigible we see DDD with one-time generation as a primary approach and MDA as just an option.","title":"Domain Driven Design vs. Model Driven Architecture"},{"location":"2016/02/26/blogs-understanding-dirigible/#microservices-vs-monoliths","text":"There is a big noise related to the Microservices concepts although they are neither new nor unknown in the technology space until now. How do they reflect on Dirigible? How can we build a business application in the Cloud following the Microservices architecture? First of all it is possible to do this. What\u2019s more, in Dirigible this style of componentization is even kind of enforced. But here comes the major difference - in Dirigible we leverage an unified platform, which the services can run on - the Dev Platform. Hence, whether you decide to divide your components to run on separate instances (to scale separately) or to have them all in a single instance - this is entirely your choice. We keep the unified approach, because in the most of the cases the performance of the local communication channel between the components, for example, is the only acceptable choice. To be fair here, the Microservices architecture does not come because it is the best option - that is because this is an approach to solve the current situation, where many different components are written in different languages, run on different platforms, hence the unification for the deployment of all these can be done only at a very low level - OS, VM, containers and the communication channel can be established on a very high (and expensive) level - TCP/HTTP/File System.","title":"Microservices vs. Monoliths"},{"location":"2016/02/26/blogs-understanding-dirigible/#roles-separation-vs-one-man-army","text":"Depending on the project scale, there is a common suggestion, which constantly appears - separation of roles. This leads to the implied conclusion that the different roles (personas) mean different persons. And this, on the other hand, means that the different persons can use different tools during the development process of a single solution, doesn't it? In Dirigible we take this very seriously - we strive to provide the full set of tools as well as runtime foundation required by all the roles concerning a given project. Whether you will decide to bring the whole crew to work on the project or you will do it alone - it is your decision - you can do both. Dirigible claims to cover all your needs, with the appropriate tooling and runtime engines to develop your next generation business application.","title":"Roles Separation vs. One Man Army"},{"location":"2016/02/26/blogs-understanding-dirigible/#open-source-vs-proprietary","text":"Dirigible is an open source project. It is based on a huge set of the open source frameworks. If there weren't such open source methodologies and initiatives, our world would never be the same, that's for sure. Dirigible would have never appeared. The collective intelligence - the major benefit of the open source, proved already many times that it can beat any other proprietary yet closed way of innovations. This leads us to the natural evolution of the Dev Platform concept - Dirigible to be used as the unified foundation for open source business services and utilities. Stay tuned for the exiting news in the next couple of weeks. Enjoy!","title":"Open Source vs. Proprietary"},{"location":"2016/03/01/d-kom/","text":"On March 01 2016, presentation about \"What's New in Dirigible\" was held by Yordan Pavlov, on a local d-kom event at Sofia. During the event, the participants got familiar with the newest features in Dirigible, such as \"Native Mobile Development\" , \"NoSQL Support\" , \"Code Completion\" and many more. Another major topic, during the presentation, was \"Why you should contribute?\" and what are the benefits from expanding the horizons and contributing to an open source projects. The presentation can be found on SlideShare","title":"What is New in Dirigible @ d-kom Sofia 2016 - Presentation"},{"location":"2016/03/08/eclipsecon/","text":"On March 08 2016, presentation about \"Cloud Development with Dirigible in the Eyes of a Java-saurus\" was held by Vladimir Pavlov, on the EclipseCon at Virginia, USA. In the session was shown how the development of cloud applications and services with Dirigible looks like - in the eyes of a hard-core veteran Java guy. There was some analogies to the Java (EE) development model and also were explored the differences between the two models. The presentation can be found on SlideShare","title":"Cloud Development with Dirigible in the Eyes of a Java-saurus - Presentation"},{"location":"2016/03/17/news-new-release-2-3/","text":"New Release 2.3.160317-R released. Features Integrated tern definition for Tabris.js in Orion Upgrade Orion to R11 Runtime Catalog Service New approach for theming (client side includes) reflected in templates Listeners concept and processor for the built-in messaging hub Persisted steps for the Flows, Jobs and Listeners (process log) Customizable Registry main menu for easy integration with tools running as Dirigible projects on the same instance Customizable home location Bugfixes and refactoring... Blogs Develop from Mobile for Mobile Understanding Dirigible What\u2019s New in Dirigible - d-kom Sofia 2016 presentation Cloud Development with Dirigible in the Eyes of a Java-saurus - EclipseCon NA 2016 Operational The full list of bug-fixes and enhancements can be found here . The source code is available at GitHub repository here . The instant trial is updated accordingly with the released version here . Enjoy!","title":"Release 2.3.160317-R"},{"location":"2016/03/17/news-new-release-2-3/#features","text":"Integrated tern definition for Tabris.js in Orion Upgrade Orion to R11 Runtime Catalog Service New approach for theming (client side includes) reflected in templates Listeners concept and processor for the built-in messaging hub Persisted steps for the Flows, Jobs and Listeners (process log) Customizable Registry main menu for easy integration with tools running as Dirigible projects on the same instance Customizable home location Bugfixes and refactoring...","title":"Features"},{"location":"2016/03/17/news-new-release-2-3/#blogs","text":"Develop from Mobile for Mobile Understanding Dirigible What\u2019s New in Dirigible - d-kom Sofia 2016 presentation Cloud Development with Dirigible in the Eyes of a Java-saurus - EclipseCon NA 2016","title":"Blogs"},{"location":"2016/03/17/news-new-release-2-3/#operational","text":"The full list of bug-fixes and enhancements can be found here . The source code is available at GitHub repository here . The instant trial is updated accordingly with the released version here .","title":"Operational"},{"location":"2016/03/17/news-new-release-2-3/#enjoy","text":"","title":"Enjoy!"},{"location":"2016/04/18/fast-prototyping-in-front-of-your-customer/","text":"Last week Georgi Georgiev , our marketing expert, held a presentation about \"What is Dirigible\" and \"How to Prototype Fast in Front of Your Customer\", at local cloud event in Sofia. Some images from the presentation, are available at: Image 1 Image 2 The whole presentation can be found on SlideShare","title":"Fast Prototyping in Front of Your Customer - Presentation"},{"location":"2016/05/19/blogs-web-sockets-and-osgi-in-servlet-container/","text":"How to use WebSockets, coming as a standard feature with the modern Servlet Containers (e.g. Tomcat 7.x) from within the embedded Equinox OSGi environment deployed as a WAR application archive? If you haven't asked yourself such a question so far, just forget it and live in peace... But in case you have already quite serious reasons to separate the functionality of your huge and complex application to plugins to be manageable and already have chosen the OSGi way with the Eclipse Equinox implementation and in the same time you want your application in the Web, most probably you already know the nasty issues that appear ones you try something aside from the standard \"ServletBridge\" scenario. Background OK, if you are not aware about the above use-case, but still want to learn what it is about let's start with some prerequisites: What is WebSockets by Matt West: http://blog.teamtreehouse.com/an-introduction-to-websockets What is OSGi in Servlet Container series by Angelo Zerr: https://angelozerr.wordpress.com/2010/08/31/osgi-equinox-in-a-servlet-container-step0/ The Problem Now, assuming you got the idea how the architecture looks like and you are convinced it worths the effort - what is the problem? On one side we have the web application environment, which is as standard as any other web application running on the Tomcat server. You can have there Servelts, WebSockets, etc. You have access to the shared libraries within the Tomcat/lib folder as any other application has. The Solution ClassLoaders visibility The first problem is how to make the WebSockets API classes to be visible at runtime by the OSGi environment? This is configured in the launch.ini file as: 1. OSGi's parent and context class-loaders have to be set to fwk 2. the transitive packages are listed in the extra property osgi.*=@null org.osgi.*=@null eclipse.*=@null osgi.parentClassloader=fwk osgi.contextClassLoaderParent=fwk org.osgi.framework.system.packages.extra=javax.websocket,javax.websocket.server,javax.mail,javax.mail.internet,org.eclipse.dirigible.ide.bridge The actual file can be found here Configure Dependency During the development you will need to include the WebSockets API in the target platform. This is required to develop your server side logic in a plugin against the WebSockets API. You can refer the already available artifact in the Orbit repository here In your *.target file add the following: <location includeAllPlatforms= \"false\" includeConfigurePhase= \"true\" includeMode= \"slicer\" includeSource= \"true\" type= \"InstallableUnit\" > ... <unit id= \"javax.websocket\" version= \"1.0.0.v20140310-1603\" /> <repository location= \"http://download.eclipse.org/tools/orbit/downloads/drops/R20150519210750/repository\" /> </location> The target platform file of Dirigible can be found here After the reloading of the target platform, javax.websocket package is available and can be added to a manifest file of the plugin you want to use for the server-side implementation: Import-Package: ... javax.websocket, javax.websocket.server ... and the corresponding sample from the Dirigible code-base here Important - use package import not plugin dependency as soon as at the runtime the classes will be exposed by the application class-loader not by the OSGi parent class-loader itself. WebSocket Proxy (outside OSGi) We made the necessary configurations, now we can start with the implementation of our WebSocket servlet. Let's create a real-time logging servlet, which can send immediately the log messages to all the clients currently connected to it. First of all we need the standard implementation of a WebSocket outside of the OSGi environment. It will accept the connections from the clients and will play a role of a bridge to the OSGi environment. We can use the standard annotations @ServerEndpoint, @onOpen, @onMessage, @onError and @onClose ... @ServerEndpoint ( \"/log\" ) public class WebSocketLogBridgeServlet { private static final Logger logger = LoggerFactory . getLogger ( WebSocketLogBridgeServlet . class ); private static Map < String , Session > openSessions = new ConcurrentHashMap < String , Session > (); @OnOpen public void onOpen ( Session session ) throws IOException { openSessions . put ( session . getId (), session ); callInternal ( \"onOpen\" , session , null ); } protected void callInternal ( String methodName , Session session , String message ) { logger . debug ( \"Getting internal pair...\" ); Object logInternal = DirigibleBridge . BRIDGES . get ( \"websocket_log_channel_internal\" ); logger . debug ( \"Getting internal pair passed: \" + ( logInternal != null )); if ( logInternal == null ) { String peerError = \"Internal WebSocket peer for Log Service is null.\" ; logger . error ( peerError ); try { session . getBasicRemote (). sendText ( peerError ); } catch ( IOException e ) { logger . error ( e . getMessage (), e ); } return ; } try { Method method = null ; if ( message == null ) { method = logInternal . getClass (). getMethod ( methodName , Session . class ); method . invoke ( logInternal , session ); } else { method = logInternal . getClass (). getMethod ( methodName , String . class , Session . class ); method . invoke ( logInternal , message , session ); } } catch ( NoSuchMethodException e ) { logger . error ( e . getMessage (), e ); } catch ( SecurityException e ) { logger . error ( e . getMessage (), e ); } catch ( IllegalAccessException e ) { logger . error ( e . getMessage (), e ); } catch ( IllegalArgumentException e ) { logger . error ( e . getMessage (), e ); } catch ( InvocationTargetException e ) { logger . error ( e . getMessage (), e ); } } @OnMessage public void onMessage ( String message , Session session ) { callInternal ( \"onMessage\" , session , message ); } @OnError public void onError ( Session session , Throwable t ) { callInternal ( \"onError\" , session , t . getMessage ()); logger . error ( t . getMessage (), t ); } @OnClose public void onClose ( Session session ) { openSessions . remove ( session . getId ()); callInternal ( \"onClose\" , session , null ); } ... full source code here The interesting part here is the BRIDGES map, which contains the already registered bridges coming from the OSGi environment. Object logInternal = DirigibleBridge . BRIDGES . get ( \"websocket_log_channel_internal\" ); The source code of the DirigibleBridge can be found here WebSocket Bridge (inside OSGi) We have already the WebSocket end-point, which will accept the connections and will redirect the corresponding calls to the internal \"bridge\" object. Let's have a look at the bridge implementation itself: ... private static Map < String , Session > openSessions = new ConcurrentHashMap < String , Session > (); @OnOpen public void onOpen ( Session session ) throws IOException { openSessions . put ( session . getId (), session ); session . getBasicRemote (). sendText ( \"[log] open: \" + session . getId ()); logger . debug ( \"[ws:log] onOpen: \" + session . getId ()); } @OnMessage public void onMessage ( String message , Session session ) { logger . debug ( \"[ws:log] onMessage: \" + message ); } @OnError public void onError ( Session session , String error ) { logger . debug ( \"[ws:log] onError: \" + error ); } @OnClose public void onClose ( Session session ) { openSessions . remove ( session . getId ()); logger . debug ( \"[ws:log] onClose: Session \" + session . getId () + \" has ended\" ); } public static void sendText ( String sessionId , String message ) { try { if ( sessionId == null ) { for ( Object element : openSessions . values ()) { Session session = ( Session ) element ; session . getBasicRemote (). sendText ( message ); } } else { openSessions . get ( sessionId ). getBasicRemote (). sendText ( message ); } } catch ( IOException e ) { logger . error ( e . getMessage (), e ); } } @Override public void log ( String level , String message ) { for ( Session session : openSessions . values ()) { try { synchronized ( session ) { session . getBasicRemote (). sendText ( String . format ( \"[%s] %s\" , level , message )); } } catch ( Throwable e ) { // do not log it with the Logger e . printStackTrace (); } } } ... source code here We can use the same WebSockets API classes like javax.websocket.Session and even the annotations for the methods (of course the annotations in the above example are just for clarity as soon as there is no actual processor for them within the OSGi environment). Ones we have the implementation of the internal (bridge) part of the pair, we have to add a registration logic to the plugin activator: public class MetricsActivator implements BundleActivator { private static final Logger logger = Logger . getLogger ( MetricsActivator . class ); WebSocketLogBridgeServletInternal webSocketLogBridgeServletInternal ; @Override public void start ( BundleContext context ) throws Exception { ... setupLogChannel (); } protected void setupLogChannel () { logger . debug ( \"Setting log channel internal ...\" ); webSocketLogBridgeServletInternal = new WebSocketLogBridgeServletInternal (); DirigibleBridge . BRIDGES . put ( \"websocket_log_channel_internal\" , webSocketLogBridgeServletInternal ); Logger . addListener ( webSocketLogBridgeServletInternal ); logger . debug ( \"Log channel internal has been set.\" ); } @Override public void stop ( BundleContext context ) throws Exception { webSocketLogBridgeServletInternal . closeAll (); Logger . removeListener ( webSocketLogBridgeServletInternal ); } } source code here WebSocket Client At this step we are ready with the server side implementation. Let's create a simple user interface in HTML and client-side JavaScript, which will connect to the Log WebSocket Service and will print every single log message to the body of the page: ... < body onload = \"connectToLog()\" > < script > var connectToLog = function () { try { var logSocket = new WebSocket ((( location . protocol === 'https:' ) ? \"wss://\" : \"ws://\" ) + window . location . host + \"/log\" ); } catch ( e ) { document . writeln ( \"<div style='background-color: black; font-family: monospace; color: red'>[\" + new Date (). toISOString () + \"][error]\" + e . message + \"</div>\" ); } logSocket . onmessage = function ( message ) { var color = \"#44EE44\" ; if ( message . data . startsWith ( \"[error]\" )) { color = \"red\" ; } var date = new Date (); var id = date . getTime (); document . writeln ( \"<div id='\" + id + \"' style='background-color: black; font-family: monospace; color: \" + color + \"'>[\" + date . toISOString () + \"]\" + message . data + \"</div>\" ); window . location . hash = \"#\" + id ; }; setInterval ( clear , 60000 ); } var clear = function () { document . body . innerHTML = '' ; document . writeln ( \"<div style='background-color: black; font-family: monospace; color: gray'>[\" + new Date (). toISOString () + \"][clear]...</div>\" ); } </ script > ... source code here The assumption here is that the protocol of the WebSocket connection has the same security level as the page itself http->ws https->wss. On receiving a log message the \"logSocket.onmessage\" function is called. The other function \"clear\" is added just for usability and performance reasons. The above user interface can be used stand-alone or can be embedded in the Registry portal or in the WebIDE. Can it be easier? Yes - with Eclipse Dirigible! The support of WebSockets in Dirigible's Scripting Services is coming with release 2.4 - today! 2.0 compliant API is on place and sample will be provided shortly. Enjoy!","title":"WebSockets and Equinox OSGi in a Servlet Container"},{"location":"2016/05/19/blogs-web-sockets-and-osgi-in-servlet-container/#background","text":"OK, if you are not aware about the above use-case, but still want to learn what it is about let's start with some prerequisites: What is WebSockets by Matt West: http://blog.teamtreehouse.com/an-introduction-to-websockets What is OSGi in Servlet Container series by Angelo Zerr: https://angelozerr.wordpress.com/2010/08/31/osgi-equinox-in-a-servlet-container-step0/","title":"Background"},{"location":"2016/05/19/blogs-web-sockets-and-osgi-in-servlet-container/#the-problem","text":"Now, assuming you got the idea how the architecture looks like and you are convinced it worths the effort - what is the problem? On one side we have the web application environment, which is as standard as any other web application running on the Tomcat server. You can have there Servelts, WebSockets, etc. You have access to the shared libraries within the Tomcat/lib folder as any other application has.","title":"The Problem"},{"location":"2016/05/19/blogs-web-sockets-and-osgi-in-servlet-container/#the-solution","text":"","title":"The Solution"},{"location":"2016/05/19/blogs-web-sockets-and-osgi-in-servlet-container/#classloaders-visibility","text":"The first problem is how to make the WebSockets API classes to be visible at runtime by the OSGi environment? This is configured in the launch.ini file as: 1. OSGi's parent and context class-loaders have to be set to fwk 2. the transitive packages are listed in the extra property osgi.*=@null org.osgi.*=@null eclipse.*=@null osgi.parentClassloader=fwk osgi.contextClassLoaderParent=fwk org.osgi.framework.system.packages.extra=javax.websocket,javax.websocket.server,javax.mail,javax.mail.internet,org.eclipse.dirigible.ide.bridge The actual file can be found here","title":"ClassLoaders visibility"},{"location":"2016/05/19/blogs-web-sockets-and-osgi-in-servlet-container/#configure-dependency","text":"During the development you will need to include the WebSockets API in the target platform. This is required to develop your server side logic in a plugin against the WebSockets API. You can refer the already available artifact in the Orbit repository here In your *.target file add the following: <location includeAllPlatforms= \"false\" includeConfigurePhase= \"true\" includeMode= \"slicer\" includeSource= \"true\" type= \"InstallableUnit\" > ... <unit id= \"javax.websocket\" version= \"1.0.0.v20140310-1603\" /> <repository location= \"http://download.eclipse.org/tools/orbit/downloads/drops/R20150519210750/repository\" /> </location> The target platform file of Dirigible can be found here After the reloading of the target platform, javax.websocket package is available and can be added to a manifest file of the plugin you want to use for the server-side implementation: Import-Package: ... javax.websocket, javax.websocket.server ... and the corresponding sample from the Dirigible code-base here Important - use package import not plugin dependency as soon as at the runtime the classes will be exposed by the application class-loader not by the OSGi parent class-loader itself.","title":"Configure Dependency"},{"location":"2016/05/19/blogs-web-sockets-and-osgi-in-servlet-container/#websocket-proxy-outside-osgi","text":"We made the necessary configurations, now we can start with the implementation of our WebSocket servlet. Let's create a real-time logging servlet, which can send immediately the log messages to all the clients currently connected to it. First of all we need the standard implementation of a WebSocket outside of the OSGi environment. It will accept the connections from the clients and will play a role of a bridge to the OSGi environment. We can use the standard annotations @ServerEndpoint, @onOpen, @onMessage, @onError and @onClose ... @ServerEndpoint ( \"/log\" ) public class WebSocketLogBridgeServlet { private static final Logger logger = LoggerFactory . getLogger ( WebSocketLogBridgeServlet . class ); private static Map < String , Session > openSessions = new ConcurrentHashMap < String , Session > (); @OnOpen public void onOpen ( Session session ) throws IOException { openSessions . put ( session . getId (), session ); callInternal ( \"onOpen\" , session , null ); } protected void callInternal ( String methodName , Session session , String message ) { logger . debug ( \"Getting internal pair...\" ); Object logInternal = DirigibleBridge . BRIDGES . get ( \"websocket_log_channel_internal\" ); logger . debug ( \"Getting internal pair passed: \" + ( logInternal != null )); if ( logInternal == null ) { String peerError = \"Internal WebSocket peer for Log Service is null.\" ; logger . error ( peerError ); try { session . getBasicRemote (). sendText ( peerError ); } catch ( IOException e ) { logger . error ( e . getMessage (), e ); } return ; } try { Method method = null ; if ( message == null ) { method = logInternal . getClass (). getMethod ( methodName , Session . class ); method . invoke ( logInternal , session ); } else { method = logInternal . getClass (). getMethod ( methodName , String . class , Session . class ); method . invoke ( logInternal , message , session ); } } catch ( NoSuchMethodException e ) { logger . error ( e . getMessage (), e ); } catch ( SecurityException e ) { logger . error ( e . getMessage (), e ); } catch ( IllegalAccessException e ) { logger . error ( e . getMessage (), e ); } catch ( IllegalArgumentException e ) { logger . error ( e . getMessage (), e ); } catch ( InvocationTargetException e ) { logger . error ( e . getMessage (), e ); } } @OnMessage public void onMessage ( String message , Session session ) { callInternal ( \"onMessage\" , session , message ); } @OnError public void onError ( Session session , Throwable t ) { callInternal ( \"onError\" , session , t . getMessage ()); logger . error ( t . getMessage (), t ); } @OnClose public void onClose ( Session session ) { openSessions . remove ( session . getId ()); callInternal ( \"onClose\" , session , null ); } ... full source code here The interesting part here is the BRIDGES map, which contains the already registered bridges coming from the OSGi environment. Object logInternal = DirigibleBridge . BRIDGES . get ( \"websocket_log_channel_internal\" ); The source code of the DirigibleBridge can be found here","title":"WebSocket Proxy (outside OSGi)"},{"location":"2016/05/19/blogs-web-sockets-and-osgi-in-servlet-container/#websocket-bridge-inside-osgi","text":"We have already the WebSocket end-point, which will accept the connections and will redirect the corresponding calls to the internal \"bridge\" object. Let's have a look at the bridge implementation itself: ... private static Map < String , Session > openSessions = new ConcurrentHashMap < String , Session > (); @OnOpen public void onOpen ( Session session ) throws IOException { openSessions . put ( session . getId (), session ); session . getBasicRemote (). sendText ( \"[log] open: \" + session . getId ()); logger . debug ( \"[ws:log] onOpen: \" + session . getId ()); } @OnMessage public void onMessage ( String message , Session session ) { logger . debug ( \"[ws:log] onMessage: \" + message ); } @OnError public void onError ( Session session , String error ) { logger . debug ( \"[ws:log] onError: \" + error ); } @OnClose public void onClose ( Session session ) { openSessions . remove ( session . getId ()); logger . debug ( \"[ws:log] onClose: Session \" + session . getId () + \" has ended\" ); } public static void sendText ( String sessionId , String message ) { try { if ( sessionId == null ) { for ( Object element : openSessions . values ()) { Session session = ( Session ) element ; session . getBasicRemote (). sendText ( message ); } } else { openSessions . get ( sessionId ). getBasicRemote (). sendText ( message ); } } catch ( IOException e ) { logger . error ( e . getMessage (), e ); } } @Override public void log ( String level , String message ) { for ( Session session : openSessions . values ()) { try { synchronized ( session ) { session . getBasicRemote (). sendText ( String . format ( \"[%s] %s\" , level , message )); } } catch ( Throwable e ) { // do not log it with the Logger e . printStackTrace (); } } } ... source code here We can use the same WebSockets API classes like javax.websocket.Session and even the annotations for the methods (of course the annotations in the above example are just for clarity as soon as there is no actual processor for them within the OSGi environment). Ones we have the implementation of the internal (bridge) part of the pair, we have to add a registration logic to the plugin activator: public class MetricsActivator implements BundleActivator { private static final Logger logger = Logger . getLogger ( MetricsActivator . class ); WebSocketLogBridgeServletInternal webSocketLogBridgeServletInternal ; @Override public void start ( BundleContext context ) throws Exception { ... setupLogChannel (); } protected void setupLogChannel () { logger . debug ( \"Setting log channel internal ...\" ); webSocketLogBridgeServletInternal = new WebSocketLogBridgeServletInternal (); DirigibleBridge . BRIDGES . put ( \"websocket_log_channel_internal\" , webSocketLogBridgeServletInternal ); Logger . addListener ( webSocketLogBridgeServletInternal ); logger . debug ( \"Log channel internal has been set.\" ); } @Override public void stop ( BundleContext context ) throws Exception { webSocketLogBridgeServletInternal . closeAll (); Logger . removeListener ( webSocketLogBridgeServletInternal ); } } source code here","title":"WebSocket Bridge (inside OSGi)"},{"location":"2016/05/19/blogs-web-sockets-and-osgi-in-servlet-container/#websocket-client","text":"At this step we are ready with the server side implementation. Let's create a simple user interface in HTML and client-side JavaScript, which will connect to the Log WebSocket Service and will print every single log message to the body of the page: ... < body onload = \"connectToLog()\" > < script > var connectToLog = function () { try { var logSocket = new WebSocket ((( location . protocol === 'https:' ) ? \"wss://\" : \"ws://\" ) + window . location . host + \"/log\" ); } catch ( e ) { document . writeln ( \"<div style='background-color: black; font-family: monospace; color: red'>[\" + new Date (). toISOString () + \"][error]\" + e . message + \"</div>\" ); } logSocket . onmessage = function ( message ) { var color = \"#44EE44\" ; if ( message . data . startsWith ( \"[error]\" )) { color = \"red\" ; } var date = new Date (); var id = date . getTime (); document . writeln ( \"<div id='\" + id + \"' style='background-color: black; font-family: monospace; color: \" + color + \"'>[\" + date . toISOString () + \"]\" + message . data + \"</div>\" ); window . location . hash = \"#\" + id ; }; setInterval ( clear , 60000 ); } var clear = function () { document . body . innerHTML = '' ; document . writeln ( \"<div style='background-color: black; font-family: monospace; color: gray'>[\" + new Date (). toISOString () + \"][clear]...</div>\" ); } </ script > ... source code here The assumption here is that the protocol of the WebSocket connection has the same security level as the page itself http->ws https->wss. On receiving a log message the \"logSocket.onmessage\" function is called. The other function \"clear\" is added just for usability and performance reasons. The above user interface can be used stand-alone or can be embedded in the Registry portal or in the WebIDE. Can it be easier? Yes - with Eclipse Dirigible! The support of WebSockets in Dirigible's Scripting Services is coming with release 2.4 - today! 2.0 compliant API is on place and sample will be provided shortly. Enjoy!","title":"WebSocket Client"},{"location":"2016/05/19/news-new-release-2-4/","text":"New version 2.4.160519-R released. Features Websockets support for Scripting Services Migration to RAP 3.0.2 Log Console (via Websockets) API 2.0 Introduction Debugging of Javascript Services improvements Java service tooling removed from the default packaging Bugfixes and refactoring... Blogs WebSockets and Equinox OSGi in a Servlet Container Operational The full list of bug-fixes and enhancements can be found here . The source code is available at GitHub repository here . The instant trial is updated accordingly with the released version here . Enjoy!","title":"Release 2.4.160519-R"},{"location":"2016/05/19/news-new-release-2-4/#features","text":"Websockets support for Scripting Services Migration to RAP 3.0.2 Log Console (via Websockets) API 2.0 Introduction Debugging of Javascript Services improvements Java service tooling removed from the default packaging Bugfixes and refactoring...","title":"Features"},{"location":"2016/05/19/news-new-release-2-4/#blogs","text":"WebSockets and Equinox OSGi in a Servlet Container","title":"Blogs"},{"location":"2016/05/19/news-new-release-2-4/#operational","text":"The full list of bug-fixes and enhancements can be found here . The source code is available at GitHub repository here . The instant trial is updated accordingly with the released version here .","title":"Operational"},{"location":"2016/05/19/news-new-release-2-4/#enjoy","text":"","title":"Enjoy!"},{"location":"2016/05/30/news-hackfmi7/","text":"Over the weekend, the seventh edition of HackFMI - Hack for Start! took place. There were plenty of interesting ideas, code and lots of fun! We are proud that the team Brainstormers - Marina, Stoyan, Antonio, Emil, Ignat and Georgi were among the winners ! The team developed a mobile application that helps all people with disabilities to move more easily in the urban environment. The mobile application provides a map with the most convenient route from point A to point B, which is set to meet the needs of such consumers. The backend REST services were implemented using Eclipse Dirigible platform. Congrats!","title":"Brainstormers at HackFMI7"},{"location":"2016/05/30/news-hackfmi7/#congrats","text":"","title":"Congrats!"},{"location":"2016/06/17/news-dirigiblelabs/","text":"We are happy to announce that the Dirigible Labs space is live! What is it? In short this is a place at GitHub https://github.com/dirigiblelabs where developers can collaborate and openly share their projects built with and run on Eclipse Dirigible. There are some important points, which have to be emphasized: The projects are not official Eclipse Foundation projects The developers must not use Eclipse provided collaboration and project management services e.g Bugzilla, IPzilla, Forum, Wiki, etc. The projects are not obliged to follow the Eclipse IP process Looks like a regular GitHub collaboration space? The only key difference is that: The developers have to sign the Eclipse CLA Why? This will give us confidence about the authors of the contributed source code and will make the eventual contribution to Eclipse Dirigible project at later point of time much easier. The full description of the User Guidelines can be found at https://wiki.eclipse.org/Dirigible/DirigibleLabs Sounds easy, right? You always can use the http://trial.dirigible.io as a starting point. If you want a new repository to be created, just write an issue under https://github.com/dirigiblelabs/dirigiblelabs project. Enjoy!","title":"Dirigible Labs is live!"},{"location":"2016/06/17/news-dirigiblelabs/#enjoy","text":"","title":"Enjoy!"},{"location":"2016/08/01/blogs-why-enterprise-js/","text":"Enterprise JavaScript - it sounds like an oxymoron, doesn't it? JavaScript evolved in the last years not only as \"the language\" for the browsers, but also as a server-side scripting language. There are already some implementations based on different underlying engines, which lead to different features sets. Let's name a few engines e.g. Mozilla Rhino, Nashorn, V8, SpiderMonkey and a couple of frameworks enhancing each of these base JavaScript engines - Node.js, RingoJS, Narwhal and many more. Here we don't even count the JavaScript derivative intermediate languages like Objective-J, TypeScript, CoffeeScript, etc. How can the business application developer choose where to start from? Which engine best meets the developer\u2019s needs? Is it true that the fastest engine is always the best one? Are there others non-functional requirements like maintainability, portability, supportability, compatibility, testability, usability, etc. which can have even bigger priority than the particular engine's and framework's performance? If we talk about the biggest enterprises, the questions like \"shall we invest in a given language, engine, framework or platform?\" are never so simple to answer. There are many different viewpoints, various aspects that have to be considered, and last but not least, the quality attributes of the given component have to be precisely evaluated. What did we do so far in Eclipse Dirigible when it comes to consciousness and pragmatism? We already set JavaScript as the major scripting language supported by the platform. The availability - engines and tooling, maturity and popularity were the main driving forces in our case. The dynamic typing nature of the language itself is a perfect match with the concept of dynamic applications we focus on, but has never been the strongest reason for choosing it. So far so good. Now, what can the developers do with this JavaScript language? Shall they start building all the required commodity frameworks for HTTP communication, database access, encryption and many more, which are de-facto standard basis in the other languages? Obviously, this is not exactly the perspective that the business developers see for themselves by starting to use one of the most powerful cloud development platforms, which Eclipse Dirigible claims to be. Coming from the Java world as many of you, the natural question is - can I reuse somehow the frameworks and APIs that I am already familiar with? But in the same time, should I go to JavaScript only modules to keep the source code clean, or can I mix Java classes and JavaScript? How easy would it be to port my source code from Java based engines like Rhino and Nashorn to non-Java ones e.g V8 later on? Having in mind all these questions, we can define our mission statement for the Enterprise JavaScript: The ultimate goal of the \"Enterprise JavaScript\" is to provide a set of a standard yet powerful APIs, which can be used by the business applications developer right away. The benefits are: Completeness Rich, but still standardized APIs; Expose legacy components and frameworks to the new environment; Portability No tight vendor lock-in to the currently chosen underlying JavaScript platform; OS, platform and database agnostic; Developers can stick to native JavaScript objects and primitives only in their source code; Usability The API itself is a standard Eclipse Dirigible project, hence can have the same life-cycle as the rest of the projects; Let's see a few examples what we are targeting on: Database Access Very natural for a Java-saurus is to use the JDBC API for access and management of relational databases. It provides classes and methods for the manipulation of the data and the metadata. It is powerful enough and in the same time, well known, so can we reuse it? The module db/database gives the port of the main JDBC objects for data management - Datasource, Connection, Statement, ResultSet. An example of how to query the records from a table and print the result into the response stream looks like this: var database = require ( 'db/database' ); var response = require ( 'net/http/response' ); var datasource = database . getDatasource (); // default var connection = datasource . getConnection (); try { var statement = connection . prepareStatement ( \"select * from DGB_FILES where FILE_PATH like ?\" ); var i = 0 ; statement . setString ( ++ i , \"%\" ); var resultSet = statement . executeQuery (); while ( resultSet . next ()) { response . println ( \"[path]: \" + resultSet . getString ( \"FILE_PATH\" )); } resultSet . close (); statement . close (); } catch ( e ) { console . trace ( e ); response . println ( e . message ); } finally { connection . close (); } response . flush (); response . close (); HTTP Communication Another very popular API used in the above example is the Servlet API giving the access from the service body to the current Request, Response and Session objects. You can find more info in the modules net/http/request , net/http/response and net/http/session . What we decided to include also in the Enterprise JavaScript is the de facto standard component for handling of the uploaded binary files. Here is the moment to send big thanks to the Apache guys. Of course, we simplified a lot the API itself and added some utilities functions to make it convenient for the JavaScript developers: var upload = require ( 'net/http/upload' ); var request = require ( 'net/http/request' ); var response = require ( 'net/http/response' ); if ( request . getMethod () === \"POST\" ) { if ( upload . isMultipartContent ()) { var files = upload . parseRequest (); files . forEach ( function ( file ) { response . println ( \"[File Name] \" + file . name ); response . println ( \"[File Data]\" ); // response.println(file.data); // as a raw byte array or as a string below response . println ( String . fromCharCode . apply ( null , file . data )); }); } else { response . println ( \"The request's content must be 'multipart'\" ); } } else if ( request . getMethod () === \"GET\" ) { response . println ( \"Use POST request.\" ); } response . flush (); response . close (); More info can be found in module net/http/upload . We also needed an HTTP client API to call external services. This one we defined similar to jQuery, no matter it is backed by the Apache's HTTPClient. You can use the module net/http/client to retrieve the raw data from an endpoint and print it to the response stream: var http = require ( 'net/http/client' ); var response = require ( 'net/http/response' ); var options = { method : 'GET' , // default host : 'http://services.odata.org' , port : 80 , path : '/V4/Northwind/Northwind.svc/' , binary : false }; var httpResponse = http . request ( options ); response . println ( httpResponse . statusMessage ); response . println ( httpResponse . data ); response . flush (); response . close (); or even simpler: var httpResponse = httpClient . get ( 'http://services.odata.org/V4/Northwind/Northwind.svc/' ); WebSockets and SOAP If you need bi-directional communication channel in your use case, you can utilize the WebSockets module net/websocket . You can implement a handler for the received messages as well as to send messages back through the channel of the same session. Can we name this API \"Enterprise\" without including the SOAP web services? Of course, not! In the module net/soap you can find how to construct a SOAP massage in order to be able to call an external SOAP web service. You can even create your own SOAP web service! Although, we are not completely sure why you would do this, but you can. Files and Streams To standardize the IO access to the underlying file system we added the module io/files . How to create, copy and delete a file with this module is shown below: files . createFile ( \"../temp/file1.txt\" ); files . copy ( \"../temp/file1.txt\" , \"../temp/file2.txt\" ); files . delete ( \"../temp/file2.txt\" ); You can also read, write and inspect the file and folders attributes. Reading from and writing to streams, for example, memory byte arrays, is possible via the module net/streams . Indexing, Messaging, Mail... The modules under the main package service e.g. service/indexing , service/messaging , and so on represents the underlying platform services. These services, as well as their management and operation, are usually provided by the platform on which Eclipse Dirigible is running. The quality and the performance of the services themselves can differ depending on the platform provider, but the goal here is to provide a unified manner of using such standard services, or at least the common denominator of their capabilities. For instance if you want to create a free text search index, you can do it like this: var indexing = require ( 'service/indexing' ); var response = require ( 'net/http/response' ); var index = indexing . getIndex ( \"myIndex\" ); var document1 = { \"id\" : \"1\" , \"content\" : \"some cool content 1\" }; var document2 = { \"id\" : \"2\" , \"content\" : \"some cool content 2\" }; index . add ( document1 ); index . add ( document2 ); var results = index . search ( \"cool\" ); for ( var i = 0 ; i < results . length ; i ++ ) { var result = results [ i ]; response . println ( \"[Found for 'cool']: \" + result . id ); } results = index . search ( \"1\" ); for ( var i = 0 ; i < results . length ; i ++ ) { result = results [ i ]; response . println ( \"[Found for '1']: \" + result . id ); } results = index . search ( \"2\" ); for ( var i = 0 ; i < results . length ; i ++ ) { result = results [ i ]; response . println ( \"[Found for '2']: \" + result . id ); } index . clear (); response . flush (); response . close (); Eclipse Dirigible provides default sample implementations of all the service APIs. To be able to redirect the API to the real platform service, you need to implement an adapter plugin to this service if it is not already available and then to configure the usage. Utilities Another set of modules under the package utils , provides some commodity functionality backed mainly by the Apache Commons - utils/base64 , utils/digest , utils/hex , etc. var hex = require ( 'utils/hex' ); var response = require ( 'net/http/response' ); response . println ( hex . encode ( 'Hex Encoded' )); response . println ( hex . decode ( '48657820456e636f646564' )); response . flush (); response . close (); Threads What would you say to have thread management API in JavaScript? This is missing even in the most popular - Node.js framework. In the Enterprise JavaScript module core/threads you can use a simple function as a \"runnable\" object. You can start/stop new threads, wait and notify locks and even use of synchronized functions. var threads = require ( 'core/threads' ); var response = require ( 'net/http/response' ); response . setContentType ( \"text/plain; charset=UTF-8\" ); // Define a JavaScript function function runnable () { response . println ( \"Hello World from a Thread!\" ); }; // Pass a JavaScript function var worker = threads . create ( runnable , \"I am a thread\" ); response . println ( worker . getName ()); worker . start (); worker . join (); // to be able to print to the response response . flush (); response . close (); Be sure that you use this module with caution! References Did you like it? Do you plan to base your development on Eclipse Dirigible against the Enterprise JavaScript? Everything you need to know about it is at http://api.dirigible.io and http://samples.dirigible.io . Enjoy!","title":"Why Enterprise JavaScript?"},{"location":"2016/08/01/blogs-why-enterprise-js/#database-access","text":"Very natural for a Java-saurus is to use the JDBC API for access and management of relational databases. It provides classes and methods for the manipulation of the data and the metadata. It is powerful enough and in the same time, well known, so can we reuse it? The module db/database gives the port of the main JDBC objects for data management - Datasource, Connection, Statement, ResultSet. An example of how to query the records from a table and print the result into the response stream looks like this: var database = require ( 'db/database' ); var response = require ( 'net/http/response' ); var datasource = database . getDatasource (); // default var connection = datasource . getConnection (); try { var statement = connection . prepareStatement ( \"select * from DGB_FILES where FILE_PATH like ?\" ); var i = 0 ; statement . setString ( ++ i , \"%\" ); var resultSet = statement . executeQuery (); while ( resultSet . next ()) { response . println ( \"[path]: \" + resultSet . getString ( \"FILE_PATH\" )); } resultSet . close (); statement . close (); } catch ( e ) { console . trace ( e ); response . println ( e . message ); } finally { connection . close (); } response . flush (); response . close ();","title":"Database Access"},{"location":"2016/08/01/blogs-why-enterprise-js/#http-communication","text":"Another very popular API used in the above example is the Servlet API giving the access from the service body to the current Request, Response and Session objects. You can find more info in the modules net/http/request , net/http/response and net/http/session . What we decided to include also in the Enterprise JavaScript is the de facto standard component for handling of the uploaded binary files. Here is the moment to send big thanks to the Apache guys. Of course, we simplified a lot the API itself and added some utilities functions to make it convenient for the JavaScript developers: var upload = require ( 'net/http/upload' ); var request = require ( 'net/http/request' ); var response = require ( 'net/http/response' ); if ( request . getMethod () === \"POST\" ) { if ( upload . isMultipartContent ()) { var files = upload . parseRequest (); files . forEach ( function ( file ) { response . println ( \"[File Name] \" + file . name ); response . println ( \"[File Data]\" ); // response.println(file.data); // as a raw byte array or as a string below response . println ( String . fromCharCode . apply ( null , file . data )); }); } else { response . println ( \"The request's content must be 'multipart'\" ); } } else if ( request . getMethod () === \"GET\" ) { response . println ( \"Use POST request.\" ); } response . flush (); response . close (); More info can be found in module net/http/upload . We also needed an HTTP client API to call external services. This one we defined similar to jQuery, no matter it is backed by the Apache's HTTPClient. You can use the module net/http/client to retrieve the raw data from an endpoint and print it to the response stream: var http = require ( 'net/http/client' ); var response = require ( 'net/http/response' ); var options = { method : 'GET' , // default host : 'http://services.odata.org' , port : 80 , path : '/V4/Northwind/Northwind.svc/' , binary : false }; var httpResponse = http . request ( options ); response . println ( httpResponse . statusMessage ); response . println ( httpResponse . data ); response . flush (); response . close (); or even simpler: var httpResponse = httpClient . get ( 'http://services.odata.org/V4/Northwind/Northwind.svc/' );","title":"HTTP Communication"},{"location":"2016/08/01/blogs-why-enterprise-js/#websockets-and-soap","text":"If you need bi-directional communication channel in your use case, you can utilize the WebSockets module net/websocket . You can implement a handler for the received messages as well as to send messages back through the channel of the same session. Can we name this API \"Enterprise\" without including the SOAP web services? Of course, not! In the module net/soap you can find how to construct a SOAP massage in order to be able to call an external SOAP web service. You can even create your own SOAP web service! Although, we are not completely sure why you would do this, but you can.","title":"WebSockets and SOAP"},{"location":"2016/08/01/blogs-why-enterprise-js/#files-and-streams","text":"To standardize the IO access to the underlying file system we added the module io/files . How to create, copy and delete a file with this module is shown below: files . createFile ( \"../temp/file1.txt\" ); files . copy ( \"../temp/file1.txt\" , \"../temp/file2.txt\" ); files . delete ( \"../temp/file2.txt\" ); You can also read, write and inspect the file and folders attributes. Reading from and writing to streams, for example, memory byte arrays, is possible via the module net/streams .","title":"Files and Streams"},{"location":"2016/08/01/blogs-why-enterprise-js/#indexing-messaging-mail","text":"The modules under the main package service e.g. service/indexing , service/messaging , and so on represents the underlying platform services. These services, as well as their management and operation, are usually provided by the platform on which Eclipse Dirigible is running. The quality and the performance of the services themselves can differ depending on the platform provider, but the goal here is to provide a unified manner of using such standard services, or at least the common denominator of their capabilities. For instance if you want to create a free text search index, you can do it like this: var indexing = require ( 'service/indexing' ); var response = require ( 'net/http/response' ); var index = indexing . getIndex ( \"myIndex\" ); var document1 = { \"id\" : \"1\" , \"content\" : \"some cool content 1\" }; var document2 = { \"id\" : \"2\" , \"content\" : \"some cool content 2\" }; index . add ( document1 ); index . add ( document2 ); var results = index . search ( \"cool\" ); for ( var i = 0 ; i < results . length ; i ++ ) { var result = results [ i ]; response . println ( \"[Found for 'cool']: \" + result . id ); } results = index . search ( \"1\" ); for ( var i = 0 ; i < results . length ; i ++ ) { result = results [ i ]; response . println ( \"[Found for '1']: \" + result . id ); } results = index . search ( \"2\" ); for ( var i = 0 ; i < results . length ; i ++ ) { result = results [ i ]; response . println ( \"[Found for '2']: \" + result . id ); } index . clear (); response . flush (); response . close (); Eclipse Dirigible provides default sample implementations of all the service APIs. To be able to redirect the API to the real platform service, you need to implement an adapter plugin to this service if it is not already available and then to configure the usage.","title":"Indexing, Messaging, Mail..."},{"location":"2016/08/01/blogs-why-enterprise-js/#utilities","text":"Another set of modules under the package utils , provides some commodity functionality backed mainly by the Apache Commons - utils/base64 , utils/digest , utils/hex , etc. var hex = require ( 'utils/hex' ); var response = require ( 'net/http/response' ); response . println ( hex . encode ( 'Hex Encoded' )); response . println ( hex . decode ( '48657820456e636f646564' )); response . flush (); response . close ();","title":"Utilities"},{"location":"2016/08/01/blogs-why-enterprise-js/#threads","text":"What would you say to have thread management API in JavaScript? This is missing even in the most popular - Node.js framework. In the Enterprise JavaScript module core/threads you can use a simple function as a \"runnable\" object. You can start/stop new threads, wait and notify locks and even use of synchronized functions. var threads = require ( 'core/threads' ); var response = require ( 'net/http/response' ); response . setContentType ( \"text/plain; charset=UTF-8\" ); // Define a JavaScript function function runnable () { response . println ( \"Hello World from a Thread!\" ); }; // Pass a JavaScript function var worker = threads . create ( runnable , \"I am a thread\" ); response . println ( worker . getName ()); worker . start (); worker . join (); // to be able to print to the response response . flush (); response . close (); Be sure that you use this module with caution!","title":"Threads"},{"location":"2016/08/01/blogs-why-enterprise-js/#references","text":"Did you like it? Do you plan to base your development on Eclipse Dirigible against the Enterprise JavaScript? Everything you need to know about it is at http://api.dirigible.io and http://samples.dirigible.io .","title":"References"},{"location":"2016/08/01/blogs-why-enterprise-js/#enjoy","text":"","title":"Enjoy!"},{"location":"2016/08/04/news-new-release-2-5/","text":"New version 2.5.160804-R released. Features Enterprise JavaScript API http://www.dirigible.io/api/index.html Built-in (console) Core (assert, config, globals, context, env, threads) Database (database) IO (files, streams) Net (soap, websocket) HTTP (request, response, session, client, upload, user) Services (exec, mail, messaging, indexing) Utils (base64, digest, hex, uuid, xml, xss Templates and Samples updates Generation services for DataStructure, ScriptingService, WebContent and WebContent for Entity Bugfixes and refactoring... Blogs Why Enterprise JavaScript? Operational The full list of bug-fixes and enhancements can be found here . The source code is available at GitHub repository here . The instant trial is updated accordingly with the released version here . Enjoy!","title":"Release 2.5.160804-R"},{"location":"2016/08/04/news-new-release-2-5/#features","text":"Enterprise JavaScript API http://www.dirigible.io/api/index.html Built-in (console) Core (assert, config, globals, context, env, threads) Database (database) IO (files, streams) Net (soap, websocket) HTTP (request, response, session, client, upload, user) Services (exec, mail, messaging, indexing) Utils (base64, digest, hex, uuid, xml, xss Templates and Samples updates Generation services for DataStructure, ScriptingService, WebContent and WebContent for Entity Bugfixes and refactoring...","title":"Features"},{"location":"2016/08/04/news-new-release-2-5/#blogs","text":"Why Enterprise JavaScript?","title":"Blogs"},{"location":"2016/08/04/news-new-release-2-5/#operational","text":"The full list of bug-fixes and enhancements can be found here . The source code is available at GitHub repository here . The instant trial is updated accordingly with the released version here .","title":"Operational"},{"location":"2016/08/04/news-new-release-2-5/#enjoy","text":"","title":"Enjoy!"},{"location":"2016/08/09/how-to-run-dirigible-anywhere-microsoft-azure/","text":"This blog is the first of series of blogs on the hot topic - \"How to Run Dirigible Anywhere?\" . Our first target to run Eclipse Dirigible on is Microsoft Azure . Micrsoft Azure Why Microsoft Azure? Microsoft Azure public cloud has proven to be mature enough to run your enterprise bussines applications, scale your business, benefit from the variety of services it provides, simplify the complex environments, pay only for what you've used and a lot more. It seems to be the right place to run your one Eclipse Dirigible instance. Here are some resources on why to choose Microsoft Azure: What is Azure Business Apps on Azure Case Studies Steps Bellow you can find the steps of how to deploy Eclipse Dirigible on Microsoft Azure. Sing Up for Microsoft Azure. To benefit from the 1 month free trial, you should have a Microsft Account, or you should create a new account. To sign up for Microsoft Azure, go to https://azure.microsoft.com and start the free trial. With the Microsoft Azure subscribtion, you will have access to 20+ availability zones around the globe, 14 virtual machines , CDN , IoT services, Hadoop and many more. NOTE: You can register only once for the free trial! Log in to Microsoft Azure Portal. The Microsoft Azure Portal is a central place for management, operations, delivery and even development of your cloud services and solutions. Create new VM with Tomcat server. To deploy Eclipse Dirigible on Microsoft Azure, you need a virtual machine equiped with JDK 6+ and Tomcat . Luckily, the provisioning of VMs in Azure is really easy and you can select between a large set of templates. Click on the New button and search for 'tomcat' . Create a new VM with the \"Apache Tomcat 8\" template, published by \"Microsoft\" . NOTE: Select the \"Pin to dashboard\" checkbox to add the VM to the portal's dashboard. Creating the VM may take up to 5 minutes, so relax, lay back and wait patiently for it. On your dashboard, you will see a tile with the VM info. Wait until the VM is in \"Running\" state. 4. Deploy Eclipse Dirigible. * Before deploying Eclipse Dirigible, ypu can get rid of some of the default content deployed with the Tomcat server. To do that, you benefit from some of the finest web-based development tools, that Azure offers. 1. Click on your WEB APP tile. 2. From the menu, click on the Tools bar and launch the App Service Editor (Preview) . 3. The web-based workbench should be displayed, with the files and folders under the wwwroot directory on the VM. 4. Navigate to \"bin/apache-tomcat-8.0.33/webapps\" and delete all files and folders under this directory. 5. Close the App Service Editor (Preview) tool and go back to your WEB APP settings page. 6. Now, you are going to use another web-based tool - the good old Console . 7. Navigate to the \"webapps\" folder of the server. cd bin/apache-tomcat-8.0.33/webapps NOTE: Unfortunately, the Console lacks the paste functionality, so you should type manualy each command in it. Now it's time to download and run the latest release of Eclipse Dirigible on this VM. Go to http://download.eclipse.org/dirigible/ and open the latest release. From the different types of downloads, you need the \"Tomcat\" and more specificaly the \"allinone\" . Right click on \"tomcat/allinone/ROOT.war\" and copy the link address. NOTE: At the time of this blog, the latest relase was 2.5. Go back to the Azure web-based Console and execute under the \"webapps\" directory the following command: curl http://download.eclipse.org/dirigible/drops/R-2.5-201608041010/tomcat/allinone/ROOT.war -o ROOT.war NOTE: The address from the curl request is the one that you've copied earlier, from the \"Eclipse Dirigible Downloads\" page. The whole download may take up to 5 min. After the download is completed, the Tomcat server will extract and run the ROOT.war. After a while, Eclipse Dirigible will be accessible through the HTTP. However, there is one more step that needs to be done, before you can use it. Assign the Eclipse Dirigible specific roles. The last step is to crete a user and assign it the following roles, in order to use Eclipse Dirigible: Everyone Developer Operator Use the web-based App Service Editor (Preview) to edit \"bin/apache-tomcat-8.0.33/conf/tomcat-users.xml\" . Add the following content: ` <role rolename=\"Everyone\"/> <role rolename=\"Developer\"/> <role rolename=\"Operator\"/> <user username=\"dirigible\" password=\"dirigible\" roles=\"Developer,Operator,Everyone\"/> ` 3. Restart the VM to apply the users configuration. Launch Eclipse Dirigible. Finally, you can launch the Eclipse Dirigible platform. To do that, click on the Browse button from the WEB APP settings. References Bookstore Sample Enjoy!","title":"How to Run Dirigible Anywhere - Microsoft Azure?"},{"location":"2016/08/09/how-to-run-dirigible-anywhere-microsoft-azure/#micrsoft-azure","text":"Why Microsoft Azure? Microsoft Azure public cloud has proven to be mature enough to run your enterprise bussines applications, scale your business, benefit from the variety of services it provides, simplify the complex environments, pay only for what you've used and a lot more. It seems to be the right place to run your one Eclipse Dirigible instance. Here are some resources on why to choose Microsoft Azure: What is Azure Business Apps on Azure Case Studies","title":"Micrsoft Azure"},{"location":"2016/08/09/how-to-run-dirigible-anywhere-microsoft-azure/#steps","text":"Bellow you can find the steps of how to deploy Eclipse Dirigible on Microsoft Azure. Sing Up for Microsoft Azure. To benefit from the 1 month free trial, you should have a Microsft Account, or you should create a new account. To sign up for Microsoft Azure, go to https://azure.microsoft.com and start the free trial. With the Microsoft Azure subscribtion, you will have access to 20+ availability zones around the globe, 14 virtual machines , CDN , IoT services, Hadoop and many more. NOTE: You can register only once for the free trial! Log in to Microsoft Azure Portal. The Microsoft Azure Portal is a central place for management, operations, delivery and even development of your cloud services and solutions. Create new VM with Tomcat server. To deploy Eclipse Dirigible on Microsoft Azure, you need a virtual machine equiped with JDK 6+ and Tomcat . Luckily, the provisioning of VMs in Azure is really easy and you can select between a large set of templates. Click on the New button and search for 'tomcat' . Create a new VM with the \"Apache Tomcat 8\" template, published by \"Microsoft\" . NOTE: Select the \"Pin to dashboard\" checkbox to add the VM to the portal's dashboard. Creating the VM may take up to 5 minutes, so relax, lay back and wait patiently for it. On your dashboard, you will see a tile with the VM info. Wait until the VM is in \"Running\" state. 4. Deploy Eclipse Dirigible. * Before deploying Eclipse Dirigible, ypu can get rid of some of the default content deployed with the Tomcat server. To do that, you benefit from some of the finest web-based development tools, that Azure offers. 1. Click on your WEB APP tile. 2. From the menu, click on the Tools bar and launch the App Service Editor (Preview) . 3. The web-based workbench should be displayed, with the files and folders under the wwwroot directory on the VM. 4. Navigate to \"bin/apache-tomcat-8.0.33/webapps\" and delete all files and folders under this directory. 5. Close the App Service Editor (Preview) tool and go back to your WEB APP settings page. 6. Now, you are going to use another web-based tool - the good old Console . 7. Navigate to the \"webapps\" folder of the server. cd bin/apache-tomcat-8.0.33/webapps NOTE: Unfortunately, the Console lacks the paste functionality, so you should type manualy each command in it. Now it's time to download and run the latest release of Eclipse Dirigible on this VM. Go to http://download.eclipse.org/dirigible/ and open the latest release. From the different types of downloads, you need the \"Tomcat\" and more specificaly the \"allinone\" . Right click on \"tomcat/allinone/ROOT.war\" and copy the link address. NOTE: At the time of this blog, the latest relase was 2.5. Go back to the Azure web-based Console and execute under the \"webapps\" directory the following command: curl http://download.eclipse.org/dirigible/drops/R-2.5-201608041010/tomcat/allinone/ROOT.war -o ROOT.war NOTE: The address from the curl request is the one that you've copied earlier, from the \"Eclipse Dirigible Downloads\" page. The whole download may take up to 5 min. After the download is completed, the Tomcat server will extract and run the ROOT.war. After a while, Eclipse Dirigible will be accessible through the HTTP. However, there is one more step that needs to be done, before you can use it. Assign the Eclipse Dirigible specific roles. The last step is to crete a user and assign it the following roles, in order to use Eclipse Dirigible: Everyone Developer Operator Use the web-based App Service Editor (Preview) to edit \"bin/apache-tomcat-8.0.33/conf/tomcat-users.xml\" . Add the following content: ` <role rolename=\"Everyone\"/> <role rolename=\"Developer\"/> <role rolename=\"Operator\"/> <user username=\"dirigible\" password=\"dirigible\" roles=\"Developer,Operator,Everyone\"/> ` 3. Restart the VM to apply the users configuration. Launch Eclipse Dirigible. Finally, you can launch the Eclipse Dirigible platform. To do that, click on the Browse button from the WEB APP settings.","title":"Steps"},{"location":"2016/08/09/how-to-run-dirigible-anywhere-microsoft-azure/#references","text":"Bookstore Sample","title":"References"},{"location":"2016/08/09/how-to-run-dirigible-anywhere-microsoft-azure/#enjoy","text":"","title":"Enjoy!"},{"location":"2016/08/17/sap-summer-practice/","text":"My name is Viktor and in the past two weeks, I took part in the Summer Student Practice in SAP Labs Bulgaria, which brought together IT students from different Bulgarian universities: Sofia University \u201cSt. Kliment Ohridski\u201d, Technical University \u2013 Sofia, University of Plovdiv \"Paisii Hilendarski\" and others. Within two weeks we, the participants, had the opportunity to expand our knowledge about modern IT topics and learn from professionals how to develop software \u2013 both theoretically and practically. Volunteers from SAP shared with us their professional experience in software architecture and design. During the first few days the schedule included lectures and theoretical introduction to the most \u201chot\u201d technology trends, methodologies and principles of project management, user experience, prototyping, documentation, maintenance and lifecycle of software products. Then, based on everyone\u2019s personal preferences, we were divided into teams. Each team, with the help of a mentor, had to prepare a practical project, based on the acquired knowledge, and present it on the last day. The Eclipse Dirigible platform grabbed my attention and I wanted to try it out. I was a part of a team of five: Vili, Boris, Desi, Svilen, and I. Here are we in the beginning - designing the application. And here are some words about the team project from each of us: Viktor: We had to develop a project using Eclipse Dirigible and we got the idea to make a \u201ctravel guide\u201d application. The plan was to gather everything you need to plan your trip in one place. We wanted every part of the application to be independent so we decided to use microservices architecture. When we saw what Eclipse Dirigible offers, we knew that it would be perfect for our needs. It turned out that it\u2019s really easy to make RESTful services in Eclipse Dirigible in just a few minutes, so we had enough time to focus on the implementation details. Each of us worked on a different part of the project, with its own user interface, and in the end we merged them together. My contribution to the project were two of those microservices: one for user profiles and one for finding hotels by given destinations and booking hotel rooms. Eclipse Dirigible helped me a lot with generating the user interface for the hotels service based on the AngularJS Framework. With just a little modification and coding, I managed to make a good looking and responsive web page. Now users can filter the hotels by different criteria, search for them on the map, check the available rooms and reserve them. Vili: Working in a team of young, educated and ambitious people is such a precious experience to me. We put our hearts and minds in this project. We had a week to work on this application that helps all the people out there to organize the desired trip. The design pattern we applied on this application is MVC. When it comes to data, we used JQuery Ajax requests and REST services. Furthermore, a great advantage of the Eclipse Dirigible, the platform we used, is its ability to generate automatically REST services depending on the built model. As all other developing platforms, Eclipse Dirigible has its own advantages and disadvantages. However, the 'crew' behind the idea puts every effort to fix the bugs. Hence, it's up to you to try and feel the adventure of Eclipse Dirigible! Desi: When you want to develop your application as fast as you can, Eclipse Dirigible helps you to concentrate on your business logic. Also, the auto-generated CRUD operations can help you out if you\u2019re not really sure how things are done in the back-end. The generated user interface is the best thing for people who don't like to deal with front-end. Being part of this project also introduced me to AngularJS and the MVC style. My part was to implement an Events service where you can find different types of events near a specified location or create your own public event. Svilen: Our two weeks of practice in SAP were very intriguing. We had a couple of lectures and a team project. Our team of five had to develop a WEB Appliaction by our own idea using the Eclipse Dirigible platform. We\u2019ve decided to create the app based on independent micro-services. I took part by creating a small service about transports - (Storky Transports Web Page). Our project is based on the MVC design pattern thanks to AngularJS. My application has two own entities in the database, one for Tickets, and one for Transports and one master entity about Cities and their airports. The data is being transfered by HTTP and REST. From my application you can choose your type of travel, city of departure, city of arrival and date. To create the RESTful API I used Eclipse Dirigible's automated scripting services for each of the entities from my database. Thanks to that, whatever the operation, I receive/pass the data in JSON format and easily can import it in my view with angular. After you choose the type of travel, an angular controller sends GET request to the server and only cities that have transport to or from are being displayed. The \"Search\" button has attached function from other angular controller that serves the tickets entity. The function sends another GET request, this time to a service of database view, filters the cities in the back-end and returns them again in JSON. The controller imports them as a view in the HTML and you can sort them by price or class thanks to angular. That's all. Boris: My part of the application is divided into two similar parts: Entertainments : When from another page (\u201cWelcome\u201d, \u201cTransport\u201d, \u201cEvents\u201d, \u201cHotels\u201d or \u201cSightseeings\u201d) is being navigated to Entertainments, the name of the destination is automatically put into the textbox bellow the \u201cDestination\u201d label. The Entertainments, that are near this city are filtered and are shown together with their entertainment type and category, rating, additional information and destination. The user may, however, delete the name of destination and see all of the entertainments in the database: With the help of the buttons \u201cFirst\u201d, \u201cPrevious\u201d, \u201dNext\u201d, \u201dLast\u201d the user may navigate through all of the entertainments if they are too many. Sightseeings : Summary I found it really easy to develop using Eclipse Dirigible. It provides everything I needed \u2013 from database modeling and management, through RESTful services, to user interface generation. It was the perfect platform. I would say that the Summer Student Practice was a great success. We had a nearly finished the project in just a few days, with a platform we never used before, and in the end everyone had learned something new. Our project got second place in the rank list. Here are we after the presentation.","title":"Summer Practice in SAP"},{"location":"2016/08/17/sap-summer-practice/#viktor","text":"We had to develop a project using Eclipse Dirigible and we got the idea to make a \u201ctravel guide\u201d application. The plan was to gather everything you need to plan your trip in one place. We wanted every part of the application to be independent so we decided to use microservices architecture. When we saw what Eclipse Dirigible offers, we knew that it would be perfect for our needs. It turned out that it\u2019s really easy to make RESTful services in Eclipse Dirigible in just a few minutes, so we had enough time to focus on the implementation details. Each of us worked on a different part of the project, with its own user interface, and in the end we merged them together. My contribution to the project were two of those microservices: one for user profiles and one for finding hotels by given destinations and booking hotel rooms. Eclipse Dirigible helped me a lot with generating the user interface for the hotels service based on the AngularJS Framework. With just a little modification and coding, I managed to make a good looking and responsive web page. Now users can filter the hotels by different criteria, search for them on the map, check the available rooms and reserve them.","title":"Viktor:"},{"location":"2016/08/17/sap-summer-practice/#vili","text":"Working in a team of young, educated and ambitious people is such a precious experience to me. We put our hearts and minds in this project. We had a week to work on this application that helps all the people out there to organize the desired trip. The design pattern we applied on this application is MVC. When it comes to data, we used JQuery Ajax requests and REST services. Furthermore, a great advantage of the Eclipse Dirigible, the platform we used, is its ability to generate automatically REST services depending on the built model. As all other developing platforms, Eclipse Dirigible has its own advantages and disadvantages. However, the 'crew' behind the idea puts every effort to fix the bugs. Hence, it's up to you to try and feel the adventure of Eclipse Dirigible!","title":"Vili:"},{"location":"2016/08/17/sap-summer-practice/#desi","text":"When you want to develop your application as fast as you can, Eclipse Dirigible helps you to concentrate on your business logic. Also, the auto-generated CRUD operations can help you out if you\u2019re not really sure how things are done in the back-end. The generated user interface is the best thing for people who don't like to deal with front-end. Being part of this project also introduced me to AngularJS and the MVC style. My part was to implement an Events service where you can find different types of events near a specified location or create your own public event.","title":"Desi:"},{"location":"2016/08/17/sap-summer-practice/#svilen","text":"Our two weeks of practice in SAP were very intriguing. We had a couple of lectures and a team project. Our team of five had to develop a WEB Appliaction by our own idea using the Eclipse Dirigible platform. We\u2019ve decided to create the app based on independent micro-services. I took part by creating a small service about transports - (Storky Transports Web Page). Our project is based on the MVC design pattern thanks to AngularJS. My application has two own entities in the database, one for Tickets, and one for Transports and one master entity about Cities and their airports. The data is being transfered by HTTP and REST. From my application you can choose your type of travel, city of departure, city of arrival and date. To create the RESTful API I used Eclipse Dirigible's automated scripting services for each of the entities from my database. Thanks to that, whatever the operation, I receive/pass the data in JSON format and easily can import it in my view with angular. After you choose the type of travel, an angular controller sends GET request to the server and only cities that have transport to or from are being displayed. The \"Search\" button has attached function from other angular controller that serves the tickets entity. The function sends another GET request, this time to a service of database view, filters the cities in the back-end and returns them again in JSON. The controller imports them as a view in the HTML and you can sort them by price or class thanks to angular. That's all.","title":"Svilen:"},{"location":"2016/08/17/sap-summer-practice/#boris","text":"My part of the application is divided into two similar parts: Entertainments : When from another page (\u201cWelcome\u201d, \u201cTransport\u201d, \u201cEvents\u201d, \u201cHotels\u201d or \u201cSightseeings\u201d) is being navigated to Entertainments, the name of the destination is automatically put into the textbox bellow the \u201cDestination\u201d label. The Entertainments, that are near this city are filtered and are shown together with their entertainment type and category, rating, additional information and destination. The user may, however, delete the name of destination and see all of the entertainments in the database: With the help of the buttons \u201cFirst\u201d, \u201cPrevious\u201d, \u201dNext\u201d, \u201dLast\u201d the user may navigate through all of the entertainments if they are too many. Sightseeings :","title":"Boris:"},{"location":"2016/08/17/sap-summer-practice/#summary","text":"I found it really easy to develop using Eclipse Dirigible. It provides everything I needed \u2013 from database modeling and management, through RESTful services, to user interface generation. It was the perfect platform. I would say that the Summer Student Practice was a great success. We had a nearly finished the project in just a few days, with a platform we never used before, and in the end everyone had learned something new. Our project got second place in the rank list. Here are we after the presentation.","title":"Summary"},{"location":"2016/08/18/how-to-run-dirigible-anywhere-microsoft-azure-part-2/","text":"This blog is part of the \"How to Run Dirigible Anywhere?\" series. In this edition, we will see how to simplify the deployment process on Microsoft Azure . Overview Do you remember the first blog, about the Microsoft Azure and how to run Eclipse Dirigible on it ( How to Run Dirigible Anywhere - Microsoft Azure )? In that blog, there were a lot of steps, before we can get Eclipse Dirigible up and running on Azure. Now, it's time to simplify the steps and narrow them down to only few mouse clicks. How is that possible? Thanks to Azure Quickstart Templates and more specifically to Azure App Service Samples - Tomcat Template . Steps Bellow, you can find the steps of how to deploy Eclipse Dirigible on Microsoft Azure through the templates available on DirigibleLabs . The templates that you can choose from are: Dirigible Trial - Azure Template This template offers the Trial Distribution of Eclipse Dirigible, which is available on http://trial.dirigible.io . Dirigible Tomcat - Azure Template This template offers the Tomcat Distribution of Eclipse Dirigible, protected with BASIC authentication, pre-configured with Default User and using the Apache Derby database. To deploy your own instance of Eclipse Dirigible on Microsoft Azure , first choose one of the available templates and then follow the steps: Click the Deploy to Azure button. Fill in the required properties. 3. Wait until the deployment is finished. 4. Use the links from the Deploy page, or log into your Microsoft Azure Portal . 5. Now, you are ready to start developing with Eclipse Dirigible on Microsoft Azure . References Help API Bookstore Sample How to Run Dirigible Anywhere - Microsoft Azure? Enjoy!","title":"How to Run Dirigible Anywhere - Microsoft Azure - Part II?"},{"location":"2016/08/18/how-to-run-dirigible-anywhere-microsoft-azure-part-2/#overview","text":"Do you remember the first blog, about the Microsoft Azure and how to run Eclipse Dirigible on it ( How to Run Dirigible Anywhere - Microsoft Azure )? In that blog, there were a lot of steps, before we can get Eclipse Dirigible up and running on Azure. Now, it's time to simplify the steps and narrow them down to only few mouse clicks. How is that possible? Thanks to Azure Quickstart Templates and more specifically to Azure App Service Samples - Tomcat Template .","title":"Overview"},{"location":"2016/08/18/how-to-run-dirigible-anywhere-microsoft-azure-part-2/#steps","text":"Bellow, you can find the steps of how to deploy Eclipse Dirigible on Microsoft Azure through the templates available on DirigibleLabs . The templates that you can choose from are: Dirigible Trial - Azure Template This template offers the Trial Distribution of Eclipse Dirigible, which is available on http://trial.dirigible.io . Dirigible Tomcat - Azure Template This template offers the Tomcat Distribution of Eclipse Dirigible, protected with BASIC authentication, pre-configured with Default User and using the Apache Derby database. To deploy your own instance of Eclipse Dirigible on Microsoft Azure , first choose one of the available templates and then follow the steps: Click the Deploy to Azure button. Fill in the required properties. 3. Wait until the deployment is finished. 4. Use the links from the Deploy page, or log into your Microsoft Azure Portal . 5. Now, you are ready to start developing with Eclipse Dirigible on Microsoft Azure .","title":"Steps"},{"location":"2016/08/18/how-to-run-dirigible-anywhere-microsoft-azure-part-2/#references","text":"Help API Bookstore Sample How to Run Dirigible Anywhere - Microsoft Azure?","title":"References"},{"location":"2016/08/18/how-to-run-dirigible-anywhere-microsoft-azure-part-2/#enjoy","text":"","title":"Enjoy!"},{"location":"2016/09/12/the-java-saurus/","text":"Have you met one? Are you one? Do you even know what this is? A long, long time ago\u2026 in March at the EclipseCon 2016, Vladimir Pavlov from SAP talked about Eclipse Dirigible, and, here I will quote, \u201chow the development of cloud applications and services with Eclipse Dirigible looks like in the eyes of a hard-core veteran Java guy.\u201d If you are curious, you can see the slides here . This is the first time people met the Java-saurus and started telling stories about it. Some say it is old, some say it is just old-fashioned, but if you ask us, the Java-saurus simply is too attached to its little Java-dinosaurs. Eclipse Dirigible is a very open-minded platform, welcoming all developers, no matter how experienced they are and no matter what programming languages they use. If you are a Java-saurus or know other Java dinosaurs that are willing to change the way they view the world, come on board of Eclipse Dirigible and enjoy the high-quality journey through the fields of JavaScript, a variety of RESTful services and widely used frameworks, and much much more. 5\u2026 4\u2026 3\u2026 2\u2026 1\u2026 and\u2026 Disclaimer: Any similarity to real-life dinosaurs is purely coincidental.","title":"The Java-saurus"},{"location":"2016/10/05/news-new-milestone-2-6-1/","text":"New version 2.6.161005-M1 released. Features Enhancements on the \"Templates\" authoring capabilities Swagger integration for API discovery and test Enterprise JavaScript API new modules Generation services exposed as REST services Dependency references feature Templates and Samples updates Bugfixes and refactoring... Blogs How to Run Dirigible Anywhere - Microsoft Azure? Summer Practice in SAP How to Run Dirigible Anywhere - Microsoft Azure - Part II? The Java-saurus Operational The full list of bug-fixes and enhancements can be found here . The source code is available at GitHub repository here . The instant trial is updated accordingly with the released version here . Enjoy!","title":"Milestone 2.6.161005-M1"},{"location":"2016/10/05/news-new-milestone-2-6-1/#features","text":"Enhancements on the \"Templates\" authoring capabilities Swagger integration for API discovery and test Enterprise JavaScript API new modules Generation services exposed as REST services Dependency references feature Templates and Samples updates Bugfixes and refactoring...","title":"Features"},{"location":"2016/10/05/news-new-milestone-2-6-1/#blogs","text":"How to Run Dirigible Anywhere - Microsoft Azure? Summer Practice in SAP How to Run Dirigible Anywhere - Microsoft Azure - Part II? The Java-saurus","title":"Blogs"},{"location":"2016/10/05/news-new-milestone-2-6-1/#operational","text":"The full list of bug-fixes and enhancements can be found here . The source code is available at GitHub repository here . The instant trial is updated accordingly with the released version here .","title":"Operational"},{"location":"2016/10/05/news-new-milestone-2-6-1/#enjoy","text":"","title":"Enjoy!"},{"location":"2016/10/14/news-new-milestone-2-6-2/","text":"New version 2.6.161014-M2 released. Features Configurable Local Repository Direct template generation method Template for mobile apps CMIS Simple Local Repository API \u2013 Extensions, Error Bugfixes Media [Video] Basics-Documentation Operational The full list of bug-fixes and enhancements can be found here . The source code is available at GitHub repository here . The instant trial is updated accordingly with the released version here . Enjoy!","title":"Milestone 2.6.161014-M2"},{"location":"2016/10/14/news-new-milestone-2-6-2/#features","text":"Configurable Local Repository Direct template generation method Template for mobile apps CMIS Simple Local Repository API \u2013 Extensions, Error Bugfixes","title":"Features"},{"location":"2016/10/14/news-new-milestone-2-6-2/#media","text":"[Video] Basics-Documentation","title":"Media"},{"location":"2016/10/14/news-new-milestone-2-6-2/#operational","text":"The full list of bug-fixes and enhancements can be found here . The source code is available at GitHub repository here . The instant trial is updated accordingly with the released version here .","title":"Operational"},{"location":"2016/10/14/news-new-milestone-2-6-2/#enjoy","text":"","title":"Enjoy!"},{"location":"2016/10/21/news-new-milestone-2-6-3/","text":"New version 2.6.161021-M3 released. Features New Mobile App Templates Lifecycle API Workspace API Extendable Entity Service Template Bugfixes Media Join us: [EclipseCon] Enterprise JavaScript ... what the heck? [EclipseCon] Native mobile applications with Dirigible and Tabris [EclipseCon] WebSockets and Equinox OSGi in a Servlet Container Operational The full list of bug-fixes and enhancements can be found here . The source code is available at GitHub repository here . The instant trial is updated accordingly with the released version here . Enjoy!","title":"Milestone 2.6.161021-M3"},{"location":"2016/10/21/news-new-milestone-2-6-3/#features","text":"New Mobile App Templates Lifecycle API Workspace API Extendable Entity Service Template Bugfixes","title":"Features"},{"location":"2016/10/21/news-new-milestone-2-6-3/#media","text":"Join us: [EclipseCon] Enterprise JavaScript ... what the heck? [EclipseCon] Native mobile applications with Dirigible and Tabris [EclipseCon] WebSockets and Equinox OSGi in a Servlet Container","title":"Media"},{"location":"2016/10/21/news-new-milestone-2-6-3/#operational","text":"The full list of bug-fixes and enhancements can be found here . The source code is available at GitHub repository here . The instant trial is updated accordingly with the released version here .","title":"Operational"},{"location":"2016/10/21/news-new-milestone-2-6-3/#enjoy","text":"","title":"Enjoy!"},{"location":"2016/10/30/news-eclipsecon-eu-2016/","text":"Best EclipseCon Europe ever! For third consecutive year Eclipse Dirigible was presented at this great forum in Ludwigsburg with three sessions. In comparison with the last year now the projects that Eclipse Cloud Development consist of have a clear focus and plan for development areas coverage. The sessions related to Eclipse Dirigible: Enterprise JavaScript ... what the heck? by Nedelcho Delchev Native mobile applications with Dirigible and Tabris by Dimitar Panayotov WebSockets and Equinox OSGi in a Servlet Container by Nedelcho Delchev ... and a lots of fun! ;) See you next year!","title":"EclipseCon Europe 2016"},{"location":"2016/10/30/news-eclipsecon-eu-2016/#see-you-next-year","text":"","title":"See you next year!"},{"location":"2016/11/03/cmis-explorer-at-sap-hana-cloud-platform/","text":"Wondering how you can easily manage the SAP HANA Cloud Platform Document Service through the browser? Now this is possible with the help of Eclipse Dirigible and the CMIS Explorer application. Overview Wondering how you can easily manage the SAP HANA Cloud Platform Document Service through the browser? Now this is possible with the help of Eclipse Dirigible and the CMIS Explorer application. In this blog, you will see how to download, configure, deploy, and run Eclipse Dirigible on the SAP HANA Cloud Platform . After that, you can go through the steps of installing and running the CMIS Explorer application. Download Eclipse Dirigible Download the latest milestone/release, which you can find at http://download.eclipse.org/dirigible/ . Note : At the time of the blog, the latest milestone was M20161021-1818 . From the selected release/milestone, navigate to the HANA Cloud Platform category and download the sap/allinone/ROOT.war file. Create a Document Repository Log in to the SAP HANA Cloud Platform Cockpit. In the Repositories section, open the Document Repositories tab. Create a new document repository. Please remember the values for the Name and the Repository Key , as we will need them later on. Deploy Eclipse Dirigible In the Applications section, open the Java Applications tab. Click on the Deploy Application button. Browse to the ROOT.war file, which you have already downloaded. For the application name, you can specify whatever you want (for example, dirigible, doc, \u2026). Change the runtime to Java Web Tomcat 8 . For the JVM Arguments input, enter this: -DjndiCmisServiceName=<name_of_repository> -DjndiCmisServiceKey=<repository_key> These are the magic settings that will allow the Eclipse Dirigible to connect and use the document repository. List of all available environment variables can be found here . Finally, the Deploy Application wizard should look something like this: Wait till the deployment is finished, but don't start the application yet! Configure Data Source Note : This step can be skipped if the https://hanatrial.ondemand.com landscape is used. Navigate to your application (in this example dirigible ) in the Java Applications tab. In the Configuration section, open the Data Source Bindings tab. Create a New Binding : For the name of the data source, leave the default name. Select the desired DB/Schema ID. Provide the required credentials. Assign Security Roles After deploying the application in the cockpit, click on its name. In the Security section, open the Roles tab. Assign the Developer and Operator roles to your user. Launch Eclipse Dirigible Go back to the Overview section and click on the Start button. Wait till the application is started. Launch Eclipse Dirigible from the Application URLs link. Finally, Eclipse Dirigible has been configured and deployed and is running into your SAP HANA Cloud Platform account. Install the CMIS Explorer The CMIS Explorer is a project in the DirigibleLabs GitHub organization. Open the CMIS Explorer in GitHub, choose Clone or download and then copy the URL. Go back to the Eclipse Dirigible Registry UI . Note : If you are wondering, this is how it looks like: Click on the Develop tile and after that on the Web IDE . Note : If this is the first time you are launching the \"Web IDE\", cancel the \u201cGet Started Project Wizard\u201d. Right-click on the Workspace Explorer and select Team > Clone . Paste the Git URL that you\u2019ve copied earlier. Username and Password are not required, so just click OK . After the project is imported into the workspace, right-click on it and press the Publish button. Expand the project and find the index.html . The application should be visible in the Preview tab, you can copy the link and open it in a new tab. The application URL can be found also through the Eclipse Dirigible Registry UI from Discover > Web . Recap In this tutorial, you have downloaded, configured, deployed, and run Eclipse Dirigible on the SAP HANA Cloud Platform , and you have leveraged the Document Service and the CMIS Explorer application. Enjoy!","title":"Document Service Explorer at SAP HANA Cloud Platform"},{"location":"2016/11/03/cmis-explorer-at-sap-hana-cloud-platform/#overview","text":"Wondering how you can easily manage the SAP HANA Cloud Platform Document Service through the browser? Now this is possible with the help of Eclipse Dirigible and the CMIS Explorer application. In this blog, you will see how to download, configure, deploy, and run Eclipse Dirigible on the SAP HANA Cloud Platform . After that, you can go through the steps of installing and running the CMIS Explorer application.","title":"Overview"},{"location":"2016/11/03/cmis-explorer-at-sap-hana-cloud-platform/#download-eclipse-dirigible","text":"Download the latest milestone/release, which you can find at http://download.eclipse.org/dirigible/ . Note : At the time of the blog, the latest milestone was M20161021-1818 . From the selected release/milestone, navigate to the HANA Cloud Platform category and download the sap/allinone/ROOT.war file.","title":"Download Eclipse Dirigible"},{"location":"2016/11/03/cmis-explorer-at-sap-hana-cloud-platform/#create-a-document-repository","text":"Log in to the SAP HANA Cloud Platform Cockpit. In the Repositories section, open the Document Repositories tab. Create a new document repository. Please remember the values for the Name and the Repository Key , as we will need them later on.","title":"Create a Document Repository"},{"location":"2016/11/03/cmis-explorer-at-sap-hana-cloud-platform/#deploy-eclipse-dirigible","text":"In the Applications section, open the Java Applications tab. Click on the Deploy Application button. Browse to the ROOT.war file, which you have already downloaded. For the application name, you can specify whatever you want (for example, dirigible, doc, \u2026). Change the runtime to Java Web Tomcat 8 . For the JVM Arguments input, enter this: -DjndiCmisServiceName=<name_of_repository> -DjndiCmisServiceKey=<repository_key> These are the magic settings that will allow the Eclipse Dirigible to connect and use the document repository. List of all available environment variables can be found here . Finally, the Deploy Application wizard should look something like this: Wait till the deployment is finished, but don't start the application yet!","title":"Deploy Eclipse Dirigible"},{"location":"2016/11/03/cmis-explorer-at-sap-hana-cloud-platform/#configure-data-source","text":"Note : This step can be skipped if the https://hanatrial.ondemand.com landscape is used. Navigate to your application (in this example dirigible ) in the Java Applications tab. In the Configuration section, open the Data Source Bindings tab. Create a New Binding : For the name of the data source, leave the default name. Select the desired DB/Schema ID. Provide the required credentials.","title":"Configure Data Source"},{"location":"2016/11/03/cmis-explorer-at-sap-hana-cloud-platform/#assign-security-roles","text":"After deploying the application in the cockpit, click on its name. In the Security section, open the Roles tab. Assign the Developer and Operator roles to your user.","title":"Assign Security Roles"},{"location":"2016/11/03/cmis-explorer-at-sap-hana-cloud-platform/#launch-eclipse-dirigible","text":"Go back to the Overview section and click on the Start button. Wait till the application is started. Launch Eclipse Dirigible from the Application URLs link. Finally, Eclipse Dirigible has been configured and deployed and is running into your SAP HANA Cloud Platform account.","title":"Launch Eclipse Dirigible"},{"location":"2016/11/03/cmis-explorer-at-sap-hana-cloud-platform/#install-the-cmis-explorer","text":"The CMIS Explorer is a project in the DirigibleLabs GitHub organization. Open the CMIS Explorer in GitHub, choose Clone or download and then copy the URL. Go back to the Eclipse Dirigible Registry UI . Note : If you are wondering, this is how it looks like: Click on the Develop tile and after that on the Web IDE . Note : If this is the first time you are launching the \"Web IDE\", cancel the \u201cGet Started Project Wizard\u201d. Right-click on the Workspace Explorer and select Team > Clone . Paste the Git URL that you\u2019ve copied earlier. Username and Password are not required, so just click OK . After the project is imported into the workspace, right-click on it and press the Publish button. Expand the project and find the index.html . The application should be visible in the Preview tab, you can copy the link and open it in a new tab. The application URL can be found also through the Eclipse Dirigible Registry UI from Discover > Web .","title":"Install the CMIS Explorer"},{"location":"2016/11/03/cmis-explorer-at-sap-hana-cloud-platform/#recap","text":"In this tutorial, you have downloaded, configured, deployed, and run Eclipse Dirigible on the SAP HANA Cloud Platform , and you have leveraged the Document Service and the CMIS Explorer application.","title":"Recap"},{"location":"2016/11/03/cmis-explorer-at-sap-hana-cloud-platform/#enjoy","text":"","title":"Enjoy!"},{"location":"2016/11/16/news-java2days-2016/","text":"Eclipse Dirigible took part of the Java2Days event in Expo Center (IEC) Sofia, Bulgaria. Vladimir Pavlov presented his view on the Cloud Development with Dirigible in the Eyes of a Java-saurus Cloud Development with Dirigible in the Eyes of a Java-saurus from Vladimir Pavlov All Java-saurus friends around the world, how do you feel now? Congrats!","title":"Java2Days 2016"},{"location":"2016/11/16/news-java2days-2016/#congrats","text":"","title":"Congrats!"},{"location":"2016/11/22/news-new-milestone-2-6-4/","text":"New version 2.6.161122-M4 released. Features RAP 3.2 version adapted Eclipse Oxygen version adapted CMIS with Destination support Passwords API Bugfixes Media Greatest EclipseCon ever: [EclipseCon] Enterprise JavaScript ... what the heck? [EclipseCon] Native mobile applications with Dirigible and Tabris [EclipseCon] WebSockets and Equinox OSGi in a Servlet Container Operational The full list of bug-fixes and enhancements can be found here . The source code is available at GitHub repository here . The instant trial is updated accordingly with the released version here . Enjoy!","title":"Milestone 2.6.161122-M4"},{"location":"2016/11/22/news-new-milestone-2-6-4/#features","text":"RAP 3.2 version adapted Eclipse Oxygen version adapted CMIS with Destination support Passwords API Bugfixes","title":"Features"},{"location":"2016/11/22/news-new-milestone-2-6-4/#media","text":"Greatest EclipseCon ever: [EclipseCon] Enterprise JavaScript ... what the heck? [EclipseCon] Native mobile applications with Dirigible and Tabris [EclipseCon] WebSockets and Equinox OSGi in a Servlet Container","title":"Media"},{"location":"2016/11/22/news-new-milestone-2-6-4/#operational","text":"The full list of bug-fixes and enhancements can be found here . The source code is available at GitHub repository here . The instant trial is updated accordingly with the released version here .","title":"Operational"},{"location":"2016/11/22/news-new-milestone-2-6-4/#enjoy","text":"","title":"Enjoy!"},{"location":"2016/12/02/news-innoweek-sap-2016/","text":"It is already a tradition the team(s) behind the Eclipse Dirigible located at SAP Labs Sofia to take part of the InnoWeek event. This year we were quite ambitious - we planned to build an end to end system for cloud development from Idea-to-Market. The modules we decided to be part of the initial built-in set of the plugins were: Define Ideas Solutions Projects Develop Code Models Issues Tasks Discover Documents Databases Services Sites Wikis Infrastructure Clusters Containers Templates Deployments Identity and Access Users Roles Assignments Profile Monitoring Market Thanks to the team's innovation spirit the \"ZEUS\" project was born. It combines the best from Kubernetes cloud management capabilities with the Dirigible rapid development techniques and contributes project management utilities. The sources of the ZEUS modules can be found as usual under DirigibleLabs on GitHub - ZEUS . The demo by Martin and Assia was great and we took the prize of the jury. Congrats!","title":"InnoWeek SAP Labs 2016"},{"location":"2016/12/02/news-innoweek-sap-2016/#congrats","text":"","title":"Congrats!"},{"location":"2016/12/03/news-new-release-2-6/","text":"New version 2.6.161203-R released. Features Enhancements on the \"Templates\" authoring capabilities Swagger integration for API discovery and test Enterprise JavaScript API new modules Generation services exposed as REST services Dependency references feature Templates and Samples updates Configurable Local Repository Direct template generation method Template for mobile apps CMIS Simple Local Repository API \u2013 Extensions, Error New Mobile App Templates Lifecycle API Workspace API Extendable Entity Service Template RAP 3.2 version adapted Eclipse Oxygen version adapted CMIS with Destination support Passwords API Bugfixes and refactoring... Media How to Run Dirigible Anywhere - Microsoft Azure? Summer Practice in SAP How to Run Dirigible Anywhere - Microsoft Azure - Part II? The Java-saurus [Video] Basics-Documentation [Video] Mobile Applications [Video] Deploy on Localhost [Video] Deploy on SAP HANA Cloud Platform [EclipseCon] Enterprise JavaScript ... what the heck? [EclipseCon] Native mobile applications with Dirigible and Tabris [EclipseCon] WebSockets and Equinox OSGi in a Servlet Container Operational The full list of bug-fixes and enhancements can be found here . The source code is available at GitHub repository here . The instant trial is updated accordingly with the released version here . Enjoy!","title":"Release 2.6.161203-R"},{"location":"2016/12/03/news-new-release-2-6/#features","text":"Enhancements on the \"Templates\" authoring capabilities Swagger integration for API discovery and test Enterprise JavaScript API new modules Generation services exposed as REST services Dependency references feature Templates and Samples updates Configurable Local Repository Direct template generation method Template for mobile apps CMIS Simple Local Repository API \u2013 Extensions, Error New Mobile App Templates Lifecycle API Workspace API Extendable Entity Service Template RAP 3.2 version adapted Eclipse Oxygen version adapted CMIS with Destination support Passwords API Bugfixes and refactoring...","title":"Features"},{"location":"2016/12/03/news-new-release-2-6/#media","text":"How to Run Dirigible Anywhere - Microsoft Azure? Summer Practice in SAP How to Run Dirigible Anywhere - Microsoft Azure - Part II? The Java-saurus [Video] Basics-Documentation [Video] Mobile Applications [Video] Deploy on Localhost [Video] Deploy on SAP HANA Cloud Platform [EclipseCon] Enterprise JavaScript ... what the heck? [EclipseCon] Native mobile applications with Dirigible and Tabris [EclipseCon] WebSockets and Equinox OSGi in a Servlet Container","title":"Media"},{"location":"2016/12/03/news-new-release-2-6/#operational","text":"The full list of bug-fixes and enhancements can be found here . The source code is available at GitHub repository here . The instant trial is updated accordingly with the released version here .","title":"Operational"},{"location":"2016/12/03/news-new-release-2-6/#enjoy","text":"","title":"Enjoy!"},{"location":"2017/01/09/news-new-milestone-2-7-1/","text":"New version 2.7.170109-M1 released. Features Extensions Manager View Enterprise JavaScript API Improvements and Fixes Dependencies for DataStructure artefacts Deep folder structure support for generation from templates Mater-Details templates Markers on Map template WebSockets Tunnel Bugfixes Media Special Prize at SAP Labs Sofia - InnoWeek 2016 for the Zeus Project https://github.com/dirigiblelabs/zeus Operational The full list of bug-fixes and enhancements can be found here . The source code is available at GitHub repository here . The instant trial is updated accordingly with the released version here . Enjoy!","title":"Milestone 2.7.170109-M1"},{"location":"2017/01/09/news-new-milestone-2-7-1/#features","text":"Extensions Manager View Enterprise JavaScript API Improvements and Fixes Dependencies for DataStructure artefacts Deep folder structure support for generation from templates Mater-Details templates Markers on Map template WebSockets Tunnel Bugfixes","title":"Features"},{"location":"2017/01/09/news-new-milestone-2-7-1/#media","text":"Special Prize at SAP Labs Sofia - InnoWeek 2016 for the Zeus Project https://github.com/dirigiblelabs/zeus","title":"Media"},{"location":"2017/01/09/news-new-milestone-2-7-1/#operational","text":"The full list of bug-fixes and enhancements can be found here . The source code is available at GitHub repository here . The instant trial is updated accordingly with the released version here .","title":"Operational"},{"location":"2017/01/09/news-new-milestone-2-7-1/#enjoy","text":"","title":"Enjoy!"},{"location":"2017/02/25/news-new-milestone-2-7-2/","text":"New version 2.7.170225-M2 released. Features Semantics on data files import - append, replace, delete Discussion Boards Template CRUD Template with DAOism and aRESTme Cockpit Template Security Fixes Bug-fixes and Re-factoring Media Join us at Eclipse Converge Conference https://www.eclipseconverge.org/na2017/session/enterprise-javascript-what-heck and at SAP d-kom Sofia 2017 on 9 March http://www.secevents.bg/gallery/view/dkom-sap-event-sofia Operational The full list of bug-fixes and enhancements can be found here . The source code is available at GitHub repository here . The instant trial is updated accordingly with the released version here . Enjoy!","title":"Milestone 2.7.170225-M2"},{"location":"2017/02/25/news-new-milestone-2-7-2/#features","text":"Semantics on data files import - append, replace, delete Discussion Boards Template CRUD Template with DAOism and aRESTme Cockpit Template Security Fixes Bug-fixes and Re-factoring","title":"Features"},{"location":"2017/02/25/news-new-milestone-2-7-2/#media","text":"Join us at Eclipse Converge Conference https://www.eclipseconverge.org/na2017/session/enterprise-javascript-what-heck and at SAP d-kom Sofia 2017 on 9 March http://www.secevents.bg/gallery/view/dkom-sap-event-sofia","title":"Media"},{"location":"2017/02/25/news-new-milestone-2-7-2/#operational","text":"The full list of bug-fixes and enhancements can be found here . The source code is available at GitHub repository here . The instant trial is updated accordingly with the released version here .","title":"Operational"},{"location":"2017/02/25/news-new-milestone-2-7-2/#enjoy","text":"","title":"Enjoy!"},{"location":"2017/03/09/news-d-kom-sap-2017/","text":"After many years of incredible demos, DemoJam part of the SAP d-kom Sofia this year went public. The format this time was a bit different. There were no six teams competing for the prizes, but the teams collaborating and extending one single business scenario. We are happy that majority of the demos this time were based on Eclipse Dirigible or to be more specific on the newest innovations on top of the platform. We showed how to install a Kubernetes cluster in a few minutes and deploy ZEUS cloud development manager. Then some business objects were created with BizON modeling tool and a full-fledged application was generated. After that a mobile application was added based on Tabris.js integrated development in Dirigible. Next was an extension to the already created business application, which connects and embeds the Ariba network as a simple catalog search . The last demo showed the most recent features of SAPUI5 . For sure there cannot be a real d-kom Sofia event without a session related to Dirigible in the agenda. This time it was about Enterprise JavaScript presented by Vladimir and Nedelcho. Congrats!","title":"SAP d-kom Sofia 2017"},{"location":"2017/03/09/news-d-kom-sap-2017/#congrats","text":"","title":"Congrats!"},{"location":"2017/03/10/blogs-apps-testfwks/","text":"Integrating new test frameworks in Dirigible presented some challenges that I will explore in this blog. They can serve as a \"watch-out list\" in the process of integrating any third-party libraries in Dirigible in future. Integration of Third-Party JavaScript Libraries in Dirigible In the last months I integrated (or tried to integrate) a number of third-party libraries to make them available to the server-side of the platform. License Before you start your integration efforts, which may turn out significant, make sure you are license compatible or can get along with the library author on the subject. That will spare you a lot of wasted time eventually. As you will see below sometimes the only way to integrate a third party library is to make some changes in its original code and you should ensure that you are on the safe side license-wise to do that. CommonJS CommonJS is designed as a common, standard module loading system, which is a fair attempt when there are some many yet so similar out there already. The downside of standards that are driven not by urgent and inevitable but nice, yet not critical needs is that people implement it with low priority, when they can and to the extent they feel they absolutely need to. Dirigible's scripting runtime ( Rhino ) supports CommonJS as module management systems. However, you should keep in mind that it is not entirely comparable to the same in NodeJS . So not every single NodeJS module out there is directly transferable in Dirigible as it is as far as module dependencies are concerned. I am referring to NodeJS here as a platform with pretty rich set of modules that would be beneficial for other CommonJS platforms too, but the principle is the same for any CommonJS-enabled library too. Lesson learned: Explore the dependencies of the library you try to integrate, how they are loaded and assess if Rhino can support that. Chances are that you may need to modify the library's loading mechanism and introduce its dependencies as Dirigible modules too. ECMAScript 2015 (ES6) ES6 introduces a great deal of improvements to JavaScript for good. In fact, they are sometimes so significant that applications and platforms can hardly catch up. For example, Dirigible's JavaScript runtime environment Rhino is ECMAScript 5 compliant and that's quite unfortunate when you need to integrate a great third party library that is pushing ES6 JavaScript to the edge (as they all should). There are translation engines ( Babel ) that are actually trying to fill this gap, but I had problems integrating Babel itself so for now it's not coming to the rescue. The point is that if you have e.g. Symbol in your library code you are likely lost. Sometimes there are useful polifills though so don;t rush to give up. Lesson learned: Check the JavaScript standard compliance of the third-party library. Look for Symbol or something else that's specific to ES6 if unsure. Type checks Type checks can be tricky in Rhino and not behave entirely as you might expect. For example, neither of the expressions below will evaluate to true in Rhino. Object . prototype . toString . apply ( function (){}) === '[object Function]' ; Object . prototype . toString . apply (( function (){})()) === '[object Function]' ; Object . prototype . toString . apply ( new Function ()) === '[object Function]' ; However, in Chrome for example it most certainly will. Unfortunately, the trick to use toString for type checks is quite common as it seems and eventually you may hit this problem. The fix is luckily trivial, and is to use something more conventional such as: typeof target === 'function', but it will certainly require that you modify the library code. And this son its own requires that the third-party code licenses you for such modifications. So take care to check beforehand. Lesson learned: Look for use of Object.prototype.toString.apply for type checks and modify accordingly (if possible) No globals for you Well written libraries will not tightly rely that they are executed in a browser and make it up for in browser-less environments. That includes global objects and functions. But you will find none of these in Rhino. And you may need to make it up for that if possible at all. For example (using Jasmine as example here), setTimeout is not a global function as Jasmine expects it to be and I need to create and inject it like this (note the use of Java): jasmineGlobal . console = console ; var timer = new java . util . Timer (); var counter = 1 ; var ids = {}; jasmineGlobal . setTimeout = function ( fn , delay ) { if ( fn ){ var id = counter ++ ; ids [ id ] = new JavaAdapter ( java . util . TimerTask , { run : fn }); timer . schedule ( ids [ id ], delay ); return id ; } }; In this example jamsineGlobal is initialized as 'this', which in the context of a Dirigible module is empty (and not window (as expected by Jasmine) Lesson learned: Look for browser-specific objects such as window, set/clearTimeout/setInterval/clearInterval, document or console. See what exactly is required from them and then mock them delegating to the Rhino/Dirigible environment.","title":"Integration of Third-Party JavaScript Libraries in Dirigible"},{"location":"2017/03/10/blogs-apps-testfwks/#integration-of-third-party-javascript-libraries-in-dirigible","text":"In the last months I integrated (or tried to integrate) a number of third-party libraries to make them available to the server-side of the platform.","title":"Integration of Third-Party JavaScript Libraries in Dirigible"},{"location":"2017/03/10/blogs-apps-testfwks/#license","text":"Before you start your integration efforts, which may turn out significant, make sure you are license compatible or can get along with the library author on the subject. That will spare you a lot of wasted time eventually. As you will see below sometimes the only way to integrate a third party library is to make some changes in its original code and you should ensure that you are on the safe side license-wise to do that.","title":"License"},{"location":"2017/03/10/blogs-apps-testfwks/#commonjs","text":"CommonJS is designed as a common, standard module loading system, which is a fair attempt when there are some many yet so similar out there already. The downside of standards that are driven not by urgent and inevitable but nice, yet not critical needs is that people implement it with low priority, when they can and to the extent they feel they absolutely need to. Dirigible's scripting runtime ( Rhino ) supports CommonJS as module management systems. However, you should keep in mind that it is not entirely comparable to the same in NodeJS . So not every single NodeJS module out there is directly transferable in Dirigible as it is as far as module dependencies are concerned. I am referring to NodeJS here as a platform with pretty rich set of modules that would be beneficial for other CommonJS platforms too, but the principle is the same for any CommonJS-enabled library too. Lesson learned: Explore the dependencies of the library you try to integrate, how they are loaded and assess if Rhino can support that. Chances are that you may need to modify the library's loading mechanism and introduce its dependencies as Dirigible modules too.","title":"CommonJS"},{"location":"2017/03/10/blogs-apps-testfwks/#ecmascript-2015-es6","text":"ES6 introduces a great deal of improvements to JavaScript for good. In fact, they are sometimes so significant that applications and platforms can hardly catch up. For example, Dirigible's JavaScript runtime environment Rhino is ECMAScript 5 compliant and that's quite unfortunate when you need to integrate a great third party library that is pushing ES6 JavaScript to the edge (as they all should). There are translation engines ( Babel ) that are actually trying to fill this gap, but I had problems integrating Babel itself so for now it's not coming to the rescue. The point is that if you have e.g. Symbol in your library code you are likely lost. Sometimes there are useful polifills though so don;t rush to give up. Lesson learned: Check the JavaScript standard compliance of the third-party library. Look for Symbol or something else that's specific to ES6 if unsure.","title":"ECMAScript 2015 (ES6)"},{"location":"2017/03/10/blogs-apps-testfwks/#type-checks","text":"Type checks can be tricky in Rhino and not behave entirely as you might expect. For example, neither of the expressions below will evaluate to true in Rhino. Object . prototype . toString . apply ( function (){}) === '[object Function]' ; Object . prototype . toString . apply (( function (){})()) === '[object Function]' ; Object . prototype . toString . apply ( new Function ()) === '[object Function]' ; However, in Chrome for example it most certainly will. Unfortunately, the trick to use toString for type checks is quite common as it seems and eventually you may hit this problem. The fix is luckily trivial, and is to use something more conventional such as: typeof target === 'function', but it will certainly require that you modify the library code. And this son its own requires that the third-party code licenses you for such modifications. So take care to check beforehand. Lesson learned: Look for use of Object.prototype.toString.apply for type checks and modify accordingly (if possible)","title":"Type checks"},{"location":"2017/03/10/blogs-apps-testfwks/#no-globals-for-you","text":"Well written libraries will not tightly rely that they are executed in a browser and make it up for in browser-less environments. That includes global objects and functions. But you will find none of these in Rhino. And you may need to make it up for that if possible at all. For example (using Jasmine as example here), setTimeout is not a global function as Jasmine expects it to be and I need to create and inject it like this (note the use of Java): jasmineGlobal . console = console ; var timer = new java . util . Timer (); var counter = 1 ; var ids = {}; jasmineGlobal . setTimeout = function ( fn , delay ) { if ( fn ){ var id = counter ++ ; ids [ id ] = new JavaAdapter ( java . util . TimerTask , { run : fn }); timer . schedule ( ids [ id ], delay ); return id ; } }; In this example jamsineGlobal is initialized as 'this', which in the context of a Dirigible module is empty (and not window (as expected by Jasmine) Lesson learned: Look for browser-specific objects such as window, set/clearTimeout/setInterval/clearInterval, document or console. See what exactly is required from them and then mock them delegating to the Rhino/Dirigible environment.","title":"No globals for you"},{"location":"2017/03/10/blogs-apps-tests-jasmine/","text":"Jasmine is a popular test framework that supports BDD (Behavior-Driven Development) with testing JavaScript code. It does not require DOM. And all that makes it a very good candidate for a test framework of choice for JavaScript Scripting Services in Dirigible. It is made available for you to use as a Dirigible GitHub project . Testing Server-Side JavaScript with Jasmine Writing tests with Jasmine is fun. It has interesting style of naming its functions so they sound quite natural. You literally describe what your code ( it ) is expect ed to do with nice fluent assertion API. Here's (a dumb simple) example of how it looks: $$j . describe ( \"A suite is just a function\" , function () { $$j . it ( \"and has a positive case\" , function () { $$j . expect ( false ). toBe ( true ); }); $$j . it ( \"and can have a negative case\" , function () { $$j . expect ( false ). not . toBe ( true ); }); }); It's pretty much a functional specification of your code. Hence, how it supports BDD. There's plenty of examples out there how to make use of it for client-side apps so I won't spend time on that right now. The point of this blog is to show how to make use of it for testing server side code in Dirigible. Jasmine API in Dirigible Scripting Environment Once you get the Jasmine project from GitHub into your workspace, you need to require the library first before you can make anything with it. Open up a file in the Test Cases section of your project (or create it manually if you don't have one yet) and start writing: var j = require(\"jasmine/jasmine\"); . The j variable is a reference to the Jasmine API and now you are completely into the Jasmine world. Set it up and use require to reference the code you want to test and start asserting its behavior using the Jasmine API as you normally would when testing client-side JavaScript libraries. var j = require ( \"jasmine/jasmine\" ); var jasmine = j . core ( j ); var env = jasmine . getEnv (); var $$j = j . interface ( jasmine , env ); Test runner So, you have your tests developed and now you are eager to run the suite. There are a couple of options here. You can go quite native to Jasmine and take care of integrating a test results reporter (we provide two reporters adapted for Dirigible for you out-of-the-box, one for console and one as a JSON service). Or even better, and I shall focus on this now, you can use the Jasmine Test Runner Service (require with path jasmine/jasmine_test_runner_svc ). It is designed to work with the core Test Runner module in Dirigible to deliver test results as a service in a form suitable for you user agent. If you requested the test suite file via a browser (or the Preview view in Dirigible IDE) it will redirect the results to the Test Dashboard HTML UI. And if you requested it e.g. with cUrl using Accept: application/json header it will deliver test results formatted as JSON as a response. This makes it suitable both for direct consumption or integration in third-party quality control systems and it will cost just a single line of code to enable. require ( \"jasmine/jasmine_test_runner_svc\" ). service ( env ); The test results output for HTML capable user agents looks like this: And when requested for JSON instead of HTML it will deliver the following payload: { \"tests\" : [ { \"id\" : \"spec0\" , \"name\" : \"and has a positive case\" , \"module\" : \"A suite is just a function \" , \"runtime\" : 36 , \"assertions\" : [ { \"message\" : \"Expected false to be true.\" , \"result\" : false } ], \"failed\" : true , \"total\" : 1 }, { \"id\" : \"spec1\" , \"name\" : \"and can have a negative case\" , \"module\" : \"A suite is just a function \" , \"runtime\" : 26 , \"assertions\" : [ { \"message\" : \"and can have a negative case assertion[toBe] passed.\" , \"result\" : true } ], \"failed\" : false , \"total\" : 1 } ], \"testSuite\" : { \"runtime\" : 122 , \"total\" : 2 , \"passed\" : 1 , \"failed\" : 1 } } Putting it all together Finally, putting it all together, here is the layout of Jasmine-Dirigible test suite with two test cases delivering results as a service, that we discussed so far. var j = require ( \"jasmine/jasmine\" ); var jasmine = j . core ( j ); var env = jasmine . getEnv (); var $$j = j . interface ( jasmine , env ); $$j . describe ( \"A suite is just a function\" , function () { $$j . it ( \"and has a positive case\" , function () { $$j . expect ( false ). toBe ( true ); }); $$j . it ( \"and can have a negative case\" , function () { $$j . expect ( false ). not . toBe ( true ); }); }); require ( \"jasmine/jasmine_test_runner_svc\" ). service ( env ); Now, you are all set to benefit from what Jasmine has to offer to you as a developer for JavaScript server-side code. References Jasmin project Dirigible Jasmin module GitHub project","title":"Testing Server-Side JavaScript with Jasmine"},{"location":"2017/03/10/blogs-apps-tests-jasmine/#testing-server-side-javascript-with-jasmine","text":"Writing tests with Jasmine is fun. It has interesting style of naming its functions so they sound quite natural. You literally describe what your code ( it ) is expect ed to do with nice fluent assertion API. Here's (a dumb simple) example of how it looks: $$j . describe ( \"A suite is just a function\" , function () { $$j . it ( \"and has a positive case\" , function () { $$j . expect ( false ). toBe ( true ); }); $$j . it ( \"and can have a negative case\" , function () { $$j . expect ( false ). not . toBe ( true ); }); }); It's pretty much a functional specification of your code. Hence, how it supports BDD. There's plenty of examples out there how to make use of it for client-side apps so I won't spend time on that right now. The point of this blog is to show how to make use of it for testing server side code in Dirigible.","title":"Testing Server-Side JavaScript with Jasmine"},{"location":"2017/03/10/blogs-apps-tests-jasmine/#jasmine-api-in-dirigible-scripting-environment","text":"Once you get the Jasmine project from GitHub into your workspace, you need to require the library first before you can make anything with it. Open up a file in the Test Cases section of your project (or create it manually if you don't have one yet) and start writing: var j = require(\"jasmine/jasmine\"); . The j variable is a reference to the Jasmine API and now you are completely into the Jasmine world. Set it up and use require to reference the code you want to test and start asserting its behavior using the Jasmine API as you normally would when testing client-side JavaScript libraries. var j = require ( \"jasmine/jasmine\" ); var jasmine = j . core ( j ); var env = jasmine . getEnv (); var $$j = j . interface ( jasmine , env );","title":"Jasmine API in Dirigible Scripting Environment"},{"location":"2017/03/10/blogs-apps-tests-jasmine/#test-runner","text":"So, you have your tests developed and now you are eager to run the suite. There are a couple of options here. You can go quite native to Jasmine and take care of integrating a test results reporter (we provide two reporters adapted for Dirigible for you out-of-the-box, one for console and one as a JSON service). Or even better, and I shall focus on this now, you can use the Jasmine Test Runner Service (require with path jasmine/jasmine_test_runner_svc ). It is designed to work with the core Test Runner module in Dirigible to deliver test results as a service in a form suitable for you user agent. If you requested the test suite file via a browser (or the Preview view in Dirigible IDE) it will redirect the results to the Test Dashboard HTML UI. And if you requested it e.g. with cUrl using Accept: application/json header it will deliver test results formatted as JSON as a response. This makes it suitable both for direct consumption or integration in third-party quality control systems and it will cost just a single line of code to enable. require ( \"jasmine/jasmine_test_runner_svc\" ). service ( env ); The test results output for HTML capable user agents looks like this: And when requested for JSON instead of HTML it will deliver the following payload: { \"tests\" : [ { \"id\" : \"spec0\" , \"name\" : \"and has a positive case\" , \"module\" : \"A suite is just a function \" , \"runtime\" : 36 , \"assertions\" : [ { \"message\" : \"Expected false to be true.\" , \"result\" : false } ], \"failed\" : true , \"total\" : 1 }, { \"id\" : \"spec1\" , \"name\" : \"and can have a negative case\" , \"module\" : \"A suite is just a function \" , \"runtime\" : 26 , \"assertions\" : [ { \"message\" : \"and can have a negative case assertion[toBe] passed.\" , \"result\" : true } ], \"failed\" : false , \"total\" : 1 } ], \"testSuite\" : { \"runtime\" : 122 , \"total\" : 2 , \"passed\" : 1 , \"failed\" : 1 } }","title":"Test runner"},{"location":"2017/03/10/blogs-apps-tests-jasmine/#putting-it-all-together","text":"Finally, putting it all together, here is the layout of Jasmine-Dirigible test suite with two test cases delivering results as a service, that we discussed so far. var j = require ( \"jasmine/jasmine\" ); var jasmine = j . core ( j ); var env = jasmine . getEnv (); var $$j = j . interface ( jasmine , env ); $$j . describe ( \"A suite is just a function\" , function () { $$j . it ( \"and has a positive case\" , function () { $$j . expect ( false ). toBe ( true ); }); $$j . it ( \"and can have a negative case\" , function () { $$j . expect ( false ). not . toBe ( true ); }); }); require ( \"jasmine/jasmine_test_runner_svc\" ). service ( env ); Now, you are all set to benefit from what Jasmine has to offer to you as a developer for JavaScript server-side code.","title":"Putting it all together"},{"location":"2017/03/10/blogs-apps-tests-jasmine/#references","text":"Jasmin project Dirigible Jasmin module GitHub project","title":"References"},{"location":"2017/03/10/blogs-apps-tests-jasmine1/","text":"In my previous blog I introduced Jasmine as a testing framework for server-side JavaScript. Here I will explore how to add the server console as another test results output channel. Server-Side Tests: Enabling Jasmine Test Results in Dirigible Console In my previous blog I introduced Jasmine as a testing framework for server-side JavaScript. Here I will explore how to add the server console as another test results output channel. It is rudimentary, yet handy channel. Lucky for you, it comes right out-of-the-box with the GitHub dirigiblelabs Jasmine project . To use it, you need to require the console reporter library and integrate it in Jasmine's environment. //get the console reporter library var console_reporter = require ( \"jasmine/reporters/console_reporter\" ); var jasmine = j . core ( j ); var env = jasmine . getEnv (); //add the reporter to Jasmine env env . addReporter ( console_reporter . jasmine_console_reporter ); $$j . describe ( \"A suite is just a function\" , function () { $$j . it ( \"and has a positive case\" , function () { $$j . expect ( false ). toBe ( true ); }); $$j . it ( \"and can have a negative case\" , function () { $$j . expect ( false ). not . toBe ( true ); }); }); With this setup, selecting a Jasmine test suite .js script file in the user workspace will yield results similar to the following when the test suite is done: [2017-03-09T23:11:05.131Z][info] [Jasmine started]: {totalSpecsDefined:2} [2017-03-09T23:11:05.139Z][info] [Suite started]: {id:\"suite1\", description:\"A suite is just a function\", fullName:\"A suite is just a function\", failedExpectations:[]} [2017-03-09T23:11:05.301Z][info] [Spec started]: {id:\"spec0\", description:\"and has a positive case\", fullName:\"A suite is just a function and has a positive case\", failedExpectations:[], passedExpectations:[], pendingReason:\"\"} [2017-03-09T23:11:05.321Z][info] [Spec done]: {id:\"spec0\", description:\"and has a positive case\", fullName:\"A suite is just a function and has a positive case\", failedExpectations:[{matcherName:\"toBe\", message:\"Expected false to be true.\", stack:undefined, passed:false, expected:true, actual:false}], passedExpectations:[], pendingReason:\"\", status:\"failed\"} [2017-03-09T23:11:05.327Z][info] [Spec started]: {id:\"spec1\", description:\"and can have a negative case\", fullName:\"A suite is just a function and can have a negative case\", failedExpectations:[], passedExpectations:[], pendingReason:\"\"} [2017-03-09T23:11:05.347Z][info] [Spec done]: {id:\"spec1\", description:\"and can have a negative case\", fullName:\"A suite is just a function and can have a negative case\", failedExpectations:[], passedExpectations:[{matcherName:\"toBe\", message:\"Passed.\", stack:\"\", passed:true}], pendingReason:\"\", status:\"passed\"} [2017-03-09T23:11:05.354Z][info] [Suite done]: {id:\"suite1\", description:\"A suite is just a function\", fullName:\"A suite is just a function\", failedExpectations:[], status:\"finished\"} [2017-03-09T23:11:05.360Z][info] [Jasmine done] And that's all folks. References Jasmin project Dirigible Jasmine module project","title":"Server-Side Tests: Enabling Jasmine Test Results in Dirigible Console"},{"location":"2017/03/10/blogs-apps-tests-jasmine1/#server-side-tests-enabling-jasmine-test-results-in-dirigible-console","text":"In my previous blog I introduced Jasmine as a testing framework for server-side JavaScript. Here I will explore how to add the server console as another test results output channel. It is rudimentary, yet handy channel. Lucky for you, it comes right out-of-the-box with the GitHub dirigiblelabs Jasmine project . To use it, you need to require the console reporter library and integrate it in Jasmine's environment. //get the console reporter library var console_reporter = require ( \"jasmine/reporters/console_reporter\" ); var jasmine = j . core ( j ); var env = jasmine . getEnv (); //add the reporter to Jasmine env env . addReporter ( console_reporter . jasmine_console_reporter ); $$j . describe ( \"A suite is just a function\" , function () { $$j . it ( \"and has a positive case\" , function () { $$j . expect ( false ). toBe ( true ); }); $$j . it ( \"and can have a negative case\" , function () { $$j . expect ( false ). not . toBe ( true ); }); }); With this setup, selecting a Jasmine test suite .js script file in the user workspace will yield results similar to the following when the test suite is done: [2017-03-09T23:11:05.131Z][info] [Jasmine started]: {totalSpecsDefined:2} [2017-03-09T23:11:05.139Z][info] [Suite started]: {id:\"suite1\", description:\"A suite is just a function\", fullName:\"A suite is just a function\", failedExpectations:[]} [2017-03-09T23:11:05.301Z][info] [Spec started]: {id:\"spec0\", description:\"and has a positive case\", fullName:\"A suite is just a function and has a positive case\", failedExpectations:[], passedExpectations:[], pendingReason:\"\"} [2017-03-09T23:11:05.321Z][info] [Spec done]: {id:\"spec0\", description:\"and has a positive case\", fullName:\"A suite is just a function and has a positive case\", failedExpectations:[{matcherName:\"toBe\", message:\"Expected false to be true.\", stack:undefined, passed:false, expected:true, actual:false}], passedExpectations:[], pendingReason:\"\", status:\"failed\"} [2017-03-09T23:11:05.327Z][info] [Spec started]: {id:\"spec1\", description:\"and can have a negative case\", fullName:\"A suite is just a function and can have a negative case\", failedExpectations:[], passedExpectations:[], pendingReason:\"\"} [2017-03-09T23:11:05.347Z][info] [Spec done]: {id:\"spec1\", description:\"and can have a negative case\", fullName:\"A suite is just a function and can have a negative case\", failedExpectations:[], passedExpectations:[{matcherName:\"toBe\", message:\"Passed.\", stack:\"\", passed:true}], pendingReason:\"\", status:\"passed\"} [2017-03-09T23:11:05.354Z][info] [Suite done]: {id:\"suite1\", description:\"A suite is just a function\", fullName:\"A suite is just a function\", failedExpectations:[], status:\"finished\"} [2017-03-09T23:11:05.360Z][info] [Jasmine done] And that's all folks.","title":"Server-Side Tests: Enabling Jasmine Test Results in Dirigible Console"},{"location":"2017/03/10/blogs-apps-tests-jasmine1/#references","text":"Jasmin project Dirigible Jasmine module project","title":"References"},{"location":"2017/03/20/news-eclipseconverge-2017/","text":"Vladimir Pavlov presented the Enterprise JavaScript at the EclipseConverge conference in San Jose, California, US. Congrats!","title":"EclipseConverge US 2017"},{"location":"2017/03/20/news-eclipseconverge-2017/#congrats","text":"","title":"Congrats!"},{"location":"2017/04/07/news-uniteddev-2017/","text":"Eclipse Dirigible at UnitedDev Conference Minsk, Belarus! Vladimir Pavlov brought Enterprise JavaScript to our belarusian friends with Eclipse Dirigible! Congrats!","title":"UnitedDev Conference 2017"},{"location":"2017/04/07/news-uniteddev-2017/#congrats","text":"","title":"Congrats!"},{"location":"2017/05/04/news-new-milestone-2-7-3/","text":"New version 2.7.170504-M3 released. Features Harmonising root folder for derby, repository and cmis Coherent repository facade Docker build fixes and improvements AIR distribution introduction Identity and Access Management Module New themes - wendy and baroness Zip Master Repository with Classloader support Bug-fixes and Re-factoring Media Join us at JPrime Conference http://jprime.io/ Statistics 200+ Downloads 1600+ Trial Users 20 000+ Unique Sessions 80 000+ Unique Views 160+ Countries 200+ Repositories in DirigibleLabs 2 Customers in Production 5 Applications in Production \u20ac 200 000 Turnover Operational The full list of bug-fixes and enhancements can be found here . The source code is available at GitHub repository here . The instant trial is updated accordingly with the released version here . Enjoy!","title":"Milestone 2.7.170504-M3"},{"location":"2017/05/04/news-new-milestone-2-7-3/#features","text":"Harmonising root folder for derby, repository and cmis Coherent repository facade Docker build fixes and improvements AIR distribution introduction Identity and Access Management Module New themes - wendy and baroness Zip Master Repository with Classloader support Bug-fixes and Re-factoring","title":"Features"},{"location":"2017/05/04/news-new-milestone-2-7-3/#media","text":"Join us at JPrime Conference http://jprime.io/","title":"Media"},{"location":"2017/05/04/news-new-milestone-2-7-3/#statistics","text":"200+ Downloads 1600+ Trial Users 20 000+ Unique Sessions 80 000+ Unique Views 160+ Countries 200+ Repositories in DirigibleLabs 2 Customers in Production 5 Applications in Production \u20ac 200 000 Turnover","title":"Statistics"},{"location":"2017/05/04/news-new-milestone-2-7-3/#operational","text":"The full list of bug-fixes and enhancements can be found here . The source code is available at GitHub repository here . The instant trial is updated accordingly with the released version here .","title":"Operational"},{"location":"2017/05/04/news-new-milestone-2-7-3/#enjoy","text":"","title":"Enjoy!"},{"location":"2017/06/08/news-new-release-2-7/","text":"New version 2.7.1706008-R released. Features Extensions Manager View Enterprise JavaScript API Improvements and Fixes Dependencies for DataStructure artefacts Deep folder structure support for generation from templates Mater-Details templates Markers on Map template WebSockets Tunnel Semantics on data files import - append, replace, delete Cockpit Template Security Fixes Harmonising root folder for derby, repository and cmis Coherent repository facade Docker build fixes and improvements AIR distribution introduction Identity and Access Management Module New themes - wendy and baroness Zip Master Repository with Classloader support Bug-fixes and Re-factoring Media Special Prize at SAP Labs Sofia - InnoWeek 2016 for the Zeus Project https://github.com/dirigiblelabs/zeus . Blog about the event here SAP d-kom Sofia 2017 http://www.secevents.bg/gallery/view/dkom-sap-event-sofia . Some photos from the DemoJam stage here Eclipse Converge Conference https://www.eclipseconverge.org/na2017/session/enterprise-javascript-what-heck by Vladimir Pavlov. Some photos from the event here UnitedDev Conference Minsk, Belarus here JPrime Conference http://jprime.io/ was awesome ... again! Thanks to the \"Gang of Five\" from BG JUG for inviting us as speakers and to the sponsors for making this happen! Statistics 230+ Downloads 1800+ Trial Users 30 000+ Unique Sessions 81 000+ Unique Views 160+ Countries 200+ Repositories in DirigibleLabs Operational The full list of bug-fixes and enhancements can be found here . The source code is available at GitHub repository here . The instant trial is updated accordingly with the released version here . Enjoy!","title":"Release 2.7.1706008-R"},{"location":"2017/06/08/news-new-release-2-7/#features","text":"Extensions Manager View Enterprise JavaScript API Improvements and Fixes Dependencies for DataStructure artefacts Deep folder structure support for generation from templates Mater-Details templates Markers on Map template WebSockets Tunnel Semantics on data files import - append, replace, delete Cockpit Template Security Fixes Harmonising root folder for derby, repository and cmis Coherent repository facade Docker build fixes and improvements AIR distribution introduction Identity and Access Management Module New themes - wendy and baroness Zip Master Repository with Classloader support Bug-fixes and Re-factoring","title":"Features"},{"location":"2017/06/08/news-new-release-2-7/#media","text":"Special Prize at SAP Labs Sofia - InnoWeek 2016 for the Zeus Project https://github.com/dirigiblelabs/zeus . Blog about the event here SAP d-kom Sofia 2017 http://www.secevents.bg/gallery/view/dkom-sap-event-sofia . Some photos from the DemoJam stage here Eclipse Converge Conference https://www.eclipseconverge.org/na2017/session/enterprise-javascript-what-heck by Vladimir Pavlov. Some photos from the event here UnitedDev Conference Minsk, Belarus here JPrime Conference http://jprime.io/ was awesome ... again! Thanks to the \"Gang of Five\" from BG JUG for inviting us as speakers and to the sponsors for making this happen!","title":"Media"},{"location":"2017/06/08/news-new-release-2-7/#statistics","text":"230+ Downloads 1800+ Trial Users 30 000+ Unique Sessions 81 000+ Unique Views 160+ Countries 200+ Repositories in DirigibleLabs","title":"Statistics"},{"location":"2017/06/08/news-new-release-2-7/#operational","text":"The full list of bug-fixes and enhancements can be found here . The source code is available at GitHub repository here . The instant trial is updated accordingly with the released version here .","title":"Operational"},{"location":"2017/06/08/news-new-release-2-7/#enjoy","text":"","title":"Enjoy!"},{"location":"2017/08/21/news-new-release-2-8/","text":"New version 2.8.170821-R released. Features Tests Cases User Interface Bug-fixes and Re-factoring Media EclipseCon 2017 DSL Editors Support in Eclipse Dirigible accepted. Statistics 310+ Downloads 2100+ Trial Users 33 000+ Unique Sessions 87 000+ Unique Views 162+ Countries 210+ Repositories in DirigibleLabs Operational The full list of bug-fixes and enhancements can be found here . The source code is available at GitHub repository here . The instant trial is updated accordingly with the released version here . Enjoy!","title":"Release 2.8.170821-R"},{"location":"2017/08/21/news-new-release-2-8/#features","text":"Tests Cases User Interface Bug-fixes and Re-factoring","title":"Features"},{"location":"2017/08/21/news-new-release-2-8/#media","text":"EclipseCon 2017 DSL Editors Support in Eclipse Dirigible accepted.","title":"Media"},{"location":"2017/08/21/news-new-release-2-8/#statistics","text":"310+ Downloads 2100+ Trial Users 33 000+ Unique Sessions 87 000+ Unique Views 162+ Countries 210+ Repositories in DirigibleLabs","title":"Statistics"},{"location":"2017/08/21/news-new-release-2-8/#operational","text":"The full list of bug-fixes and enhancements can be found here . The source code is available at GitHub repository here . The instant trial is updated accordingly with the released version here .","title":"Operational"},{"location":"2017/08/21/news-new-release-2-8/#enjoy","text":"","title":"Enjoy!"},{"location":"2017/10/04/news-javaone-2017/","text":"Developers from all over the world joined this year's edition of the JavaOne conference in San Francisco, California (USA), on October 1st, 2017. Tsvetan Stoyanov and Vladimir Pavlov represented the Eclipse Dirigible cloud development platform at the conference. We were represented by Tsvetan Stoyanov at the Eclipse booth where he gave an overview of the currently available main features of the Dirigible platform as well as the upcoming look and feel of its soon-to-be released version 3.0 . There were ongoing video tutorial sessions at the Eclipse booth during the event. During these sessions, people expressed their interest by giving valuable suggestions for improvement of the Dirigible cloud development platform in terms of the overall usability of the Dirigble IDE. In general, we made quite an impression on our guests at the Eclipse booth. In the meantime, Vladimir Pavlov presented the Enterprise JavaScript at the conference. We really appreciate everyone for all the constructive feedback we received at the JavaOne conference and we are looking forward to our next event!","title":"JavaOne 2017"},{"location":"2017/11/14/news-new-release-3-0/","text":"New version 3.0 released. Features First All-New Release of Eclipse Dirigible This release will be a major technology change as well as simplification regarding life-cycle management of the projects. AppServer goes non-OSGi Light WebIDE is promoted as default - Angular 1.x/Bootstrap/GoldenLayout with Orion Editor Deployment model - Kubernetes + Docker Structured Storage (RDBMS) - PostgreSQL Messaging Service - ActiveMQ Indexing Engine - Lucene JavaScript Engine - Nashorn with ES6 support and V8 as an option CXF for RESTful services Project structure simplification Plain Java modules for services Webjars like modules for APIs and IDE plgins Webjars like modules also for Dirigible's Applications Media EclipseCon 2017 DSL Editors Support in Eclipse Dirigible by Amine Lajmi. JavaOne conference in San Francisco, California (USA) by Tsvetan Stoyanov and Vladimir Pavlov Statistics 520+ Downloads 1600+ Docker Pulls 2400+ Trial Users 36 000+ Unique Sessions 95 000+ Unique Views 165 Countries 240+ Repositories in DirigibleLabs Operational The full list of bug-fixes and enhancements can be found here . The source code is available at GitHub repository here . Note: the trial instance is still on version 2.8, but the new one will come soon - stay tuned! Enjoy!","title":"Release 3.0"},{"location":"2017/11/14/news-new-release-3-0/#features","text":"First All-New Release of Eclipse Dirigible This release will be a major technology change as well as simplification regarding life-cycle management of the projects. AppServer goes non-OSGi Light WebIDE is promoted as default - Angular 1.x/Bootstrap/GoldenLayout with Orion Editor Deployment model - Kubernetes + Docker Structured Storage (RDBMS) - PostgreSQL Messaging Service - ActiveMQ Indexing Engine - Lucene JavaScript Engine - Nashorn with ES6 support and V8 as an option CXF for RESTful services Project structure simplification Plain Java modules for services Webjars like modules for APIs and IDE plgins Webjars like modules also for Dirigible's Applications","title":"Features"},{"location":"2017/11/14/news-new-release-3-0/#media","text":"EclipseCon 2017 DSL Editors Support in Eclipse Dirigible by Amine Lajmi. JavaOne conference in San Francisco, California (USA) by Tsvetan Stoyanov and Vladimir Pavlov","title":"Media"},{"location":"2017/11/14/news-new-release-3-0/#statistics","text":"520+ Downloads 1600+ Docker Pulls 2400+ Trial Users 36 000+ Unique Sessions 95 000+ Unique Views 165 Countries 240+ Repositories in DirigibleLabs","title":"Statistics"},{"location":"2017/11/14/news-new-release-3-0/#operational","text":"The full list of bug-fixes and enhancements can be found here . The source code is available at GitHub repository here . Note: the trial instance is still on version 2.8, but the new one will come soon - stay tuned!","title":"Operational"},{"location":"2017/11/14/news-new-release-3-0/#enjoy","text":"","title":"Enjoy!"},{"location":"2018/01/19/news-new-release-3-1/","text":"New version 3.1 released. Features Multiple Editors support Custom Datasources support RS v3 API completed DAO v3 API completed Indexing v3 API completed Database Repository support CMIS v3 API CMIS Service (local and managed) Bookstore template Job Engine Job Template Listener Template Documents Perspective Search Service Search View Extension Perspective Template Extension View Template Bugfixes Better memory allocation in Repository import Usability improvements in Database perspective Open Resource in Repository Perspective Overloaded methods with inherited parameters fix Statistics 770+ Downloads 1600+ Docker Pulls 2800+ Trial Users 38 000+ Unique Sessions 102 000+ Unique Views 170 Countries 250+ Repositories in DirigibleLabs Operational The full list of bug-fixes and enhancements can be found here . The source code is available at GitHub repository here . The instant trial is updated accordingly with the released version here . Enjoy!","title":"Release 3.1"},{"location":"2018/01/19/news-new-release-3-1/#features","text":"Multiple Editors support Custom Datasources support RS v3 API completed DAO v3 API completed Indexing v3 API completed Database Repository support CMIS v3 API CMIS Service (local and managed) Bookstore template Job Engine Job Template Listener Template Documents Perspective Search Service Search View Extension Perspective Template Extension View Template","title":"Features"},{"location":"2018/01/19/news-new-release-3-1/#bugfixes","text":"Better memory allocation in Repository import Usability improvements in Database perspective Open Resource in Repository Perspective Overloaded methods with inherited parameters fix","title":"Bugfixes"},{"location":"2018/01/19/news-new-release-3-1/#statistics","text":"770+ Downloads 1600+ Docker Pulls 2800+ Trial Users 38 000+ Unique Sessions 102 000+ Unique Views 170 Countries 250+ Repositories in DirigibleLabs","title":"Statistics"},{"location":"2018/01/19/news-new-release-3-1/#operational","text":"The full list of bug-fixes and enhancements can be found here . The source code is available at GitHub repository here . The instant trial is updated accordingly with the released version here .","title":"Operational"},{"location":"2018/01/19/news-new-release-3-1/#enjoy","text":"","title":"Enjoy!"},{"location":"2018/02/02/blogs-3x-a-new-era-began/","text":"Hello Dirigibles! Let the new era begin! As a community-driven project, we stick to a very important principle that helps us navigate throughout the new emerging technologies and focus on the right priorities: We Listen! Based on the feedback we have received so far, we had to take a few major decisions: Moved to the standard Java/Maven development model for the core components The OSGi-based development model coming with Maven and Tycho integration, Orbit repositories and target platform definitions was listed many times as something too complex by the younger generation of developers who tried to understand the project source code and become contributors. The comparison was often with Spring Boot and other similar frameworks and projects. The decision was not easy, but we jumped to pure Maven project structure. The major benefit from this decision is that now you can build your own stack including also external dependencies more easily and in a more natural way. Moved from Eclipse RAP to pure Angular 1.x/Boostrap/GoldenLayout for WebIDE Of all the technologies we have been using, Eclipse RAP has been the most stable one. As a Web port of the Eclipse Rich Client Platform (RCP), we expected that the thousands of Eclipse plugin developers would recognize Dirigible as the easiest way to port their existing plugins to the Web or just to leverage their experience to create some brand new Cloud-related plugins. This did not happen. We decided to go to pure Angular 1.x/Boostrap/GoldenLayout user interfaces even for the WebIDE parts. The front-end now uses a set of RESTful services for workspace management, lifecycle management, repository, database, documents, etc., following the standard Web 2.0 approach. We have chosen that approach for building applications with Dirigible, hence now we are developing Dirigible with Dirigible itself. Finally we can say that! Adapt V8 engine in the API layer The JavaScript language and the community around it is quite an interesting phenomenon. The language itself, acknowledged as de facto THE front-end programming language, in recent years has also started gaining attention as a back-end language. There are several engines that were used for that and still exist, but now it seems we have a clear winner - V8. It supports the latest language specification and in most cases it is the fastest one. We adopted it via the great J2V8 bridge. As a side effect, we had to reimplement the Enterprise Javascript API layer to support such a non-JVM engine. Webjars for applications content To comply with the legacy of CI/CD processes, where requirements such as reproducibility, immutability, testability are must-have features of the underlying framework, we had to add a new approach of packaging of the applications for production. We decided to follow the so called \"webjars\" structures, where the application content (e.g. HTML files, database definitions, extensions, etc.) are packed as a standard Java archive and are accessible at runtime in the same way as they reside within the repository. In this way, nobody can change them once they are built into a deployable archive. The side benefit is that they can be distributed in the same way as the rest of the core modules - as standard Maven dependencies. The focus, the development model and the main goal - reconfirmed What remained and was reconfirmed was the focus on the business applications development in the cloud. Not just a general purpose IDE or a platform, but tailored for specific scenarios required by the businesses to optimize their processes. In-system programming was the clear differentiator giving an unique development experience and the fastest turn-around time in the Cloud. It was a hard period for all contributors to reimplement almost the whole stack from scratch - but we did it! In the next few days, we plan to publish a series of blog articles explaining how exactly we did it and how you can use it - to extend, configure, and run Dirigible in the most optimal way.","title":"3.x Series - A new era has begun!"},{"location":"2018/02/02/blogs-3x-a-new-era-began/#let-the-new-era-begin","text":"As a community-driven project, we stick to a very important principle that helps us navigate throughout the new emerging technologies and focus on the right priorities: We Listen! Based on the feedback we have received so far, we had to take a few major decisions:","title":"Let the new era begin!"},{"location":"2018/02/02/blogs-3x-a-new-era-began/#moved-to-the-standard-javamaven-development-model-for-the-core-components","text":"The OSGi-based development model coming with Maven and Tycho integration, Orbit repositories and target platform definitions was listed many times as something too complex by the younger generation of developers who tried to understand the project source code and become contributors. The comparison was often with Spring Boot and other similar frameworks and projects. The decision was not easy, but we jumped to pure Maven project structure. The major benefit from this decision is that now you can build your own stack including also external dependencies more easily and in a more natural way.","title":"Moved to the standard Java/Maven development model for the core components"},{"location":"2018/02/02/blogs-3x-a-new-era-began/#moved-from-eclipse-rap-to-pure-angular-1xboostrapgoldenlayout-for-webide","text":"Of all the technologies we have been using, Eclipse RAP has been the most stable one. As a Web port of the Eclipse Rich Client Platform (RCP), we expected that the thousands of Eclipse plugin developers would recognize Dirigible as the easiest way to port their existing plugins to the Web or just to leverage their experience to create some brand new Cloud-related plugins. This did not happen. We decided to go to pure Angular 1.x/Boostrap/GoldenLayout user interfaces even for the WebIDE parts. The front-end now uses a set of RESTful services for workspace management, lifecycle management, repository, database, documents, etc., following the standard Web 2.0 approach. We have chosen that approach for building applications with Dirigible, hence now we are developing Dirigible with Dirigible itself. Finally we can say that!","title":"Moved from Eclipse RAP to pure Angular 1.x/Boostrap/GoldenLayout for WebIDE"},{"location":"2018/02/02/blogs-3x-a-new-era-began/#adapt-v8-engine-in-the-api-layer","text":"The JavaScript language and the community around it is quite an interesting phenomenon. The language itself, acknowledged as de facto THE front-end programming language, in recent years has also started gaining attention as a back-end language. There are several engines that were used for that and still exist, but now it seems we have a clear winner - V8. It supports the latest language specification and in most cases it is the fastest one. We adopted it via the great J2V8 bridge. As a side effect, we had to reimplement the Enterprise Javascript API layer to support such a non-JVM engine.","title":"Adapt V8 engine in the API layer"},{"location":"2018/02/02/blogs-3x-a-new-era-began/#webjars-for-applications-content","text":"To comply with the legacy of CI/CD processes, where requirements such as reproducibility, immutability, testability are must-have features of the underlying framework, we had to add a new approach of packaging of the applications for production. We decided to follow the so called \"webjars\" structures, where the application content (e.g. HTML files, database definitions, extensions, etc.) are packed as a standard Java archive and are accessible at runtime in the same way as they reside within the repository. In this way, nobody can change them once they are built into a deployable archive. The side benefit is that they can be distributed in the same way as the rest of the core modules - as standard Maven dependencies.","title":"Webjars for applications content"},{"location":"2018/02/02/blogs-3x-a-new-era-began/#the-focus-the-development-model-and-the-main-goal-reconfirmed","text":"What remained and was reconfirmed was the focus on the business applications development in the cloud. Not just a general purpose IDE or a platform, but tailored for specific scenarios required by the businesses to optimize their processes. In-system programming was the clear differentiator giving an unique development experience and the fastest turn-around time in the Cloud. It was a hard period for all contributors to reimplement almost the whole stack from scratch - but we did it! In the next few days, we plan to publish a series of blog articles explaining how exactly we did it and how you can use it - to extend, configure, and run Dirigible in the most optimal way.","title":"The focus, the development model and the main goal - reconfirmed"},{"location":"2018/02/22/blogs-eclipse-dirigible/","text":"This article was republished from Eclipse Newsletter , February 2018 Overview Dirigible is an open-source cloud development platform, part of the Eclipse foundation and the top-level Eclipse Cloud Development project. The ultimate goal of the platform is to provide software developers with the right toolset for building, running, and operating business applications in the cloud. To achieve this goal, Dirigible provides both independent Design Time and Runtime components. Mission Nowadays, providing a full-stack application development platform is not enough. Building and running on top of it has to be fast and smooth! Having that in mind, slow and cumbersome \"Build\" , \"CI\" , and \"Deployment\" processes have a direct impact on development productivity. In this line of thought, it isn't hard to imagine that the Java development model for web applications doesn't fit in the cloud world. Luckily, one of the strongest advantages of Dirigible comes at hand - the In-System Development model. Right from the early days of Dirigible, it was clear that it is going to be the platform for Business Applications Development in the cloud and not just another general purpose IDE in the browser. The reason for that decision is pretty simple - \"One size doesn't fit all\" ! Making a choice between providing \"In-System Development\" in the cloud and adding support for a new language (Java, C#, PHP, ...) , is really easy. The new language doesn't really add much to the uniqueness and usability of the platform, as the In-System development model does! Architecture The goal of the In-System development model is to ultimately change the state of the system while it's up and running, without affecting the overall performance and without service degradation. You can easily think of several such systems like Programmable Microcontrollers, Relational Database Management Systems, ABAP. As mentioned earlier, Dirigible provides a suitable design time and runtime for that, so let's talk a little bit about the architecture. The Dirigible stack is pretty simple: The building blocks are: Application Server (provided) Runtime (built-in) Engine(s) - (Rhino/Nashorn/V8) Repository - (fs/database) Design Time (built-in) Web IDE (workspace/database/git/... perspective) Applications (developed) Application (database/rest/ui) Application (indexing/messaging/job) Application (extensionpoint/extension) ... Enterprise JavaScript The language of choice in the Dirigible business application platform is JavaScript ! But why JavaScript? Why not Java? Is it mature enough, is it scalable, can it satisfy the business application needs? The answer is: It sure does! The code that is being written is similar to Java. The developers can write their business logic in a synchronous fashion and can leverage a large set of Enterprise JavaScript APIs. For heavy loads, the Dirigible stack performs better than the NodeJS due to multithreading of the underlying JVM and the application server, and using the same V8 engine underneath. Examples Request/Response API var response = require ( 'http/v3/response' ); response . println ( \"Hello World!\" ); response . flush (); response . close (); Database API : var database = require ( 'db/v3/database' ); var response = require ( 'http/v3/response' ); var connection = database . getConnection (); try { var statement = connection . prepareStatement ( \"select * from MY_TABLE where MY_PATH like ?\" ); var i = 0 ; statement . setString ( ++ i , \"%\" ); var resultSet = statement . executeQuery (); while ( resultSet . next ()) { response . println ( \"[path]: \" + resultSet . getString ( \"MY_PATH\" )); } resultSet . close (); statement . close (); } catch ( e ) { console . trace ( e ); response . println ( e . message ); } finally { connection . close (); } response . flush (); response . close (); The provided Enterprise JavaScript APIs leverage some of the mature Java specifications and de facto standards (e.g. JDBC, Servlet, CMIS, ActiveMQ, File System, Streams, etc.). Eliminating the build process (due to the lack of compilation) and at the same time exposing proven frameworks (that does the heavy lifting) , results in having the perfect environment for in-system development of business applications, with close to \"Zero Turn-Around-Time\" . In conclusion, the Dirigible platform is really tailored to the needs of Business Application Developers . Getting Started Download Get the latest release from: http://download.eclipse.org/dirigible The latest master branch can be found at: https://github.com/eclipse/dirigible Download the latest Tomcat 8.x from: https://tomcat.apache.org/download-80.cgi NOTE: You can use the try out instance, that is available at http://dirigible.eclipse.org and skip through the Develop section Start Put the ROOT.war into the ${tomcat-dir}/webapps directory Execute ./catalina.sh start from the ${tomcat-dir}/bin directory Login Open: http://localhost:8080 Log in with the default dirigible/dirigible credentials Develop Project Create a project Click + -> Project Database table Generate a Database Table Right-click New > Generate > Database table Edit the students.table definition { \"name\" : \"Students\" , \"type\" : \"TABLE\" , \"columns\" : [{ \"name\" : \"ID\" , \"type\" : \"INTEGER\" , \"primaryKey\" : \"true\" }, { \"name\" : \"FIRST_NAME\" , \"type\" : \"VARCHAR\" , \"length\" : \"50\" }, { \"name\" : \"LAST_NAME\" , \"type\" : \"VARCHAR\" , \"length\" : \"50\" }, { \"name\" : \"AGE\" , \"type\" : \"INTEGER\" }] } Publish Right-click the project and select Publish NOTE: The auto publish function is enabled by default Explore The database scheme can be explored from the Database perspective Click Window > Open Perspective > Database Insert some sample data insert into students values ( 1 , 'John' , 'Doe' , 25 ) insert into students values ( 2 , 'Jane' , 'Doe' , 23 ) Note: The perspectives are available also from the side menu REST service Generate a Hello World service Right-click New > Generate > Hello World Edit the students.js service var database = require ( 'db/v3/database' ); var response = require ( 'http/v3/response' ); var students = listStudents (); response . println ( students ); response . flush (); response . close (); function listStudents () { let students = []; var connection = database . getConnection (); try { var statement = connection . prepareStatement ( \"select * from STUDENTS\" ); var resultSet = statement . executeQuery (); while ( resultSet . next ()) { students . push ({ 'id' : resultSet . getInt ( 'ID' ), 'firstName' : resultSet . getString ( 'FIRST_NAME' ), 'lastName' : resultSet . getString ( 'LAST_NAME' ), 'age' : resultSet . getInt ( 'AGE' ) }); } resultSet . close (); statement . close (); } catch ( e ) { console . error ( e ); response . println ( e . message ); } finally { connection . close (); } return students ; } Explore The student.js service is accessible through the Preview view NOTE: All backend services are up and running after save/publish, due to the In-System Development Create a UI Generate a HTML5 (AngularJS) page Right-click New > Generate > HTML5 (AngularJS) Edit the page <!DOCTYPE html> < html lang = \"en\" ng-app = \"page\" > < head > < meta charset = \"utf-8\" > < meta http-equiv = \"X-UA-Compatible\" content = \"IE=edge\" > < meta name = \"viewport\" content = \"width=device-width, initial-scale=1.0\" > < meta name = \"description\" content = \"\" > < meta name = \"author\" content = \"\" > < link type = \"text/css\" rel = \"stylesheet\" href = \"/services/v3/core/theme/bootstrap.min.css\" > < link type = \"text/css\" rel = \"stylesheet\" href = \"/services/v3/web/resources/font-awesome-4.7.0/css/font-awesome.min.css\" > < script type = \"text/javascript\" src = \"/services/v3/web/resources/angular/1.4.7/angular.min.js\" ></ script > < script type = \"text/javascript\" src = \"/services/v3/web/resources/angular/1.4.7/angular-resource.min.js\" ></ script > </ head > < body ng-controller = \"PageController\" > < div > < div class = \"page-header\" > < h1 > Students </ h1 > </ div > < div class = \"container\" > < table class = \"table table-hover\" > < thead > < th > Id </ th > < th > First Name </ th > < th > Last Name </ th > < th > Age </ th > </ thead > < tbody > < tr ng-repeat = \"student in students\" > {% raw %} < td > {{student.id}} </ td > < td > {{student.firstName}} </ td > < td > {{student.lastName}} </ td > < td > {{student.age}} </ td > {% endraw %} </ tr > </ tbody > </ table > </ div > </ div > < script type = \"text/javascript\" > angular . module ( 'page' , []); angular . module ( 'page' ). controller ( 'PageController' , function ( $scope , $http ) { $http . get ( '../../js/university/students.js' ) . success ( function ( data ) { $scope . students = data ; }); }); </ script > </ body > </ html > \"What's next?\" The In-System Development model provides the business application developers with the right toolset for rapid application development. By leveraging a few built-in templates and the Enterprise JavaScript API , whole vertical scenarios can be set up in several minutes. With the close to Zero Turn-Around-Time , changes in the backend can be made and applied on the fly, through an elegant Web IDE. The perfect fit for your digital transformation ! The goal of the Dirigible platform is clear - ease the developers as much as possible and let them concentrate on the development of critical business logic. So, what's next? Can I provide my own set of templates? Can I expose a new Enterprise JavaScript API? Can I provide a new perspective/view? Can I build my own Dirigible stack? Can it be integrated with the services of my cloud provider? To all these questions, the answer is simple: Yes , you can do it! Resources Site: http://www.dirigible.io Help: http://www.dirigible.io/help/ API: http://www.dirigible.io/api/ YouTube: https://www.youtube.com/c/dirigibleio Facebook: https://www.facebook.com/dirigible.io Twitter: https://twitter.com/dirigible_io Enjoy!","title":"Eclipse Dirigible - Getting Started"},{"location":"2018/02/22/blogs-eclipse-dirigible/#overview","text":"Dirigible is an open-source cloud development platform, part of the Eclipse foundation and the top-level Eclipse Cloud Development project. The ultimate goal of the platform is to provide software developers with the right toolset for building, running, and operating business applications in the cloud. To achieve this goal, Dirigible provides both independent Design Time and Runtime components.","title":"Overview"},{"location":"2018/02/22/blogs-eclipse-dirigible/#mission","text":"Nowadays, providing a full-stack application development platform is not enough. Building and running on top of it has to be fast and smooth! Having that in mind, slow and cumbersome \"Build\" , \"CI\" , and \"Deployment\" processes have a direct impact on development productivity. In this line of thought, it isn't hard to imagine that the Java development model for web applications doesn't fit in the cloud world. Luckily, one of the strongest advantages of Dirigible comes at hand - the In-System Development model. Right from the early days of Dirigible, it was clear that it is going to be the platform for Business Applications Development in the cloud and not just another general purpose IDE in the browser. The reason for that decision is pretty simple - \"One size doesn't fit all\" ! Making a choice between providing \"In-System Development\" in the cloud and adding support for a new language (Java, C#, PHP, ...) , is really easy. The new language doesn't really add much to the uniqueness and usability of the platform, as the In-System development model does!","title":"Mission"},{"location":"2018/02/22/blogs-eclipse-dirigible/#architecture","text":"The goal of the In-System development model is to ultimately change the state of the system while it's up and running, without affecting the overall performance and without service degradation. You can easily think of several such systems like Programmable Microcontrollers, Relational Database Management Systems, ABAP. As mentioned earlier, Dirigible provides a suitable design time and runtime for that, so let's talk a little bit about the architecture. The Dirigible stack is pretty simple: The building blocks are: Application Server (provided) Runtime (built-in) Engine(s) - (Rhino/Nashorn/V8) Repository - (fs/database) Design Time (built-in) Web IDE (workspace/database/git/... perspective) Applications (developed) Application (database/rest/ui) Application (indexing/messaging/job) Application (extensionpoint/extension) ...","title":"Architecture"},{"location":"2018/02/22/blogs-eclipse-dirigible/#enterprise-javascript","text":"The language of choice in the Dirigible business application platform is JavaScript ! But why JavaScript? Why not Java? Is it mature enough, is it scalable, can it satisfy the business application needs? The answer is: It sure does! The code that is being written is similar to Java. The developers can write their business logic in a synchronous fashion and can leverage a large set of Enterprise JavaScript APIs. For heavy loads, the Dirigible stack performs better than the NodeJS due to multithreading of the underlying JVM and the application server, and using the same V8 engine underneath.","title":"Enterprise JavaScript"},{"location":"2018/02/22/blogs-eclipse-dirigible/#examples","text":"Request/Response API var response = require ( 'http/v3/response' ); response . println ( \"Hello World!\" ); response . flush (); response . close (); Database API : var database = require ( 'db/v3/database' ); var response = require ( 'http/v3/response' ); var connection = database . getConnection (); try { var statement = connection . prepareStatement ( \"select * from MY_TABLE where MY_PATH like ?\" ); var i = 0 ; statement . setString ( ++ i , \"%\" ); var resultSet = statement . executeQuery (); while ( resultSet . next ()) { response . println ( \"[path]: \" + resultSet . getString ( \"MY_PATH\" )); } resultSet . close (); statement . close (); } catch ( e ) { console . trace ( e ); response . println ( e . message ); } finally { connection . close (); } response . flush (); response . close (); The provided Enterprise JavaScript APIs leverage some of the mature Java specifications and de facto standards (e.g. JDBC, Servlet, CMIS, ActiveMQ, File System, Streams, etc.). Eliminating the build process (due to the lack of compilation) and at the same time exposing proven frameworks (that does the heavy lifting) , results in having the perfect environment for in-system development of business applications, with close to \"Zero Turn-Around-Time\" . In conclusion, the Dirigible platform is really tailored to the needs of Business Application Developers .","title":"Examples"},{"location":"2018/02/22/blogs-eclipse-dirigible/#getting-started","text":"Download Get the latest release from: http://download.eclipse.org/dirigible The latest master branch can be found at: https://github.com/eclipse/dirigible Download the latest Tomcat 8.x from: https://tomcat.apache.org/download-80.cgi NOTE: You can use the try out instance, that is available at http://dirigible.eclipse.org and skip through the Develop section Start Put the ROOT.war into the ${tomcat-dir}/webapps directory Execute ./catalina.sh start from the ${tomcat-dir}/bin directory Login Open: http://localhost:8080 Log in with the default dirigible/dirigible credentials Develop Project Create a project Click + -> Project Database table Generate a Database Table Right-click New > Generate > Database table Edit the students.table definition { \"name\" : \"Students\" , \"type\" : \"TABLE\" , \"columns\" : [{ \"name\" : \"ID\" , \"type\" : \"INTEGER\" , \"primaryKey\" : \"true\" }, { \"name\" : \"FIRST_NAME\" , \"type\" : \"VARCHAR\" , \"length\" : \"50\" }, { \"name\" : \"LAST_NAME\" , \"type\" : \"VARCHAR\" , \"length\" : \"50\" }, { \"name\" : \"AGE\" , \"type\" : \"INTEGER\" }] } Publish Right-click the project and select Publish NOTE: The auto publish function is enabled by default Explore The database scheme can be explored from the Database perspective Click Window > Open Perspective > Database Insert some sample data insert into students values ( 1 , 'John' , 'Doe' , 25 ) insert into students values ( 2 , 'Jane' , 'Doe' , 23 ) Note: The perspectives are available also from the side menu REST service Generate a Hello World service Right-click New > Generate > Hello World Edit the students.js service var database = require ( 'db/v3/database' ); var response = require ( 'http/v3/response' ); var students = listStudents (); response . println ( students ); response . flush (); response . close (); function listStudents () { let students = []; var connection = database . getConnection (); try { var statement = connection . prepareStatement ( \"select * from STUDENTS\" ); var resultSet = statement . executeQuery (); while ( resultSet . next ()) { students . push ({ 'id' : resultSet . getInt ( 'ID' ), 'firstName' : resultSet . getString ( 'FIRST_NAME' ), 'lastName' : resultSet . getString ( 'LAST_NAME' ), 'age' : resultSet . getInt ( 'AGE' ) }); } resultSet . close (); statement . close (); } catch ( e ) { console . error ( e ); response . println ( e . message ); } finally { connection . close (); } return students ; } Explore The student.js service is accessible through the Preview view NOTE: All backend services are up and running after save/publish, due to the In-System Development Create a UI Generate a HTML5 (AngularJS) page Right-click New > Generate > HTML5 (AngularJS) Edit the page <!DOCTYPE html> < html lang = \"en\" ng-app = \"page\" > < head > < meta charset = \"utf-8\" > < meta http-equiv = \"X-UA-Compatible\" content = \"IE=edge\" > < meta name = \"viewport\" content = \"width=device-width, initial-scale=1.0\" > < meta name = \"description\" content = \"\" > < meta name = \"author\" content = \"\" > < link type = \"text/css\" rel = \"stylesheet\" href = \"/services/v3/core/theme/bootstrap.min.css\" > < link type = \"text/css\" rel = \"stylesheet\" href = \"/services/v3/web/resources/font-awesome-4.7.0/css/font-awesome.min.css\" > < script type = \"text/javascript\" src = \"/services/v3/web/resources/angular/1.4.7/angular.min.js\" ></ script > < script type = \"text/javascript\" src = \"/services/v3/web/resources/angular/1.4.7/angular-resource.min.js\" ></ script > </ head > < body ng-controller = \"PageController\" > < div > < div class = \"page-header\" > < h1 > Students </ h1 > </ div > < div class = \"container\" > < table class = \"table table-hover\" > < thead > < th > Id </ th > < th > First Name </ th > < th > Last Name </ th > < th > Age </ th > </ thead > < tbody > < tr ng-repeat = \"student in students\" > {% raw %} < td > {{student.id}} </ td > < td > {{student.firstName}} </ td > < td > {{student.lastName}} </ td > < td > {{student.age}} </ td > {% endraw %} </ tr > </ tbody > </ table > </ div > </ div > < script type = \"text/javascript\" > angular . module ( 'page' , []); angular . module ( 'page' ). controller ( 'PageController' , function ( $scope , $http ) { $http . get ( '../../js/university/students.js' ) . success ( function ( data ) { $scope . students = data ; }); }); </ script > </ body > </ html >","title":"Getting Started"},{"location":"2018/02/22/blogs-eclipse-dirigible/#whats-next","text":"The In-System Development model provides the business application developers with the right toolset for rapid application development. By leveraging a few built-in templates and the Enterprise JavaScript API , whole vertical scenarios can be set up in several minutes. With the close to Zero Turn-Around-Time , changes in the backend can be made and applied on the fly, through an elegant Web IDE. The perfect fit for your digital transformation ! The goal of the Dirigible platform is clear - ease the developers as much as possible and let them concentrate on the development of critical business logic. So, what's next? Can I provide my own set of templates? Can I expose a new Enterprise JavaScript API? Can I provide a new perspective/view? Can I build my own Dirigible stack? Can it be integrated with the services of my cloud provider? To all these questions, the answer is simple: Yes , you can do it!","title":"\"What's next?\""},{"location":"2018/02/22/blogs-eclipse-dirigible/#resources","text":"Site: http://www.dirigible.io Help: http://www.dirigible.io/help/ API: http://www.dirigible.io/api/ YouTube: https://www.youtube.com/c/dirigibleio Facebook: https://www.facebook.com/dirigible.io Twitter: https://twitter.com/dirigible_io Enjoy!","title":"Resources"},{"location":"2018/03/02/blogs-3x-ide/","text":"Dirigible is a cloud runtime platform that comes with a neat, all-in-one, frustration-free package of devops productivity tools, including a brand new cloud IDE for in-system application development. This blog is a getting-to-know the new cloud IDE. Meet and greet A picture's worth a thousand words they say... We took our years-long experience in building high-productivity web-based IDE and used it to create a completely new cloud IDE from ground up , using exclusively lean, web-native UI technologies (vanilla JS, JQuery , AngularJS , Twitter Bootstrap ) backed by lightweight services. The new design follows the latest trends in the segment, enriched with some unique flavors, such as interactive work plot personalization (a.k.a. as perspective in Eclipse) to provide a real-world, high-productivity finishing. Our primary design goals (in short) were to deliver - functionally rich, desktop-like experience (performant, reliable) - highly configurable and interactively composable working area - highly extensible and customizable core - leveraging popular in the community, web-native technologies and frameworks Building blocks From end user perspective, the IDE is composition of perspectives , each consisting of the necessary tools to accomplish certain goal. There are three areas with fixed positions: - top-area toolbar for the menus , theme selection and user control; - sidebar to the left, with shortcuts e.g. to the perspectives; - statusbar at the bottom, for notifications and other use by the tools. The tools that constitute perspectives are laid out in different (predefined) regions of the work plot, but their position is not fixed and can be changed by dragging it to a new one. The perspectives are simply predefined configurations and end users are free to open , move or close tools on the work plot of a perspective as they see fit. The tools can also be maximized or minimized , even popped out in own window. The tools are the minimal atomic parts in the IDE. They are referred to as views or editors and each type is handled differently. What's in the box The IDE package contains the Workbench , Git , Database , Repository and Terminal perspectives. The list is neither limited, nor fixed. Workbench The Workbench perspective comprises Workspace , Import , Properties , Console and Preview views, plus the editors registered for each file type. In a word, the minimal toolset for file management, preview and editing operations. A very handy feature is also the template-based project and artifacts scaffolding generators. New in 3.x - Multiple workspaces per user . User now can create multiple workspaces and use the Workspace view to manage and switch between them. - Non-normative project file structure . The projects file organization is now non-normative and entirely up-to your preferences. - Multiple editors . The IDE now supports multiple editors registered for different file (MIME) types. More than one editor can be registered for one file type and in this case a \" Open with... \" context menu entry is rendered for the user to select, which one to use. Git Git perspective is built from tools supporting Git client operations. It doesn't aim to be what EGit is to Eclipse, but rather to present a simplified interface for the most common operations, such as cloning a repository to a workspace, pulling changes, and pushing commits. For more sophisticated command-line interaction see Terminal Database The Database perspective is essential for full stack developers. It features a database explorer, a console to execute SQL statements and preview results in table format. Repository The Repository perspective offers explorer for the repository of the Dirigible instance where the IDE is running, and import/export snapshots. Terminal The key view in the perspective is a terminal that emulates console client connected to the environment of the Dirigible IDE that can execute commands. Editors The editors that have been integrated are Orion and Ace . More sophisticated and also visual editors are in the pipeline. Core UI framework The Core UI framework is an Angular module ( ideUiCore ) that exposes a number of key components, building the backbone of perspectives and tools in the cloud IDE. Many of these can be further customized and some are part of larger compositions (e.g. the Angular directives for menu, sidebar or statusbar). The design encourages customizations if you are up to some tricky scenario or just rolling out a whole new fully functional perspective with a just a couple lines of code. To give you the idea how literally true is that, here is a clue: < body ng-app = \"workbench\" ng-controller = \"WorkbenchController as wb\" > < div menu menu-data-url = \"../../js/ide/services/menu.js\" ></ div > < div class = \"shell\" > < div class = \"sidebar list-group\" sidebar active = \"Workbench\" ></ div > < div id = \"workbench\" class = \"plane\" views-layout views-layout-model = \"wb.layoutModel\" ></ div > </ div > < div class = \"statusbar\" status-bar > {{message}} </ div > </ body > In this HTML template, the directives menu , sidebar , views-layout and statusbar will build a standard perspective layout for you. All you need to add to that (in the corresponding controller) is, which are the views that will be part of the perspective (note the views array property in the layoutModel member below): ... . controller ( 'WorkbenchController' , [ 'Layouts' , function ( Layouts ){ this . layoutModel = { views : [ 'workspace' , 'import' , 'editor' , 'properties' , 'console' , 'preview' ] ... } The components in the core UI framework provide a coherent look and feel for the perspectives and their views and editors in the IDE. A brief description for some of the key components follows. Message Hub The IDE building blocks work together in choreography . An action in the Workspace view for example opens-up an editor, or triggers the Preview view to send a request to a service. The communication between the isolated choreography participants is decentralized, and realized by a highly performant, entirely client-side framework - the Message Hub . The Message Hub is a self-contained (no dependencies) JS library that leverages the HTML5 messaging API to convey messages across the UI component isolation (iframe) boundaries via a simplified, yet highly customizable interface. It works across domains if necessary, yet implementing all best-practices for secure cross-origin client-side communication. Here is a hint for the simplicity of the API: A. Load the library < script type = \"text/javascript\" src = \"ui/message-hub.js\" ></ script > <!-- and the following for Angular Apps --> < script type = \"text/javascript\" src = \"ui/ui-layout.js\" ></ script > < script type = \"text/javascript\" src = \"ui/ui-core-ng-modules.js\" ></ script > B. Get an instance - With vanilla JS var messageHub = new FramesMessageHub (); Or in Anguar app angular . module ( 'App' , [ 'ideUiCore' ]) ... . controller ( 'SomeController' , [ 'messageHub' , function ( messageHub ){ ... C. Subscirbe for messages of type 'namespace.messageName' javascript , messageHub.on('namespace.messageName', function(message, postEvent){ //do something... }); D. Post a message to subscribers for the 'namespace.messageName' messages messageHub . send ( 'namespace.messageName' , message ); Using the message hub framework, we build highly performant loosely coupled integrations between isolated components, reducing the boilerplate in setting up communication channels to the bare minimum. Layouts The cloud IDE layout API delegates the layout management to the GoldenLayout framework \u2013 a \u201c multi-window JavaScript layout manager for webapps \u201c, as the author defines it. It handles all the magic of laying things out, stacking, moving interactively, popping out, maximize/minimize, close and open of views and editors. The angular directive views-layout encapsulates all the complexity of initializing the layout of views in a perspective and reduces it all to a very simple configuration. < div id = \"workbench\" class = \"plane\" views-layout views-layout-model = \"wb.layoutModel\" ></ div > In that code snippet above, wb.layoutModel is a JSON like: { views : [ 'workspace' , 'import' , 'editor' , 'properties' , 'console' , 'preview' ] } The strings in the views array are in fact identifiers for the views registered in the Views Registry maintained by the framework. The registry entries provide essential configuration information for the views, such as their intended region on the work plot, factory function, label and specific configuration. The registry is populated by the views.js service. Layouts is a convenience bag of functions that significantly simplifies the work with layouts. It takes care of views registry setup, the work plot regions configuration, layout initialization, serialization, control on the layout manager, open view and open editor functions, global notifications and others. For example, the API to open programmatically a view (after layout initialization): Layouts.manager.open(viewId, regionId); Toolbar The Toolbar is a composite that aggregates the drop-down menus, the theme selection, the user name and sign-out control. It uses the corresponding UI microservices available in the ideUiCore module as Menu , User and Theme . Having a fully functional standard template menu in a perspective costs as much as this line: < div menu menu-data-url = \"../../js/ide/services/menu.js\" ></ div > The Angular directive menu will take care to render it as appropriate and all it needs for that is the (perspective-specific) URL of a service that will provide the menu items configuration. By convention, all UI components are built with Bootstrap 3.x CSS and the themes in the cloud IDE are actually custom Bootstrap CSS. A UI microservice enables dynamic change of the CSS upon change of the theme automatically. It is available as Angular Factory Theme . The Angular service User provides the details for the user that are rendered by the Menu directive, such as the user name. Sidebar The sidebar is Angular directive that takes care to render a standard sidebar in the framework template. It works with the perspectives.js service to populate the registered perspectives as shortcuts. Statusbar The statusbar is an Angular directive that renders a standard, fixed-position footer. The component is subscribed to listen to message types configured as value of the status-bar-topic attribute, or by default to status-message messages. Extensibility and Dynamic Compositions The content of the Menu, Sidebar, Open With (editor) action list, the views/editors in a perspective and their positions on the work plot are all examples of configurations that are delivered at runtime by Dirigible services. They leverage the extensions concept in Dirigible, so integrating a new menu (for example) is as easy as a Dirigible module \u201cadvertising\u201d itself (see file.extension ) to the corresponding Dirigible extension point (see menu.extensionpoint ). At runtime, the extensions will be invoked dynamically, their results aggregated and ultimately delivered to the front-end by a service responsible to mashup everything into a lean consumable JSON model (see menu.js ). The whole mechanism shares concepts with the Eclipse plugin framework. It detaches the client-side, which would render anything that can satisfy its data format needs, and server-side data composition mechanisms from the data contributors which are resolved and invoked dynamically. Therefore, to extend the system, all you need to do is to focus on providing a compliant data contributor and the system will take care to resolve and request it for its piece of data when required. Enjoy!","title":"Dirigible Cloud IDE"},{"location":"2018/03/02/blogs-3x-ide/#meet-and-greet","text":"A picture's worth a thousand words they say... We took our years-long experience in building high-productivity web-based IDE and used it to create a completely new cloud IDE from ground up , using exclusively lean, web-native UI technologies (vanilla JS, JQuery , AngularJS , Twitter Bootstrap ) backed by lightweight services. The new design follows the latest trends in the segment, enriched with some unique flavors, such as interactive work plot personalization (a.k.a. as perspective in Eclipse) to provide a real-world, high-productivity finishing. Our primary design goals (in short) were to deliver - functionally rich, desktop-like experience (performant, reliable) - highly configurable and interactively composable working area - highly extensible and customizable core - leveraging popular in the community, web-native technologies and frameworks","title":"Meet and greet"},{"location":"2018/03/02/blogs-3x-ide/#building-blocks","text":"From end user perspective, the IDE is composition of perspectives , each consisting of the necessary tools to accomplish certain goal. There are three areas with fixed positions: - top-area toolbar for the menus , theme selection and user control; - sidebar to the left, with shortcuts e.g. to the perspectives; - statusbar at the bottom, for notifications and other use by the tools. The tools that constitute perspectives are laid out in different (predefined) regions of the work plot, but their position is not fixed and can be changed by dragging it to a new one. The perspectives are simply predefined configurations and end users are free to open , move or close tools on the work plot of a perspective as they see fit. The tools can also be maximized or minimized , even popped out in own window. The tools are the minimal atomic parts in the IDE. They are referred to as views or editors and each type is handled differently.","title":"Building blocks"},{"location":"2018/03/02/blogs-3x-ide/#whats-in-the-box","text":"The IDE package contains the Workbench , Git , Database , Repository and Terminal perspectives. The list is neither limited, nor fixed.","title":"What's in the box"},{"location":"2018/03/02/blogs-3x-ide/#workbench","text":"The Workbench perspective comprises Workspace , Import , Properties , Console and Preview views, plus the editors registered for each file type. In a word, the minimal toolset for file management, preview and editing operations. A very handy feature is also the template-based project and artifacts scaffolding generators. New in 3.x - Multiple workspaces per user . User now can create multiple workspaces and use the Workspace view to manage and switch between them. - Non-normative project file structure . The projects file organization is now non-normative and entirely up-to your preferences. - Multiple editors . The IDE now supports multiple editors registered for different file (MIME) types. More than one editor can be registered for one file type and in this case a \" Open with... \" context menu entry is rendered for the user to select, which one to use.","title":"Workbench"},{"location":"2018/03/02/blogs-3x-ide/#git","text":"Git perspective is built from tools supporting Git client operations. It doesn't aim to be what EGit is to Eclipse, but rather to present a simplified interface for the most common operations, such as cloning a repository to a workspace, pulling changes, and pushing commits. For more sophisticated command-line interaction see Terminal","title":"Git"},{"location":"2018/03/02/blogs-3x-ide/#database","text":"The Database perspective is essential for full stack developers. It features a database explorer, a console to execute SQL statements and preview results in table format.","title":"Database"},{"location":"2018/03/02/blogs-3x-ide/#repository","text":"The Repository perspective offers explorer for the repository of the Dirigible instance where the IDE is running, and import/export snapshots.","title":"Repository"},{"location":"2018/03/02/blogs-3x-ide/#terminal","text":"The key view in the perspective is a terminal that emulates console client connected to the environment of the Dirigible IDE that can execute commands.","title":"Terminal"},{"location":"2018/03/02/blogs-3x-ide/#editors","text":"The editors that have been integrated are Orion and Ace . More sophisticated and also visual editors are in the pipeline.","title":"Editors"},{"location":"2018/03/02/blogs-3x-ide/#core-ui-framework","text":"The Core UI framework is an Angular module ( ideUiCore ) that exposes a number of key components, building the backbone of perspectives and tools in the cloud IDE. Many of these can be further customized and some are part of larger compositions (e.g. the Angular directives for menu, sidebar or statusbar). The design encourages customizations if you are up to some tricky scenario or just rolling out a whole new fully functional perspective with a just a couple lines of code. To give you the idea how literally true is that, here is a clue: < body ng-app = \"workbench\" ng-controller = \"WorkbenchController as wb\" > < div menu menu-data-url = \"../../js/ide/services/menu.js\" ></ div > < div class = \"shell\" > < div class = \"sidebar list-group\" sidebar active = \"Workbench\" ></ div > < div id = \"workbench\" class = \"plane\" views-layout views-layout-model = \"wb.layoutModel\" ></ div > </ div > < div class = \"statusbar\" status-bar > {{message}} </ div > </ body > In this HTML template, the directives menu , sidebar , views-layout and statusbar will build a standard perspective layout for you. All you need to add to that (in the corresponding controller) is, which are the views that will be part of the perspective (note the views array property in the layoutModel member below): ... . controller ( 'WorkbenchController' , [ 'Layouts' , function ( Layouts ){ this . layoutModel = { views : [ 'workspace' , 'import' , 'editor' , 'properties' , 'console' , 'preview' ] ... } The components in the core UI framework provide a coherent look and feel for the perspectives and their views and editors in the IDE. A brief description for some of the key components follows.","title":"Core UI framework"},{"location":"2018/03/02/blogs-3x-ide/#message-hub","text":"The IDE building blocks work together in choreography . An action in the Workspace view for example opens-up an editor, or triggers the Preview view to send a request to a service. The communication between the isolated choreography participants is decentralized, and realized by a highly performant, entirely client-side framework - the Message Hub . The Message Hub is a self-contained (no dependencies) JS library that leverages the HTML5 messaging API to convey messages across the UI component isolation (iframe) boundaries via a simplified, yet highly customizable interface. It works across domains if necessary, yet implementing all best-practices for secure cross-origin client-side communication. Here is a hint for the simplicity of the API: A. Load the library < script type = \"text/javascript\" src = \"ui/message-hub.js\" ></ script > <!-- and the following for Angular Apps --> < script type = \"text/javascript\" src = \"ui/ui-layout.js\" ></ script > < script type = \"text/javascript\" src = \"ui/ui-core-ng-modules.js\" ></ script > B. Get an instance - With vanilla JS var messageHub = new FramesMessageHub (); Or in Anguar app angular . module ( 'App' , [ 'ideUiCore' ]) ... . controller ( 'SomeController' , [ 'messageHub' , function ( messageHub ){ ... C. Subscirbe for messages of type 'namespace.messageName' javascript , messageHub.on('namespace.messageName', function(message, postEvent){ //do something... }); D. Post a message to subscribers for the 'namespace.messageName' messages messageHub . send ( 'namespace.messageName' , message ); Using the message hub framework, we build highly performant loosely coupled integrations between isolated components, reducing the boilerplate in setting up communication channels to the bare minimum.","title":"Message Hub"},{"location":"2018/03/02/blogs-3x-ide/#layouts","text":"The cloud IDE layout API delegates the layout management to the GoldenLayout framework \u2013 a \u201c multi-window JavaScript layout manager for webapps \u201c, as the author defines it. It handles all the magic of laying things out, stacking, moving interactively, popping out, maximize/minimize, close and open of views and editors. The angular directive views-layout encapsulates all the complexity of initializing the layout of views in a perspective and reduces it all to a very simple configuration. < div id = \"workbench\" class = \"plane\" views-layout views-layout-model = \"wb.layoutModel\" ></ div > In that code snippet above, wb.layoutModel is a JSON like: { views : [ 'workspace' , 'import' , 'editor' , 'properties' , 'console' , 'preview' ] } The strings in the views array are in fact identifiers for the views registered in the Views Registry maintained by the framework. The registry entries provide essential configuration information for the views, such as their intended region on the work plot, factory function, label and specific configuration. The registry is populated by the views.js service. Layouts is a convenience bag of functions that significantly simplifies the work with layouts. It takes care of views registry setup, the work plot regions configuration, layout initialization, serialization, control on the layout manager, open view and open editor functions, global notifications and others. For example, the API to open programmatically a view (after layout initialization): Layouts.manager.open(viewId, regionId);","title":"Layouts"},{"location":"2018/03/02/blogs-3x-ide/#toolbar","text":"The Toolbar is a composite that aggregates the drop-down menus, the theme selection, the user name and sign-out control. It uses the corresponding UI microservices available in the ideUiCore module as Menu , User and Theme . Having a fully functional standard template menu in a perspective costs as much as this line: < div menu menu-data-url = \"../../js/ide/services/menu.js\" ></ div > The Angular directive menu will take care to render it as appropriate and all it needs for that is the (perspective-specific) URL of a service that will provide the menu items configuration. By convention, all UI components are built with Bootstrap 3.x CSS and the themes in the cloud IDE are actually custom Bootstrap CSS. A UI microservice enables dynamic change of the CSS upon change of the theme automatically. It is available as Angular Factory Theme . The Angular service User provides the details for the user that are rendered by the Menu directive, such as the user name.","title":"Toolbar"},{"location":"2018/03/02/blogs-3x-ide/#sidebar","text":"The sidebar is Angular directive that takes care to render a standard sidebar in the framework template. It works with the perspectives.js service to populate the registered perspectives as shortcuts.","title":"Sidebar"},{"location":"2018/03/02/blogs-3x-ide/#statusbar","text":"The statusbar is an Angular directive that renders a standard, fixed-position footer. The component is subscribed to listen to message types configured as value of the status-bar-topic attribute, or by default to status-message messages.","title":"Statusbar"},{"location":"2018/03/02/blogs-3x-ide/#extensibility-and-dynamic-compositions","text":"The content of the Menu, Sidebar, Open With (editor) action list, the views/editors in a perspective and their positions on the work plot are all examples of configurations that are delivered at runtime by Dirigible services. They leverage the extensions concept in Dirigible, so integrating a new menu (for example) is as easy as a Dirigible module \u201cadvertising\u201d itself (see file.extension ) to the corresponding Dirigible extension point (see menu.extensionpoint ). At runtime, the extensions will be invoked dynamically, their results aggregated and ultimately delivered to the front-end by a service responsible to mashup everything into a lean consumable JSON model (see menu.js ). The whole mechanism shares concepts with the Eclipse plugin framework. It detaches the client-side, which would render anything that can satisfy its data format needs, and server-side data composition mechanisms from the data contributors which are resolved and invoked dynamically. Therefore, to extend the system, all you need to do is to focus on providing a compliant data contributor and the system will take care to resolve and request it for its piece of data when required.","title":"Extensibility and Dynamic Compositions"},{"location":"2018/03/02/blogs-3x-ide/#enjoy","text":"","title":"Enjoy!"},{"location":"2018/05/19/news-new-release-3-2/","text":"New version 3.2 released. Features Flowable engine integration BPMN Modeler Database Schema Modeler Database Schema synchronization support Entity Data Modeler Full-stack Application Templates Launchpad Template Monaco editor added as an optional one ACE editor added as an optional one Velocity template engine added as an alternative Debug Perspective Logs View Jobs View Extensions View Listeners View DataStructures View Access View Roles View Registry View MySQL support for Persistence layer H2 support for Persistence layer BPM API Workspace API RBAC for CMIS Alice theme Florence theme Bugfixes Support for non proxy hosts in HTTP Client Facade Refactoring of the dependencies Disable the filtering option of maven copy content plugin Logging of known properties IDE support for 'dirty' files Statistics 1090+ Downloads 1600+ Docker Pulls 2800+ Trial Users 44 000+ Unique Sessions 117 000+ Unique Views 171 Countries 279 Repositories in DirigibleLabs Operational The full list of bug-fixes and enhancements can be found here . The source code is available at GitHub repository here . The instant trial is updated accordingly with the released version here . Enjoy!","title":"Release 3.2"},{"location":"2018/05/19/news-new-release-3-2/#features","text":"Flowable engine integration BPMN Modeler Database Schema Modeler Database Schema synchronization support Entity Data Modeler Full-stack Application Templates Launchpad Template Monaco editor added as an optional one ACE editor added as an optional one Velocity template engine added as an alternative Debug Perspective Logs View Jobs View Extensions View Listeners View DataStructures View Access View Roles View Registry View MySQL support for Persistence layer H2 support for Persistence layer BPM API Workspace API RBAC for CMIS Alice theme Florence theme","title":"Features"},{"location":"2018/05/19/news-new-release-3-2/#bugfixes","text":"Support for non proxy hosts in HTTP Client Facade Refactoring of the dependencies Disable the filtering option of maven copy content plugin Logging of known properties IDE support for 'dirty' files","title":"Bugfixes"},{"location":"2018/05/19/news-new-release-3-2/#statistics","text":"1090+ Downloads 1600+ Docker Pulls 2800+ Trial Users 44 000+ Unique Sessions 117 000+ Unique Views 171 Countries 279 Repositories in DirigibleLabs","title":"Statistics"},{"location":"2018/05/19/news-new-release-3-2/#operational","text":"The full list of bug-fixes and enhancements can be found here . The source code is available at GitHub repository here . The instant trial is updated accordingly with the released version here .","title":"Operational"},{"location":"2018/05/19/news-new-release-3-2/#enjoy","text":"","title":"Enjoy!"},{"location":"2018/05/31/news-jprime-2018/","text":"We are proud to be part of jPrime Conference again in 2018! This time we had two workshops: the first one related to the Kubernetes container management and our own tool Zeus, which helps for the better overview and cataloging of the deployments; and the second one showing how a production delivery of Dirigible's application can be made; The guides from the workshops can be found here: Zeus on Kubernetes Helium Custom Stack It was quite crowded in the room both days and we were glad to even go deeper by explaining the most recent features releated to MDA tooling, such as Database Schema Modeler, BPMN Modeler and espacially the Entity Data Modeler with the Full-stack Application Templates. It was really wonderful to see so many participants again this year in the de-facto the biggest developer conference in Bulgaria ! Thanks again for the Go5 and all the organizers, sponsors and volunteers! Congrats!","title":"jPrime 2018"},{"location":"2018/05/31/news-jprime-2018/#congrats","text":"","title":"Congrats!"},{"location":"2018/06/25/kubernetes-keycloak-postgresql-dirigible/","text":"This article is dedicated to the \"production-ready\" setup of Eclipse Dirigible in a Kubernetes cluster. Overview In this article we are going to use Kubernes cluster, Keycloak IAM and PostgreSQL database for setting up a productive Eclipse Dirigible development platform. The target Kubernetes deployment is shown bellow: Kubernetes is an open source system for automating deployment, scaling, and management of containerized applications in a cluster environment. You can read more about Kubernetes here . Keycloak is an open source Identity and Access Management system for applications and services. You can read more about Keycloak here . PostgreSQL is a powerful open source object-relational database system with over 30 years of active development that has earned it a strong reputation for reliability, feature robustness, and performance. You can read more about PostgreSQL here . Eclipse Dirigible is a Cloud Development Platform providing development tools and runtime environment. It supports full development life-cycle of on-demand applications by leveraging in-system programming models and rapid application development techniques. You can read more about Dirigible here . Prerequisites In this article we assume that you have already running productive Kubernetes Cluster and configured kubectl for it. If you don't have such, you can create one by using the GKE or the open-source Gardener project. Also we need a configured Helm (The Kubernetes Package Manager) , if you don't have it, you can follow this installation guide . Kubernetes Certificate Management Controller cert-manager is a native Kubernetes certificate management controller. It can help with issuing certificates from a variety of sources, such as Let\u2019s Encrypt , HashiCorp Vault, or a simple signing keypair. You can read more about the cert-manager here . helm install --name cert-manager --namespace kube-system stable/cert-manager We are going to use cert-manager for issuing certificates for our access points to the Keycloak Admin Console and Eclipse Dirigible IDE. Namespaces and ClusterIssuer auth.yaml kind : Namespace metadata : name : auth ... kind : ClusterIssuer metadata : name : letsencrypt-production spec : acme : server : https://acme-v02.api.letsencrypt.org/directory email : <your-email-address> privateKeySecretRef : name : letsencrypt-production http01 : {} Note: For testing purposes it's recommended to use the staging Let's Encrypt server. The whole YAML is available here . Before creating the Kubernetes resources, you should replace the placeholders with the correct values. kubectl create -f auth.yaml Keycloak and PostgreSQL keycloak.yaml kind : StatefulSet metadata : name : postgres ... spec : containers : - name : postgres image : postgres env : - name : PGDATA value : \"/var/lib/postgresql/data/pgdata\" - name : POSTGRES_USER value : \"keycloak\" - name : POSTGRES_PASSWORD value : \"keycloak\" ... kind : Deployment metadata : name : keycloak ... spec : containers : - name : keycloak image : jboss/keycloak env : - name : PROXY_ADDRESS_FORWARDING value : \"true\" - name : DB_VENDOR value : \"postgres\" - name : DB_USER value : \"keycloak\" - name : DB_PASSWORD value : \"keycloak\" - name : DB_ADDR value : \"postgres-jdbc.auth\" - name : KEYCLOAK_USER value : \"admin\" - name : KEYCLOAK_PASSWORD value : \"admin\" ... kind : Ingress metadata : name : keycloak annotations : ingress.kubernetes.io/ssl-redirect : \"true\" kubernetes.io/tls-acme : \"true\" certmanager.k8s.io/cluster-issuer : \"letsencrypt-production\" kubernetes.io/ingress.class : \"nginx\" spec : tls : - hosts : - keycloak.<your-domain-name> secretName : keycloak-production-letsencrypt rules : - host : keycloak.<your-domain-name> ... Note: The maximum length of the host name (e.g. keycloak.YOUR-DOMAIN-NAME ) used for issuing Let's Encrypt certificate is 63 symbols. The whole YAML is available here . Before creating the Kubernetes resources, you should replace the placeholders with the correct values. kubectl create -f keycloak.yaml Dirigible and PostgreSQL dirigible.yaml kind : StatefulSet metadata : name : postgres ... spec : containers : - name : postgres image : postgres env : - name : PGDATA value : \"/var/lib/postgresql/data/pgdata\" - name : POSTGRES_USER value : \"dirigible\" - name : POSTGRES_PASSWORD value : \"dirigible\" ... kind : StatefulSet metadata : name : dirigible ... spec : containers : - name : dirigible image : dirigiblelabs/dirigible-keycloak env : - name : DIRIGIBLE_DATABASE_PROVIDER value : \"custom\" - name : DIRIGIBLE_DATABASE_CUSTOM_DATASOURCES value : \"POSTGRES\" - name : POSTGRES_URL value : \"jdbc:postgresql://postgres-jdbc.dirigible:5432/dirigible\" - name : POSTGRES_USERNAME value : \"dirigible\" - name : POSTGRES_PASSWORD value : \"dirigible\" ... - name : KEYCLOAK_CONFIDENTIAL_PORT value : \"443\" - name : KEYCLOAK_SSL_REQUIRED value : \"none\" - name : KEYCLOAK_CLIENT_ID value : \"dirigible\" - name : KEYCLOAK_REALM value : \"master\" - name : KEYCLOAK_AUTH_SERVER_URL value : \"https://keycloak.<your-domain-name>/auth\" ... kind : Ingress metadata : annotations : ingress.kubernetes.io/ssl-redirect : \"true\" kubernetes.io/tls-acme : \"true\" certmanager.k8s.io/cluster-issuer : \"letsencrypt-production\" kubernetes.io/ingress.class : \"nginx\" name : dirigible namespace : dirigible spec : tls : - hosts : - ide.<your-domain-name> secretName : dirigible-certificate rules : - host : ide.<your-domain-name> Note: The maximum length of the host name (e.g. ide.YOUR-DOMAIN-NAME ) used for issuing Let's Encrypt certificate is 63 symbols. The whole list of Eclipse Dirigible environment variables can be found here The whole YAML is available here . Before creating the Kubernetes resources, you should replace the placeholders with the correct values. kubectl create -f dirigible.yaml Add Keycloak Client and Users Open the Keycloak welcome page ( https://keycloak.YOUR-DOMAIN-NAME ) and click on the Admin Console , login with admin/admin credentials (see keycloak.yaml ). Create new client named dirigible For the Root URL add Root URL: http://ide.YOUR-DOMAIN-NAME Add Client Roles: Everyone Developer Operator Create new user Assign User's roles from the dirigible client Set password from the Credentials tab Open the Eclipse Dirigible IDE: http://ide.YOUR-DOMAIN-NAME/ and login with the credentials that were created previously in the Keycloak Admin Console. The Keycloak documentation can be found here . Also you can find out how to enable Keycloak Social Login with GitHub here . Credits How to launch nginx-ingress and cert-manager in Kubernetes","title":"Kubernetes, Keycloak, PostgreSQL & Dirigible"},{"location":"2018/06/25/kubernetes-keycloak-postgresql-dirigible/#overview","text":"In this article we are going to use Kubernes cluster, Keycloak IAM and PostgreSQL database for setting up a productive Eclipse Dirigible development platform. The target Kubernetes deployment is shown bellow:","title":"Overview"},{"location":"2018/06/25/kubernetes-keycloak-postgresql-dirigible/#kubernetes","text":"is an open source system for automating deployment, scaling, and management of containerized applications in a cluster environment. You can read more about Kubernetes here .","title":"Kubernetes"},{"location":"2018/06/25/kubernetes-keycloak-postgresql-dirigible/#keycloak","text":"is an open source Identity and Access Management system for applications and services. You can read more about Keycloak here .","title":"Keycloak"},{"location":"2018/06/25/kubernetes-keycloak-postgresql-dirigible/#postgresql","text":"is a powerful open source object-relational database system with over 30 years of active development that has earned it a strong reputation for reliability, feature robustness, and performance. You can read more about PostgreSQL here .","title":"PostgreSQL"},{"location":"2018/06/25/kubernetes-keycloak-postgresql-dirigible/#eclipse-dirigible","text":"is a Cloud Development Platform providing development tools and runtime environment. It supports full development life-cycle of on-demand applications by leveraging in-system programming models and rapid application development techniques. You can read more about Dirigible here .","title":"Eclipse Dirigible"},{"location":"2018/06/25/kubernetes-keycloak-postgresql-dirigible/#prerequisites","text":"In this article we assume that you have already running productive Kubernetes Cluster and configured kubectl for it. If you don't have such, you can create one by using the GKE or the open-source Gardener project. Also we need a configured Helm (The Kubernetes Package Manager) , if you don't have it, you can follow this installation guide .","title":"Prerequisites"},{"location":"2018/06/25/kubernetes-keycloak-postgresql-dirigible/#kubernetes-certificate-management-controller","text":"cert-manager is a native Kubernetes certificate management controller. It can help with issuing certificates from a variety of sources, such as Let\u2019s Encrypt , HashiCorp Vault, or a simple signing keypair. You can read more about the cert-manager here . helm install --name cert-manager --namespace kube-system stable/cert-manager We are going to use cert-manager for issuing certificates for our access points to the Keycloak Admin Console and Eclipse Dirigible IDE.","title":"Kubernetes Certificate Management Controller"},{"location":"2018/06/25/kubernetes-keycloak-postgresql-dirigible/#namespaces-and-clusterissuer","text":"","title":"Namespaces and ClusterIssuer"},{"location":"2018/06/25/kubernetes-keycloak-postgresql-dirigible/#authyaml","text":"kind : Namespace metadata : name : auth ... kind : ClusterIssuer metadata : name : letsencrypt-production spec : acme : server : https://acme-v02.api.letsencrypt.org/directory email : <your-email-address> privateKeySecretRef : name : letsencrypt-production http01 : {} Note: For testing purposes it's recommended to use the staging Let's Encrypt server. The whole YAML is available here . Before creating the Kubernetes resources, you should replace the placeholders with the correct values. kubectl create -f auth.yaml","title":"auth.yaml"},{"location":"2018/06/25/kubernetes-keycloak-postgresql-dirigible/#keycloak-and-postgresql","text":"","title":"Keycloak and PostgreSQL"},{"location":"2018/06/25/kubernetes-keycloak-postgresql-dirigible/#keycloakyaml","text":"kind : StatefulSet metadata : name : postgres ... spec : containers : - name : postgres image : postgres env : - name : PGDATA value : \"/var/lib/postgresql/data/pgdata\" - name : POSTGRES_USER value : \"keycloak\" - name : POSTGRES_PASSWORD value : \"keycloak\" ... kind : Deployment metadata : name : keycloak ... spec : containers : - name : keycloak image : jboss/keycloak env : - name : PROXY_ADDRESS_FORWARDING value : \"true\" - name : DB_VENDOR value : \"postgres\" - name : DB_USER value : \"keycloak\" - name : DB_PASSWORD value : \"keycloak\" - name : DB_ADDR value : \"postgres-jdbc.auth\" - name : KEYCLOAK_USER value : \"admin\" - name : KEYCLOAK_PASSWORD value : \"admin\" ... kind : Ingress metadata : name : keycloak annotations : ingress.kubernetes.io/ssl-redirect : \"true\" kubernetes.io/tls-acme : \"true\" certmanager.k8s.io/cluster-issuer : \"letsencrypt-production\" kubernetes.io/ingress.class : \"nginx\" spec : tls : - hosts : - keycloak.<your-domain-name> secretName : keycloak-production-letsencrypt rules : - host : keycloak.<your-domain-name> ... Note: The maximum length of the host name (e.g. keycloak.YOUR-DOMAIN-NAME ) used for issuing Let's Encrypt certificate is 63 symbols. The whole YAML is available here . Before creating the Kubernetes resources, you should replace the placeholders with the correct values. kubectl create -f keycloak.yaml","title":"keycloak.yaml"},{"location":"2018/06/25/kubernetes-keycloak-postgresql-dirigible/#dirigible-and-postgresql","text":"","title":"Dirigible and PostgreSQL"},{"location":"2018/06/25/kubernetes-keycloak-postgresql-dirigible/#dirigibleyaml","text":"kind : StatefulSet metadata : name : postgres ... spec : containers : - name : postgres image : postgres env : - name : PGDATA value : \"/var/lib/postgresql/data/pgdata\" - name : POSTGRES_USER value : \"dirigible\" - name : POSTGRES_PASSWORD value : \"dirigible\" ... kind : StatefulSet metadata : name : dirigible ... spec : containers : - name : dirigible image : dirigiblelabs/dirigible-keycloak env : - name : DIRIGIBLE_DATABASE_PROVIDER value : \"custom\" - name : DIRIGIBLE_DATABASE_CUSTOM_DATASOURCES value : \"POSTGRES\" - name : POSTGRES_URL value : \"jdbc:postgresql://postgres-jdbc.dirigible:5432/dirigible\" - name : POSTGRES_USERNAME value : \"dirigible\" - name : POSTGRES_PASSWORD value : \"dirigible\" ... - name : KEYCLOAK_CONFIDENTIAL_PORT value : \"443\" - name : KEYCLOAK_SSL_REQUIRED value : \"none\" - name : KEYCLOAK_CLIENT_ID value : \"dirigible\" - name : KEYCLOAK_REALM value : \"master\" - name : KEYCLOAK_AUTH_SERVER_URL value : \"https://keycloak.<your-domain-name>/auth\" ... kind : Ingress metadata : annotations : ingress.kubernetes.io/ssl-redirect : \"true\" kubernetes.io/tls-acme : \"true\" certmanager.k8s.io/cluster-issuer : \"letsencrypt-production\" kubernetes.io/ingress.class : \"nginx\" name : dirigible namespace : dirigible spec : tls : - hosts : - ide.<your-domain-name> secretName : dirigible-certificate rules : - host : ide.<your-domain-name> Note: The maximum length of the host name (e.g. ide.YOUR-DOMAIN-NAME ) used for issuing Let's Encrypt certificate is 63 symbols. The whole list of Eclipse Dirigible environment variables can be found here The whole YAML is available here . Before creating the Kubernetes resources, you should replace the placeholders with the correct values. kubectl create -f dirigible.yaml","title":"dirigible.yaml"},{"location":"2018/06/25/kubernetes-keycloak-postgresql-dirigible/#add-keycloak-client-and-users","text":"Open the Keycloak welcome page ( https://keycloak.YOUR-DOMAIN-NAME ) and click on the Admin Console , login with admin/admin credentials (see keycloak.yaml ). Create new client named dirigible For the Root URL add Root URL: http://ide.YOUR-DOMAIN-NAME Add Client Roles: Everyone Developer Operator Create new user Assign User's roles from the dirigible client Set password from the Credentials tab Open the Eclipse Dirigible IDE: http://ide.YOUR-DOMAIN-NAME/ and login with the credentials that were created previously in the Keycloak Admin Console. The Keycloak documentation can be found here . Also you can find out how to enable Keycloak Social Login with GitHub here .","title":"Add Keycloak Client and Users"},{"location":"2018/06/25/kubernetes-keycloak-postgresql-dirigible/#credits","text":"How to launch nginx-ingress and cert-manager in Kubernetes","title":"Credits"},{"location":"2018/11/08/blogs-make-low-code-great-again/","text":"Buy Application or Build Application It's been a fundamental question for Enterprises and SMEs over the last few decades. Can you save money by buying a packaged software, which follows the best practices and does exactly what you need or is this just an imaginary dream? Obviously, there is no single answer to this simple question. Usually, companies still stick to the packaged ready-to-use solutions coming from well-established software vendors for their core business processes, but at the same time open the door for in-house LoB applications built by their own IT staff or a partner. While the first one gives them stability for the mainstream business, the latter gives them an innovation power to cover the brand new yet differentiating business models. Sounds reasonable and pragmatic, no chief executive will be fired by following this strategy. Let's leave aside the packaged software case with its configurability, customization and extensibility strengths for another blog post and focus now on the build-your-own-application scenario. What does \"build\" mean for a company, which doesn't have an IT background? There are several options here - you can hire and manage your own developers, contact partners, use freelancers ... All these options have their pros and cons. What happens in reality is that most companies just go for all of them at the same time to minimize the risks. On one hand, this leads very easily to a situation, where the company has its own staff that has to gain technological know-how for the projects and try to control the development processes, time frames and feature sets. On the other hand, there are partners that offer developer manpower, but in fact they strive for maximum execution time i.e. budget, claiming the highest possible quality at the lowest possible cost. Depending on the complexity of the project and the technology stack, the negotiations can be very hard for everyone in that round and the outcome always results in a - wrong estimation . The good thing here is that nobody actually expects that the estimation will be precise, so why are we wasting time in useless activities? Can we build the application directly instead of making estimations? Here comes the Low-Code/No-Code hype. Also, the reborn hype related to BPM. Also, the reborn hype for MDA and RAD. Are they just the next wave of cool stuff that soon will be just a record in software history without a meaningful impact? Only time will tell. What is different nowadays that can lead to a massive usage of high productivity tools for building tailored applications? It is unlikely that there will be a new vendor of packaged software, who can build everything for everybody - it's an unrealistic huge investment The companies no more stop at the stage where they just follow the standard best practices for their industry - they need to be innovative to survive Cloud infrastructure is already matured enough at a level where one can use it to run a high-scale SaaS solution entirely based on the Cloud Old-fashioned software technologies do not fit well with the new infrastructure and quality requirements Transparency (and the ability to prove it) of the whole lifecycle of the business software development is already a must - not a nice-to-have feature and Time-to-market is the most important goal when applying a new business model - nobody can wait months and years for its implementation All abovementioned reasons, make the Low-Code/No-Code tools and even whole development platforms to rise again. This time in the Cloud - instantly accessible via a Web interface. They will fight for a multibillion business segment in the next few years, hence their business case looks promising. There is just a small problem - all of them are quite expensive for the SMBs, even for enterprises, although they have better ROI, TCD and TCO metrics than the standard development models. And there is a reason for this. The business scenarios are usually complex; hence somebody has to invest a fairly large amount of effort to build a solution. If it is not paid by the customer for the development, then it is paid by the platform vendor for building RAD tools, providing robust middleware, giving great monitoring and operations tools. Then the customer pays for the platform more and less for the development on this platform. It is quite simple and fair, isn't it? What exactly does such a platform provide? Is there an open-source alternative? BPM or MDA? There are two major approaches at the moment - Business-Process-Model driven tools and platforms and those who rely on the Model-Driven-Architecture concepts. While the first one gives extremely fast and exhaustive implementation of the workflows including automated and user interactive tasks, the second one is focused on the definition of the domain model (or similar) and generation of the backbone of an application - mainly with CRUD support. So, following both approaches you can cover both - the structure and the behavior aspects for a given business scenario. What did we decide to provide in Dirigible? As you can guess, following our principle to cover the full development lifecycle end-to-end, the decision was simple - to provide both... and more. We managed to integrate the world's leading BPM engine - Flowable along with the browser-based BPMN 2.0 modeler. Now, you can create a business model on-the-fly on the live system and even to implement the steps in the same way using our famous Enterprise JavaScript API . More information about how to create a simple process you can find under the samples section . For the second stream, we decided to follow the Entity-Data-Model approach, where all the information needed for the generation process is included in a single artifact. Now, you can visually drag-and-drop the entities representing your domain model as well as to set the parameters in separated spaces e.g. General, Database, User Interface. Then, you can choose one of the provided generation templates and build a whole business application including the whole database layout, RESTful backend services, CRUD forms, reports and even a launchpad home page. This one is very useful for administrative or simple internal LoB applications. For more sophisticated user interfaces, for instance, you can use the already available (during the generation) extension points. To try it by yourself, you can just follow the steps in this tutorial . For the complementary features with regards to collaborative development, issue tracking, requirements and project management, validation and verification of the releases and even design-thinking tools, we mainly integrate GitHub, TravisCI, Docker, and some other Cloud-based third-party development services as well. Does it mean that Dirigible is a full-fledged Low-Code/No-Code platform? No. It is an open-source project providing lots of features covering variety of scenarios in this space, but it is not a product. - Can I consider building a real productive Low-Code/No-Code platform based on Dirigible? Definitely - YES!","title":"Make Low-Code/No-Code Platforms Great Again!"},{"location":"2018/11/08/blogs-make-low-code-great-again/#buy-application-or-build-application","text":"It's been a fundamental question for Enterprises and SMEs over the last few decades. Can you save money by buying a packaged software, which follows the best practices and does exactly what you need or is this just an imaginary dream? Obviously, there is no single answer to this simple question. Usually, companies still stick to the packaged ready-to-use solutions coming from well-established software vendors for their core business processes, but at the same time open the door for in-house LoB applications built by their own IT staff or a partner. While the first one gives them stability for the mainstream business, the latter gives them an innovation power to cover the brand new yet differentiating business models. Sounds reasonable and pragmatic, no chief executive will be fired by following this strategy. Let's leave aside the packaged software case with its configurability, customization and extensibility strengths for another blog post and focus now on the build-your-own-application scenario.","title":"Buy Application or Build Application"},{"location":"2018/11/08/blogs-make-low-code-great-again/#what-does-build-mean-for-a-company-which-doesnt-have-an-it-background","text":"There are several options here - you can hire and manage your own developers, contact partners, use freelancers ... All these options have their pros and cons. What happens in reality is that most companies just go for all of them at the same time to minimize the risks. On one hand, this leads very easily to a situation, where the company has its own staff that has to gain technological know-how for the projects and try to control the development processes, time frames and feature sets. On the other hand, there are partners that offer developer manpower, but in fact they strive for maximum execution time i.e. budget, claiming the highest possible quality at the lowest possible cost. Depending on the complexity of the project and the technology stack, the negotiations can be very hard for everyone in that round and the outcome always results in a - wrong estimation . The good thing here is that nobody actually expects that the estimation will be precise, so why are we wasting time in useless activities?","title":"What does \"build\" mean for a company, which doesn't have an IT background?"},{"location":"2018/11/08/blogs-make-low-code-great-again/#can-we-build-the-application-directly-instead-of-making-estimations","text":"Here comes the Low-Code/No-Code hype. Also, the reborn hype related to BPM. Also, the reborn hype for MDA and RAD. Are they just the next wave of cool stuff that soon will be just a record in software history without a meaningful impact? Only time will tell. What is different nowadays that can lead to a massive usage of high productivity tools for building tailored applications? It is unlikely that there will be a new vendor of packaged software, who can build everything for everybody - it's an unrealistic huge investment The companies no more stop at the stage where they just follow the standard best practices for their industry - they need to be innovative to survive Cloud infrastructure is already matured enough at a level where one can use it to run a high-scale SaaS solution entirely based on the Cloud Old-fashioned software technologies do not fit well with the new infrastructure and quality requirements Transparency (and the ability to prove it) of the whole lifecycle of the business software development is already a must - not a nice-to-have feature and Time-to-market is the most important goal when applying a new business model - nobody can wait months and years for its implementation All abovementioned reasons, make the Low-Code/No-Code tools and even whole development platforms to rise again. This time in the Cloud - instantly accessible via a Web interface. They will fight for a multibillion business segment in the next few years, hence their business case looks promising. There is just a small problem - all of them are quite expensive for the SMBs, even for enterprises, although they have better ROI, TCD and TCO metrics than the standard development models. And there is a reason for this. The business scenarios are usually complex; hence somebody has to invest a fairly large amount of effort to build a solution. If it is not paid by the customer for the development, then it is paid by the platform vendor for building RAD tools, providing robust middleware, giving great monitoring and operations tools. Then the customer pays for the platform more and less for the development on this platform. It is quite simple and fair, isn't it? What exactly does such a platform provide? Is there an open-source alternative?","title":"Can we build the application directly instead of making estimations?"},{"location":"2018/11/08/blogs-make-low-code-great-again/#bpm-or-mda","text":"There are two major approaches at the moment - Business-Process-Model driven tools and platforms and those who rely on the Model-Driven-Architecture concepts. While the first one gives extremely fast and exhaustive implementation of the workflows including automated and user interactive tasks, the second one is focused on the definition of the domain model (or similar) and generation of the backbone of an application - mainly with CRUD support. So, following both approaches you can cover both - the structure and the behavior aspects for a given business scenario. What did we decide to provide in Dirigible? As you can guess, following our principle to cover the full development lifecycle end-to-end, the decision was simple - to provide both... and more. We managed to integrate the world's leading BPM engine - Flowable along with the browser-based BPMN 2.0 modeler. Now, you can create a business model on-the-fly on the live system and even to implement the steps in the same way using our famous Enterprise JavaScript API . More information about how to create a simple process you can find under the samples section . For the second stream, we decided to follow the Entity-Data-Model approach, where all the information needed for the generation process is included in a single artifact. Now, you can visually drag-and-drop the entities representing your domain model as well as to set the parameters in separated spaces e.g. General, Database, User Interface. Then, you can choose one of the provided generation templates and build a whole business application including the whole database layout, RESTful backend services, CRUD forms, reports and even a launchpad home page. This one is very useful for administrative or simple internal LoB applications. For more sophisticated user interfaces, for instance, you can use the already available (during the generation) extension points. To try it by yourself, you can just follow the steps in this tutorial . For the complementary features with regards to collaborative development, issue tracking, requirements and project management, validation and verification of the releases and even design-thinking tools, we mainly integrate GitHub, TravisCI, Docker, and some other Cloud-based third-party development services as well.","title":"BPM or MDA?"},{"location":"2018/11/08/blogs-make-low-code-great-again/#does-it-mean-that-dirigible-is-a-full-fledged-low-codeno-code-platform","text":"No. It is an open-source project providing lots of features covering variety of scenarios in this space, but it is not a product.","title":"Does it mean that Dirigible is a full-fledged Low-Code/No-Code platform?"},{"location":"2018/11/08/blogs-make-low-code-great-again/#-can-i-consider-building-a-real-productive-low-codeno-code-platform-based-on-dirigible","text":"Definitely - YES!","title":"- Can I consider building a real productive Low-Code/No-Code platform based on Dirigible?"},{"location":"2018/11/09/dirigible-extend-embed-reuse/","text":"The latest major upgrade of Dirigible to 3.x opens the door for scenarios like building custom stacks, standardized application CI, embedded Dirigible and many more ... Overview With the latest major upgrade to Eclipse Dirigible 3.x, there are a lot of improvements starting from the project structure and stretching all the way up to the entirely new Web IDE. Some of them are: - New Web IDE - Entity Data Modeler - Support for Business Processes - Standardized Applications CI (WebJars) - Keycloak Integration - 200+ Maven Artifacts - OSGi Free Modules - and many more ... In this post, we will emphasize on the improved CI process and the scenarios it unlocks. For example, with the 200+ Maven Artifacts, the customization of Dirigible is more flexible than ever. Custom Dirigible Stack can be built with ease, or only some modules can be added as dependencies in existing projects (e.g. SQL & Persistency modules). Finally, having a hybrid (embedded) deployment is another interesting capability that is worth looking at (e.g. in existing Spring Stack). Custom Stack Building a custom Dirigible stack is the second-best option to run in production (if the pre-built releases don't fit the project needs). The Helium Custom Stack tutorial explores in detail all aspects of building a custom Dirigible stack: 1. Setting up maven project(s) layout 2. Building WebJar(s) 3. Exposing an Enterprise JavaScript API (both Java facade and JavaScript API) 4. Consuming Dirigible dependencies Reuse of Modules With 200+ Maven artifacts, it's obvious that some modules can be reused even in non-Dirigible related projects. For example, the SQL builder and the ORM can be consumed on their own: Database - SQL Builder: Builder: ... import org.eclipse.dirigible.database.sql.SqlFactory ; ... public class StudentsDao { private static SqlFactory sqlFactory ; public List < StudentEntity > searchByFirstName ( String name ) { String sql = getSqlFactory () . select () . column ( \"*\" ) . from ( \"STUDENTS\" ) . where ( \"STUDENT_FIRST_NAME like ?\" ) . build (); return query ( sql , name ); } private SqlFactory getSqlFactory () { if ( sqlFactory == null ) { Connection connection = null ; try { connection = getConnection (); sqlFactory = SqlFactory . getNative ( connection ); } finally { closeConnection ( connection ); } } return sqlFactory ; } ... Dependency: <dependency> <groupId> org.eclipse.dirigible </groupId> <artifactId> dirigible-database-sql </artifactId> <version> 3.2.8 </version> </dependency> Database - ORM: Dirigible's ORM is compatible with the Java Persistence API : Entity ... import javax.persistence.Column ; import javax.persistence.GeneratedValue ; import javax.persistence.GenerationType ; import javax.persistence.Id ; import javax.persistence.Table ; ... @Table ( name = \"STUDENTS\" ) public class StudentEntity { @Id @GeneratedValue ( strategy = GenerationType . IDENTITY ) @Column ( name = \"STUDENT_ID\" , columnDefinition = \"BIGINT\" ) private Long id ; ... 1. DAO: ... import org.eclipse.dirigible.database.persistence.PersistenceManager ; ... public class StudentsDao { private PersistenceManager < StudentEntity > persistenceManager = new PersistenceManager <> (); public StudentEntity find ( Long id ) { Connection connection = null ; try { connection = getConnection (); return persistenceManager . find ( connection , StudentEntity . class , id ); } finally { closeConnection ( connection ); } } public List < StudentEntity > query ( String sql , Object ... values ) { Connection connection = null ; try { connection = getConnection (); return persistenceManager . query ( connection , StudentEntity . class , sql , values ); } finally { closeConnection ( connection ); } } ... 1. Dependency <dependency> <groupId> org.eclipse.dirigible </groupId> <artifactId> dirigible-database-persistence </artifactId> <version> 3.2.8 </version> </dependency> Embedded Dirigible The last option is the hybrid/embedded deployment, where a legacy application is running in coexistence with part of the Dirigible stack. The setup targets the scenarios where there is a lot of legacy (Java) code, but the low-code/no-code and In-System Development capabilities of Dirigible are desired. ... import org.eclipse.dirigible.runtime.core.embed.EmbeddedDirigible ; ... public void callDirigible () { EmbeddedDirigible dirigible = new EmbeddedDirigible (); dirigible . load ( \"./content\" ); dirigible . executeJavaScript ( \"project/api.js\" ); } ... For more details about this setup, check out the embedded Dirigible sample . Resources Experiment with the single-click deployment of the following demos from EclipseCon 2018 : ( GitHub ) ( GitHub ) ( GitHub ) ( GitHub ) ( GitHub )","title":"Dirigible - Extend, Embed, Reuse"},{"location":"2018/11/09/dirigible-extend-embed-reuse/#overview","text":"With the latest major upgrade to Eclipse Dirigible 3.x, there are a lot of improvements starting from the project structure and stretching all the way up to the entirely new Web IDE. Some of them are: - New Web IDE - Entity Data Modeler - Support for Business Processes - Standardized Applications CI (WebJars) - Keycloak Integration - 200+ Maven Artifacts - OSGi Free Modules - and many more ... In this post, we will emphasize on the improved CI process and the scenarios it unlocks. For example, with the 200+ Maven Artifacts, the customization of Dirigible is more flexible than ever. Custom Dirigible Stack can be built with ease, or only some modules can be added as dependencies in existing projects (e.g. SQL & Persistency modules). Finally, having a hybrid (embedded) deployment is another interesting capability that is worth looking at (e.g. in existing Spring Stack).","title":"Overview"},{"location":"2018/11/09/dirigible-extend-embed-reuse/#custom-stack","text":"Building a custom Dirigible stack is the second-best option to run in production (if the pre-built releases don't fit the project needs). The Helium Custom Stack tutorial explores in detail all aspects of building a custom Dirigible stack: 1. Setting up maven project(s) layout 2. Building WebJar(s) 3. Exposing an Enterprise JavaScript API (both Java facade and JavaScript API) 4. Consuming Dirigible dependencies","title":"Custom Stack"},{"location":"2018/11/09/dirigible-extend-embed-reuse/#reuse-of-modules","text":"With 200+ Maven artifacts, it's obvious that some modules can be reused even in non-Dirigible related projects. For example, the SQL builder and the ORM can be consumed on their own:","title":"Reuse of Modules"},{"location":"2018/11/09/dirigible-extend-embed-reuse/#database-sql-builder","text":"Builder: ... import org.eclipse.dirigible.database.sql.SqlFactory ; ... public class StudentsDao { private static SqlFactory sqlFactory ; public List < StudentEntity > searchByFirstName ( String name ) { String sql = getSqlFactory () . select () . column ( \"*\" ) . from ( \"STUDENTS\" ) . where ( \"STUDENT_FIRST_NAME like ?\" ) . build (); return query ( sql , name ); } private SqlFactory getSqlFactory () { if ( sqlFactory == null ) { Connection connection = null ; try { connection = getConnection (); sqlFactory = SqlFactory . getNative ( connection ); } finally { closeConnection ( connection ); } } return sqlFactory ; } ... Dependency: <dependency> <groupId> org.eclipse.dirigible </groupId> <artifactId> dirigible-database-sql </artifactId> <version> 3.2.8 </version> </dependency>","title":"Database - SQL Builder:"},{"location":"2018/11/09/dirigible-extend-embed-reuse/#database-orm","text":"Dirigible's ORM is compatible with the Java Persistence API : Entity ... import javax.persistence.Column ; import javax.persistence.GeneratedValue ; import javax.persistence.GenerationType ; import javax.persistence.Id ; import javax.persistence.Table ; ... @Table ( name = \"STUDENTS\" ) public class StudentEntity { @Id @GeneratedValue ( strategy = GenerationType . IDENTITY ) @Column ( name = \"STUDENT_ID\" , columnDefinition = \"BIGINT\" ) private Long id ; ... 1. DAO: ... import org.eclipse.dirigible.database.persistence.PersistenceManager ; ... public class StudentsDao { private PersistenceManager < StudentEntity > persistenceManager = new PersistenceManager <> (); public StudentEntity find ( Long id ) { Connection connection = null ; try { connection = getConnection (); return persistenceManager . find ( connection , StudentEntity . class , id ); } finally { closeConnection ( connection ); } } public List < StudentEntity > query ( String sql , Object ... values ) { Connection connection = null ; try { connection = getConnection (); return persistenceManager . query ( connection , StudentEntity . class , sql , values ); } finally { closeConnection ( connection ); } } ... 1. Dependency <dependency> <groupId> org.eclipse.dirigible </groupId> <artifactId> dirigible-database-persistence </artifactId> <version> 3.2.8 </version> </dependency>","title":"Database - ORM:"},{"location":"2018/11/09/dirigible-extend-embed-reuse/#embedded-dirigible","text":"The last option is the hybrid/embedded deployment, where a legacy application is running in coexistence with part of the Dirigible stack. The setup targets the scenarios where there is a lot of legacy (Java) code, but the low-code/no-code and In-System Development capabilities of Dirigible are desired. ... import org.eclipse.dirigible.runtime.core.embed.EmbeddedDirigible ; ... public void callDirigible () { EmbeddedDirigible dirigible = new EmbeddedDirigible (); dirigible . load ( \"./content\" ); dirigible . executeJavaScript ( \"project/api.js\" ); } ... For more details about this setup, check out the embedded Dirigible sample .","title":"Embedded Dirigible"},{"location":"2018/11/09/dirigible-extend-embed-reuse/#resources","text":"Experiment with the single-click deployment of the following demos from EclipseCon 2018 : ( GitHub ) ( GitHub ) ( GitHub ) ( GitHub ) ( GitHub )","title":"Resources"},{"location":"2018/11/12/blogs-dirigible-ide-on-che-workspaces/","text":"Eclipse Cloud Development - ONE team, ONE product What is Eclipse Cloud Development (ECD) and why should I consider it? ECD is a Top-Level Project (TLP) at Eclipse Foundation that provides open-source implementations of standards, services and frameworks that enable developing for and in the Cloud. If you read the definition from the home page, you will be misled that this is a single product or at least a bunch of projects that are complementary to each other and can run simultaneously. That was not exactly true for several years, since the beginning of the ECD initiative itself. Apart from Flux, which was a collaboration development middleware framework, there were actually three major full-stack development platforms - Orion, Che and Dirigible, each of them with its own Web IDE and own backend. They were just three fancy vehicles parked in a special place in front of the Eclipse Foundation house. Each of them was built for its own purpose and based on its own technology stack, without so much care about the others. Good start - there was quite a big room for improvement. I remember the invaluable initial discussions we had in San Francisco more than three years ago. We tried to understand each other, which are the scenarios we want to cover, how to integrate them and how exactly to respond to the community, which required from us ONE single offering for their Cloud development needs. The plan was just roughly defined, but all of us were eager to go for it and to collaborate much closely. Time has passed, many things have changed. The projects matured by passing several reimplementation phases, clarified the goals and strategies, some acquisitions happened, new players appeared and even one was retired. Still, nobody has seen a prominent path forward for a much deeper integration. Until now! Eclipse Che as a center of gravity for Cloud development environments In the last few months Che guys were working hard on the new approach for workspaces management for the 7.0 release. One of the major changes is that now they allow contributions not only for IDE plugins, but also for whole Web IDE stacks as separate Docker containers. This helped them to retire the old-fashioned GWT based Web IDE and replace it with the modern Monaco based one - Theia. This also gives an opportunity for other development platforms, leveraging different development models and covering different development scenarios to land on the Che planet as well. This was seen by all of us as a great opportunity to finally start a new age of integration, which can lead to a real consolidation of tools, models, and efforts. Dirigible as a Che editor plugin Following the new extensibility concept, first we had to create a plugin descriptor for Dirigible. It contains the metadata about the content you want to contribute - name, description, Docker image identifier, environment variables, etc. version: 1.0.0 type: Che Editor name: eclipse-dirigible id: org.eclipse.che.editor.dirigible title: Eclipse Dirigible as Editor for Eclipse Che description: Eclipse Dirigible as Editor for Eclipse Che icon: http://download.eclipse.org/dirigible/dirigible.png endpoints: - name: \"dirigible\" public: true targetPort: 8080 attributes: protocol: http type: ide containers: - name: eclipse-dirigible image: dirigiblelabs/dirigible-anonymous env: - name: DIRIGIBLE_REPOSITORY_LOCAL_ROOT_FOLDER value: /projects/dirigible/repository - name: DIRIGIBLE_REPOSITORY_LOCAL_ROOT_FOLDER_IS_ABSOLUTE value: true - name: DIRIGIBLE_REPOSITORY_SEARCH_ROOT_FOLDER value: /projects/dirigible/repository - name: DIRIGIBLE_REPOSITORY_SEARCH_ROOT_FOLDER_IS_ABSOLUTE value: true - name: DIRIGIBLE_CMS_INTERNAL_ROOT_FOLDER value: /projects/dirigible/cms - name: DIRIGIBLE_CMS_INTERNAL_ROOT_FOLDER_IS_ABSOLUTE value: true - name: DIRIGIBLE_DATABASE_H2_ROOT_FOLDER_DEFAULT value: /projects/dirigible/h2 - name: DIRIGIBLE_DATABASE_H2_URL value: jdbc:h2:/projects/dirigible/h2 - name: DIRIGIBLE_OPERATIONS_LOGS_ROOT_FOLDER_DEFAULT value: /usr/local/tomcat/logs volumes: - mountPath: \"/projects\" name: projects ports: - exposedPort: 8080 memory-limit: \"512M\" The GitHub repository containing the project is at: https://github.com/dirigiblelabs/dirigible-che-editor-plugin Because the development environment is secured by OpenShift underneath, we use here the dirigiblelabs/dirigible-anonymous Docker image of Dirigible. Environment variables mainly redirect the file system dependent components of Dirigible to use the default /projects persistent folder. We made several experiments with different sets of configurations, which we activated on the local Che registry by using the publish_plugin command. publish_plugin dirigible-che-editor-plugin 1.0.0 che Once we agreed how the first version of the plugin should look like, we had to add our plugin definition to the official Che registry metadata to be available by default on any standard Che environment. The process says we have to make a PR to the repository: https://github.com/eclipse/che-plugin-registry . The actual PR is: https://github.com/eclipse/che-plugin-registry/pull/54 What it does is adding the metadata of the given plugin under a predefined folder structure of the Che registry: id: org.eclipse.che.editor.dirigible version: 1.0.0 type: Che Editor name: dirigible-che-editor-plugin title: Eclipse Dirigible for Eclipse Che description: Eclipse Dirigible as App Development Platform for Eclipse Che icon: https://www.dirigible.io/img/logo/dirigible-logo.png url: https://github.com/dirigiblelabs/dirigible-che-editor-plugin/releases/download/1.0.0/dirigible-che-editor-plugin.tar.gz The document with all the needed steps presented by Gorkem and Florent at EclipseCon Europe 2018 can be found at: https://docs.google.com/document/d/1hFXTwzIU3MnqcciXH9E7xyUtEJRUeUuJ-e0JlEhTKjo/edit Start Dirigible based workspace in Che Since the beginning of this week you can go on the public Che environment on the OpenShift platform at: https://che.openshift.io/dashboard/#/workspaces and create a new workspace. In the configurations wizard, choose Che 7 dev stack and dirigible-che-editor-plugin . Click the \"Create\" button and wait until the workspace gets created. Note: You may need to wait a bit more the first time for Dirigible to get initialized, then refresh the browser. What is the benefit of running Dirigible on Che Now, there are two more options for running Dirigible - on the OpenShift Cloud platform and on the Eclipse Che workspace management platform. So, what are the benefits then to run Dirigible on Che? First of all, you get a holistic experience on your development process. Che is the basis, where all the different frameworks, languages and tools complement each other to cover the maximum set of requirements for building your next generation Cloud services. We have to be really honest with ourselves here - in Dirigible it is quite unlikely that we build C/C++ tooling, for instance. This doesn't fit our goals and vision about high-productivity development of business applications. But, also we have to admit that somebody might need such a low-level component written in C/C++ for e.g. integration purposes. Thanks to this variety of options in Che now (and even more in the future), the developer doesn't need to go out to some external environments for such cases. Second, you have the ability to run Dirigible on any platform where Che is deployed. It includes the front runner OpenShift platform as well as some other commercial and enterprise-grade Cloud platforms. This opens to the huge Che community all the scenarios for business applications development such as model-driven approach, business-process and in-system programming models and all the rest coming with Dirigible. Last but not least, it is crucial for us to organize the efforts spent on the Cloud development topics under Eclipse Foundation in a much better way. Nobody has unlimited resources to solve the infinite numbers of challenges that we are currently facing. It will not be easy, but I am sure: together we can do it!","title":"Running Dirigible on Che Workspaces"},{"location":"2018/11/12/blogs-dirigible-ide-on-che-workspaces/#eclipse-cloud-development-one-team-one-product","text":"What is Eclipse Cloud Development (ECD) and why should I consider it? ECD is a Top-Level Project (TLP) at Eclipse Foundation that provides open-source implementations of standards, services and frameworks that enable developing for and in the Cloud. If you read the definition from the home page, you will be misled that this is a single product or at least a bunch of projects that are complementary to each other and can run simultaneously. That was not exactly true for several years, since the beginning of the ECD initiative itself. Apart from Flux, which was a collaboration development middleware framework, there were actually three major full-stack development platforms - Orion, Che and Dirigible, each of them with its own Web IDE and own backend. They were just three fancy vehicles parked in a special place in front of the Eclipse Foundation house. Each of them was built for its own purpose and based on its own technology stack, without so much care about the others. Good start - there was quite a big room for improvement. I remember the invaluable initial discussions we had in San Francisco more than three years ago. We tried to understand each other, which are the scenarios we want to cover, how to integrate them and how exactly to respond to the community, which required from us ONE single offering for their Cloud development needs. The plan was just roughly defined, but all of us were eager to go for it and to collaborate much closely. Time has passed, many things have changed. The projects matured by passing several reimplementation phases, clarified the goals and strategies, some acquisitions happened, new players appeared and even one was retired. Still, nobody has seen a prominent path forward for a much deeper integration. Until now!","title":"Eclipse Cloud Development - ONE team, ONE product"},{"location":"2018/11/12/blogs-dirigible-ide-on-che-workspaces/#eclipse-che-as-a-center-of-gravity-for-cloud-development-environments","text":"In the last few months Che guys were working hard on the new approach for workspaces management for the 7.0 release. One of the major changes is that now they allow contributions not only for IDE plugins, but also for whole Web IDE stacks as separate Docker containers. This helped them to retire the old-fashioned GWT based Web IDE and replace it with the modern Monaco based one - Theia. This also gives an opportunity for other development platforms, leveraging different development models and covering different development scenarios to land on the Che planet as well. This was seen by all of us as a great opportunity to finally start a new age of integration, which can lead to a real consolidation of tools, models, and efforts.","title":"Eclipse Che as a center of gravity for Cloud development environments"},{"location":"2018/11/12/blogs-dirigible-ide-on-che-workspaces/#dirigible-as-a-che-editor-plugin","text":"Following the new extensibility concept, first we had to create a plugin descriptor for Dirigible. It contains the metadata about the content you want to contribute - name, description, Docker image identifier, environment variables, etc. version: 1.0.0 type: Che Editor name: eclipse-dirigible id: org.eclipse.che.editor.dirigible title: Eclipse Dirigible as Editor for Eclipse Che description: Eclipse Dirigible as Editor for Eclipse Che icon: http://download.eclipse.org/dirigible/dirigible.png endpoints: - name: \"dirigible\" public: true targetPort: 8080 attributes: protocol: http type: ide containers: - name: eclipse-dirigible image: dirigiblelabs/dirigible-anonymous env: - name: DIRIGIBLE_REPOSITORY_LOCAL_ROOT_FOLDER value: /projects/dirigible/repository - name: DIRIGIBLE_REPOSITORY_LOCAL_ROOT_FOLDER_IS_ABSOLUTE value: true - name: DIRIGIBLE_REPOSITORY_SEARCH_ROOT_FOLDER value: /projects/dirigible/repository - name: DIRIGIBLE_REPOSITORY_SEARCH_ROOT_FOLDER_IS_ABSOLUTE value: true - name: DIRIGIBLE_CMS_INTERNAL_ROOT_FOLDER value: /projects/dirigible/cms - name: DIRIGIBLE_CMS_INTERNAL_ROOT_FOLDER_IS_ABSOLUTE value: true - name: DIRIGIBLE_DATABASE_H2_ROOT_FOLDER_DEFAULT value: /projects/dirigible/h2 - name: DIRIGIBLE_DATABASE_H2_URL value: jdbc:h2:/projects/dirigible/h2 - name: DIRIGIBLE_OPERATIONS_LOGS_ROOT_FOLDER_DEFAULT value: /usr/local/tomcat/logs volumes: - mountPath: \"/projects\" name: projects ports: - exposedPort: 8080 memory-limit: \"512M\" The GitHub repository containing the project is at: https://github.com/dirigiblelabs/dirigible-che-editor-plugin Because the development environment is secured by OpenShift underneath, we use here the dirigiblelabs/dirigible-anonymous Docker image of Dirigible. Environment variables mainly redirect the file system dependent components of Dirigible to use the default /projects persistent folder. We made several experiments with different sets of configurations, which we activated on the local Che registry by using the publish_plugin command. publish_plugin dirigible-che-editor-plugin 1.0.0 che Once we agreed how the first version of the plugin should look like, we had to add our plugin definition to the official Che registry metadata to be available by default on any standard Che environment. The process says we have to make a PR to the repository: https://github.com/eclipse/che-plugin-registry . The actual PR is: https://github.com/eclipse/che-plugin-registry/pull/54 What it does is adding the metadata of the given plugin under a predefined folder structure of the Che registry: id: org.eclipse.che.editor.dirigible version: 1.0.0 type: Che Editor name: dirigible-che-editor-plugin title: Eclipse Dirigible for Eclipse Che description: Eclipse Dirigible as App Development Platform for Eclipse Che icon: https://www.dirigible.io/img/logo/dirigible-logo.png url: https://github.com/dirigiblelabs/dirigible-che-editor-plugin/releases/download/1.0.0/dirigible-che-editor-plugin.tar.gz The document with all the needed steps presented by Gorkem and Florent at EclipseCon Europe 2018 can be found at: https://docs.google.com/document/d/1hFXTwzIU3MnqcciXH9E7xyUtEJRUeUuJ-e0JlEhTKjo/edit","title":"Dirigible as a Che editor plugin"},{"location":"2018/11/12/blogs-dirigible-ide-on-che-workspaces/#start-dirigible-based-workspace-in-che","text":"Since the beginning of this week you can go on the public Che environment on the OpenShift platform at: https://che.openshift.io/dashboard/#/workspaces and create a new workspace. In the configurations wizard, choose Che 7 dev stack and dirigible-che-editor-plugin . Click the \"Create\" button and wait until the workspace gets created. Note: You may need to wait a bit more the first time for Dirigible to get initialized, then refresh the browser.","title":"Start Dirigible based workspace in Che"},{"location":"2018/11/12/blogs-dirigible-ide-on-che-workspaces/#what-is-the-benefit-of-running-dirigible-on-che","text":"Now, there are two more options for running Dirigible - on the OpenShift Cloud platform and on the Eclipse Che workspace management platform. So, what are the benefits then to run Dirigible on Che? First of all, you get a holistic experience on your development process. Che is the basis, where all the different frameworks, languages and tools complement each other to cover the maximum set of requirements for building your next generation Cloud services. We have to be really honest with ourselves here - in Dirigible it is quite unlikely that we build C/C++ tooling, for instance. This doesn't fit our goals and vision about high-productivity development of business applications. But, also we have to admit that somebody might need such a low-level component written in C/C++ for e.g. integration purposes. Thanks to this variety of options in Che now (and even more in the future), the developer doesn't need to go out to some external environments for such cases. Second, you have the ability to run Dirigible on any platform where Che is deployed. It includes the front runner OpenShift platform as well as some other commercial and enterprise-grade Cloud platforms. This opens to the huge Che community all the scenarios for business applications development such as model-driven approach, business-process and in-system programming models and all the rest coming with Dirigible. Last but not least, it is crucial for us to organize the efforts spent on the Cloud development topics under Eclipse Foundation in a much better way. Nobody has unlimited resources to solve the infinite numbers of challenges that we are currently facing. It will not be easy, but I am sure: together we can do it!","title":"What is the benefit of running Dirigible on Che"},{"location":"2018/11/13/blogs-dirigible-landed-in-faculty-of-mathematics-and-informatics/","text":"For third consecutive year, the User Assistance (UA) team of SAP Labs Bulgaria holds a Software Documentation course at the Faculty of Mathematics and Informatics at Sofia University \u2018St. Kliment Ohridski\u2019. The number of participating students is growing rapidly and this year it has reached one hundred. The main idea of the course is to present the Technical Communicator profession as well as to give students the opportunity to dive in this area and guide them through their first steps. For that purpose, we needed an open-source software to be documented by the students. It had to be easily accessible, innovative, interesting, and with a simple UI in order to grab their attention. That\u2019s how Eclipse Dirigible took central part in the Software Documentation course. Eclipse Dirigible is a Cloud Development Platform providing development tools and a runtime environment. Dirigible provides capabilities for end-to-end development processes \u2013 modeling and management of databases, development of RESTful services, generation of pattern-based user interfaces, role-based security, integration of external services, testing, debugging, operations, and monitoring. Dirigible also supports full development lifecycle of on-demand applications by leveraging in-system programming models and rapid application development techniques. The most important thing for us is that Dirigible enables the students to develop their own projects, test different technologies and scenarios, learn popular programming languages. As a member of the UA team and a graphic expert, I prepared the lecture and the assignments concerning Simple Graphics and Infographics. The lecture includes the general principles of creating graphics and infographics, typography basics, and the required software for the purpose. The assignments for the past two years consisted of creating a simple graphic for a certain task or feature, revamping existing graphics, or creating an infographic including determined information. Here is what two of our students came up with last year: I am looking forward to seeing more well-executed assignments at the end of the curriculum this year. I hope to meet some of the students as contributors to the open-source world and more specifically to the Eclipse Dirigible project.","title":"Dirigible Landed in the Faculty of Mathematics and Informatics"},{"location":"2018/11/24/blogs-node-in-dirigible/","text":"Node.js in Dirigible? Are you kidding? Why do I need Node.js, when I already have Enterprise JavaScript? Well, it was a few years ago when we defined what Enterprise JavaScript is. We described it as a set of stable API facades in the JavaScript language, which can be used by business application developers to reliably code against these API facades. For simplicity, we chose the synchronous model with blocking API, handled in a multi-threaded environment to lower the entry barrier for our target group of developers. More details can be found in the Why Enterprise JavaScript? and Understanding Dirigible blog posts. Having these reasons in mind, we set a border line between how we understand the usage of the JavaScript language and how the Node.js guys have implemented it. We are targeting different scenarios, that is why we have never striven to be compatible with it. This is still true for the main scenarios that we target. What about the \"Function as a Service\" scenarios? No doubt, there are cases and types of functionalities, which are simple (e.g. single action), short-living (quickly executable), rarely triggered, stateless, contextless, and atomic enough (without external dependencies), that can be run as \"functions\" only. This can reduce the required computation power for the execution in scale. Hence, this can significantly reduce the cost. The current Java-based runtime of Dirigible is not quite suitable for such cases. It has a longer bootstrap time, as well as a bigger memory footprint for the initialization in comparison with more lightweight frameworks like Node.js and Go. Hence, the natural path forward is to introduce Node.js and Go support to be able to offload the main stateful business application instances by moving the stateless modules out as \"functions\". This can be beneficial in a well-managed, highly distributed environment such as Kubernetes clusters. Otherwise, we recommend the standard built-in message-driven approach as well as the BPM capabilities of Dirigible. Command Engine Recently, we introduced a feature that allows the developer to write modules in any native language, which is supported by the underlying operation system. Then such modules can be executed as regular Dirigible services. We pipe the input and output streams and provide the result of the execution as a response to the HTTP call. The main purpose of this functionality is to allow developers to implement complementary extensions for their business applications via arbitrary integration channels not supported by the Dirigible core runtime out of the box. The simplest example is just to run a shell script. There are three noteworthy features of the Command Engine: 1. You can use different command line arguments depending on the target OS e.g. linux , mac , windows 2. You can set environment variables before the execution and also define the ones to be cleared 3. The target directory of the execution is set as the root directory of the Registry space of the Dirigible Repository (in case of File-System Repository) How to execute my Node.js code? Prerequisites Let's assume that you already have Node.js installed on your machine or container where the Dirigible instance is running. To test that, open the Terminal perspective and type: node -v If the command is unknown, install Node.js depending on your operating system - package-manager Hello World Example Navigate to the Workspace perspective Create a new project called hello_node . Create a new file named hello.js . Open the file in the editor and type the following line: console.log('Hello from Node!'); Save the file (auto-publish on save is set by default). Note: If you have noticed the \"Hello from Node!\" message in the Console view, it is still executed by the built-in JavaScript engine - stay calm. Create a new file named run.command Open the file in the editor and insert the following lines: { \"description\" : \"command description\" , \"contentType\" : \"text/plain\" , \"commands\" : [ { \"os\" : \"linux\" , \"command\" : \"node hello_node/hello.js\" }, { \"os\" : \"mac\" , \"command\" : \"node hello_node/hello.js\" }, { \"os\" : \"windows\" , \"command\" : \"node hello_node/hello.js\" } ] } Save the file, select it in the Workspace view, and check the result of the execution in the Preview window. What about dependencies? The simplest scenario with a single script file works well, what about multiple files with cross references? Create a new project called complex_node Create a file that will play the role of the library module node_lib.js Enter the following lines: exports . sum = function ( a , b ) { return a + b ; } Create a new file that will play the role of the service module node_service.js Enter the following lines: var node_lib = require ( \"../complex_node/node_lib\" ); var sum = node_lib . sum ( 2 , 3 ); console . log ( \"The Sum is: \" + sum ); Now, create the command file with name run.command and with the following content: { \"description\" : \"command description\" , \"contentType\" : \"text/plain\" , \"commands\" : [ { \"os\" : \"linux\" , \"command\" : \"node complex_node/node_service.js\" }, { \"os\" : \"mac\" , \"command\" : \"node complex_node/node_service.js\" }, { \"os\" : \"windows\" , \"command\" : \"node complex_node/node_service.js\" } ] } Select the file in the Workspace Explorer and see the result of the execution in the Preview window: The Sum is: 5 Node.js is cool, but it is still JavaScript. What about Go? Well, let's try a simple Go program following the same approach. If you do not have Go installed on your machine or container, just follow these instructions . Create a project called hello_go Create a file with name hello.go with the following content: package main import \"fmt\" func main () { fmt . Println ( \"hello world\" ) } Create the run.command with the following content: { \"description\" : \"command description\" , \"contentType\" : \"text/plain\" , \"commands\" : [ { \"os\" : \"linux\" , \"command\" : \"go run ./hello_go/hello.go\" }, { \"os\" : \"mac\" , \"command\" : \"go run ./hello_go/hello.go\" }, { \"os\" : \"windows\" , \"command\" : \"go run ./hello_go/hello.go\" } ] } After you publish and select the run.command file in the Workspace Explorer, you should see the following result in the Preview window: hello world That was nice! Can I run Java maybe? Let's assume that for some reason you would like to write a \"function\" module in the Java programming language (e.g. with the newest GraalVM). In this case we will need a preliminary step to compile the Java class before the execution. Create a project named hello_java Create a file named Hello.java with the following content: package hello_java ; public class Hello { public static void main ( String [] args ) { System . out . println ( \"Hello World!\" ); } } Create a shell command script run.sh to first compile and then execute the class: javac ./hello_java/Hello.java java hello_java.Hello Finally create the command file run.command with the following content: { \"description\" : \"command description\" , \"contentType\" : \"text/plain\" , \"commands\" : [ { \"os\" : \"linux\" , \"command\" : \"sh hello_java/run.sh\" }, { \"os\" : \"mac\" , \"command\" : \"sh hello_java/run.sh\" }, { \"os\" : \"windows\" , \"command\" : \"hello_java/run.bat\" } ] } Save all, publish and voila - you have a running Java program as a service in Dirigible! What's next? We have to admit that the introduction of the new Command engine is just the first step in the direction of the native multi-language support in Dirigible. There is still a lot to be done to adapt the Language Server Protocol extensions for the different languages. Fortunately, there are already very good examples available on how to do this at the backend like Eclipse standalone IDE, and in the editors - Monaco and Orion. But still, this is not a trivial task and it will take some time to implement in Dirigible. Another idea is to have a pool of running native servers, e.g Express nodes, to push the code to and to use them as external executors. In this case, we can pipe the network Socket streams instead of the standard in/out streams. This approach can lay the foundation for many more scenarios as well. Integration with the actual \"Function as a Service\" offerings by the Cloud platforms is also something that is yet to come. For instance, a tool for building Docker images based on these native modules and Cloud platform Registry integration would be a very useful feature of the Dirigible Web IDE. Summary? Well, for those of you who have read the blog post too fast, it explains how to write native modules in Node.js , Go , and Java and use them as integrated services in Dirigible environment. Enjoy!","title":"Node.js in Dirigible?"},{"location":"2018/11/24/blogs-node-in-dirigible/#why-do-i-need-nodejs-when-i-already-have-enterprise-javascript","text":"Well, it was a few years ago when we defined what Enterprise JavaScript is. We described it as a set of stable API facades in the JavaScript language, which can be used by business application developers to reliably code against these API facades. For simplicity, we chose the synchronous model with blocking API, handled in a multi-threaded environment to lower the entry barrier for our target group of developers. More details can be found in the Why Enterprise JavaScript? and Understanding Dirigible blog posts. Having these reasons in mind, we set a border line between how we understand the usage of the JavaScript language and how the Node.js guys have implemented it. We are targeting different scenarios, that is why we have never striven to be compatible with it. This is still true for the main scenarios that we target. What about the \"Function as a Service\" scenarios? No doubt, there are cases and types of functionalities, which are simple (e.g. single action), short-living (quickly executable), rarely triggered, stateless, contextless, and atomic enough (without external dependencies), that can be run as \"functions\" only. This can reduce the required computation power for the execution in scale. Hence, this can significantly reduce the cost. The current Java-based runtime of Dirigible is not quite suitable for such cases. It has a longer bootstrap time, as well as a bigger memory footprint for the initialization in comparison with more lightweight frameworks like Node.js and Go. Hence, the natural path forward is to introduce Node.js and Go support to be able to offload the main stateful business application instances by moving the stateless modules out as \"functions\". This can be beneficial in a well-managed, highly distributed environment such as Kubernetes clusters. Otherwise, we recommend the standard built-in message-driven approach as well as the BPM capabilities of Dirigible.","title":"Why do I need Node.js, when I already have Enterprise JavaScript?"},{"location":"2018/11/24/blogs-node-in-dirigible/#command-engine","text":"Recently, we introduced a feature that allows the developer to write modules in any native language, which is supported by the underlying operation system. Then such modules can be executed as regular Dirigible services. We pipe the input and output streams and provide the result of the execution as a response to the HTTP call. The main purpose of this functionality is to allow developers to implement complementary extensions for their business applications via arbitrary integration channels not supported by the Dirigible core runtime out of the box. The simplest example is just to run a shell script. There are three noteworthy features of the Command Engine: 1. You can use different command line arguments depending on the target OS e.g. linux , mac , windows 2. You can set environment variables before the execution and also define the ones to be cleared 3. The target directory of the execution is set as the root directory of the Registry space of the Dirigible Repository (in case of File-System Repository)","title":"Command Engine"},{"location":"2018/11/24/blogs-node-in-dirigible/#how-to-execute-my-nodejs-code","text":"","title":"How to execute my Node.js code?"},{"location":"2018/11/24/blogs-node-in-dirigible/#prerequisites","text":"Let's assume that you already have Node.js installed on your machine or container where the Dirigible instance is running. To test that, open the Terminal perspective and type: node -v If the command is unknown, install Node.js depending on your operating system - package-manager","title":"Prerequisites"},{"location":"2018/11/24/blogs-node-in-dirigible/#hello-world-example","text":"Navigate to the Workspace perspective Create a new project called hello_node . Create a new file named hello.js . Open the file in the editor and type the following line: console.log('Hello from Node!'); Save the file (auto-publish on save is set by default). Note: If you have noticed the \"Hello from Node!\" message in the Console view, it is still executed by the built-in JavaScript engine - stay calm. Create a new file named run.command Open the file in the editor and insert the following lines: { \"description\" : \"command description\" , \"contentType\" : \"text/plain\" , \"commands\" : [ { \"os\" : \"linux\" , \"command\" : \"node hello_node/hello.js\" }, { \"os\" : \"mac\" , \"command\" : \"node hello_node/hello.js\" }, { \"os\" : \"windows\" , \"command\" : \"node hello_node/hello.js\" } ] } Save the file, select it in the Workspace view, and check the result of the execution in the Preview window.","title":"Hello World Example"},{"location":"2018/11/24/blogs-node-in-dirigible/#what-about-dependencies","text":"The simplest scenario with a single script file works well, what about multiple files with cross references? Create a new project called complex_node Create a file that will play the role of the library module node_lib.js Enter the following lines: exports . sum = function ( a , b ) { return a + b ; } Create a new file that will play the role of the service module node_service.js Enter the following lines: var node_lib = require ( \"../complex_node/node_lib\" ); var sum = node_lib . sum ( 2 , 3 ); console . log ( \"The Sum is: \" + sum ); Now, create the command file with name run.command and with the following content: { \"description\" : \"command description\" , \"contentType\" : \"text/plain\" , \"commands\" : [ { \"os\" : \"linux\" , \"command\" : \"node complex_node/node_service.js\" }, { \"os\" : \"mac\" , \"command\" : \"node complex_node/node_service.js\" }, { \"os\" : \"windows\" , \"command\" : \"node complex_node/node_service.js\" } ] } Select the file in the Workspace Explorer and see the result of the execution in the Preview window: The Sum is: 5","title":"What about dependencies?"},{"location":"2018/11/24/blogs-node-in-dirigible/#nodejs-is-cool-but-it-is-still-javascript-what-about-go","text":"Well, let's try a simple Go program following the same approach. If you do not have Go installed on your machine or container, just follow these instructions . Create a project called hello_go Create a file with name hello.go with the following content: package main import \"fmt\" func main () { fmt . Println ( \"hello world\" ) } Create the run.command with the following content: { \"description\" : \"command description\" , \"contentType\" : \"text/plain\" , \"commands\" : [ { \"os\" : \"linux\" , \"command\" : \"go run ./hello_go/hello.go\" }, { \"os\" : \"mac\" , \"command\" : \"go run ./hello_go/hello.go\" }, { \"os\" : \"windows\" , \"command\" : \"go run ./hello_go/hello.go\" } ] } After you publish and select the run.command file in the Workspace Explorer, you should see the following result in the Preview window: hello world","title":"Node.js is cool, but it is still JavaScript. What about Go?"},{"location":"2018/11/24/blogs-node-in-dirigible/#that-was-nice-can-i-run-java-maybe","text":"Let's assume that for some reason you would like to write a \"function\" module in the Java programming language (e.g. with the newest GraalVM). In this case we will need a preliminary step to compile the Java class before the execution. Create a project named hello_java Create a file named Hello.java with the following content: package hello_java ; public class Hello { public static void main ( String [] args ) { System . out . println ( \"Hello World!\" ); } } Create a shell command script run.sh to first compile and then execute the class: javac ./hello_java/Hello.java java hello_java.Hello Finally create the command file run.command with the following content: { \"description\" : \"command description\" , \"contentType\" : \"text/plain\" , \"commands\" : [ { \"os\" : \"linux\" , \"command\" : \"sh hello_java/run.sh\" }, { \"os\" : \"mac\" , \"command\" : \"sh hello_java/run.sh\" }, { \"os\" : \"windows\" , \"command\" : \"hello_java/run.bat\" } ] } Save all, publish and voila - you have a running Java program as a service in Dirigible!","title":"That was nice! Can I run Java maybe?"},{"location":"2018/11/24/blogs-node-in-dirigible/#whats-next","text":"We have to admit that the introduction of the new Command engine is just the first step in the direction of the native multi-language support in Dirigible. There is still a lot to be done to adapt the Language Server Protocol extensions for the different languages. Fortunately, there are already very good examples available on how to do this at the backend like Eclipse standalone IDE, and in the editors - Monaco and Orion. But still, this is not a trivial task and it will take some time to implement in Dirigible. Another idea is to have a pool of running native servers, e.g Express nodes, to push the code to and to use them as external executors. In this case, we can pipe the network Socket streams instead of the standard in/out streams. This approach can lay the foundation for many more scenarios as well. Integration with the actual \"Function as a Service\" offerings by the Cloud platforms is also something that is yet to come. For instance, a tool for building Docker images based on these native modules and Cloud platform Registry integration would be a very useful feature of the Dirigible Web IDE.","title":"What's next?"},{"location":"2018/11/24/blogs-node-in-dirigible/#summary","text":"Well, for those of you who have read the blog post too fast, it explains how to write native modules in Node.js , Go , and Java and use them as integrated services in Dirigible environment.","title":"Summary?"},{"location":"2018/11/24/blogs-node-in-dirigible/#enjoy","text":"","title":"Enjoy!"},{"location":"2018/12/05/you-dont-need-abs-to-model-apps/","text":"Two of the coolest additions in version 3.x of Eclipse Dirigible are without a doubt the Entity Data Modeler (EDM) and the Business Process Modeler (BPM). They take the concept of model-driven architecture to the next level. What the \u201chack\u201d does that mean, you\u2019d probably say? With the fast pace of technological evolution (Cloud Computing, AI, IoT, etc.), application developers face a common problem \u2013 how to develop proof of concepts as quickly as possible, and to receive early feedback from customers. Dirigible provides you with the opportunity to use In-System and Rapid application development techniques such as code generation, EDM, BPM, and Enterprise JavaScript APIs. The Entity Data Modeler plays a huge role in model-driven development. It allows developers to create application prototypes based on linked entities. These entities can be Books, Stores, Currencies, Categories, among others. Everything that your customers may ever need. Every single one of these entities has its own unique identifier (ID), along with any other set of unique properties you\u2019d like to assign to these entities. They are stored in database tables and you can interconnect them to make your business application come true. To develop business applications, you need persistency, RESTful services, and a user interface with CRUD operations to create, edit, delete, and list entities. There are predefined templates that help you generate your application from the model, so you don\u2019t have to start the development process from scratch. Based on the model you\u2019ve come up with, you can then generate your full-stack application: Awesome, isn\u2019t it? But\u2026 that\u2019s just a set of well-organized CRUD views integrated into an Admin UI, which was generated from the EDM. Sure, the Entity Data Modeler can help me join the dots between all app entities, but how can I develop a more complex feature in the app itself? What about building a marketplace, or a feedback system, or a service request system for customers to use? Of course, you can build applications with separate data, logic, and presentation layers. These layers can reuse parts of the admin functionalities. For example, here is a bookshop marketplace that consumes several services from the admin application: That sounds great, but behind every enterprise solution, there must be a set of very complex business processes and models. Is there a way to develop this type of processes with Dirigible or even reuse already existing Activiti/Flowable processes? Sure, you can! All this is possible thanks to the Business Process Modeler. Eclipse Dirigible has an integrated BPM engine based on Flowable. This engine lets you define or reuse your business processes by adding service tasks and flows. These tasks enhance your business solution and will truly make your application enterprise-ready. What does that mean exactly, you'd say? Let's take a brief look at the following example: This is what the flow of a Print on Demand business process looks like at the background in the Eclipse Dirigible Web IDE. Meanwhile, here is an example for a custom-built view that lets users purchase their books on demand: By the way, this Print on Demand view is integrated in the marketplace thanks to the lightweight extensibility concept built in Dirigible. See Dirigible - Extend, Embed, Reuse . Right now, if there was a book on developing business applications with the Eclipse Dirigible Web IDE, I\u2019d be the first one to purchase it. While I\u2019m waiting though, I\u2019ll keep on exploring the ins and outs of this cool basket of modern tools for developers of business applications. The EDM and the BPM tools are just the beginning, I\u2019m sure of it! Resources Experiment with the single-click deployment of the following demos from EclipseCon 2018 : ( GitHub ) ( GitHub ) ( GitHub )","title":"You Dont Need Abs to Model Apps"},{"location":"2018/12/05/you-dont-need-abs-to-model-apps/#resources","text":"Experiment with the single-click deployment of the following demos from EclipseCon 2018 : ( GitHub ) ( GitHub ) ( GitHub )","title":"Resources"},{"location":"2018/12/20/news-new-release-3-3/","text":"New version 3.3 released. Aggregated Features and Fixes since 3.2 to 3.3 (Type B) Features Keycloak integration and support + Docker image Support for Report entity type in the Entity Data Modeler Copy/Paste support for Entity Data Modeler Copy/Paste support for Database Schema Modeler DBCP version update to 2.2.0 Job form editor Listener form editor Extension Point form editor Extension form editor Table form editor View form editor Access form editor Roles form editor Support for checkboxes added in Application Templates Table Report UI added in Application Templates Pie Chart UI added in Application Templates Embedded Dirigible use-case support Bar Chart Support for Entity Model Line Chart Support for Entity Model Run On Feature Plugins View Command Engine Branding Service Discussions Perspective Standalone Packages (e.g. CMS) White-listing Authorizations Run-on Form Orion version 19.0 update Usage Statistics OpenShift build Dynamic themes Repository Facade API Tomcat version 8.5.34 update Anonymous Runtime Fixes Look up for *.schema files as a pre-delivered content Default theme configuration parameter Entity Data Modeler fixes Full-stack application template fixes Mobile application template with Tabris.js PostgreSQL database related fixes Sybase ASE database related fixes Save in silent mode for BPMN Modeler Security access files synchronisation optimisation Application Templates related fixes Support for nullable and boolean values in Application Templates Entity Data Modeler fixes Publishing after Git Clone fixes Launchpad Template Fixes Paging support for the Entity based templates Big files support in the Documents View exists() method in dialects Deep folder support for upload and unpacking of zip files PostgreSQL - Synchronizing process for Roles Master Repository Support External launchpad support Empty folders support in zip download/upload Themes fixes OpenUI5 Templates refactoring Added Properties and Environment Variables in the Configurations listing Master Repository adaptations and fixes Version Service About View Image API Resize Service for images in Documents File/New Menu adaptations openView event support in Menu Relative URIs Improved anonymous support traverse() and list() methods added Configurable messaging store Docker files per package Public Registry Synchronizer added Added \"X-Requested-With\" header to login forms Close Prevention Sort and Order in rs API Flowable built-in Database Configuration Lazy Loading in Database Explorer Configurable Temp Directory for Git Database queries fix Fix logging issues Adds \"database-custom\" dependency into Anonymous builds Swagger 2.0 canonicalizing Statistics 420+ Downloads 2.1K+ Docker Pulls 5.2K+ Trial Users 48K+ Unique Sessions 131K+ Unique Views 172 Countries 327 Repositories in DirigibleLabs Operational The full list of bug-fixes and enhancements can be found here . The source code is available at GitHub repository here . The instant trial is updated accordingly with the released version here . Enjoy!","title":"Release 3.3"},{"location":"2018/12/20/news-new-release-3-3/#features","text":"Keycloak integration and support + Docker image Support for Report entity type in the Entity Data Modeler Copy/Paste support for Entity Data Modeler Copy/Paste support for Database Schema Modeler DBCP version update to 2.2.0 Job form editor Listener form editor Extension Point form editor Extension form editor Table form editor View form editor Access form editor Roles form editor Support for checkboxes added in Application Templates Table Report UI added in Application Templates Pie Chart UI added in Application Templates Embedded Dirigible use-case support Bar Chart Support for Entity Model Line Chart Support for Entity Model Run On Feature Plugins View Command Engine Branding Service Discussions Perspective Standalone Packages (e.g. CMS) White-listing Authorizations Run-on Form Orion version 19.0 update Usage Statistics OpenShift build Dynamic themes Repository Facade API Tomcat version 8.5.34 update Anonymous Runtime","title":"Features"},{"location":"2018/12/20/news-new-release-3-3/#fixes","text":"Look up for *.schema files as a pre-delivered content Default theme configuration parameter Entity Data Modeler fixes Full-stack application template fixes Mobile application template with Tabris.js PostgreSQL database related fixes Sybase ASE database related fixes Save in silent mode for BPMN Modeler Security access files synchronisation optimisation Application Templates related fixes Support for nullable and boolean values in Application Templates Entity Data Modeler fixes Publishing after Git Clone fixes Launchpad Template Fixes Paging support for the Entity based templates Big files support in the Documents View exists() method in dialects Deep folder support for upload and unpacking of zip files PostgreSQL - Synchronizing process for Roles Master Repository Support External launchpad support Empty folders support in zip download/upload Themes fixes OpenUI5 Templates refactoring Added Properties and Environment Variables in the Configurations listing Master Repository adaptations and fixes Version Service About View Image API Resize Service for images in Documents File/New Menu adaptations openView event support in Menu Relative URIs Improved anonymous support traverse() and list() methods added Configurable messaging store Docker files per package Public Registry Synchronizer added Added \"X-Requested-With\" header to login forms Close Prevention Sort and Order in rs API Flowable built-in Database Configuration Lazy Loading in Database Explorer Configurable Temp Directory for Git Database queries fix Fix logging issues Adds \"database-custom\" dependency into Anonymous builds Swagger 2.0 canonicalizing","title":"Fixes"},{"location":"2018/12/20/news-new-release-3-3/#statistics","text":"420+ Downloads 2.1K+ Docker Pulls 5.2K+ Trial Users 48K+ Unique Sessions 131K+ Unique Views 172 Countries 327 Repositories in DirigibleLabs","title":"Statistics"},{"location":"2018/12/20/news-new-release-3-3/#operational","text":"The full list of bug-fixes and enhancements can be found here . The source code is available at GitHub repository here . The instant trial is updated accordingly with the released version here .","title":"Operational"},{"location":"2018/12/20/news-new-release-3-3/#enjoy","text":"","title":"Enjoy!"},{"location":"2019/09/10/news-new-release-3-5/","text":"New version 3.5 released. Release of Type B Features Select branch for Push Select branch for Pull Usage Statistics Import an arbitrary file into a workspace folder Generic support for Statusbar Programmatic Custom Datasources Support Destinations API v4 jsonpath and alphanumeric APIs v4 Fixes Reset perspective option in Dirigible Validation of the Listener handler to be done on Start Restart the Listener after modification Require confirmation from user on deletion of files, folders or projects Problem with setTimestamp, setTime and setDate of Statement Response API println and print don't work with UTF-8 characters Security - Missing isInRole() method Updating Date is not working on HANA database Updating Boolean is not working on HANA database Fiori theme fixes and improvements Minor fixes Statistics 4000+ Downloads 10K+ Docker Pulls 5.4K+ Trial Users 59K+ Sessions 179 Countries 354 Repositories in DirigibleLabs Operational Available packages for download - https://download.eclipse.org/dirigible/drops/R-3.5-201909101520/index.html Docker images at Docker Hub under DirigibleLabs organization: https://hub.docker.com/u/dirigiblelabs/ Maven Central artifacts by org.eclipse.dirigible namespace: https://mvnrepository.com/artifact/org.eclipse.dirigible The full list of bug-fixes and enhancements can be found here: https://github.com/eclipse/dirigible/milestone/27 The source code is available at GitHub repository here: https://github.com/eclipse/dirigible/tree/3.5.0 The instant trial is updated accordingly with the released version here: http://trial.dirigible.io Enjoy!","title":"Release 3.5"},{"location":"2019/09/10/news-new-release-3-5/#features","text":"Select branch for Push Select branch for Pull Usage Statistics Import an arbitrary file into a workspace folder Generic support for Statusbar Programmatic Custom Datasources Support Destinations API v4 jsonpath and alphanumeric APIs v4","title":"Features"},{"location":"2019/09/10/news-new-release-3-5/#fixes","text":"Reset perspective option in Dirigible Validation of the Listener handler to be done on Start Restart the Listener after modification Require confirmation from user on deletion of files, folders or projects Problem with setTimestamp, setTime and setDate of Statement Response API println and print don't work with UTF-8 characters Security - Missing isInRole() method Updating Date is not working on HANA database Updating Boolean is not working on HANA database Fiori theme fixes and improvements Minor fixes","title":"Fixes"},{"location":"2019/09/10/news-new-release-3-5/#statistics","text":"4000+ Downloads 10K+ Docker Pulls 5.4K+ Trial Users 59K+ Sessions 179 Countries 354 Repositories in DirigibleLabs","title":"Statistics"},{"location":"2019/09/10/news-new-release-3-5/#operational","text":"Available packages for download - https://download.eclipse.org/dirigible/drops/R-3.5-201909101520/index.html Docker images at Docker Hub under DirigibleLabs organization: https://hub.docker.com/u/dirigiblelabs/ Maven Central artifacts by org.eclipse.dirigible namespace: https://mvnrepository.com/artifact/org.eclipse.dirigible The full list of bug-fixes and enhancements can be found here: https://github.com/eclipse/dirigible/milestone/27 The source code is available at GitHub repository here: https://github.com/eclipse/dirigible/tree/3.5.0 The instant trial is updated accordingly with the released version here: http://trial.dirigible.io","title":"Operational"},{"location":"2019/09/10/news-new-release-3-5/#enjoy","text":"","title":"Enjoy!"},{"location":"2019/09/25/how-does-eclipse-dirigible-contribute-to-eclipse-che-7/","text":"Eclipse Che unites a wide range of different frameworks, programming languages, and development tools, and helps developers design and create next-level services on the Cloud. Eclipse Che provides you with a default Web IDE. However, Eclipse Che also allows you to plug in other IDEs, because the default IDE may not be able to cover your use case. For example, we work on Eclipse Dirigible \u2013 an open-source cloud development platform that comes with its own Web IDE. You can directly integrate the Eclipse Dirigible Web IDE in Eclipse Che. This means that you can create a workspace in Eclipse Ch\u0435 using the Eclipse Dirigible Web IDE instead of the default Eclipse Theia IDE. What is so cool about that? Developers can run Eclipse Dirigible on whatever platform Eclipse Che 7 is deployed. The most notable example is the OpenShift platform offered by Red Hat. That way, the Eclipse Dirigible portfolio of services and features for business application development becomes available to the entire Che community. What does Eclipse Dirigible have to offer? Now, let us take a look at what this portfolio currently consists of. Eclipse Dirigible puts an emphasis on low-code/no-code tools for developing business applications. As of version 3.4, Eclipse Dirigible provides the following tools: In-system development with server-side JavaScript You can develop backend applications using Enterprise JavaScript. Enhanced RESTful frameworks - RS and RS data Entity data modeler You can generate an application using predefined application templates. Business process modeler You can model process flows and implement in-system and Java tasks. Database modeler You can design your own database schema with tables, views, and their relations. Job scheduler You can define declaratively and schedule jobs that run regularly. Message listener You can create topics and queues and subscribe for events. Kubernetes support For productive use cases, we recommend that you use Kubernetes, Keycloak, and PostgreSQL. Why use JavaScript as a business application language? At Dirigible, we have decided to focus on JavaScript, because it has a small learning curve, and it is a well-known programming language that has proven itself in the context of web development throughout the years. For business application development, which is our case, JavaScript is just a tool, which lets you consume the standardized set of Enterprise APIs that we provide. Additionally, Dirigible allows you to set the default server-side JavaScript execution as synchronous, so you could develop your service in a callback-free way. For example, some of the most popular Enterprise APIs that you can use are: Database / Database DAO HTTP Client / HTTP Client Async CMIS HTTP Request / HTTP Response / HTTP RS BPM Process Are there any alternatives to Eclipse Dirigible? There are alternatives to Eclipse Dirigible and these are platforms such as Mendix and Force.com by Salesforce. However, you have to purchase the corresponding licenses to start using them. In the open-source world though, there are no alternatives to this day. There are other open-source platforms such as Eclipse Theia and Jupyter, but they are not competing directly with Eclipse Dirigible, because they specialize in other areas. For example, Eclipse Theia focuses on general-purpose code editing using the VSCode platform while Jupyter, on the other hand, is the right choice when it comes to big data analysis and data mining. However, none of these platforms provide what Eclipse Dirigible has to offer in terms of low-code/no-code tools for developing business applications. At least for now. Conclusions Thanks to the great collaboration with the Eclipse Che team, Eclipse Dirigible is on the right way of achieving its ultimate goal, which is to provide developers of business applications with the fastest turnaround time in the Cloud and a unique user experience at the same time. So why don\u2019t you give it a try ? If there is something that you don't like, or you think it can be improved, don't hesitate to share your feedback . The Eclipse Dirigible team will definitely appreciate it. That is one of the best things about the open-source community that we are all part of! Resources How to Run Eclipse Dirigible on Eclipse Che 7","title":"How Does Eclipse Dirigible Contribute to Eclipse Che 7?"},{"location":"2019/09/25/how-does-eclipse-dirigible-contribute-to-eclipse-che-7/#what-is-so-cool-about-that","text":"Developers can run Eclipse Dirigible on whatever platform Eclipse Che 7 is deployed. The most notable example is the OpenShift platform offered by Red Hat. That way, the Eclipse Dirigible portfolio of services and features for business application development becomes available to the entire Che community.","title":"What is so cool about that?"},{"location":"2019/09/25/how-does-eclipse-dirigible-contribute-to-eclipse-che-7/#what-does-eclipse-dirigible-have-to-offer","text":"Now, let us take a look at what this portfolio currently consists of. Eclipse Dirigible puts an emphasis on low-code/no-code tools for developing business applications. As of version 3.4, Eclipse Dirigible provides the following tools: In-system development with server-side JavaScript You can develop backend applications using Enterprise JavaScript. Enhanced RESTful frameworks - RS and RS data Entity data modeler You can generate an application using predefined application templates. Business process modeler You can model process flows and implement in-system and Java tasks. Database modeler You can design your own database schema with tables, views, and their relations. Job scheduler You can define declaratively and schedule jobs that run regularly. Message listener You can create topics and queues and subscribe for events. Kubernetes support For productive use cases, we recommend that you use Kubernetes, Keycloak, and PostgreSQL.","title":"What does Eclipse Dirigible have to offer?"},{"location":"2019/09/25/how-does-eclipse-dirigible-contribute-to-eclipse-che-7/#why-use-javascript-as-a-business-application-language","text":"At Dirigible, we have decided to focus on JavaScript, because it has a small learning curve, and it is a well-known programming language that has proven itself in the context of web development throughout the years. For business application development, which is our case, JavaScript is just a tool, which lets you consume the standardized set of Enterprise APIs that we provide. Additionally, Dirigible allows you to set the default server-side JavaScript execution as synchronous, so you could develop your service in a callback-free way. For example, some of the most popular Enterprise APIs that you can use are: Database / Database DAO HTTP Client / HTTP Client Async CMIS HTTP Request / HTTP Response / HTTP RS BPM Process","title":"Why use JavaScript as a business application language?"},{"location":"2019/09/25/how-does-eclipse-dirigible-contribute-to-eclipse-che-7/#are-there-any-alternatives-to-eclipse-dirigible","text":"There are alternatives to Eclipse Dirigible and these are platforms such as Mendix and Force.com by Salesforce. However, you have to purchase the corresponding licenses to start using them. In the open-source world though, there are no alternatives to this day. There are other open-source platforms such as Eclipse Theia and Jupyter, but they are not competing directly with Eclipse Dirigible, because they specialize in other areas. For example, Eclipse Theia focuses on general-purpose code editing using the VSCode platform while Jupyter, on the other hand, is the right choice when it comes to big data analysis and data mining. However, none of these platforms provide what Eclipse Dirigible has to offer in terms of low-code/no-code tools for developing business applications. At least for now.","title":"Are there any alternatives to Eclipse Dirigible?"},{"location":"2019/09/25/how-does-eclipse-dirigible-contribute-to-eclipse-che-7/#conclusions","text":"Thanks to the great collaboration with the Eclipse Che team, Eclipse Dirigible is on the right way of achieving its ultimate goal, which is to provide developers of business applications with the fastest turnaround time in the Cloud and a unique user experience at the same time. So why don\u2019t you give it a try ? If there is something that you don't like, or you think it can be improved, don't hesitate to share your feedback . The Eclipse Dirigible team will definitely appreciate it. That is one of the best things about the open-source community that we are all part of!","title":"Conclusions"},{"location":"2019/09/25/how-does-eclipse-dirigible-contribute-to-eclipse-che-7/#resources","text":"How to Run Eclipse Dirigible on Eclipse Che 7","title":"Resources"},{"location":"2019/11/24/news-new-release-4-0/","text":"New version 4.0 released. Release of Type B Features Major change for API to v4 Destination API v4 with Managed Destination Provider Mail API v4 Workspace API v4 Fixes Migration related fixes User Interface related fixes Git pull with Gitlab Minor fixes Statistics 4300+ Downloads 11K+ Docker Pulls 5.5K+ Trial Users 62K+ Sessions 179 Countries 356 Repositories in DirigibleLabs Operational Available packages for download - https://download.eclipse.org/dirigible/drops/R-4.0-201911241404/index.html Docker images at Docker Hub under DirigibleLabs organization: https://hub.docker.com/u/dirigiblelabs/ Maven Central artifacts by org.eclipse.dirigible namespace: https://mvnrepository.com/artifact/org.eclipse.dirigible The full list of bug-fixes and enhancements can be found here: https://github.com/eclipse/dirigible/milestone/24?closed=1 The source code is available at GitHub repository here: https://github.com/eclipse/dirigible/tree/4.0.0 The instant trial is updated accordingly with the released version here: http://trial.dirigible.io Enjoy!","title":"Release 4.0"},{"location":"2019/11/24/news-new-release-4-0/#features","text":"Major change for API to v4 Destination API v4 with Managed Destination Provider Mail API v4 Workspace API v4","title":"Features"},{"location":"2019/11/24/news-new-release-4-0/#fixes","text":"Migration related fixes User Interface related fixes Git pull with Gitlab Minor fixes","title":"Fixes"},{"location":"2019/11/24/news-new-release-4-0/#statistics","text":"4300+ Downloads 11K+ Docker Pulls 5.5K+ Trial Users 62K+ Sessions 179 Countries 356 Repositories in DirigibleLabs","title":"Statistics"},{"location":"2019/11/24/news-new-release-4-0/#operational","text":"Available packages for download - https://download.eclipse.org/dirigible/drops/R-4.0-201911241404/index.html Docker images at Docker Hub under DirigibleLabs organization: https://hub.docker.com/u/dirigiblelabs/ Maven Central artifacts by org.eclipse.dirigible namespace: https://mvnrepository.com/artifact/org.eclipse.dirigible The full list of bug-fixes and enhancements can be found here: https://github.com/eclipse/dirigible/milestone/24?closed=1 The source code is available at GitHub repository here: https://github.com/eclipse/dirigible/tree/4.0.0 The instant trial is updated accordingly with the released version here: http://trial.dirigible.io","title":"Operational"},{"location":"2019/11/24/news-new-release-4-0/#enjoy","text":"","title":"Enjoy!"},{"location":"2019/12/27/news-new-release-4-1/","text":"New version 4.1 released. Release of Type B Features Enchanced persistence models for references Embedded mode and executable jar removed from distributions Update to JDK 11 OData persistence layer Ephemeral distibution for SAP Cloud Platform Case sensitive parameter for tables and columns names Fixes Database API fixes HTTP Client fixes Custom datasources fixes Quartz integrated with datasources management layer Minor fixes Statistics 64K+ Sessions 45K+ Users 180 Countries 356 Repositories in DirigibleLabs Operational Available packages for download - https://download.eclipse.org/dirigible/drops/R-4.1-201912271640/index.html Docker images at Docker Hub under DirigibleLabs organization: https://hub.docker.com/u/dirigiblelabs/ Maven Central artifacts by org.eclipse.dirigible namespace: https://mvnrepository.com/artifact/org.eclipse.dirigible The full list of bug-fixes and enhancements can be found here: https://github.com/eclipse/dirigible/milestone/28?closed=1 The source code is available at GitHub repository here: https://github.com/eclipse/dirigible/tree/4.1.0 The instant trial is updated accordingly with the released version here: http://trial.dirigible.io Enjoy!","title":"Release 4.1"},{"location":"2019/12/27/news-new-release-4-1/#features","text":"Enchanced persistence models for references Embedded mode and executable jar removed from distributions Update to JDK 11 OData persistence layer Ephemeral distibution for SAP Cloud Platform Case sensitive parameter for tables and columns names","title":"Features"},{"location":"2019/12/27/news-new-release-4-1/#fixes","text":"Database API fixes HTTP Client fixes Custom datasources fixes Quartz integrated with datasources management layer Minor fixes","title":"Fixes"},{"location":"2019/12/27/news-new-release-4-1/#statistics","text":"64K+ Sessions 45K+ Users 180 Countries 356 Repositories in DirigibleLabs","title":"Statistics"},{"location":"2019/12/27/news-new-release-4-1/#operational","text":"Available packages for download - https://download.eclipse.org/dirigible/drops/R-4.1-201912271640/index.html Docker images at Docker Hub under DirigibleLabs organization: https://hub.docker.com/u/dirigiblelabs/ Maven Central artifacts by org.eclipse.dirigible namespace: https://mvnrepository.com/artifact/org.eclipse.dirigible The full list of bug-fixes and enhancements can be found here: https://github.com/eclipse/dirigible/milestone/28?closed=1 The source code is available at GitHub repository here: https://github.com/eclipse/dirigible/tree/4.1.0 The instant trial is updated accordingly with the released version here: http://trial.dirigible.io","title":"Operational"},{"location":"2019/12/27/news-new-release-4-1/#enjoy","text":"","title":"Enjoy!"},{"location":"2020/01/14/news-new-release-4-2/","text":"New version 4.2 has been released. Release is of Type B Features OData artefact for declarative service exposure (*.odata) Pretty names parameter for tables and columns names Fixes Dependencies fixes Minor fixes Statistics 64K+ Sessions 45K+ Users 180 Countries 356 Repositories in DirigibleLabs Operational Available packages for download - https://download.eclipse.org/dirigible/drops/R-4.2-202001141444/index.html Docker images at Docker Hub under DirigibleLabs organization: https://hub.docker.com/u/dirigiblelabs/ Maven Central artifacts by org.eclipse.dirigible namespace: https://mvnrepository.com/artifact/org.eclipse.dirigible The full list of bug-fixes and enhancements can be found here: https://github.com/eclipse/dirigible/milestone/29?closed=1 The source code is available at GitHub repository here: https://github.com/eclipse/dirigible/tree/4.2.0 The instant trial is updated accordingly with the released version here: http://trial.dirigible.io Enjoy!","title":"Release 4.2"},{"location":"2020/01/14/news-new-release-4-2/#features","text":"OData artefact for declarative service exposure (*.odata) Pretty names parameter for tables and columns names","title":"Features"},{"location":"2020/01/14/news-new-release-4-2/#fixes","text":"Dependencies fixes Minor fixes","title":"Fixes"},{"location":"2020/01/14/news-new-release-4-2/#statistics","text":"64K+ Sessions 45K+ Users 180 Countries 356 Repositories in DirigibleLabs","title":"Statistics"},{"location":"2020/01/14/news-new-release-4-2/#operational","text":"Available packages for download - https://download.eclipse.org/dirigible/drops/R-4.2-202001141444/index.html Docker images at Docker Hub under DirigibleLabs organization: https://hub.docker.com/u/dirigiblelabs/ Maven Central artifacts by org.eclipse.dirigible namespace: https://mvnrepository.com/artifact/org.eclipse.dirigible The full list of bug-fixes and enhancements can be found here: https://github.com/eclipse/dirigible/milestone/29?closed=1 The source code is available at GitHub repository here: https://github.com/eclipse/dirigible/tree/4.2.0 The instant trial is updated accordingly with the released version here: http://trial.dirigible.io","title":"Operational"},{"location":"2020/01/14/news-new-release-4-2/#enjoy","text":"","title":"Enjoy!"},{"location":"2020/01/20/managing-documents-with-eclipse-dirigible-in-the-sap-cloud-platform-neo-environment/","text":"This blog presents the Document Explorer \u2013 a feature that you can use as part of the Eclipse Dirigible Web IDE. The Explorer allows you to upload, overwrite, download, delete, and search for pictures, spreadsheets, PDF files, and videos, among other artifacts. The Document Explorer of Dirigible is compatible with SAP Cloud Platform Document service in the Neo environment ... To read the whole article go to: Managing Documents with Eclipse Dirigible in the SAP Cloud Platform Neo Environment","title":"Managing Documents with Eclipse Dirigible in the SAP Cloud Platform Neo Environment"},{"location":"2020/02/05/sending-emails-with-the-eclipse-dirigible-mail-api/","text":"In this blog, we\u2019ll take a look at one of the newest Eclipse Dirigible features. It allows you to send e-mails from Eclipse Dirigible with the Mail Client API . For the purpose of this demo, I\u2019ll be using my Eclipse Dirigible (SAP Ephemeral edition) setup in the Neo environment of SAP Cloud Platform along with a Gmail account used for testing this use case ... To read the whole article go to: Sending E-Mails with the Eclipse Dirigible Mail API","title":"Sending E-Mails with the Eclipse Dirigible Mail API"},{"location":"2020/02/15/how-to-deploy-eclipse-dirigible-in-the-sap-cloud-platform-cloud-foundry-environment/","text":"Eclipse Dirigible is an open-source cloud development platform, that provides capabilities for end-to-end development process from database modeling and management, through RESTful services using server-side JavaScript, to pattern-based user interface generation, role based security, external services integration, testing, debugging, operations and monitoring ... To read the whole article go to: How to deploy Eclipse Dirigible in the SAP Cloud Platform Cloud Foundry environment","title":"How to deploy Eclipse Dirigible in the SAP Cloud Platform Cloud Foundry environment"},{"location":"2020/02/15/how-to-deploy-eclipse-dirigible-in-the-sap-cloud-platform-neo-environment/","text":"Eclipse Dirigible is an open-source cloud development platform, that provides capabilities for end-to-end development process from database modeling and management, through RESTful services using server-side JavaScript, to pattern-based user interface generation, role based security, external services integration, testing, debugging, operations and monitoring ... To read the whole article go to: How to deploy Eclipse Dirigible in the SAP Cloud Platform Neo environment","title":"How to deploy Eclipse Dirigible in the SAP Cloud Platform Neo environment"},{"location":"2020/03/11/news-new-release-4-3/","text":"New version 4.3 has been released. Release is of Type B Features Calculated properties support SAP Cloud Foundry tailored package Content v4 API Template Engine Configurable Internal Jobs Multiple Schema Support in OData Fixes Add Execute Button in the SQL View Add tooltips for all icons in the Entity Data Modeller Debugger via https Minor fixes Statistics 68K+ Sessions 47K+ Users 182 Countries 360 Repositories in DirigibleLabs Operational Available packages for download - https://download.eclipse.org/dirigible/drops/R-4.3-202003111648/index.html Docker images at Docker Hub under DirigibleLabs organization: https://hub.docker.com/u/dirigiblelabs/ Maven Central artifacts by org.eclipse.dirigible namespace: https://mvnrepository.com/artifact/org.eclipse.dirigible The full list of bug-fixes and enhancements can be found here: https://github.com/eclipse/dirigible/milestone/29?closed=1 The source code is available at GitHub repository here: https://github.com/eclipse/dirigible/tree/4.3.0 The instant trial is updated accordingly with the released version here: http://trial.dirigible.io Enjoy!","title":"Release 4.3"},{"location":"2020/03/11/news-new-release-4-3/#features","text":"Calculated properties support SAP Cloud Foundry tailored package Content v4 API Template Engine Configurable Internal Jobs Multiple Schema Support in OData","title":"Features"},{"location":"2020/03/11/news-new-release-4-3/#fixes","text":"Add Execute Button in the SQL View Add tooltips for all icons in the Entity Data Modeller Debugger via https Minor fixes","title":"Fixes"},{"location":"2020/03/11/news-new-release-4-3/#statistics","text":"68K+ Sessions 47K+ Users 182 Countries 360 Repositories in DirigibleLabs","title":"Statistics"},{"location":"2020/03/11/news-new-release-4-3/#operational","text":"Available packages for download - https://download.eclipse.org/dirigible/drops/R-4.3-202003111648/index.html Docker images at Docker Hub under DirigibleLabs organization: https://hub.docker.com/u/dirigiblelabs/ Maven Central artifacts by org.eclipse.dirigible namespace: https://mvnrepository.com/artifact/org.eclipse.dirigible The full list of bug-fixes and enhancements can be found here: https://github.com/eclipse/dirigible/milestone/29?closed=1 The source code is available at GitHub repository here: https://github.com/eclipse/dirigible/tree/4.3.0 The instant trial is updated accordingly with the released version here: http://trial.dirigible.io","title":"Operational"},{"location":"2020/03/11/news-new-release-4-3/#enjoy","text":"","title":"Enjoy!"},{"location":"2020/04/04/news-new-release-4-4/","text":"New version 4.4 has been released. Release is of Type A Features Terminal replaced with xterm.js Workspace pluggable File->New templates Themes in templates Fixes Messaging handler fixes Styling improvements Minor fixes Statistics 69K+ Sessions 48K+ Users 182 Countries 367 Repositories in DirigibleLabs Operational Available packages for download - https://download.eclipse.org/dirigible/drops/R-4.4-202004040404/index.html/index.html Docker images at Docker Hub under DirigibleLabs organization: https://hub.docker.com/u/dirigiblelabs/ Maven Central artifacts by org.eclipse.dirigible namespace: https://mvnrepository.com/artifact/org.eclipse.dirigible The full list of bug-fixes and enhancements can be found here: https://github.com/eclipse/dirigible/milestone/31?closed=1 The source code is available at GitHub repository here: https://github.com/eclipse/dirigible/tree/4.4.0 The instant trial is updated accordingly with the released version here: http://trial.dirigible.io Enjoy!","title":"Release 4.4"},{"location":"2020/04/04/news-new-release-4-4/#features","text":"Terminal replaced with xterm.js Workspace pluggable File->New templates Themes in templates","title":"Features"},{"location":"2020/04/04/news-new-release-4-4/#fixes","text":"Messaging handler fixes Styling improvements Minor fixes","title":"Fixes"},{"location":"2020/04/04/news-new-release-4-4/#statistics","text":"69K+ Sessions 48K+ Users 182 Countries 367 Repositories in DirigibleLabs","title":"Statistics"},{"location":"2020/04/04/news-new-release-4-4/#operational","text":"Available packages for download - https://download.eclipse.org/dirigible/drops/R-4.4-202004040404/index.html/index.html Docker images at Docker Hub under DirigibleLabs organization: https://hub.docker.com/u/dirigiblelabs/ Maven Central artifacts by org.eclipse.dirigible namespace: https://mvnrepository.com/artifact/org.eclipse.dirigible The full list of bug-fixes and enhancements can be found here: https://github.com/eclipse/dirigible/milestone/31?closed=1 The source code is available at GitHub repository here: https://github.com/eclipse/dirigible/tree/4.4.0 The instant trial is updated accordingly with the released version here: http://trial.dirigible.io","title":"Operational"},{"location":"2020/04/04/news-new-release-4-4/#enjoy","text":"","title":"Enjoy!"},{"location":"2020/05/04/news-new-release-4-5/","text":"New version 4.5 has been released. Release is of Type A Features Link external directory as a project in the workspace Git re-architecture (beta) Git View with local and remote branches Mounting the the cloned folder as project Staging View introduced History View introduced Diff Editor Add command Checkout command License update to EPL 2.0 On-save extensibility JavaScript Generation Engine Monaco (VSCode Editor) set as default editor Commonjs support Cross-file references for code-completion Adding a proxy service Templates per file extension filtering GraalVM Engine introduced and set as default (beta) Chrome Dev Tools replaced the Debug View (beta) Fixes build on Windows fixed Styling improvements Minor fixes Statistics 51K+ Users 72K+ Sessions 183 Countries 372 Repositories in DirigibleLabs Operational Available packages for download - https://download.eclipse.org/dirigible/drops/R-4.5-202005042045/index.html/index.html Docker images at Docker Hub under DirigibleLabs organization: https://hub.docker.com/u/dirigiblelabs/ Maven Central artifacts by org.eclipse.dirigible namespace: https://search.maven.org/search?q=org.eclipse.dirigible The full list of bug-fixes and enhancements can be found here: https://github.com/eclipse/dirigible/milestone/32?closed=1 The source code is available at GitHub repository here: https://github.com/eclipse/dirigible/tree/4.5.0 The instant trial is updated accordingly with the released version here: http://trial.dirigible.io Enjoy!","title":"Release 4.5"},{"location":"2020/05/04/news-new-release-4-5/#features","text":"Link external directory as a project in the workspace Git re-architecture (beta) Git View with local and remote branches Mounting the the cloned folder as project Staging View introduced History View introduced Diff Editor Add command Checkout command License update to EPL 2.0 On-save extensibility JavaScript Generation Engine Monaco (VSCode Editor) set as default editor Commonjs support Cross-file references for code-completion Adding a proxy service Templates per file extension filtering GraalVM Engine introduced and set as default (beta) Chrome Dev Tools replaced the Debug View (beta)","title":"Features"},{"location":"2020/05/04/news-new-release-4-5/#fixes","text":"build on Windows fixed Styling improvements Minor fixes","title":"Fixes"},{"location":"2020/05/04/news-new-release-4-5/#statistics","text":"51K+ Users 72K+ Sessions 183 Countries 372 Repositories in DirigibleLabs","title":"Statistics"},{"location":"2020/05/04/news-new-release-4-5/#operational","text":"Available packages for download - https://download.eclipse.org/dirigible/drops/R-4.5-202005042045/index.html/index.html Docker images at Docker Hub under DirigibleLabs organization: https://hub.docker.com/u/dirigiblelabs/ Maven Central artifacts by org.eclipse.dirigible namespace: https://search.maven.org/search?q=org.eclipse.dirigible The full list of bug-fixes and enhancements can be found here: https://github.com/eclipse/dirigible/milestone/32?closed=1 The source code is available at GitHub repository here: https://github.com/eclipse/dirigible/tree/4.5.0 The instant trial is updated accordingly with the released version here: http://trial.dirigible.io","title":"Operational"},{"location":"2020/05/04/news-new-release-4-5/#enjoy","text":"","title":"Enjoy!"},{"location":"2020/05/07/what-is-eclipse-dirigible/","text":"Eclipse Dirigible is an open source project that provides development tools (Web IDE) and runtime environment (Java based) for building and running Business Applications in the Cloud. Dirigible provides the shortest possible turnaround time, during application development and boosts the developers\u2019 productivity with modeling tools, application templates and In-System development experience ... To read the whole article go to: What is Eclipse Dirigible?","title":"What is Eclipse Dirigible?"},{"location":"2020/05/31/news-new-release-4-6/","text":"New version 4.6 has been released. Release is of Type A Features NVARCHAR support Folder based role-concept for Document Perspsective Replace ACE Editor with Monaco in Database Perspective Optimized switch between perspectives Support of multiple projects in a single Git repository Fixes Disable Terminal in Trial Public access for Cloud Foundry Delete Project fixes Minor fixes Statistics 52K+ Users 73K+ Sessions 183 Countries 372 Repositories in DirigibleLabs Operational Available packages for download - https://download.eclipse.org/dirigible/drops/R-4.6-202005311900/index.html/index.html Docker images at Docker Hub under DirigibleLabs organization: https://hub.docker.com/u/dirigiblelabs/ Maven Central artifacts by org.eclipse.dirigible namespace: https://search.maven.org/search?q=org.eclipse.dirigible The full list of bug-fixes and enhancements can be found here: https://github.com/eclipse/dirigible/milestone/33?closed=1 The source code is available at GitHub repository here: https://github.com/eclipse/dirigible/tree/4.6.0 The instant trial is updated accordingly with the released version here: http://trial.dirigible.io Enjoy!","title":"Release 4.6"},{"location":"2020/05/31/news-new-release-4-6/#features","text":"NVARCHAR support Folder based role-concept for Document Perspsective Replace ACE Editor with Monaco in Database Perspective Optimized switch between perspectives Support of multiple projects in a single Git repository","title":"Features"},{"location":"2020/05/31/news-new-release-4-6/#fixes","text":"Disable Terminal in Trial Public access for Cloud Foundry Delete Project fixes Minor fixes","title":"Fixes"},{"location":"2020/05/31/news-new-release-4-6/#statistics","text":"52K+ Users 73K+ Sessions 183 Countries 372 Repositories in DirigibleLabs","title":"Statistics"},{"location":"2020/05/31/news-new-release-4-6/#operational","text":"Available packages for download - https://download.eclipse.org/dirigible/drops/R-4.6-202005311900/index.html/index.html Docker images at Docker Hub under DirigibleLabs organization: https://hub.docker.com/u/dirigiblelabs/ Maven Central artifacts by org.eclipse.dirigible namespace: https://search.maven.org/search?q=org.eclipse.dirigible The full list of bug-fixes and enhancements can be found here: https://github.com/eclipse/dirigible/milestone/33?closed=1 The source code is available at GitHub repository here: https://github.com/eclipse/dirigible/tree/4.6.0 The instant trial is updated accordingly with the released version here: http://trial.dirigible.io","title":"Operational"},{"location":"2020/05/31/news-new-release-4-6/#enjoy","text":"","title":"Enjoy!"},{"location":"2020/06/25/news-new-release-5-0/","text":"New version 5.0 has been released. Release is of Type B Features Roles management for Documents Manager only distro Managed Database for CMS only distro Keep SQL Queries last state File history support for Git Perspective Execute a selected snippet in SQL View Execute API v4 Lifecycle API v4 SOAP API v4 Websocket API v4 Websocket descriptor for server-side endpoints (*.websocket) Close & Close All actions for editors Unpublish project support Fixes Configuration management enhancements Remove alert, when changing perspectives Delete of git project from the workspace fix Debug not working in Docker container fix Public access for Cloud Foundry distro fixes Minor fixes Statistics 52K+ Users 74K+ Sessions 183 Countries 376 Repositories in DirigibleLabs Operational Available packages for download - https://download.eclipse.org/dirigible/drops/R-5.0-202006252250/index.html Docker images at Docker Hub under DirigibleLabs organization: https://hub.docker.com/u/dirigiblelabs/ Maven Central artifacts by org.eclipse.dirigible namespace: https://search.maven.org/search?q=org.eclipse.dirigible The full list of bug-fixes and enhancements can be found here: https://github.com/eclipse/dirigible/milestone/34?closed=1 The source code is available at GitHub repository here: https://github.com/eclipse/dirigible/tree/5.0.0 The instant trial is updated accordingly with the released version here: http://trial.dirigible.io Enjoy!","title":"Release 5.0"},{"location":"2020/06/25/news-new-release-5-0/#features","text":"Roles management for Documents Manager only distro Managed Database for CMS only distro Keep SQL Queries last state File history support for Git Perspective Execute a selected snippet in SQL View Execute API v4 Lifecycle API v4 SOAP API v4 Websocket API v4 Websocket descriptor for server-side endpoints (*.websocket) Close & Close All actions for editors Unpublish project support","title":"Features"},{"location":"2020/06/25/news-new-release-5-0/#fixes","text":"Configuration management enhancements Remove alert, when changing perspectives Delete of git project from the workspace fix Debug not working in Docker container fix Public access for Cloud Foundry distro fixes Minor fixes","title":"Fixes"},{"location":"2020/06/25/news-new-release-5-0/#statistics","text":"52K+ Users 74K+ Sessions 183 Countries 376 Repositories in DirigibleLabs","title":"Statistics"},{"location":"2020/06/25/news-new-release-5-0/#operational","text":"Available packages for download - https://download.eclipse.org/dirigible/drops/R-5.0-202006252250/index.html Docker images at Docker Hub under DirigibleLabs organization: https://hub.docker.com/u/dirigiblelabs/ Maven Central artifacts by org.eclipse.dirigible namespace: https://search.maven.org/search?q=org.eclipse.dirigible The full list of bug-fixes and enhancements can be found here: https://github.com/eclipse/dirigible/milestone/34?closed=1 The source code is available at GitHub repository here: https://github.com/eclipse/dirigible/tree/5.0.0 The instant trial is updated accordingly with the released version here: http://trial.dirigible.io","title":"Operational"},{"location":"2020/06/25/news-new-release-5-0/#enjoy","text":"","title":"Enjoy!"},{"location":"2020/06/29/celebrating-5-years-in-open-source/","text":"Eclipse Dirigible just turned five years in open source. Five years in Eclipse Foundation within the Eclipse Cloud Development group. Five years of innovations with many friends around the globe, lots of realised dreams, first-class happiness. GraalVM 's GraalJS Fast, easy-to-use, easy-to-upgrade from Nashorn or Rhino, ECMA 2020 compliant, deeply integrated with the host JVM, fast interoperability with JVM languages like Scala and Kotlin, embeddable, JVM agnostic, stable, robust... just perfect for our needs. We were quite happy so far by using Mozilla Rhino as the default scripting engine, but its slow adoption of the most recent ECMA specs was definitely an issue. Hence, we were kind of forced to look for another option for the future development of the stack. The biggest surprise was about the time and efforts it took to adapt our API layer to use GraalJS instead of Rhino - literally zero. How many projects or products support straigthforward and compatible migration from one major version to another? The fact that GraalJS is even a totally different project, driven by different people and still provides a smooth migration path from Rhino, deserves admirations. Chrome DevTools Another invaluable gift coming along with GraalJS is the Chrome DevTools debug protocol support. A few years ago we tried to adapt Rhino and V8 debug API and to expose them to the Chrome DevTools, but it was quite unstable due to the lack of public specification of the debug protocol itself and on the other hand not so trivial behavior of the tools themselves. So, you can imagine how speechless we were left once we tried to connect the dots and it just worked. The decision to replace our Debug Perspective's own tools with the well-known yet very powerful Chrome DevTools came naturally. Xterm.js We were also happy to add one more jewel in the most recent release was the Xterm.js terminal interface written in JavaScript and run entirely in the browser. It is adopted quite widely by many tools already as most prominent ones are the VSCode itslef and Eclipse Theia/Che projects. It connects to the server-side endpoint via websocket, so no need to open the port 22 on the server as it was a security-related requirement from our side. It integrates nicely with the ttyd terminal server, which we have embedded in the stack as well. Monaco Major advantage of VSCode is its editor - Monaco. During the past few years it became the most advanced open source code editor, that\u2019s easy to embed and enhance. The investment and support by Microsoft in VSCode and Monaco in particular, gives a good perspective and confidence of the project's future. We were quite happy by using Orion, but recently we decided to bet on Monaco as the default code editor for version 5.0 and above of Dirigible. All the innovations and integrations related to writing source code assumed to go to Monaco now. Another benefit of using Monaco is its diff editor, which became a part of the last but not least major feature of 5.0 release. Git Support Git support in Dirigible was available, since the very beginning. You could clone, push pull or share projects. So far, the supported operations were over-simplified due to the fact that the file system (workspaces, projects, files) was abstracted. It was possible to have workspaces stored in a RDBMS for instance. This had its advantage when you had to run Dirigible on a platform with limited functionalities or by some other reasons. Of course, the drawback was the very limited support of Git integrations, which in fact is more important for developers than having an abstract file system. In 5.0 we decided to first stick to the native file system only, then it was possible to implement a full-fledged Git perspective with listing and changes of branches, low-level operations on files for staging, diff editor, etc. Conclusion With the latest release we set the future direction of the Dirigible project from a technology perspective. We fixed the problematic dependencies by betting on new and emerging projects as well as reverted some of the questionable architectural decisions from the past the future of Dirigible looks quite bright. What's next? Now, we can safely focus on what Eclipse Dirigible always was supposed to give to developers - high-productivity application development platform. Many improvements to the MDA tools are planned already related to the built-in extensibility of the entities, distributed models, security validations and role-based access management in generation templates. The unified inbox for process events as well as better integration of user tasks are examples of what we see in the BPM related tools as next steps. Do you want to join forces with us in this endeavor? Graduation One more good news came along with this release - completed graduation review! We are mature - ayeeeee! \ud83d\udc83 \ud83d\udd7a \ud83e\uddd1\u200d\ud83c\udf93\ud83d\udc68\u200d\ud83c\udf93\ud83e\uddd1\u200d\ud83c\udfa4\ud83d\udc68\u200d\ud83c\udfa4\ud83d\udc69\u200d\ud83c\udfa4\ud83e\udd35\ud83d\udc70\ud83d\udc68\u200d\ud83e\uddb3\ud83e\uddd1\u200d\ud83e\uddb3\ud83d\udc69\u200d\ud83d\ude80\ud83e\uddd1\u200d\ud83d\ude92\ud83e\uddd1\u200d\ud83c\udf3e OMG! \ud83e\udd26\u200d\u2642\ufe0f","title":"Eclipse Dirigible 5.0 - celebrating 5 years in open source with 5 killer features"},{"location":"2020/06/29/celebrating-5-years-in-open-source/#graalvms-graaljs","text":"Fast, easy-to-use, easy-to-upgrade from Nashorn or Rhino, ECMA 2020 compliant, deeply integrated with the host JVM, fast interoperability with JVM languages like Scala and Kotlin, embeddable, JVM agnostic, stable, robust... just perfect for our needs. We were quite happy so far by using Mozilla Rhino as the default scripting engine, but its slow adoption of the most recent ECMA specs was definitely an issue. Hence, we were kind of forced to look for another option for the future development of the stack. The biggest surprise was about the time and efforts it took to adapt our API layer to use GraalJS instead of Rhino - literally zero. How many projects or products support straigthforward and compatible migration from one major version to another? The fact that GraalJS is even a totally different project, driven by different people and still provides a smooth migration path from Rhino, deserves admirations.","title":"GraalVM's GraalJS"},{"location":"2020/06/29/celebrating-5-years-in-open-source/#chrome-devtools","text":"Another invaluable gift coming along with GraalJS is the Chrome DevTools debug protocol support. A few years ago we tried to adapt Rhino and V8 debug API and to expose them to the Chrome DevTools, but it was quite unstable due to the lack of public specification of the debug protocol itself and on the other hand not so trivial behavior of the tools themselves. So, you can imagine how speechless we were left once we tried to connect the dots and it just worked. The decision to replace our Debug Perspective's own tools with the well-known yet very powerful Chrome DevTools came naturally.","title":"Chrome DevTools"},{"location":"2020/06/29/celebrating-5-years-in-open-source/#xtermjs","text":"We were also happy to add one more jewel in the most recent release was the Xterm.js terminal interface written in JavaScript and run entirely in the browser. It is adopted quite widely by many tools already as most prominent ones are the VSCode itslef and Eclipse Theia/Che projects. It connects to the server-side endpoint via websocket, so no need to open the port 22 on the server as it was a security-related requirement from our side. It integrates nicely with the ttyd terminal server, which we have embedded in the stack as well.","title":"Xterm.js"},{"location":"2020/06/29/celebrating-5-years-in-open-source/#monaco","text":"Major advantage of VSCode is its editor - Monaco. During the past few years it became the most advanced open source code editor, that\u2019s easy to embed and enhance. The investment and support by Microsoft in VSCode and Monaco in particular, gives a good perspective and confidence of the project's future. We were quite happy by using Orion, but recently we decided to bet on Monaco as the default code editor for version 5.0 and above of Dirigible. All the innovations and integrations related to writing source code assumed to go to Monaco now. Another benefit of using Monaco is its diff editor, which became a part of the last but not least major feature of 5.0 release.","title":"Monaco"},{"location":"2020/06/29/celebrating-5-years-in-open-source/#git-support","text":"Git support in Dirigible was available, since the very beginning. You could clone, push pull or share projects. So far, the supported operations were over-simplified due to the fact that the file system (workspaces, projects, files) was abstracted. It was possible to have workspaces stored in a RDBMS for instance. This had its advantage when you had to run Dirigible on a platform with limited functionalities or by some other reasons. Of course, the drawback was the very limited support of Git integrations, which in fact is more important for developers than having an abstract file system. In 5.0 we decided to first stick to the native file system only, then it was possible to implement a full-fledged Git perspective with listing and changes of branches, low-level operations on files for staging, diff editor, etc.","title":"Git Support"},{"location":"2020/06/29/celebrating-5-years-in-open-source/#conclusion","text":"With the latest release we set the future direction of the Dirigible project from a technology perspective. We fixed the problematic dependencies by betting on new and emerging projects as well as reverted some of the questionable architectural decisions from the past the future of Dirigible looks quite bright. What's next? Now, we can safely focus on what Eclipse Dirigible always was supposed to give to developers - high-productivity application development platform. Many improvements to the MDA tools are planned already related to the built-in extensibility of the entities, distributed models, security validations and role-based access management in generation templates. The unified inbox for process events as well as better integration of user tasks are examples of what we see in the BPM related tools as next steps. Do you want to join forces with us in this endeavor?","title":"Conclusion"},{"location":"2020/06/29/celebrating-5-years-in-open-source/#graduation","text":"One more good news came along with this release - completed graduation review! We are mature - ayeeeee! \ud83d\udc83 \ud83d\udd7a \ud83e\uddd1\u200d\ud83c\udf93\ud83d\udc68\u200d\ud83c\udf93\ud83e\uddd1\u200d\ud83c\udfa4\ud83d\udc68\u200d\ud83c\udfa4\ud83d\udc69\u200d\ud83c\udfa4\ud83e\udd35\ud83d\udc70\ud83d\udc68\u200d\ud83e\uddb3\ud83e\uddd1\u200d\ud83e\uddb3\ud83d\udc69\u200d\ud83d\ude80\ud83e\uddd1\u200d\ud83d\ude92\ud83e\uddd1\u200d\ud83c\udf3e OMG! \ud83e\udd26\u200d\u2642\ufe0f","title":"Graduation"},{"location":"2020/08/24/news-new-release-5-1/","text":"New version 5.1 has been released. Release is of Type A Features Support for required properties Security Roles management the Entity/Property UIs Support for more widget types Support for pattern based validation Support for widget length Support for pattern hint Support for Color widget type Projection Entity type introduced Application template separation SAP Cloud Foundry - Runtime Only Image Enhanced build of application WAR from the pre-defined packages SAP Cloud Foundry Ephemeral - Runtime Only Form Builder - Experimental Fixes List the available icon names in a dropdown SAP Cloud Foundry - Missing Default Database Configuration SAP CMS - MS files content type override Minor fixes Statistics 54K+ Users 77K+ Sessions 184 Countries 394 Repositories in DirigibleLabs Operational Available packages for download - https://download.eclipse.org/dirigible/drops/R-5.1-202008241951/index.html Docker images at Docker Hub under DirigibleLabs organization: https://hub.docker.com/u/dirigiblelabs/ Maven Central artifacts by org.eclipse.dirigible namespace: https://search.maven.org/search?q=org.eclipse.dirigible The full list of bug-fixes and enhancements can be found here: https://github.com/eclipse/dirigible/milestone/35?closed=1 The source code is available at GitHub repository here: https://github.com/eclipse/dirigible/tree/5.1.0 The instant trial is updated accordingly with the released version here: http://trial.dirigible.io Enjoy!","title":"Release 5.1"},{"location":"2020/08/24/news-new-release-5-1/#features","text":"Support for required properties Security Roles management the Entity/Property UIs Support for more widget types Support for pattern based validation Support for widget length Support for pattern hint Support for Color widget type Projection Entity type introduced Application template separation SAP Cloud Foundry - Runtime Only Image Enhanced build of application WAR from the pre-defined packages SAP Cloud Foundry Ephemeral - Runtime Only Form Builder - Experimental","title":"Features"},{"location":"2020/08/24/news-new-release-5-1/#fixes","text":"List the available icon names in a dropdown SAP Cloud Foundry - Missing Default Database Configuration SAP CMS - MS files content type override Minor fixes","title":"Fixes"},{"location":"2020/08/24/news-new-release-5-1/#statistics","text":"54K+ Users 77K+ Sessions 184 Countries 394 Repositories in DirigibleLabs","title":"Statistics"},{"location":"2020/08/24/news-new-release-5-1/#operational","text":"Available packages for download - https://download.eclipse.org/dirigible/drops/R-5.1-202008241951/index.html Docker images at Docker Hub under DirigibleLabs organization: https://hub.docker.com/u/dirigiblelabs/ Maven Central artifacts by org.eclipse.dirigible namespace: https://search.maven.org/search?q=org.eclipse.dirigible The full list of bug-fixes and enhancements can be found here: https://github.com/eclipse/dirigible/milestone/35?closed=1 The source code is available at GitHub repository here: https://github.com/eclipse/dirigible/tree/5.1.0 The instant trial is updated accordingly with the released version here: http://trial.dirigible.io","title":"Operational"},{"location":"2020/08/24/news-new-release-5-1/#enjoy","text":"","title":"Enjoy!"},{"location":"2020/09/02/news-new-release-5-2/","text":"New version 5.2 has been released. Release is of Type A Features OData generation from Entity Data Model OData rest layer added by default in the full stack application Expand support for OData in templates Fixes Fix bpmn editor works with older version of jquery Minor fixes Statistics 54K+ Users 77K+ Sessions 184 Countries 395 Repositories in DirigibleLabs Operational Available packages for download - https://download.eclipse.org/dirigible/drops/R-5.2-202009020052/index.html Docker images at Docker Hub under DirigibleLabs organization: https://hub.docker.com/u/dirigiblelabs/ Maven Central artifacts by org.eclipse.dirigible namespace: https://search.maven.org/search?q=org.eclipse.dirigible The full list of bug-fixes and enhancements can be found here: https://github.com/eclipse/dirigible/milestone/36?closed=1 The source code is available at GitHub repository here: https://github.com/eclipse/dirigible/tree/5.2.0 The instant trial is updated accordingly with the released version here: http://trial.dirigible.io Enjoy!","title":"Release 5.2"},{"location":"2020/09/02/news-new-release-5-2/#features","text":"OData generation from Entity Data Model OData rest layer added by default in the full stack application Expand support for OData in templates","title":"Features"},{"location":"2020/09/02/news-new-release-5-2/#fixes","text":"Fix bpmn editor works with older version of jquery Minor fixes","title":"Fixes"},{"location":"2020/09/02/news-new-release-5-2/#statistics","text":"54K+ Users 77K+ Sessions 184 Countries 395 Repositories in DirigibleLabs","title":"Statistics"},{"location":"2020/09/02/news-new-release-5-2/#operational","text":"Available packages for download - https://download.eclipse.org/dirigible/drops/R-5.2-202009020052/index.html Docker images at Docker Hub under DirigibleLabs organization: https://hub.docker.com/u/dirigiblelabs/ Maven Central artifacts by org.eclipse.dirigible namespace: https://search.maven.org/search?q=org.eclipse.dirigible The full list of bug-fixes and enhancements can be found here: https://github.com/eclipse/dirigible/milestone/36?closed=1 The source code is available at GitHub repository here: https://github.com/eclipse/dirigible/tree/5.2.0 The instant trial is updated accordingly with the released version here: http://trial.dirigible.io","title":"Operational"},{"location":"2020/09/02/news-new-release-5-2/#enjoy","text":"","title":"Enjoy!"},{"location":"2020/10/05/news-new-release-5-3/","text":"New version 5.3 has been released. Release is of Type A Features Select Partial Generation Views ordering Monaco - code completion of published modules Add Tiles for the Generic Templates in Welcome Page Add support for properties mapping in OData Add support for nullable properties in OData OpenUI5 starter pack Generated REST API - add support for the produced content type Git Share multiple projects to the same git repository readEntitySimpleProperty and readEntitySimplePropertyValue in OData Add a generic template for *.websocket sample Add support for \"many-to-one\" associations in OData Add support for create entity in OData Add support for delete entity in OData Add support for update entity in OData Add support for autoIncrement property in DAO Add Commit Id Info in About page Fixes HTTP Client Async - class not found Feed properties serialization issues Add support for optional OData generation Set on focus the selected view from the launchpad Tolerant Foreign Keys in Schema Default value support in DAO Schema SQL is not correct Missing Default Value property in the Schema Modeler Missing quotes for default value in materializing Protect the service path for OData Git Share project leads to broken project in the workspace NullPointerException on stop container Fix duplicated reference keys during OData transformation in OData Cannot see first project in Workbench on smaller screens SAP CF - Import Project Fails SAP CF - Missing Database Binding Configuration SAP CF - Add Support for Binding of HANA Schema Minor fixes Statistics 55K+ Users 79K+ Sessions 184 Countries 407 Repositories in DirigibleLabs Operational Available packages for download - https://download.eclipse.org/dirigible/drops/R-5.3-202010050300/index.html Docker images at Docker Hub under DirigibleLabs organization: https://hub.docker.com/u/dirigiblelabs/ Maven Central artifacts by org.eclipse.dirigible namespace: https://search.maven.org/search?q=org.eclipse.dirigible The full list of bug-fixes and enhancements can be found here: https://github.com/eclipse/dirigible/milestone/37?closed=1 The source code is available at GitHub repository here: https://github.com/eclipse/dirigible/tree/5.3.0 The instant trial is updated accordingly with the released version here: http://trial.dirigible.io Enjoy!","title":"Release 5.3"},{"location":"2020/10/05/news-new-release-5-3/#features","text":"Select Partial Generation Views ordering Monaco - code completion of published modules Add Tiles for the Generic Templates in Welcome Page Add support for properties mapping in OData Add support for nullable properties in OData OpenUI5 starter pack Generated REST API - add support for the produced content type Git Share multiple projects to the same git repository readEntitySimpleProperty and readEntitySimplePropertyValue in OData Add a generic template for *.websocket sample Add support for \"many-to-one\" associations in OData Add support for create entity in OData Add support for delete entity in OData Add support for update entity in OData Add support for autoIncrement property in DAO Add Commit Id Info in About page","title":"Features"},{"location":"2020/10/05/news-new-release-5-3/#fixes","text":"HTTP Client Async - class not found Feed properties serialization issues Add support for optional OData generation Set on focus the selected view from the launchpad Tolerant Foreign Keys in Schema Default value support in DAO Schema SQL is not correct Missing Default Value property in the Schema Modeler Missing quotes for default value in materializing Protect the service path for OData Git Share project leads to broken project in the workspace NullPointerException on stop container Fix duplicated reference keys during OData transformation in OData Cannot see first project in Workbench on smaller screens SAP CF - Import Project Fails SAP CF - Missing Database Binding Configuration SAP CF - Add Support for Binding of HANA Schema Minor fixes","title":"Fixes"},{"location":"2020/10/05/news-new-release-5-3/#statistics","text":"55K+ Users 79K+ Sessions 184 Countries 407 Repositories in DirigibleLabs","title":"Statistics"},{"location":"2020/10/05/news-new-release-5-3/#operational","text":"Available packages for download - https://download.eclipse.org/dirigible/drops/R-5.3-202010050300/index.html Docker images at Docker Hub under DirigibleLabs organization: https://hub.docker.com/u/dirigiblelabs/ Maven Central artifacts by org.eclipse.dirigible namespace: https://search.maven.org/search?q=org.eclipse.dirigible The full list of bug-fixes and enhancements can be found here: https://github.com/eclipse/dirigible/milestone/37?closed=1 The source code is available at GitHub repository here: https://github.com/eclipse/dirigible/tree/5.3.0 The instant trial is updated accordingly with the released version here: http://trial.dirigible.io","title":"Operational"},{"location":"2020/10/05/news-new-release-5-3/#enjoy","text":"","title":"Enjoy!"},{"location":"2020/10/23/how-to-deploy-eclipse-dirigible-in-the-sap-cloud-platform-kyma-environment/","text":"Eclipse Dirigible is an open-source cloud development platform, that provides capabilities for end-to-end development process from database modeling and management, through RESTful services using server-side JavaScript, to pattern-based user interface generation, role based security, external services integration, testing, debugging, operations and monitoring ... To read the whole article go to: How to deploy Eclipse Dirigible in the SAP Cloud Platform Kyma environment","title":"How to deploy Eclipse Dirigible in the SAP Cloud Platform Kyma environment"},{"location":"2020/10/23/news-new-release-5-4/","text":"New version 5.4 has been released. Release is of Type A Features Kyma build JWT token and OAuth flow Fixes Invalid metadata in OData generation in case of PostgreSQL database Cloud Foundry access constraints Minor fixes Statistics 56K+ Users 80K+ Sessions 185 Countries 408 Repositories in DirigibleLabs Operational Available packages for download - https://download.eclipse.org/dirigible/drops/R-5.4-202010231540/index.html Docker images at Docker Hub under DirigibleLabs organization: https://hub.docker.com/u/dirigiblelabs/ Maven Central artifacts by org.eclipse.dirigible namespace: https://search.maven.org/search?q=org.eclipse.dirigible The full list of bug-fixes and enhancements can be found here: https://github.com/eclipse/dirigible/milestone/38?closed=1 The source code is available at GitHub repository here: https://github.com/eclipse/dirigible/tree/5.4.0 The instant trial is updated accordingly with the released version here: http://trial.dirigible.io Enjoy!","title":"Release 5.4"},{"location":"2020/10/23/news-new-release-5-4/#features","text":"Kyma build JWT token and OAuth flow","title":"Features"},{"location":"2020/10/23/news-new-release-5-4/#fixes","text":"Invalid metadata in OData generation in case of PostgreSQL database Cloud Foundry access constraints Minor fixes","title":"Fixes"},{"location":"2020/10/23/news-new-release-5-4/#statistics","text":"56K+ Users 80K+ Sessions 185 Countries 408 Repositories in DirigibleLabs","title":"Statistics"},{"location":"2020/10/23/news-new-release-5-4/#operational","text":"Available packages for download - https://download.eclipse.org/dirigible/drops/R-5.4-202010231540/index.html Docker images at Docker Hub under DirigibleLabs organization: https://hub.docker.com/u/dirigiblelabs/ Maven Central artifacts by org.eclipse.dirigible namespace: https://search.maven.org/search?q=org.eclipse.dirigible The full list of bug-fixes and enhancements can be found here: https://github.com/eclipse/dirigible/milestone/38?closed=1 The source code is available at GitHub repository here: https://github.com/eclipse/dirigible/tree/5.4.0 The instant trial is updated accordingly with the released version here: http://trial.dirigible.io","title":"Operational"},{"location":"2020/10/23/news-new-release-5-4/#enjoy","text":"","title":"Enjoy!"},{"location":"2020/11/11/news-new-release-5-5/","text":"New version 5.5 has been released. Release is of Type A Features Kafka Consumer API Kafka Producer API OAuth - Use HTTP session storage as cache for JWT Add support for OAuth \"client secret\" flow authentication - Cloud Foundry Add support for OAuth \"client secret\" flow authentication - Kyma Fixes Move the Reset option to the Windows dropdown DAO - add support for case sensitive settings Minor fixes Statistics 56K+ Users 80K+ Sessions 185 Countries 408 Repositories in DirigibleLabs Operational Available packages for download - https://download.eclipse.org/dirigible/drops/R-5.5-202011111515/index.html Docker images at Docker Hub under DirigibleLabs organization: https://hub.docker.com/u/dirigiblelabs/ Maven Central artifacts by org.eclipse.dirigible namespace: https://search.maven.org/search?q=org.eclipse.dirigible The full list of bug-fixes and enhancements can be found here: https://github.com/eclipse/dirigible/milestone/39?closed=1 The source code is available at GitHub repository here: https://github.com/eclipse/dirigible/tree/5.5.0 The instant trial is updated accordingly with the released version here: http://trial.dirigible.io Enjoy!","title":"Release 5.5"},{"location":"2020/11/11/news-new-release-5-5/#features","text":"Kafka Consumer API Kafka Producer API OAuth - Use HTTP session storage as cache for JWT Add support for OAuth \"client secret\" flow authentication - Cloud Foundry Add support for OAuth \"client secret\" flow authentication - Kyma","title":"Features"},{"location":"2020/11/11/news-new-release-5-5/#fixes","text":"Move the Reset option to the Windows dropdown DAO - add support for case sensitive settings Minor fixes","title":"Fixes"},{"location":"2020/11/11/news-new-release-5-5/#statistics","text":"56K+ Users 80K+ Sessions 185 Countries 408 Repositories in DirigibleLabs","title":"Statistics"},{"location":"2020/11/11/news-new-release-5-5/#operational","text":"Available packages for download - https://download.eclipse.org/dirigible/drops/R-5.5-202011111515/index.html Docker images at Docker Hub under DirigibleLabs organization: https://hub.docker.com/u/dirigiblelabs/ Maven Central artifacts by org.eclipse.dirigible namespace: https://search.maven.org/search?q=org.eclipse.dirigible The full list of bug-fixes and enhancements can be found here: https://github.com/eclipse/dirigible/milestone/39?closed=1 The source code is available at GitHub repository here: https://github.com/eclipse/dirigible/tree/5.5.0 The instant trial is updated accordingly with the released version here: http://trial.dirigible.io","title":"Operational"},{"location":"2020/11/11/news-new-release-5-5/#enjoy","text":"","title":"Enjoy!"},{"location":"2020/11/19/eclipse-dirigible-building-application-docker-image/","text":"Starting with Eclipse Dirigible 5.0, there are built-in integrations with the SAP Cloud Platform Cloud Foundry and Kyma environments. To deploy Eclipse Dirigible on either one of these environments, you need to use a Docker image ... To read the whole article go to: Eclipse Dirigible \u2013 Building a Docker Image for Your Application","title":"Eclipse Dirigible \u2013 Building a Docker Image for Your Application"},{"location":"2020/11/20/how-to-deploy-eclipse-dirigible-private-docker-image-in-the-sap-cloud-platform-cloud-foundry-environment/","text":"Starting with Eclipse Dirigible 5.0, there are built-in integrations with the SAP Cloud Platform Cloud Foundry and Kyma environments. To deploy Eclipse Dirigible on either one of these environments, you need to use a Docker image. In this tutorial, I\u2019m going to show you how to deploy Eclipse Dirigible based Docker image from a private Docker repository ... To read the whole article go to: How to deploy Eclipse Dirigible private Docker image in the SAP Cloud Platform Cloud Foundry environment","title":"How to deploy Eclipse Dirigible private Docker image in the SAP Cloud Platform Cloud Foundry environment"},{"location":"2020/11/24/eclipse-dirigible-sap-identity-and-authentication-service-integration-on-the-sap-cloud-platform/","text":"Starting with Eclipse Dirigible 5.0, there are built-in integrations with the SAP Cloud Platform Cloud Foundry and Kyma environments. Beyond the most basic configuration with the default Identity Provider, there are plenty of use cases where integration with the SAP Identity and Authentication Service is needed ... To read the whole article go to: Eclipse Dirigible \u2013 SAP Identity and Authentication Service Integration on the SAP Cloud Platform","title":"Eclipse Dirigible \u2013 SAP Identity and Authentication Service Integration on the SAP Cloud Platform"},{"location":"2020/11/24/how-to-deploy-eclipse-dirigible-private-docker-image-in-the-sap-cloud-platform-kyma-environment/","text":"Starting with Eclipse Dirigible 5.0, there are built-in integrations with the SAP Cloud Platform Cloud Foundry and Kyma environments. To deploy Eclipse Dirigible on either one of these environments, you need to use a Docker image. In this tutorial, I\u2019m going to show you how to deploy Eclipse Dirigible based Docker image from a private Docker repository ... To read the whole article go to: How to deploy Eclipse Dirigible private Docker image in the SAP Cloud Platform Kyma environment","title":"How to deploy Eclipse Dirigible private Docker image in the SAP Cloud Platform Kyma environment"},{"location":"2020/12/16/2020-what-a-year-for-eclipse-dirigible/","text":"It has been a challenging, but in the same time an incredible year for Eclipse Dirigible in terms of progress, contribution and adoption. 2020 in numbers: 12 releases from 4.2 to 5.6 with 1 major 5.0 138 issues fixed 11 blog posts 10 new API - Content, Template Engine, Execute, Lifecycle, SOAP, Websocket, Kafka Consumer, Kafka Producer, MongoDB Client, MongoDB DAO 11K+ users from 143 countries for 2020 412 repositories in DirigibleLabs till date Notable new features Packages for SAP Cloud Platfom Neo , Cloud Foundry and Kyma OData v2 support based on Apache Olingo Entity Modeler improvements - calculated properties, security roles, pattern based validation, projection entity type, extension entity type Form Builder based on AngularJS and Bootstrap introduced OpenUI5 starter pack JWT token and OAuth2 flow Renovation Terminal replaced with xterm.js Monaco (VSCode Editor) set as default editor GraalVM engine introduced and set as default Debug View replaced with Chrome Dev Tools Git functionality re-architecture License License updated to EPL 2.0 REUSE compliant Conferences & Social Media What is Eclipse Dirigible? What is Low Code Development? at EclipseCon Pan-European Matchathon New videos in the channel Slack channel with 49 participants Derivative work Project \"XSK\" - compatible environment for SAP HANA Extended Application Services (XS) based applications Stay safe and healthy! See you all in 2021! \ud83e\udd73","title":"2020 - What a year for Eclipse Dirigible!"},{"location":"2020/12/16/2020-what-a-year-for-eclipse-dirigible/#2020-in-numbers","text":"12 releases from 4.2 to 5.6 with 1 major 5.0 138 issues fixed 11 blog posts 10 new API - Content, Template Engine, Execute, Lifecycle, SOAP, Websocket, Kafka Consumer, Kafka Producer, MongoDB Client, MongoDB DAO 11K+ users from 143 countries for 2020 412 repositories in DirigibleLabs till date","title":"2020 in numbers:"},{"location":"2020/12/16/2020-what-a-year-for-eclipse-dirigible/#notable-new-features","text":"Packages for SAP Cloud Platfom Neo , Cloud Foundry and Kyma OData v2 support based on Apache Olingo Entity Modeler improvements - calculated properties, security roles, pattern based validation, projection entity type, extension entity type Form Builder based on AngularJS and Bootstrap introduced OpenUI5 starter pack JWT token and OAuth2 flow","title":"Notable new features"},{"location":"2020/12/16/2020-what-a-year-for-eclipse-dirigible/#renovation","text":"Terminal replaced with xterm.js Monaco (VSCode Editor) set as default editor GraalVM engine introduced and set as default Debug View replaced with Chrome Dev Tools Git functionality re-architecture","title":"Renovation"},{"location":"2020/12/16/2020-what-a-year-for-eclipse-dirigible/#license","text":"License updated to EPL 2.0 REUSE compliant","title":"License"},{"location":"2020/12/16/2020-what-a-year-for-eclipse-dirigible/#conferences-social-media","text":"What is Eclipse Dirigible? What is Low Code Development? at EclipseCon Pan-European Matchathon New videos in the channel Slack channel with 49 participants","title":"Conferences &amp; Social Media"},{"location":"2020/12/16/2020-what-a-year-for-eclipse-dirigible/#derivative-work","text":"Project \"XSK\" - compatible environment for SAP HANA Extended Application Services (XS) based applications Stay safe and healthy! See you all in 2021! \ud83e\udd73","title":"Derivative work"},{"location":"2020/12/22/news-new-release-5-6/","text":"New version 5.6 has been released. Release is of Type A Features MongoDB Client API MongoDB DAO API MongoDB based persistence for Application Templates MongoDB based full-stack Application Templates Case Sensitive support for the Persistence Layer Sidebar Navigation support for Entity Data Modeler Fixes Case Sensitive support for Constraints Missing Git commit info SAP Kyma local database configuration SAP Cloud Foundary related fixes PostgreSQL related fixes ActiveMQ version update to support PostgreSQL Kafka parameters configurable via environment Minor fixes Statistics 57K+ Users 82K+ Sessions 186 Countries 412 Repositories in DirigibleLabs Operational Available packages for download - https://github.com/eclipse/dirigible/releases/tag/v5.6.0 Docker images at Docker Hub under DirigibleLabs organization: https://hub.docker.com/u/dirigiblelabs/ Maven Central artifacts by org.eclipse.dirigible namespace: https://search.maven.org/search?q=org.eclipse.dirigible The full list of bug-fixes and enhancements can be found here: https://github.com/eclipse/dirigible/milestone/40?closed=1 The source code is available at GitHub repository here: https://github.com/eclipse/dirigible/tree/5.6.0 The instant trial is updated accordingly with the released version here: http://trial.dirigible.io Enjoy!","title":"Release 5.6"},{"location":"2020/12/22/news-new-release-5-6/#features","text":"MongoDB Client API MongoDB DAO API MongoDB based persistence for Application Templates MongoDB based full-stack Application Templates Case Sensitive support for the Persistence Layer Sidebar Navigation support for Entity Data Modeler","title":"Features"},{"location":"2020/12/22/news-new-release-5-6/#fixes","text":"Case Sensitive support for Constraints Missing Git commit info SAP Kyma local database configuration SAP Cloud Foundary related fixes PostgreSQL related fixes ActiveMQ version update to support PostgreSQL Kafka parameters configurable via environment Minor fixes","title":"Fixes"},{"location":"2020/12/22/news-new-release-5-6/#statistics","text":"57K+ Users 82K+ Sessions 186 Countries 412 Repositories in DirigibleLabs","title":"Statistics"},{"location":"2020/12/22/news-new-release-5-6/#operational","text":"Available packages for download - https://github.com/eclipse/dirigible/releases/tag/v5.6.0 Docker images at Docker Hub under DirigibleLabs organization: https://hub.docker.com/u/dirigiblelabs/ Maven Central artifacts by org.eclipse.dirigible namespace: https://search.maven.org/search?q=org.eclipse.dirigible The full list of bug-fixes and enhancements can be found here: https://github.com/eclipse/dirigible/milestone/40?closed=1 The source code is available at GitHub repository here: https://github.com/eclipse/dirigible/tree/5.6.0 The instant trial is updated accordingly with the released version here: http://trial.dirigible.io","title":"Operational"},{"location":"2020/12/22/news-new-release-5-6/#enjoy","text":"","title":"Enjoy!"},{"location":"2021/01/31/news-new-release-5-7/","text":"New version 5.7 has been released. Release is of Type A Features Help , API and Samples migrated to MkDocs Migrate form TravisCI to GitHub Actions Persisted State and Log for the Synchronizers Synchronizers interdependencies Fixes Case Sensitive support for PostgreSQL fixes Case Sensitive support for complex expressions fixes Update Apache CXF to 3.4.1 in Dirigible 3.2.X SAP Cloud Foundry - Add support for PostgreSQL hyperscaler service instance Minor fixes Statistics 58K+ Users 83K+ Sessions 186 Countries 415 Repositories in DirigibleLabs Operational Available packages for download - https://github.com/eclipse/dirigible/releases/tag/v5.7.0 Docker images at Docker Hub under DirigibleLabs organization: https://hub.docker.com/u/dirigiblelabs/ Maven Central artifacts by org.eclipse.dirigible namespace: https://search.maven.org/search?q=org.eclipse.dirigible The full list of bug-fixes and enhancements can be found here: https://github.com/eclipse/dirigible/milestone/41?closed=1 The source code is available at GitHub repository here: https://github.com/eclipse/dirigible/tree/5.7.0 The instant trial is updated accordingly with the released version here: http://trial.dirigible.io Enjoy!","title":"Release 5.7"},{"location":"2021/01/31/news-new-release-5-7/#features","text":"Help , API and Samples migrated to MkDocs Migrate form TravisCI to GitHub Actions Persisted State and Log for the Synchronizers Synchronizers interdependencies","title":"Features"},{"location":"2021/01/31/news-new-release-5-7/#fixes","text":"Case Sensitive support for PostgreSQL fixes Case Sensitive support for complex expressions fixes Update Apache CXF to 3.4.1 in Dirigible 3.2.X SAP Cloud Foundry - Add support for PostgreSQL hyperscaler service instance Minor fixes","title":"Fixes"},{"location":"2021/01/31/news-new-release-5-7/#statistics","text":"58K+ Users 83K+ Sessions 186 Countries 415 Repositories in DirigibleLabs","title":"Statistics"},{"location":"2021/01/31/news-new-release-5-7/#operational","text":"Available packages for download - https://github.com/eclipse/dirigible/releases/tag/v5.7.0 Docker images at Docker Hub under DirigibleLabs organization: https://hub.docker.com/u/dirigiblelabs/ Maven Central artifacts by org.eclipse.dirigible namespace: https://search.maven.org/search?q=org.eclipse.dirigible The full list of bug-fixes and enhancements can be found here: https://github.com/eclipse/dirigible/milestone/41?closed=1 The source code is available at GitHub repository here: https://github.com/eclipse/dirigible/tree/5.7.0 The instant trial is updated accordingly with the released version here: http://trial.dirigible.io","title":"Operational"},{"location":"2021/01/31/news-new-release-5-7/#enjoy","text":"","title":"Enjoy!"},{"location":"2021/02/18/news-new-release-5-8/","text":"New version 5.8 has been released. Release is of Type A Features Configurable options for GraalVM Javascript Engine Custom datasource option for Cloud Foundry Build and Releases as GitHub Actions Configurations View 17 UI related improvements Last modified info for the Repository Synchronizers optimizations Fixes Launchpad fixes Git clone on a default branch different than 'master' fix Minor fixes Statistics 59K+ Users 84K+ Sessions 186 Countries 423 Repositories in DirigibleLabs Operational Available packages for download - https://github.com/eclipse/dirigible/releases/tag/v5.8.0 Docker images at Docker Hub under DirigibleLabs organization: https://hub.docker.com/u/dirigiblelabs/ Maven Central artifacts by org.eclipse.dirigible namespace: https://search.maven.org/search?q=org.eclipse.dirigible The full list of bug-fixes and enhancements can be found here: https://github.com/eclipse/dirigible/milestone/42?closed=1 The source code is available at GitHub repository here: https://github.com/eclipse/dirigible/tree/5.7.0 The instant trial is updated accordingly with the released version here: http://trial.dirigible.io Enjoy!","title":"Release 5.8"},{"location":"2021/02/18/news-new-release-5-8/#features","text":"Configurable options for GraalVM Javascript Engine Custom datasource option for Cloud Foundry Build and Releases as GitHub Actions Configurations View 17 UI related improvements Last modified info for the Repository Synchronizers optimizations","title":"Features"},{"location":"2021/02/18/news-new-release-5-8/#fixes","text":"Launchpad fixes Git clone on a default branch different than 'master' fix Minor fixes","title":"Fixes"},{"location":"2021/02/18/news-new-release-5-8/#statistics","text":"59K+ Users 84K+ Sessions 186 Countries 423 Repositories in DirigibleLabs","title":"Statistics"},{"location":"2021/02/18/news-new-release-5-8/#operational","text":"Available packages for download - https://github.com/eclipse/dirigible/releases/tag/v5.8.0 Docker images at Docker Hub under DirigibleLabs organization: https://hub.docker.com/u/dirigiblelabs/ Maven Central artifacts by org.eclipse.dirigible namespace: https://search.maven.org/search?q=org.eclipse.dirigible The full list of bug-fixes and enhancements can be found here: https://github.com/eclipse/dirigible/milestone/42?closed=1 The source code is available at GitHub repository here: https://github.com/eclipse/dirigible/tree/5.7.0 The instant trial is updated accordingly with the released version here: http://trial.dirigible.io","title":"Operational"},{"location":"2021/02/18/news-new-release-5-8/#enjoy","text":"","title":"Enjoy!"},{"location":"2021/03/26/news-new-release-5-9/","text":"New version 5.9 has been released. Release is of Type A Features Logs setup/configuration Enhance page title in the 'Access' tab of the 'Documents' Pluggable Javascript Module Source Provider Switch the default theme to the light one Cache repository resources by default After successful import, refresh Workspace Explorer Generate Helm charts as part of the release action Enhance exists method to accept artefact type Add more charts capabilities Custom Dirigible Docker Image in Helm Add support for Stored Procedures in Database Explorer Add support for Functions in Database Explorer PDF API Security OAuth API Add Support for Stored Procedures in SQL View Database Add Support for Stored Procedures API Fixes Redundant ?refreshToken= appended to URL Database - invalid encapsulating of entity name Build fails with no space left on device No enum constant org.eclipse.dirigible.database.sql.DataType.FLOAT SAP CF Runtime only deployment is not working Database Query results are limited to 100 records Make Git Commit Repository Agnostic Logout is not working SAP CF & Kyma - keep the initial access path after authentication No Column annotation found Fails to initialize terminal server in windows environment Busy page is stuck PostgreSQL issues PostgreSQL - Syntax error at or near \"PRIMARY\" PostgreSQL - Multiple primary keys for table \"activemq_acks\" are not allowed Minor fixes Statistics 60K+ Users 86K+ Sessions 187 Countries 426 Repositories in DirigibleLabs Operational Available packages for download - https://github.com/eclipse/dirigible/releases/tag/v5.9.0 Docker images at Docker Hub under DirigibleLabs organization: https://hub.docker.com/u/dirigiblelabs/ Maven Central artifacts by org.eclipse.dirigible namespace: https://search.maven.org/search?q=org.eclipse.dirigible The full list of bug-fixes and enhancements can be found here: https://github.com/eclipse/dirigible/milestone/42?closed=1 The source code is available at GitHub repository here: https://github.com/eclipse/dirigible/tree/5.9.0 The instant trial is updated accordingly with the released version here: http://trial.dirigible.io Enjoy!","title":"Release 5.9"},{"location":"2021/03/26/news-new-release-5-9/#features","text":"Logs setup/configuration Enhance page title in the 'Access' tab of the 'Documents' Pluggable Javascript Module Source Provider Switch the default theme to the light one Cache repository resources by default After successful import, refresh Workspace Explorer Generate Helm charts as part of the release action Enhance exists method to accept artefact type Add more charts capabilities Custom Dirigible Docker Image in Helm Add support for Stored Procedures in Database Explorer Add support for Functions in Database Explorer PDF API Security OAuth API Add Support for Stored Procedures in SQL View Database Add Support for Stored Procedures API","title":"Features"},{"location":"2021/03/26/news-new-release-5-9/#fixes","text":"Redundant ?refreshToken= appended to URL Database - invalid encapsulating of entity name Build fails with no space left on device No enum constant org.eclipse.dirigible.database.sql.DataType.FLOAT SAP CF Runtime only deployment is not working Database Query results are limited to 100 records Make Git Commit Repository Agnostic Logout is not working SAP CF & Kyma - keep the initial access path after authentication No Column annotation found Fails to initialize terminal server in windows environment Busy page is stuck PostgreSQL issues PostgreSQL - Syntax error at or near \"PRIMARY\" PostgreSQL - Multiple primary keys for table \"activemq_acks\" are not allowed Minor fixes","title":"Fixes"},{"location":"2021/03/26/news-new-release-5-9/#statistics","text":"60K+ Users 86K+ Sessions 187 Countries 426 Repositories in DirigibleLabs","title":"Statistics"},{"location":"2021/03/26/news-new-release-5-9/#operational","text":"Available packages for download - https://github.com/eclipse/dirigible/releases/tag/v5.9.0 Docker images at Docker Hub under DirigibleLabs organization: https://hub.docker.com/u/dirigiblelabs/ Maven Central artifacts by org.eclipse.dirigible namespace: https://search.maven.org/search?q=org.eclipse.dirigible The full list of bug-fixes and enhancements can be found here: https://github.com/eclipse/dirigible/milestone/42?closed=1 The source code is available at GitHub repository here: https://github.com/eclipse/dirigible/tree/5.9.0 The instant trial is updated accordingly with the released version here: http://trial.dirigible.io","title":"Operational"},{"location":"2021/03/26/news-new-release-5-9/#enjoy","text":"","title":"Enjoy!"},{"location":"2021/04/24/news-new-release-5-10/","text":"New version 5.10 has been released. Release is of Type A Features Logs setup/configuration Database - Persist the last used datasource Database - All procedure results are displayed HANA SQL builder - Implement AlterSequenceBuilder Git - Autofill GIt Notifications Branding of the Help menu items Monaco - Improved Code Completion Separate common implementation of OData Engine Add support for callbacks OData - Add annotation for SAPData Fixes Redundant ?refreshToken= appended to URL Files are not uploaded Git Perspective Issue (Committed Code is not present in github) Update the term SAP Cloud Platform HanaSqlDialect - incorrect processing of exist Save button not working Monaco - Code completion suggestion not triggered by dot operator HANA - Duplicate name for dirigible tables Configurations - Java array is returned instead of JS array Preview - Refresh/Set URL on Save File Worspace - Add Dirigible-Editor header on create file Missing some type mappings support from DB to EDM Minor fixes Statistics 61K+ Users 87K+ Sessions 188 Countries 430 Repositories in DirigibleLabs Operational Available packages for download - https://github.com/eclipse/dirigible/releases/tag/v5.10.0 Docker images at Docker Hub under DirigibleLabs organization: https://hub.docker.com/u/dirigiblelabs/ Maven Central artifacts by org.eclipse.dirigible namespace: https://search.maven.org/search?q=org.eclipse.dirigible The full list of bug-fixes and enhancements can be found here: https://github.com/eclipse/dirigible/milestone/43?closed=1 The source code is available at GitHub repository here: https://github.com/eclipse/dirigible/tree/5.10.0 The instant trial is updated accordingly with the released version here: http://trial.dirigible.io Enjoy!","title":"Release 5.10"},{"location":"2021/04/24/news-new-release-5-10/#features","text":"Logs setup/configuration Database - Persist the last used datasource Database - All procedure results are displayed HANA SQL builder - Implement AlterSequenceBuilder Git - Autofill GIt Notifications Branding of the Help menu items Monaco - Improved Code Completion Separate common implementation of OData Engine Add support for callbacks OData - Add annotation for SAPData","title":"Features"},{"location":"2021/04/24/news-new-release-5-10/#fixes","text":"Redundant ?refreshToken= appended to URL Files are not uploaded Git Perspective Issue (Committed Code is not present in github) Update the term SAP Cloud Platform HanaSqlDialect - incorrect processing of exist Save button not working Monaco - Code completion suggestion not triggered by dot operator HANA - Duplicate name for dirigible tables Configurations - Java array is returned instead of JS array Preview - Refresh/Set URL on Save File Worspace - Add Dirigible-Editor header on create file Missing some type mappings support from DB to EDM Minor fixes","title":"Fixes"},{"location":"2021/04/24/news-new-release-5-10/#statistics","text":"61K+ Users 87K+ Sessions 188 Countries 430 Repositories in DirigibleLabs","title":"Statistics"},{"location":"2021/04/24/news-new-release-5-10/#operational","text":"Available packages for download - https://github.com/eclipse/dirigible/releases/tag/v5.10.0 Docker images at Docker Hub under DirigibleLabs organization: https://hub.docker.com/u/dirigiblelabs/ Maven Central artifacts by org.eclipse.dirigible namespace: https://search.maven.org/search?q=org.eclipse.dirigible The full list of bug-fixes and enhancements can be found here: https://github.com/eclipse/dirigible/milestone/43?closed=1 The source code is available at GitHub repository here: https://github.com/eclipse/dirigible/tree/5.10.0 The instant trial is updated accordingly with the released version here: http://trial.dirigible.io","title":"Operational"},{"location":"2021/04/24/news-new-release-5-10/#enjoy","text":"","title":"Enjoy!"},{"location":"2021/05/27/news-new-release-5-11/","text":"New version 5.11 has been released. Release is of Type A Features Add client API for etcd Provide API for Apache Spark Provide API for Redis with Jedis driver Provide API for RabbitMQ Provide API for Elasticsearch Documentation improvements Kyma & CF - Set DIRIGIBLE_OAUTH_ENABLED Update Hana Driver Server OAuth Fixes When creating and selecting a new file, the IDE says it doesn't exist and \"Publish all\" doesn't work Preview does not react on \"unpublish\" event PostgreCreateViewBuilder & MySQLCreateViewBuilder fixes Association Name with Prefix Space in perspective name leads to errors Configurations - Adds product related variables File with extension .xsodata can not be deleted When creating files .xsodata file cannot be loaded Minor fixes Statistics 62K+ Users 88K+ Sessions 188 Countries 430 Repositories in DirigibleLabs Operational Available packages for download - https://github.com/eclipse/dirigible/releases/tag/v5.11.0 Docker images at Docker Hub under DirigibleLabs organization: https://hub.docker.com/u/dirigiblelabs/ Maven Central artifacts by org.eclipse.dirigible namespace: https://search.maven.org/search?q=org.eclipse.dirigible The full list of bug-fixes and enhancements can be found here: https://github.com/eclipse/dirigible/milestone/45?closed=1 The source code is available at GitHub repository here: https://github.com/eclipse/dirigible/tree/5.11.0 The instant trial is updated accordingly with the released version here: http://trial.dirigible.io Enjoy!","title":"Release 5.11"},{"location":"2021/05/27/news-new-release-5-11/#features","text":"Add client API for etcd Provide API for Apache Spark Provide API for Redis with Jedis driver Provide API for RabbitMQ Provide API for Elasticsearch Documentation improvements Kyma & CF - Set DIRIGIBLE_OAUTH_ENABLED Update Hana Driver Server OAuth","title":"Features"},{"location":"2021/05/27/news-new-release-5-11/#fixes","text":"When creating and selecting a new file, the IDE says it doesn't exist and \"Publish all\" doesn't work Preview does not react on \"unpublish\" event PostgreCreateViewBuilder & MySQLCreateViewBuilder fixes Association Name with Prefix Space in perspective name leads to errors Configurations - Adds product related variables File with extension .xsodata can not be deleted When creating files .xsodata file cannot be loaded Minor fixes","title":"Fixes"},{"location":"2021/05/27/news-new-release-5-11/#statistics","text":"62K+ Users 88K+ Sessions 188 Countries 430 Repositories in DirigibleLabs","title":"Statistics"},{"location":"2021/05/27/news-new-release-5-11/#operational","text":"Available packages for download - https://github.com/eclipse/dirigible/releases/tag/v5.11.0 Docker images at Docker Hub under DirigibleLabs organization: https://hub.docker.com/u/dirigiblelabs/ Maven Central artifacts by org.eclipse.dirigible namespace: https://search.maven.org/search?q=org.eclipse.dirigible The full list of bug-fixes and enhancements can be found here: https://github.com/eclipse/dirigible/milestone/45?closed=1 The source code is available at GitHub repository here: https://github.com/eclipse/dirigible/tree/5.11.0 The instant trial is updated accordingly with the released version here: http://trial.dirigible.io","title":"Operational"},{"location":"2021/05/27/news-new-release-5-11/#enjoy","text":"","title":"Enjoy!"},{"location":"2021/07/04/news-new-release-5-12/","text":"New version 5.12 has been released. Release is of Type A Features Composite primary key support in OData Annotation support in OData Session API - added language member and invocation count method Added Views and Layout Settings Removed Terminal from descktop-all package SAP Neo packages OAuth configuration enhancements Fixes Update of Readme Update of build instruction Updater of Contributing Fiori theme fixes Statusbar fixes Added special treatment for the welcome tab Dublicate primarykey in SQL assemble string fix Fix bug when processing table type in odata Fix issue with missing table DIRIGIBLE_ODATA_HANDLER HTTP Request Fixes OData tests moved to the right module Minor fixes Statistics 62K+ Users 89K+ Sessions 188 Countries 432 Repositories in DirigibleLabs Operational Available packages for download - https://github.com/eclipse/dirigible/releases/tag/v5.12.0 Docker images at Docker Hub under DirigibleLabs organization: https://hub.docker.com/u/dirigiblelabs/ Maven Central artifacts by org.eclipse.dirigible namespace: https://search.maven.org/search?q=org.eclipse.dirigible The full list of bug-fixes and enhancements can be found here: https://github.com/eclipse/dirigible/milestone/46?closed=1 The source code is available at GitHub repository here: https://github.com/eclipse/dirigible/tree/5.12.0 The instant trial is updated accordingly with the released version here: http://trial.dirigible.io Enjoy!","title":"Release 5.12"},{"location":"2021/07/04/news-new-release-5-12/#features","text":"Composite primary key support in OData Annotation support in OData Session API - added language member and invocation count method Added Views and Layout Settings Removed Terminal from descktop-all package SAP Neo packages OAuth configuration enhancements","title":"Features"},{"location":"2021/07/04/news-new-release-5-12/#fixes","text":"Update of Readme Update of build instruction Updater of Contributing Fiori theme fixes Statusbar fixes Added special treatment for the welcome tab Dublicate primarykey in SQL assemble string fix Fix bug when processing table type in odata Fix issue with missing table DIRIGIBLE_ODATA_HANDLER HTTP Request Fixes OData tests moved to the right module Minor fixes","title":"Fixes"},{"location":"2021/07/04/news-new-release-5-12/#statistics","text":"62K+ Users 89K+ Sessions 188 Countries 432 Repositories in DirigibleLabs","title":"Statistics"},{"location":"2021/07/04/news-new-release-5-12/#operational","text":"Available packages for download - https://github.com/eclipse/dirigible/releases/tag/v5.12.0 Docker images at Docker Hub under DirigibleLabs organization: https://hub.docker.com/u/dirigiblelabs/ Maven Central artifacts by org.eclipse.dirigible namespace: https://search.maven.org/search?q=org.eclipse.dirigible The full list of bug-fixes and enhancements can be found here: https://github.com/eclipse/dirigible/milestone/46?closed=1 The source code is available at GitHub repository here: https://github.com/eclipse/dirigible/tree/5.12.0 The instant trial is updated accordingly with the released version here: http://trial.dirigible.io","title":"Operational"},{"location":"2021/07/04/news-new-release-5-12/#enjoy","text":"","title":"Enjoy!"},{"location":"2021/09/29/news-new-release-6-0/","text":"New version 6.0 has been released. Release is of Type B Features Adding NCLOB data type \u0410llow creating of table without PK definition Added CSV support, updated preview Improved REST Services Exception Handling Console - Adds auto scroll Added odata navigation unit test Expose command line execution via api-core Enabled Monaco CSV/CSVIM support CSV form editor Alter existing table with data Adding int - byte array conversion to BytesFacade Add UTF8Facade to api-utils Support of non-master branches for content WebJars adoption Implementing Drop/Create Builder for TableTyp\u0435 Implementation of merge entity with reference id for OData Implementation of insert with referenced entity for OData Added new CSVIM editor swagger-ui updated to 3.51.2 Add support for Buildpacks h2 database version updated to 1.4.200 SAP CF - Add Support for Binding of HANA Cloud Create Pre-release Workflow Liquibase integration Added Problems View Create SECURITY.md Added symbol column to Problems Model Simplify content profile usage Busy Welcome Page - sorting of the jobs Documents - Access Constraints Layering Documents - adding \"readOnly\" & \"writeOnly\" permissions Use System Datasource by Default Added Image View Initial Spring Boot based distro OData addition to Spring Boot distro Added Cors filter to Spring Boot distro Configured error pages for Spring Boot distro Added built-in websockets for Spring Boot distro Implement full commonjs require Implement assert module and add it to js tests Set angularjs version to 1.8.2 Added method for searching and limiting problems results Fixes ODATA update/create of entities Console - Undefined message breaks the execution flow Console - Trace method is not showing the trace stack Console - Fix logging of Java native objects Use better error message when the configuration of odata join column is Check of synonym existence Fixed table fk generation and tests on alter ByteOrder.BIG_ENDIAN.name instead of string literal BytesFacade OData load artifacts for a specific schema Health and Timeout as separate modules Added mapping from exception to status code for OData Customizing the property value on read for OData Guice removed template-form-builder-angularjs name fix Modules ordering Collect BPM related modules under a single parent Collect all the modules related to CMS/Documents under a single group Delete Orion from the main repository Delete ACE from the main repository CMS references fixes Proper handling in case terminal is not available Added get headers for the HTTP API upload Added test for create with reference key for OData Fixed connection closing on update/delete/create Added test for update reference ID Added test for create with reference key Reduce RabbitMQ's image version to 3.8.19 for testcontainers Using workspace path for caching Using caffeine for the repository cache Separate templating related functionality Running nightly build on windows and linux Retrieval OData using API Bootstrap optimization Unable to create publish request, due to long User ID fix Move the content jars under different root Remove Javascript and Database grouping modules Removing discussions perspective from default packaging Silent SystemDB setting Data name for references column OData associations fixes OData schema test fix Documents - Import Export functionality for constraints Use properties for switching off modules from content profile Remove v3 APIs from API modules License plugin fixes JavaScript API tests fix Adjusting TableTypeBuilders to support primary keys for Type definition Fix delete statement and simplify content profile usage Files & Zip - Read/Write Native Bytes Repository & Registry - Read/Write Native Bytes Exec - fix code completion Increased PROBLEM_EXPECTED size for parser error messages Improved unit tests of the OData module Improved unit tests - deleted unused dependencies and refactored tests Documents - updates project structure Removing jboss-rmi-api_1.0_spec optional dependency \u0410dding schema for checking existance on sequence Serialization for jackson fixes Adds \"Dirigible-Editor\" header to Publish/Unpublish actions Change css styles Global enable/disable synchronizers service Logging optimization Employee sample added Expand on member property for OData fix Add shema to foreign keys constraint Fix Module.js paths Create fallback context in executor Fix a bug on updating and deleting entities with composite keys Fix delete entity to use the column names instead of Entity fields Added delete entity test Remove built-in Discussions in favor of GitHub Discussions Fixed empty criteria and date searches Added selected count and total row count to problems search Repository not able to delete files Repository not opening files Registry view not opening files Minor fixes Statistics 65K+ Users 93K+ Sessions 188 Countries 439 Repositories in DirigibleLabs Operational Available packages for download - https://github.com/eclipse/dirigible/releases/tag/v6.0.0 Docker images at Docker Hub under DirigibleLabs organization: https://hub.docker.com/u/dirigiblelabs/ Maven Central artifacts by org.eclipse.dirigible namespace: https://search.maven.org/search?q=org.eclipse.dirigible The full list of bug-fixes and enhancements can be found here: https://github.com/eclipse/dirigible/milestone/47?closed=1 The source code is available at GitHub repository here: https://github.com/eclipse/dirigible/tree/6.0.0 The instant trial is updated accordingly with the released version here: http://trial.dirigible.io Enjoy!","title":"Release 6.0"},{"location":"2021/09/29/news-new-release-6-0/#features","text":"Adding NCLOB data type \u0410llow creating of table without PK definition Added CSV support, updated preview Improved REST Services Exception Handling Console - Adds auto scroll Added odata navigation unit test Expose command line execution via api-core Enabled Monaco CSV/CSVIM support CSV form editor Alter existing table with data Adding int - byte array conversion to BytesFacade Add UTF8Facade to api-utils Support of non-master branches for content WebJars adoption Implementing Drop/Create Builder for TableTyp\u0435 Implementation of merge entity with reference id for OData Implementation of insert with referenced entity for OData Added new CSVIM editor swagger-ui updated to 3.51.2 Add support for Buildpacks h2 database version updated to 1.4.200 SAP CF - Add Support for Binding of HANA Cloud Create Pre-release Workflow Liquibase integration Added Problems View Create SECURITY.md Added symbol column to Problems Model Simplify content profile usage Busy Welcome Page - sorting of the jobs Documents - Access Constraints Layering Documents - adding \"readOnly\" & \"writeOnly\" permissions Use System Datasource by Default Added Image View Initial Spring Boot based distro OData addition to Spring Boot distro Added Cors filter to Spring Boot distro Configured error pages for Spring Boot distro Added built-in websockets for Spring Boot distro Implement full commonjs require Implement assert module and add it to js tests Set angularjs version to 1.8.2 Added method for searching and limiting problems results","title":"Features"},{"location":"2021/09/29/news-new-release-6-0/#fixes","text":"ODATA update/create of entities Console - Undefined message breaks the execution flow Console - Trace method is not showing the trace stack Console - Fix logging of Java native objects Use better error message when the configuration of odata join column is Check of synonym existence Fixed table fk generation and tests on alter ByteOrder.BIG_ENDIAN.name instead of string literal BytesFacade OData load artifacts for a specific schema Health and Timeout as separate modules Added mapping from exception to status code for OData Customizing the property value on read for OData Guice removed template-form-builder-angularjs name fix Modules ordering Collect BPM related modules under a single parent Collect all the modules related to CMS/Documents under a single group Delete Orion from the main repository Delete ACE from the main repository CMS references fixes Proper handling in case terminal is not available Added get headers for the HTTP API upload Added test for create with reference key for OData Fixed connection closing on update/delete/create Added test for update reference ID Added test for create with reference key Reduce RabbitMQ's image version to 3.8.19 for testcontainers Using workspace path for caching Using caffeine for the repository cache Separate templating related functionality Running nightly build on windows and linux Retrieval OData using API Bootstrap optimization Unable to create publish request, due to long User ID fix Move the content jars under different root Remove Javascript and Database grouping modules Removing discussions perspective from default packaging Silent SystemDB setting Data name for references column OData associations fixes OData schema test fix Documents - Import Export functionality for constraints Use properties for switching off modules from content profile Remove v3 APIs from API modules License plugin fixes JavaScript API tests fix Adjusting TableTypeBuilders to support primary keys for Type definition Fix delete statement and simplify content profile usage Files & Zip - Read/Write Native Bytes Repository & Registry - Read/Write Native Bytes Exec - fix code completion Increased PROBLEM_EXPECTED size for parser error messages Improved unit tests of the OData module Improved unit tests - deleted unused dependencies and refactored tests Documents - updates project structure Removing jboss-rmi-api_1.0_spec optional dependency \u0410dding schema for checking existance on sequence Serialization for jackson fixes Adds \"Dirigible-Editor\" header to Publish/Unpublish actions Change css styles Global enable/disable synchronizers service Logging optimization Employee sample added Expand on member property for OData fix Add shema to foreign keys constraint Fix Module.js paths Create fallback context in executor Fix a bug on updating and deleting entities with composite keys Fix delete entity to use the column names instead of Entity fields Added delete entity test Remove built-in Discussions in favor of GitHub Discussions Fixed empty criteria and date searches Added selected count and total row count to problems search Repository not able to delete files Repository not opening files Registry view not opening files Minor fixes","title":"Fixes"},{"location":"2021/09/29/news-new-release-6-0/#statistics","text":"65K+ Users 93K+ Sessions 188 Countries 439 Repositories in DirigibleLabs","title":"Statistics"},{"location":"2021/09/29/news-new-release-6-0/#operational","text":"Available packages for download - https://github.com/eclipse/dirigible/releases/tag/v6.0.0 Docker images at Docker Hub under DirigibleLabs organization: https://hub.docker.com/u/dirigiblelabs/ Maven Central artifacts by org.eclipse.dirigible namespace: https://search.maven.org/search?q=org.eclipse.dirigible The full list of bug-fixes and enhancements can be found here: https://github.com/eclipse/dirigible/milestone/47?closed=1 The source code is available at GitHub repository here: https://github.com/eclipse/dirigible/tree/6.0.0 The instant trial is updated accordingly with the released version here: http://trial.dirigible.io","title":"Operational"},{"location":"2021/09/29/news-new-release-6-0/#enjoy","text":"","title":"Enjoy!"},{"location":"2021/10/07/news-new-release-6-1/","text":"New version 6.1 has been released. Release is of Type A Fixes Preview url won't open in Safari due to CORS errors Adjust column text size in the Problems tab Multiple Expand on OData v2 not working as expected Patch On Entity Results In NPE Minor fixes Statistics 66K+ Users 94K+ Sessions 188 Countries 443 Repositories in DirigibleLabs Operational Available packages for download - https://github.com/eclipse/dirigible/releases/tag/v6.1.0 Docker images at Docker Hub under DirigibleLabs organization: https://hub.docker.com/u/dirigiblelabs/ Maven Central artifacts by org.eclipse.dirigible namespace: https://search.maven.org/search?q=org.eclipse.dirigible The full list of bug-fixes and enhancements can be found here: https://github.com/eclipse/dirigible/milestone/50?closed=1 The source code is available at GitHub repository here: https://github.com/eclipse/dirigible/tree/6.1.0 The instant trial is updated accordingly with the released version here: http://trial.dirigible.io Enjoy!","title":"Release 6.1"},{"location":"2021/10/07/news-new-release-6-1/#fixes","text":"Preview url won't open in Safari due to CORS errors Adjust column text size in the Problems tab Multiple Expand on OData v2 not working as expected Patch On Entity Results In NPE Minor fixes","title":"Fixes"},{"location":"2021/10/07/news-new-release-6-1/#statistics","text":"66K+ Users 94K+ Sessions 188 Countries 443 Repositories in DirigibleLabs","title":"Statistics"},{"location":"2021/10/07/news-new-release-6-1/#operational","text":"Available packages for download - https://github.com/eclipse/dirigible/releases/tag/v6.1.0 Docker images at Docker Hub under DirigibleLabs organization: https://hub.docker.com/u/dirigiblelabs/ Maven Central artifacts by org.eclipse.dirigible namespace: https://search.maven.org/search?q=org.eclipse.dirigible The full list of bug-fixes and enhancements can be found here: https://github.com/eclipse/dirigible/milestone/50?closed=1 The source code is available at GitHub repository here: https://github.com/eclipse/dirigible/tree/6.1.0 The instant trial is updated accordingly with the released version here: http://trial.dirigible.io","title":"Operational"},{"location":"2021/10/07/news-new-release-6-1/#enjoy","text":"","title":"Enjoy!"},{"location":"2021/10/11/low-code-mobile-apps-with-dirigible-and-ns/","text":"WebViews Sometimes Work Nowadays, modern browsers allow web developers to access more and more native APIs and thus making them a platform good enough too meet more and more needs. Sometimes though you have a good reason to ask users to install your app on a device without native UI being necessary. And even more - what if you just reuse your web app code? Of course, I am talking about WebViews. WebView If you are happy with how your app looks in browsers, but you need to use platform APIs that are limited for PWAs (like Notifications , Bluetooth , Face ID , Offline Storage , etc.), a WebView application with JS-to-native messages would do the trick. And it's fairly simple to produce - create a single-view application with a WebView and implement some callbacks in both JavaScript and native code ( here is how you can do it in iOS). If it's simple, why don't you automate it? Step 1: Generate a WebView Mobile App from Dirigible First, let's create a WebView app for iOS from scratch. Create a new Xcode project, choose Single View Application and add a WKWebView to your one-and-only UIViewController. You need to add some boilerplate code to make your WKWebview open a URL. import SwiftUI import WebKit struct ContentView : View { var body : some View { Webview ( url : URL ( string : \"https://www.dirigible.io/\" ) ! ) } } struct Webview : UIViewRepresentable { let url : URL func makeUIView ( context : UIViewRepresentableContext < Webview > ) -> WKWebView { let config = WKWebViewConfiguration () let webview = WKWebView ( frame : CGRect . zero , configuration : config ) let request = URLRequest ( url : self . url ) webview . load ( request ) return webview } func updateUIView ( _ webview : WKWebView , context : UIViewRepresentableContext < Webview > ) { let request = URLRequest ( url : self . url , cachePolicy : . returnCacheDataElseLoad ) webview . load ( request ) } } Therefore, this works with the public URL of your deployed app. Now you can go ahead and publish your app in the App Store. If we change just the WKWebView URL, it should be really simple to automate it. Let's go through the steps that need to be automated: Create a Xcode project template to build the app from. In this project, we update the URL in the WebView configuration code to match the public index URL of our app. Replace the URL in the WebView configuration code with the public index URL of our app. Build and archive the iOS application. Send the archived application to a user via the Dirigible UI. Step 1. We already did that, but let's add a placeholder for the app URL, which we will be updating using a regex. For steps 2. and 3. I created a Node.js script that you can get from here and play with it. For Step 4. I created an endpoint in TransportProjectRestService.java : @GET @Path ( \"/project/{workspace}/{project}/ios\" ) @ApiOperation ( \"Generate ipa file\" ) @ApiResponses ({ @ApiResponse ( code = 200 , message = \"Project Exported\" ) }) public void exportProjectIos ( @Suspended AsyncResponse asyncResponse , @ApiParam ( value = \"Name of the Workspace\" , required = true ) @PathParam ( \"workspace\" ) String workspace , @ApiParam ( value = \"Name of the Project\" , required = true ) @PathParam ( \"project\" ) String project , @QueryParam ( \"previewUrl\" ) String previewUrl ) throws RepositoryExportException { String user = UserFacade . getName (); if ( user == null ) { asyncResponse . resume ( createErrorResponseForbidden ( NO_LOGGED_IN_USER )); } String appUrl = previewUrl + project + \"/index.html\" ; ProcessBuilder pb = new ProcessBuilder ( \"node\" , APP_GENERATOR_SCRIPT_PATH , \"generate\" , appUrl ); pb . inheritIO (); try { Process p = pb . start (); CompletableFuture onProcessExit = p . onExit (); onProcessExit . get (); onProcessExit . thenAccept ( ph -> { ByteArrayOutputStream baos = null ; baos = new ByteArrayOutputStream (); ZipOutputStream zipOut = new ZipOutputStream ( baos ); File fileToZip = new File ( GENERATED_APP_BUILD_PATH ); try { zipFile ( fileToZip , fileToZip . getName (), zipOut ); } catch ( IOException e ) { e . printStackTrace (); } try { zipOut . close (); } catch ( IOException e ) { e . printStackTrace (); } asyncResponse . resume ( Response . ok (). header ( \"Content-Disposition\" , \"attachment; filename=\\\"\" + project + \"-\" + \"build.zip\\\"\" ). entity ( baos . toByteArray ()). build ()); }); } catch ( IOException e ) { asyncResponse . resume ( Response . noContent (). build ()); } catch ( ExecutionException e ) { e . printStackTrace (); asyncResponse . resume ( Response . noContent (). build ()); } catch ( InterruptedException e ) { e . printStackTrace (); asyncResponse . resume ( Response . noContent (). build ()); } } It does the following: Gets the public URL of the Dirigible app from the request parameters. Calls the Node.js script with the URL as a parameter. Archives the contents of the build folder (archived iOS artifacts). Sends the .zip in the response. Now we need some front-end stuff. I went for the simplest way possible - added a new Export iOS app in the project right-button menu ( workspace.js ). The result: And when we load the app in the iOS Simulator: Step 2: Call Native APIs from the Dirigible App At the beginning of this post, I talked about messages between JS and native code, but this would require a bunch of code for handling different scenarios. Fortunately, there is a better way. NativeScript - Native Calls NativeScript's runtime allows native calls from JavaScript while keeping the exact same class, methods and property names as you are writing native code. This practically eliminates any need for learning bridge-specific APIs and if you want to do a native call, you can just refer to the corresponding docs. For example, this is how we initialize a UIViewController in Objective-C: UIViewController * vc = [ UIViewController alloc ] init ]; Using NativeScript it becomes: let vc = UIViewController . alloc (). init (); Since the NativeScript runtime works in a separate thread, we can't share context between it and our web app. That's why it provides worker -like interface. Keep in mind that this interface is still an experimental feature. For example, this is how you can get the model of the device from your Dirigible application: let worker = new NSWorker ( \"postmessage(UIDevice.currentDevice.localizedModel)\" ); onNativeMessage = function ( msg ) { console . log ( \"Message from native - \" + JSON . stringify ( msg )); $ ( '#model' ). text ( JSON . stringify ( msg . data )); } To make our Xcode project template project support this some changes are necessary - add the NativeScript framework and some other build settings in order to build and link the project properly. And this is the final result: Note What we reviewed in this article is a research topic rather than a fully implemented feature in Dirigible. The generation of mobile apps is certainly coming to Dirigible at some point, but there is a lot of work left to make it production-ready. That being said, any feedback, ideas and, of course, contribution will be appreciated. Link to the code sample on GitHub can be found here .","title":"Low-code mobile apps with Dirigible and NativeScript"},{"location":"2021/10/11/low-code-mobile-apps-with-dirigible-and-ns/#webviews-sometimes-work","text":"Nowadays, modern browsers allow web developers to access more and more native APIs and thus making them a platform good enough too meet more and more needs. Sometimes though you have a good reason to ask users to install your app on a device without native UI being necessary. And even more - what if you just reuse your web app code? Of course, I am talking about WebViews. WebView If you are happy with how your app looks in browsers, but you need to use platform APIs that are limited for PWAs (like Notifications , Bluetooth , Face ID , Offline Storage , etc.), a WebView application with JS-to-native messages would do the trick. And it's fairly simple to produce - create a single-view application with a WebView and implement some callbacks in both JavaScript and native code ( here is how you can do it in iOS). If it's simple, why don't you automate it?","title":"WebViews Sometimes Work"},{"location":"2021/10/11/low-code-mobile-apps-with-dirigible-and-ns/#step-1-generate-a-webview-mobile-app-from-dirigible","text":"First, let's create a WebView app for iOS from scratch. Create a new Xcode project, choose Single View Application and add a WKWebView to your one-and-only UIViewController. You need to add some boilerplate code to make your WKWebview open a URL. import SwiftUI import WebKit struct ContentView : View { var body : some View { Webview ( url : URL ( string : \"https://www.dirigible.io/\" ) ! ) } } struct Webview : UIViewRepresentable { let url : URL func makeUIView ( context : UIViewRepresentableContext < Webview > ) -> WKWebView { let config = WKWebViewConfiguration () let webview = WKWebView ( frame : CGRect . zero , configuration : config ) let request = URLRequest ( url : self . url ) webview . load ( request ) return webview } func updateUIView ( _ webview : WKWebView , context : UIViewRepresentableContext < Webview > ) { let request = URLRequest ( url : self . url , cachePolicy : . returnCacheDataElseLoad ) webview . load ( request ) } } Therefore, this works with the public URL of your deployed app. Now you can go ahead and publish your app in the App Store. If we change just the WKWebView URL, it should be really simple to automate it. Let's go through the steps that need to be automated: Create a Xcode project template to build the app from. In this project, we update the URL in the WebView configuration code to match the public index URL of our app. Replace the URL in the WebView configuration code with the public index URL of our app. Build and archive the iOS application. Send the archived application to a user via the Dirigible UI. Step 1. We already did that, but let's add a placeholder for the app URL, which we will be updating using a regex. For steps 2. and 3. I created a Node.js script that you can get from here and play with it. For Step 4. I created an endpoint in TransportProjectRestService.java : @GET @Path ( \"/project/{workspace}/{project}/ios\" ) @ApiOperation ( \"Generate ipa file\" ) @ApiResponses ({ @ApiResponse ( code = 200 , message = \"Project Exported\" ) }) public void exportProjectIos ( @Suspended AsyncResponse asyncResponse , @ApiParam ( value = \"Name of the Workspace\" , required = true ) @PathParam ( \"workspace\" ) String workspace , @ApiParam ( value = \"Name of the Project\" , required = true ) @PathParam ( \"project\" ) String project , @QueryParam ( \"previewUrl\" ) String previewUrl ) throws RepositoryExportException { String user = UserFacade . getName (); if ( user == null ) { asyncResponse . resume ( createErrorResponseForbidden ( NO_LOGGED_IN_USER )); } String appUrl = previewUrl + project + \"/index.html\" ; ProcessBuilder pb = new ProcessBuilder ( \"node\" , APP_GENERATOR_SCRIPT_PATH , \"generate\" , appUrl ); pb . inheritIO (); try { Process p = pb . start (); CompletableFuture onProcessExit = p . onExit (); onProcessExit . get (); onProcessExit . thenAccept ( ph -> { ByteArrayOutputStream baos = null ; baos = new ByteArrayOutputStream (); ZipOutputStream zipOut = new ZipOutputStream ( baos ); File fileToZip = new File ( GENERATED_APP_BUILD_PATH ); try { zipFile ( fileToZip , fileToZip . getName (), zipOut ); } catch ( IOException e ) { e . printStackTrace (); } try { zipOut . close (); } catch ( IOException e ) { e . printStackTrace (); } asyncResponse . resume ( Response . ok (). header ( \"Content-Disposition\" , \"attachment; filename=\\\"\" + project + \"-\" + \"build.zip\\\"\" ). entity ( baos . toByteArray ()). build ()); }); } catch ( IOException e ) { asyncResponse . resume ( Response . noContent (). build ()); } catch ( ExecutionException e ) { e . printStackTrace (); asyncResponse . resume ( Response . noContent (). build ()); } catch ( InterruptedException e ) { e . printStackTrace (); asyncResponse . resume ( Response . noContent (). build ()); } } It does the following: Gets the public URL of the Dirigible app from the request parameters. Calls the Node.js script with the URL as a parameter. Archives the contents of the build folder (archived iOS artifacts). Sends the .zip in the response. Now we need some front-end stuff. I went for the simplest way possible - added a new Export iOS app in the project right-button menu ( workspace.js ). The result: And when we load the app in the iOS Simulator:","title":"Step 1: Generate a WebView Mobile App from Dirigible"},{"location":"2021/10/11/low-code-mobile-apps-with-dirigible-and-ns/#step-2-call-native-apis-from-the-dirigible-app","text":"At the beginning of this post, I talked about messages between JS and native code, but this would require a bunch of code for handling different scenarios. Fortunately, there is a better way. NativeScript - Native Calls NativeScript's runtime allows native calls from JavaScript while keeping the exact same class, methods and property names as you are writing native code. This practically eliminates any need for learning bridge-specific APIs and if you want to do a native call, you can just refer to the corresponding docs. For example, this is how we initialize a UIViewController in Objective-C: UIViewController * vc = [ UIViewController alloc ] init ]; Using NativeScript it becomes: let vc = UIViewController . alloc (). init (); Since the NativeScript runtime works in a separate thread, we can't share context between it and our web app. That's why it provides worker -like interface. Keep in mind that this interface is still an experimental feature. For example, this is how you can get the model of the device from your Dirigible application: let worker = new NSWorker ( \"postmessage(UIDevice.currentDevice.localizedModel)\" ); onNativeMessage = function ( msg ) { console . log ( \"Message from native - \" + JSON . stringify ( msg )); $ ( '#model' ). text ( JSON . stringify ( msg . data )); } To make our Xcode project template project support this some changes are necessary - add the NativeScript framework and some other build settings in order to build and link the project properly. And this is the final result: Note What we reviewed in this article is a research topic rather than a fully implemented feature in Dirigible. The generation of mobile apps is certainly coming to Dirigible at some point, but there is a lot of work left to make it production-ready. That being said, any feedback, ideas and, of course, contribution will be appreciated. Link to the code sample on GitHub can be found here .","title":"Step 2: Call Native APIs from the Dirigible App"},{"location":"2021/10/14/kubernetes-aws-gardener-istio-letsencrypt-dirigible/","text":"Overview In this article we are going to setup custom domain for Dirigible application in Kubernes cluster with Gardener , AWS Route 53 , Istio , Let's encrypt . The target Kubernetes deployment is shown bellow: Kubernetes AWS Route 53 Gardener Istio Overview Kubernetes is an open source system for automating deployment, scaling, and management of containerized applications in a cluster environment. You can read more about Kubernetes here . Overview Amazon Route 53 is a highly available and scalable cloud Domain Name System (DNS) web service. here . Overview Deliver fully-managed clusters at scale everywhere with your own Kubernetes-as-a-Service. Kubernetes-native system managing the full lifecycle of conformant Kubernetes clusters as a service on Alicloud, AWS, Azure, GCP, OpenStack, EquinixMetal, vSphere, MetalStack, and Kubevirt with minimal TCO. here . Overview Istio is an open source service mesh that layers transparently onto existing distributed applications. Istio\u2019s powerful features provide a uniform and more efficient way to secure, connect, and monitor services. here . Prerequisites In this article we assume that you have already running productive Kubernetes Cluster on Gardener and configured kubectl for it. If you don't have such, you can create one by using the the open-source Gardener project. Also you will need AWS account or AWS Free Tier , you need to install Istio and Dirigible AWS Route 53 Configuration Create hosted zone - when you create hosted zone choose type Public hosted zone see the image below. After you create your hosted zone you can delegate your subdomain to AWS, if you don't host your parent domain in AWS. You can take the name servers which you can see in the image bellow and add ns records to your domain. But if you host your domain in AWS you don't need to delegate. Create new user - which will provide to Gardener dns provider. When you create user select credential type to be Access key - Programmatic access ( you see the image below). Create group - add user to group, but for this scenario we need to create new group which will be using only for this purpose. That's why, click on Create group and it will open new tab to create the group. Create Policy - before you create the new group click on Create policy it will open new tab to create the policy. On the first step click on the JSON see the image below: Leave this tab open and find your Hosted zone ID see the image below: Add your hosted zone id to the JSON you can use this example json { \"Version\" : \"2012-10-17\" , \"Statement\" : [ { \"Sid\" : \"VisualEditor0\" , \"Effect\" : \"Allow\" , \"Action\" : \"route53:ListResourceRecordSets\" , \"Resource\" : \"arn:aws:route53:::hostedzone/*\" }, { \"Sid\" : \"VisualEditor1\" , \"Effect\" : \"Allow\" , \"Action\" : \"route53:GetHostedZone\" , \"Resource\" : \"arn:aws:route53:::hostedzone/Z2XXXXXXXXXXXX\" }, { \"Sid\" : \"VisualEditor2\" , \"Effect\" : \"Allow\" , \"Action\" : \"route53:ListHostedZones\" , \"Resource\" : \"*\" }, { \"Sid\" : \"VisualEditor3\" , \"Effect\" : \"Allow\" , \"Action\" : \"route53:ChangeResourceRecordSets\" , \"Resource\" : \"arn:aws:route53:::hostedzone/Z2XXXXXXXXXXXX\" } ] } Note It's very important to add your correct hosted zone id We don't need tags, see image below: \u0422ype policy name, see image below: Add new policy to the group, see image below: Add new group to the user . We don't need tags: Note Before you click on create user check Permissions summary that consist your new group. Download your access key . Gardener Configuration Provide AWS Route 53 credentials - we need to provide our AWS Route 53 credentials from the previous step: Add gardener extensions to the Shoot cluster - configure dns and Let's Encrypt certificate. Open Gardener Shoot yaml file and add DNS providers - shoot-dns-service , shoot-cert-service : spec : dns : providers : - secretName : my-aws-route53-secret type : aws-route53 extensions : - type : shoot-dns-service providerConfig : apiVersion : service.dns.extensions.gardener.cloud/v1alpha1 kind : DNSConfig dnsProviderReplication : enabled : true - type : shoot-cert-service providerConfig : apiVersion : service.cert.extensions.gardener.cloud/v1alpha1 issuers : - email : <your-email-here> name : <type-name-for-the-issue> server : 'https://acme-v02.api.letsencrypt.org/directory' Create subdomain for your application - we can use DNSEntry for Gardener, because in Gardener Shoot yaml file we configured: dnsProviderReplication : enabled : true Find Istio ingress gateway external ip: kubectl get services istio-ingressgateway -n istio-system \\ --output jsonpath='{.status.loadBalancer.ingress[0].hostname}' apiVersion : dns.gardener.cloud/v1alpha1 kind : DNSEntry metadata : annotations : dns.gardener.cloud/class : garden name : dns-entry namespace : default spec : dnsName : \"app.demo.dirigible.io\" ttl : 600 targets : - <type-here-the-result-from-previous-command> Istio Configuration We need to configure our istio ingress gateway to accept our new sub domain app.demo.dirigible.io and the certificate. Apply the dns configuration and certificate - in this article we will configure istio ingress gateway to accept wildcard certificate. kubectl edit svc istio-ingressgateway -n istio-system # Please edit the object below. Lines beginning with a '#' will be ignored, # and an empty file will abort the edit. If an error occurs while saving this file will be # reopened with the relevant failures. # apiVersion : v1 kind : Service metadata : annotations : cert.gardener.cloud/issuer : app.demo.dirigible.io cert.gardener.cloud/secretname : wildcard-tls dns.gardener.cloud/class : garden dns.gardener.cloud/dnsnames : '*.demo.dirigible.io' dns.gardener.cloud/ttl : \"120\" Gateway configuration - configure Gateway and VirtualService for Dirigible application or any. apiVersion : networking.istio.io/v1alpha3 kind : Gateway metadata : name : dirigible spec : selector : istio : ingressgateway servers : - port : number : 80 name : http protocol : HTTP tls : httpsRedirect : true hosts : - \"app.demo.dirigible.io\" - port : number : 443 name : https protocol : HTTPS tls : mode : SIMPLE credentialName : wildcard-tls hosts : - \"app.demo.dirigible.io\" --- apiVersion : networking.istio.io/v1alpha3 kind : VirtualService metadata : name : dirigible spec : hosts : - \"app.demo.dirigible.io\" gateways : - dirigible http : - match : - uri : regex : /.* route : - destination : host : dirigible port : number : 8080","title":"Custom Domain in Kubernetes with AWS Route 53, Gardener, Istio & Let's encrypt"},{"location":"2021/10/14/kubernetes-aws-gardener-istio-letsencrypt-dirigible/#overview","text":"In this article we are going to setup custom domain for Dirigible application in Kubernes cluster with Gardener , AWS Route 53 , Istio , Let's encrypt . The target Kubernetes deployment is shown bellow: Kubernetes AWS Route 53 Gardener Istio Overview Kubernetes is an open source system for automating deployment, scaling, and management of containerized applications in a cluster environment. You can read more about Kubernetes here . Overview Amazon Route 53 is a highly available and scalable cloud Domain Name System (DNS) web service. here . Overview Deliver fully-managed clusters at scale everywhere with your own Kubernetes-as-a-Service. Kubernetes-native system managing the full lifecycle of conformant Kubernetes clusters as a service on Alicloud, AWS, Azure, GCP, OpenStack, EquinixMetal, vSphere, MetalStack, and Kubevirt with minimal TCO. here . Overview Istio is an open source service mesh that layers transparently onto existing distributed applications. Istio\u2019s powerful features provide a uniform and more efficient way to secure, connect, and monitor services. here .","title":"Overview"},{"location":"2021/10/14/kubernetes-aws-gardener-istio-letsencrypt-dirigible/#prerequisites","text":"In this article we assume that you have already running productive Kubernetes Cluster on Gardener and configured kubectl for it. If you don't have such, you can create one by using the the open-source Gardener project. Also you will need AWS account or AWS Free Tier , you need to install Istio and Dirigible","title":"Prerequisites"},{"location":"2021/10/14/kubernetes-aws-gardener-istio-letsencrypt-dirigible/#aws-route-53-configuration","text":"Create hosted zone - when you create hosted zone choose type Public hosted zone see the image below. After you create your hosted zone you can delegate your subdomain to AWS, if you don't host your parent domain in AWS. You can take the name servers which you can see in the image bellow and add ns records to your domain. But if you host your domain in AWS you don't need to delegate. Create new user - which will provide to Gardener dns provider. When you create user select credential type to be Access key - Programmatic access ( you see the image below). Create group - add user to group, but for this scenario we need to create new group which will be using only for this purpose. That's why, click on Create group and it will open new tab to create the group. Create Policy - before you create the new group click on Create policy it will open new tab to create the policy. On the first step click on the JSON see the image below: Leave this tab open and find your Hosted zone ID see the image below: Add your hosted zone id to the JSON you can use this example json { \"Version\" : \"2012-10-17\" , \"Statement\" : [ { \"Sid\" : \"VisualEditor0\" , \"Effect\" : \"Allow\" , \"Action\" : \"route53:ListResourceRecordSets\" , \"Resource\" : \"arn:aws:route53:::hostedzone/*\" }, { \"Sid\" : \"VisualEditor1\" , \"Effect\" : \"Allow\" , \"Action\" : \"route53:GetHostedZone\" , \"Resource\" : \"arn:aws:route53:::hostedzone/Z2XXXXXXXXXXXX\" }, { \"Sid\" : \"VisualEditor2\" , \"Effect\" : \"Allow\" , \"Action\" : \"route53:ListHostedZones\" , \"Resource\" : \"*\" }, { \"Sid\" : \"VisualEditor3\" , \"Effect\" : \"Allow\" , \"Action\" : \"route53:ChangeResourceRecordSets\" , \"Resource\" : \"arn:aws:route53:::hostedzone/Z2XXXXXXXXXXXX\" } ] } Note It's very important to add your correct hosted zone id We don't need tags, see image below: \u0422ype policy name, see image below: Add new policy to the group, see image below: Add new group to the user . We don't need tags: Note Before you click on create user check Permissions summary that consist your new group. Download your access key .","title":"AWS Route 53 Configuration"},{"location":"2021/10/14/kubernetes-aws-gardener-istio-letsencrypt-dirigible/#gardener-configuration","text":"Provide AWS Route 53 credentials - we need to provide our AWS Route 53 credentials from the previous step: Add gardener extensions to the Shoot cluster - configure dns and Let's Encrypt certificate. Open Gardener Shoot yaml file and add DNS providers - shoot-dns-service , shoot-cert-service : spec : dns : providers : - secretName : my-aws-route53-secret type : aws-route53 extensions : - type : shoot-dns-service providerConfig : apiVersion : service.dns.extensions.gardener.cloud/v1alpha1 kind : DNSConfig dnsProviderReplication : enabled : true - type : shoot-cert-service providerConfig : apiVersion : service.cert.extensions.gardener.cloud/v1alpha1 issuers : - email : <your-email-here> name : <type-name-for-the-issue> server : 'https://acme-v02.api.letsencrypt.org/directory' Create subdomain for your application - we can use DNSEntry for Gardener, because in Gardener Shoot yaml file we configured: dnsProviderReplication : enabled : true Find Istio ingress gateway external ip: kubectl get services istio-ingressgateway -n istio-system \\ --output jsonpath='{.status.loadBalancer.ingress[0].hostname}' apiVersion : dns.gardener.cloud/v1alpha1 kind : DNSEntry metadata : annotations : dns.gardener.cloud/class : garden name : dns-entry namespace : default spec : dnsName : \"app.demo.dirigible.io\" ttl : 600 targets : - <type-here-the-result-from-previous-command>","title":"Gardener Configuration"},{"location":"2021/10/14/kubernetes-aws-gardener-istio-letsencrypt-dirigible/#istio-configuration","text":"We need to configure our istio ingress gateway to accept our new sub domain app.demo.dirigible.io and the certificate. Apply the dns configuration and certificate - in this article we will configure istio ingress gateway to accept wildcard certificate. kubectl edit svc istio-ingressgateway -n istio-system # Please edit the object below. Lines beginning with a '#' will be ignored, # and an empty file will abort the edit. If an error occurs while saving this file will be # reopened with the relevant failures. # apiVersion : v1 kind : Service metadata : annotations : cert.gardener.cloud/issuer : app.demo.dirigible.io cert.gardener.cloud/secretname : wildcard-tls dns.gardener.cloud/class : garden dns.gardener.cloud/dnsnames : '*.demo.dirigible.io' dns.gardener.cloud/ttl : \"120\" Gateway configuration - configure Gateway and VirtualService for Dirigible application or any. apiVersion : networking.istio.io/v1alpha3 kind : Gateway metadata : name : dirigible spec : selector : istio : ingressgateway servers : - port : number : 80 name : http protocol : HTTP tls : httpsRedirect : true hosts : - \"app.demo.dirigible.io\" - port : number : 443 name : https protocol : HTTPS tls : mode : SIMPLE credentialName : wildcard-tls hosts : - \"app.demo.dirigible.io\" --- apiVersion : networking.istio.io/v1alpha3 kind : VirtualService metadata : name : dirigible spec : hosts : - \"app.demo.dirigible.io\" gateways : - dirigible http : - match : - uri : regex : /.* route : - destination : host : dirigible port : number : 8080","title":"Istio Configuration"},{"location":"2021/11/1/dirigible-runs-material/","text":"Intro Until recently, the Eclipse Dirigible website was powered by Jekyll . As part of a comprehensive update of the website's look-and-feel, we've switched entirely to Material for MkDocs . In addition, we added our favorite Dirigible gold into the website color pallette. We're quite excited by the result so we decided to sum everything up in this post. Read on for more details as well as a couple of before/after comparisons. Main Site Before Here's the old look of the Eclipse Dirigible website: After And here's how it looks now: Eclipse Dirigible Documentation Before The old documentation (i.e., help) page represented a long table of contents: After Currently, there's a landing page with a built-in search and tiles that give you hints when you hover over them: Dirigiballs Everywhere By now, you've probably noticed the habitual presence of meatball-looking creatures all over the site. Meet our out-of-this-world friends, the \"dirigiballs\". They have generously accepted our invitation to pose for a couple of photos for the site. We hope everyone has as much fun looking at them as we had during the shootout. If you take a look at the rest of the Dirigible sites, you'll notice that the dirigiballs have invaded our whole landscape: dirigible.io/blogs dirigible.io/news dirigible.io/releases dirigible.io/api dirigible.io/samples On a serious note, credit goes to unDraw for the great illustrations.","title":"Dirigible now runs Material for MkDocs"},{"location":"2021/11/1/dirigible-runs-material/#intro","text":"Until recently, the Eclipse Dirigible website was powered by Jekyll . As part of a comprehensive update of the website's look-and-feel, we've switched entirely to Material for MkDocs . In addition, we added our favorite Dirigible gold into the website color pallette. We're quite excited by the result so we decided to sum everything up in this post. Read on for more details as well as a couple of before/after comparisons.","title":"Intro"},{"location":"2021/11/1/dirigible-runs-material/#main-site","text":"","title":"Main Site"},{"location":"2021/11/1/dirigible-runs-material/#before","text":"Here's the old look of the Eclipse Dirigible website:","title":"Before"},{"location":"2021/11/1/dirigible-runs-material/#after","text":"And here's how it looks now:","title":"After"},{"location":"2021/11/1/dirigible-runs-material/#eclipse-dirigible-documentation","text":"","title":"Eclipse Dirigible Documentation"},{"location":"2021/11/1/dirigible-runs-material/#before_1","text":"The old documentation (i.e., help) page represented a long table of contents:","title":"Before"},{"location":"2021/11/1/dirigible-runs-material/#after_1","text":"Currently, there's a landing page with a built-in search and tiles that give you hints when you hover over them:","title":"After"},{"location":"2021/11/1/dirigible-runs-material/#dirigiballs-everywhere","text":"By now, you've probably noticed the habitual presence of meatball-looking creatures all over the site. Meet our out-of-this-world friends, the \"dirigiballs\". They have generously accepted our invitation to pose for a couple of photos for the site. We hope everyone has as much fun looking at them as we had during the shootout. If you take a look at the rest of the Dirigible sites, you'll notice that the dirigiballs have invaded our whole landscape: dirigible.io/blogs dirigible.io/news dirigible.io/releases dirigible.io/api dirigible.io/samples On a serious note, credit goes to unDraw for the great illustrations.","title":"Dirigiballs Everywhere"},{"location":"2021/11/2/material-blogging-capabilities/","text":"Overview In this blog, we're going to discuss how to add blogging capabilities to Material for MkDocs . Here's what we refer to as blogging capabilities: author's GitHub avatar, name, and link to GitHub profile a calendar icon with a publishing date next to it a clock icon with a value for time to read next to it You can also see the above mentioned capabilities under the title of this blog. In particular, we'll look at: What kind of metadata key-value pairs you need to define in your .md file and how. How to override a specific block in the main.html file that MkDocs uses as a template when building the HTML output from your .md source, so that the metadata values provided in your .md file are reflected in the HTML output. As a result, a blog author will just have to provide sufficient metadata in the frontmatter of their .md file and data about author, publishing date, and reading time will be displayed as part of their blog. Cool, right? This can also be done manually by including a piece of HTML code in each .md file but we wanted to have everything set up for blog authors in a way that they can focus on the writing itself. Adding Metadata to Your Blog Metadata about an .md file (also called frontmatter) is declared within a specific block in the beginning of the .md file itself and is denoted by the triple dashes at the start and end of the block. Usually, the metadata is not processed when generating HTML output from the .md file. With MkDocs, metadata can be displayed on the page or used to control the page rendering, but only if this is supported by the theme you're using with MkDocs. For more details, checkout the MkDocs documentation . We have to determine what metadata key-value pairs are needed for the blogging capabilities. As mentioned above, we want to have name, GitHub avatar, and link to GitHub profile of the author, as well as publishing date and reading time. Open your .md file and add the following lines: --- author : <Your Name> author_gh_user : <Your GitHub User> read_time : <Reading Time> publish_date : <Date of Publishing> --- It's quite self-explanatory which metadata key-value pairs are responsible for which of the blogging capabilities. You can find more details in step 5 of Overriding the Content Block . The more interesting one is author_gh_user . This value will be used for both getting the author's GitHub avatar and creating a hyperlink to their GitHub profile. Make sure the title is also set in the metadata. Setting the title in the metadata will help position the blogging capabilities in the right place - under the title and before the rest of your blog. --- title : <Your Blog Title> author : <Your Name> author_gh_user : <Your GitHub User> read_time : <Reading Time> publish_date : <Date of Publishing> --- When the title is set in the metadata, use Heading 2 level ( ## This is a heading 2 ) as the highest heading level in your blog. Otherwise, the first Heading 1 you use will overwrite the title from the frontmatter and cause formatting issues. Overriding the Content Block MkDocs supports theme extension out-of-the-box. Material for MkDocs leverages this feature and provides the possibility to override a partial (such as the default header or footer) or a template block. The process is described in detail in the Extending the theme section of the Material for MkDocs documentation. Moreover, Material for MkDocs provides a ready-made content template blog, among others. Overriding Blocks provides the full details about template blogs that are provided by the theme. Since we want to add the blogging capabilities above the content, but just under the title of our blog, we'll have to override the content block. Follow the steps below: Create an overrides directory on the same level where your mkdocs.yml resides. Open your mkdocs.yml and add a reference to the overrides directory using the custom_dir parameter: theme : name : material custom_dir : overrides In the overrides directory, create a new file main.html . Copy the original code of the content block from the source files of Material for MkDocs and paste it in your main.html . Here's the code you need: <!-- Content --> {% block content %} <!-- Edit button --> {% if page.edit_url %} < a href = \"{{ page.edit_url }}\" title = \"{{ lang.t('edit.link.title') }}\" class = \"md-content__button md-icon\" > {% include \".icons/material/pencil.svg\" %} </ a > {% endif %} <!-- Hack: check whether the content contains a h1 headline. If it doesn't, the page title (or respectively site name) is used as the main headline. --> {% if not \"\\x3ch1\" in page.content %} < h1 > {{ page.title | d(config.site_name, true)}} </ h1 > {% endif %} <!-- Markdown content --> {{ page.content }} <!-- Last update of source file --> {% if page and page.meta %} {% if page.meta.git_revision_date_localized or page.meta.revision_date %} {% include \"partials/source-file.html\" %} {% endif %} {% endif %} {% endblock %} Although we're overriding a template block in main.html , the actual code resides in the base.html file that main.html extends. Open base.html in your browser and scroll down to the content block. Under Markdown content , add the custom HTML code we need for the blogging capabilities: <!-- Markdown content --> {% if page and page.meta and page.meta.author_gh_user %} < aside class = \"mdx-author\" > < p > < img src = \"https://avatars.githubusercontent.com/{{ page.meta.author_gh_user }}\" alt = \"@{{ page.meta.author_gh_user }}\" > </ p > < p > < span > < b > {{ page.meta.author }} </ b > \u00b7 < a href = \"https://github.com/{{ page.meta.author_gh_user }}\" > @{{ page.meta.author_gh_user }} </ a > </ span > < span > < svg xmlns = \"http://www.w3.org/2000/svg\" width = \"16\" height = \"16\" fill = \"currentColor\" class = \"bi bi-calendar2\" viewBox = \"0 0 16 16\" > < path d = \"M3.5 0a.5.5 0 0 1 .5.5V1h8V.5a.5.5 0 0 1 1 0V1h1a2 2 0 0 1 2 2v11a2 2 0 0 1-2 2H2a2 2 0 0 1-2-2V3a2 2 0 0 1 2-2h1V.5a.5.5 0 0 1 .5-.5zM2 2a1 1 0 0 0-1 1v11a1 1 0 0 0 1 1h12a1 1 0 0 0 1-1V3a1 1 0 0 0-1-1H2z\" /> < path d = \"M2.5 4a.5.5 0 0 1 .5-.5h10a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5H3a.5.5 0 0 1-.5-.5V4z\" /> </ svg > {{ page.meta.publish_date }} \u00b7 < svg xmlns = \"http://www.w3.org/2000/svg\" width = \"16\" height = \"16\" fill = \"currentColor\" class = \"bi bi-clock\" viewBox = \"0 0 16 16\" > < path d = \"M8 3.5a.5.5 0 0 0-1 0V9a.5.5 0 0 0 .252.434l3.5 2a.5.5 0 0 0 .496-.868L8 8.71V3.5z\" /> < path d = \"M8 16A8 8 0 1 0 8 0a8 8 0 0 0 0 16zm7-8A7 7 0 1 1 1 8a7 7 0 0 1 14 0z\" /> </ svg > {{ page.meta.read_time }} read </ span > </ p > </ aside > {% endif %} {{ page.content }} Kudos to squidfunk for providing the raw code of his own implementation as part of this discussion . By following the steps above, you've already overriden and extended the content block with information about the blog author, publishing date, and reading time. Let's have a closer look at some of the settings: {% if page and page.meta and page.meta.author_gh_user %} ensures that the blogging capabilities will be shown on the page only if the metadata key author_gh_user is defined in the .md file metadata. https://avatars.githubusercontent.com/{{ page.meta.author_gh_user }} is the URL from which the author's avatar is extracted. It uses the author_gh_user value provided in the .md metadata to get the avatar from the author's GitHub profile. {{ page.meta.author }} uses the author value provided in the .md metadata. <a href=\"https://github.com/{{ page.meta.author_gh_user }}\">@{{ page.meta.author_gh_user }}</a> uses the author_gh_user value provided in the .md metadata to create a hyperlink to the author's GitHub profile. the <svg>...</svg> elements provide a calendar and a clock Bootstrap Icons , while {{ page.meta.publish_date }} and {{ page.meta.read_time }} use the publish_date and read_time values, respectively, from the .md metadata. Create a custom stylesheet file ( custom.css ) in the docs/stylesheets directory and add a reference to it in the mkdocs.yml : extra_css : - stylesheets/custom.css Any additional stylesheet files should be placed in a stylesheets directory within your docs folder. For more details, you can refer to Additional CSS . Add the following styles to custom.css : /* Styles for blog-like features - author avatar & name, posting date, min to read, etc. */ . md-typeset . mdx-author img { border-radius : 100 % ; height : 2 rem ; } . md-typeset . mdx-author { display : flex ; font-size : .68 rem ; } . md-typeset . mdx-author p > span { display : block ; } p { display : block ; margin-block-start : 1 em ; margin-block-end : 1 em ; margin-inline-start : 0 px ; margin-inline-end : 0 px ; } . md-typeset . mdx-author p : first-child { flex-shrink : 0 ; margin-right : .8 rem ; } This will provide the desired styling of our blogging capabilities. You can always play with the styles to make them more appealing. That's it. You have enabled blogging capabilities for your Material for MkDocs website. Go ahead and try it out!","title":"Enable Blogging Capabilities with Material for MkDocs"},{"location":"2021/11/2/material-blogging-capabilities/#overview","text":"In this blog, we're going to discuss how to add blogging capabilities to Material for MkDocs . Here's what we refer to as blogging capabilities: author's GitHub avatar, name, and link to GitHub profile a calendar icon with a publishing date next to it a clock icon with a value for time to read next to it You can also see the above mentioned capabilities under the title of this blog. In particular, we'll look at: What kind of metadata key-value pairs you need to define in your .md file and how. How to override a specific block in the main.html file that MkDocs uses as a template when building the HTML output from your .md source, so that the metadata values provided in your .md file are reflected in the HTML output. As a result, a blog author will just have to provide sufficient metadata in the frontmatter of their .md file and data about author, publishing date, and reading time will be displayed as part of their blog. Cool, right? This can also be done manually by including a piece of HTML code in each .md file but we wanted to have everything set up for blog authors in a way that they can focus on the writing itself.","title":"Overview"},{"location":"2021/11/2/material-blogging-capabilities/#adding-metadata-to-your-blog","text":"Metadata about an .md file (also called frontmatter) is declared within a specific block in the beginning of the .md file itself and is denoted by the triple dashes at the start and end of the block. Usually, the metadata is not processed when generating HTML output from the .md file. With MkDocs, metadata can be displayed on the page or used to control the page rendering, but only if this is supported by the theme you're using with MkDocs. For more details, checkout the MkDocs documentation . We have to determine what metadata key-value pairs are needed for the blogging capabilities. As mentioned above, we want to have name, GitHub avatar, and link to GitHub profile of the author, as well as publishing date and reading time. Open your .md file and add the following lines: --- author : <Your Name> author_gh_user : <Your GitHub User> read_time : <Reading Time> publish_date : <Date of Publishing> --- It's quite self-explanatory which metadata key-value pairs are responsible for which of the blogging capabilities. You can find more details in step 5 of Overriding the Content Block . The more interesting one is author_gh_user . This value will be used for both getting the author's GitHub avatar and creating a hyperlink to their GitHub profile. Make sure the title is also set in the metadata. Setting the title in the metadata will help position the blogging capabilities in the right place - under the title and before the rest of your blog. --- title : <Your Blog Title> author : <Your Name> author_gh_user : <Your GitHub User> read_time : <Reading Time> publish_date : <Date of Publishing> --- When the title is set in the metadata, use Heading 2 level ( ## This is a heading 2 ) as the highest heading level in your blog. Otherwise, the first Heading 1 you use will overwrite the title from the frontmatter and cause formatting issues.","title":"Adding Metadata to Your Blog"},{"location":"2021/11/2/material-blogging-capabilities/#overriding-the-content-block","text":"MkDocs supports theme extension out-of-the-box. Material for MkDocs leverages this feature and provides the possibility to override a partial (such as the default header or footer) or a template block. The process is described in detail in the Extending the theme section of the Material for MkDocs documentation. Moreover, Material for MkDocs provides a ready-made content template blog, among others. Overriding Blocks provides the full details about template blogs that are provided by the theme. Since we want to add the blogging capabilities above the content, but just under the title of our blog, we'll have to override the content block. Follow the steps below: Create an overrides directory on the same level where your mkdocs.yml resides. Open your mkdocs.yml and add a reference to the overrides directory using the custom_dir parameter: theme : name : material custom_dir : overrides In the overrides directory, create a new file main.html . Copy the original code of the content block from the source files of Material for MkDocs and paste it in your main.html . Here's the code you need: <!-- Content --> {% block content %} <!-- Edit button --> {% if page.edit_url %} < a href = \"{{ page.edit_url }}\" title = \"{{ lang.t('edit.link.title') }}\" class = \"md-content__button md-icon\" > {% include \".icons/material/pencil.svg\" %} </ a > {% endif %} <!-- Hack: check whether the content contains a h1 headline. If it doesn't, the page title (or respectively site name) is used as the main headline. --> {% if not \"\\x3ch1\" in page.content %} < h1 > {{ page.title | d(config.site_name, true)}} </ h1 > {% endif %} <!-- Markdown content --> {{ page.content }} <!-- Last update of source file --> {% if page and page.meta %} {% if page.meta.git_revision_date_localized or page.meta.revision_date %} {% include \"partials/source-file.html\" %} {% endif %} {% endif %} {% endblock %} Although we're overriding a template block in main.html , the actual code resides in the base.html file that main.html extends. Open base.html in your browser and scroll down to the content block. Under Markdown content , add the custom HTML code we need for the blogging capabilities: <!-- Markdown content --> {% if page and page.meta and page.meta.author_gh_user %} < aside class = \"mdx-author\" > < p > < img src = \"https://avatars.githubusercontent.com/{{ page.meta.author_gh_user }}\" alt = \"@{{ page.meta.author_gh_user }}\" > </ p > < p > < span > < b > {{ page.meta.author }} </ b > \u00b7 < a href = \"https://github.com/{{ page.meta.author_gh_user }}\" > @{{ page.meta.author_gh_user }} </ a > </ span > < span > < svg xmlns = \"http://www.w3.org/2000/svg\" width = \"16\" height = \"16\" fill = \"currentColor\" class = \"bi bi-calendar2\" viewBox = \"0 0 16 16\" > < path d = \"M3.5 0a.5.5 0 0 1 .5.5V1h8V.5a.5.5 0 0 1 1 0V1h1a2 2 0 0 1 2 2v11a2 2 0 0 1-2 2H2a2 2 0 0 1-2-2V3a2 2 0 0 1 2-2h1V.5a.5.5 0 0 1 .5-.5zM2 2a1 1 0 0 0-1 1v11a1 1 0 0 0 1 1h12a1 1 0 0 0 1-1V3a1 1 0 0 0-1-1H2z\" /> < path d = \"M2.5 4a.5.5 0 0 1 .5-.5h10a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5H3a.5.5 0 0 1-.5-.5V4z\" /> </ svg > {{ page.meta.publish_date }} \u00b7 < svg xmlns = \"http://www.w3.org/2000/svg\" width = \"16\" height = \"16\" fill = \"currentColor\" class = \"bi bi-clock\" viewBox = \"0 0 16 16\" > < path d = \"M8 3.5a.5.5 0 0 0-1 0V9a.5.5 0 0 0 .252.434l3.5 2a.5.5 0 0 0 .496-.868L8 8.71V3.5z\" /> < path d = \"M8 16A8 8 0 1 0 8 0a8 8 0 0 0 0 16zm7-8A7 7 0 1 1 1 8a7 7 0 0 1 14 0z\" /> </ svg > {{ page.meta.read_time }} read </ span > </ p > </ aside > {% endif %} {{ page.content }} Kudos to squidfunk for providing the raw code of his own implementation as part of this discussion . By following the steps above, you've already overriden and extended the content block with information about the blog author, publishing date, and reading time. Let's have a closer look at some of the settings: {% if page and page.meta and page.meta.author_gh_user %} ensures that the blogging capabilities will be shown on the page only if the metadata key author_gh_user is defined in the .md file metadata. https://avatars.githubusercontent.com/{{ page.meta.author_gh_user }} is the URL from which the author's avatar is extracted. It uses the author_gh_user value provided in the .md metadata to get the avatar from the author's GitHub profile. {{ page.meta.author }} uses the author value provided in the .md metadata. <a href=\"https://github.com/{{ page.meta.author_gh_user }}\">@{{ page.meta.author_gh_user }}</a> uses the author_gh_user value provided in the .md metadata to create a hyperlink to the author's GitHub profile. the <svg>...</svg> elements provide a calendar and a clock Bootstrap Icons , while {{ page.meta.publish_date }} and {{ page.meta.read_time }} use the publish_date and read_time values, respectively, from the .md metadata. Create a custom stylesheet file ( custom.css ) in the docs/stylesheets directory and add a reference to it in the mkdocs.yml : extra_css : - stylesheets/custom.css Any additional stylesheet files should be placed in a stylesheets directory within your docs folder. For more details, you can refer to Additional CSS . Add the following styles to custom.css : /* Styles for blog-like features - author avatar & name, posting date, min to read, etc. */ . md-typeset . mdx-author img { border-radius : 100 % ; height : 2 rem ; } . md-typeset . mdx-author { display : flex ; font-size : .68 rem ; } . md-typeset . mdx-author p > span { display : block ; } p { display : block ; margin-block-start : 1 em ; margin-block-end : 1 em ; margin-inline-start : 0 px ; margin-inline-end : 0 px ; } . md-typeset . mdx-author p : first-child { flex-shrink : 0 ; margin-right : .8 rem ; } This will provide the desired styling of our blogging capabilities. You can always play with the styles to make them more appealing. That's it. You have enabled blogging capabilities for your Material for MkDocs website. Go ahead and try it out!","title":"Overriding the Content Block"},{"location":"2022/01/14/dirigible-vscode-theia-custom-editors/","text":"Recently, I was tasked with porting an extension from Eclipse Dirigible to VS Code and Eclipse Theia. During that process, I found some interesting things about how those products work and their design choices, which inspired this short blog post. I will try to explain the main differences between them from the point of view of an extension developer. This will not be a tutorial on how to make extensions, instead it will be more focused on overall design differences between the IDEs (Integrated Development Environment). What are they? First, let me give you a brief introduction to what each of those products are and what they are best suited for. Eclipse Dirigible This is a cloud development environment, featuring a low-code platform for rapid development of business applications, while also providing a runtime. It is best suited for people who need a cloud IDE (Integrated Development Environment), which focuses on JavaScript development with the ability to connect to databases such as SAP HANA and PostgreSQL. Visual Studio Code (VS Code) This one is quite popular and does not need much of an introduction. It is a desktop-focused code editor, which can also run in the cloud. It is best suited for people who need a general-purpose IDE with a clean and simple UI (User Interface). Eclipse Theia Eclipse Theia is a cloud and desktop IDE framework. Its primary aim is to be a modular, vendor-agnostic version of VS Code. It is not a fork or a one-to-one copy of VS Code but it is API (Application Programming Interface) compatible with it and shares a lot of its components. While it can be used as an IDE, it is an IDE framework which means that it is used as a base for creating other IDEs. It is best suited for people who need to develop their own custom IDE, without reinventing the wheel. One extension to rule them all \u201cExtension\u201d is the official name used by VS Code. In Dirigible, the same thing is referred to as a \u201cmodule\u201d. The equivalent in Theia is called \u201cplug-in\u201d. All three platforms are built using web technologies such as HTML, CSS and JavaScript, so my initial reaction was that I could take the Dirigible module and make it run in the other two by making some minor changes. I tested that hypothesis, and while it can be achieved by making some sacrifices, I would not recommend it. Here is a screenshot of my attempt at running an unmodified Dirigible module inside a VS Code extension serving as a container: It does run but the first and most obvious problem is that the user interface does not react to the theme selected in VS Code. This makes the extension feel very out of place. Another problem I encountered is that input fields created by Dirigible\u2019s UI framework disable the save action in VS Code, when focused. This is probably caused by the input field model in AngularJS, but I did not spend too much time trying to figure it out. After seeing those problems, I decided that the best way to go about this is to have two separate extensions. One for Dirigible and one for the other two. Theia and other editors based on Theia are, as I said, API compatible with VS Code, so from an extension point of view they are the same. This reduces the maintenance burden significantly. Something to note here is that Theia has something called \u201cextensions\u201d, but they are not the same thing as the extensions found in VS Code and I will not be talking about them as they serve a different use case. As mentioned earlier, in Theia, VS Code extensions are referred to as \u201cplug-ins\u201d. Dirigible view modules and theming Every view module in Dirigible has a few basic components. Each view is contained in its own iframe window. For the view itself, Dirigible provides its own version of Bootstrap as a CSS framework combined with AngularJS as a front-end framework. This means that Dirigible provides ready-to-use widgets and a developer can quickly create a view module. Those components, however, are not mandatory. If developers want to, they can use their own framework and make the UI however they like. Everything is permitted as long as it is contained inside the iframe of the view. Theming in Dirigible is done by having each theme implement its own colors, fonts and widget sizes, in its own CSS file, packaged inside a theme module. The only rule is that CSS classes and IDs must have the same names as the default theme . When a view requests the IDE stylesheet, the back end responds with the CSS file of the currently selected theme. This means that a view is never aware of what theme is being used . Currently, this is being reworked as we move away from Bootstrap and adopt the \u201cfundamental-styles\u201d open-source project initiated by SAP. Modules can communicate with other modules by making use of something called MessageHub. It is an abstraction layer for the \u2018postMessage\u2019 publisher-subscriber system found in every major browser. When communicating with the back end , modules use the Dirigible RESTful API. View modules are stateful , meaning that if they are created and active, they will not lose their state even if the user moves their focus to a different view in another tab and they will not have to be redrawn when focus is returned to them. Developing an extension in Dirigible In Dirigible, modules are dynamically loaded. You just create a normal project, then create a project.json file which points to the folder containing the module and Dirigible will detect and load it based on its content. No special development host is needed. When you make a change, all you must do is refresh the view. This allows for rapid development but depending on what view you are working on, it could also mean that it can stop Dirigible from rendering its UI when there is a significant problem with the view. If you want to see examples of Dirigible views and more detailed information, you can take a look at the following GitHub repository: https://github.com/dirigiblelabs/sample-ide-perspective . Custom editors in Dirigible When you create a custom editor in Dirigible, your communication with the back end must be kept to a minimum . After all, Dirigible is a cloud IDE and frequent requests can lead to a bad user experience. When a user opens a file, the editor receives the contents of the file from the back end and all editing and unsaved changes are done and saved on the client machine. When editing is done and the user saves the file, its contents are sent to the back end, where the old file will be replaced. Dirigible does not provide a universal API to create a custom editor. At least not yet. This means that functionalities such as undo and redo have to be implemented by the custom editor itself. Theia/VS Code extensions and theming In VS Code, and therefore Theia, extensions are done in a very different way . In fact, it\u2019s almost the exact opposite of Dirigible. Most extensions do not create their own UI. Instead, they use the VS Code API which creates the UI for them, which limits where the extension can be shown and what the UI can do. Most extensions are small add-ons to the status, activity, or side bar. If your extension is more advanced, like a custom file editor, or you need more visual space and a custom UI, your only option is to use something called WebViews . This splits the extension into two parts. Front end and back end. Like in Dirigible, WebViews are iframes but have some strict content policies applied to them. At the time of writing, there is no UI framework provided by VS Code that you can use, so it is only plain HTML and CSS. The only thing you will have as a helping hand are the default VS Code colors in the form of CSS variables, which will be injected into your WebView. Technically speaking, you can use Angular or React but as I said, WebViews have some strict content policies, so they do not fully work out-of-the-box . This makes WebView extensions inconsistent and hard to implement, especially if you want your extensions to look at home inside the IDE. There has been some recent work on developing an official UI Toolkit but at the time of writing, it is just a public preview. The back-end part of the extension communicates with the front end using the WebView API which looks and feels very similar to MessageHub. WebViews are also stateless . This means that once a user focuses on another editor and the WebView is no longer visible, its UI is destroyed. When a user focuses back, the UI is created again. This happens even if there are unsaved changes. To not lose those changes, you can use the WebView state API which stores a JavaScript object describing the last known state of the WebView. There is an option which you can enable, that will make your WebView stateful like in Dirigible, but it is not recommended as there are some performance penalties and should be used only if there is no other option. Finally, WebViews are aware of themes. The colors from the current theme are injected into the WebView and your body element will have a special CSS class assigned to it, which will tell you if the theme is dark or light. Most of the time, your UI will work without problems regardless of themes, but in some small edge cases, you may need to implement special rules based on the theme selected. Developing an extension in Theia/VS Code Extensions in VS Code and Theia are not loaded dynamically , at least not in the same way they are in Dirigible. When developing an extension, before you could test it, you must compile it first, then start something called an \u201cExtension Development Host\u201d. It is a special instance of the IDE that runs your extension. Every time you make a change, you must recompile and restart the development host . It does not take a lot of time, but it is something that slows you down. On the plus side, if there is something very wrong with your extension, it will not affect the non-development host. Custom editors in Theia/VS Code In the case of a custom editor, when a user opens a file, the back end sends the file contents to the front end and every change, no matter small or big, must be send back. Once the file is saved, it is again sent to the front end, which is redrawn. This means that unlike Dirigible, actual editing and all unsaved changes take place in the back end back-end front end just displays its current state . VS Code also provides a custom editor API, simplifying the process. Functionalities such as save, undo, and redo are handled by the IDE. That being said, the developer (or developers) can create their own editor API from scratch if they need to. Summary To summarize everything, VS Code and Theia have a different design from Dirigible. VS Code can be a bit more intimidating in the beginning and has a steep learning curve but once you get the hang of it, it is quite easy to develop extensions for it. The biggest problem it has is that it does not have a proper UI framework. Dirigible is easier to start with, loads modules dynamically and has a proper UI framework, but lacks more advanced APIs and you may end up having to write your own functionality for certain things. As I said in the beginning of this post, you can make Dirigible modules run inside VS Code and Theia, but you will be making some sacrifices. The maintenance burden will be bigger, and you may encounter some unexpected bugs. If you need to make an extension which supports all three, make one for Dirigible and one for the other two. It will take more time when starting out, but it will prove to be the better choice in the long run. The main question, of course, is do you really need to support all three? In fact, VS Code and Theia target efficient coding experience, while Dirigible is focused on RAD/LCNC tooling, so depending on your scenario you can choose one of these complementary frameworks as a basis for your tooling.","title":"Eclipse Dirigible vs Visual Studio Code vs Eclipse Theia - Custom Editors"},{"location":"2022/01/14/dirigible-vscode-theia-custom-editors/#what-are-they","text":"First, let me give you a brief introduction to what each of those products are and what they are best suited for.","title":"What are they?"},{"location":"2022/01/14/dirigible-vscode-theia-custom-editors/#eclipse-dirigible","text":"This is a cloud development environment, featuring a low-code platform for rapid development of business applications, while also providing a runtime. It is best suited for people who need a cloud IDE (Integrated Development Environment), which focuses on JavaScript development with the ability to connect to databases such as SAP HANA and PostgreSQL.","title":"Eclipse Dirigible"},{"location":"2022/01/14/dirigible-vscode-theia-custom-editors/#visual-studio-code-vs-code","text":"This one is quite popular and does not need much of an introduction. It is a desktop-focused code editor, which can also run in the cloud. It is best suited for people who need a general-purpose IDE with a clean and simple UI (User Interface).","title":"Visual Studio Code (VS Code)"},{"location":"2022/01/14/dirigible-vscode-theia-custom-editors/#eclipse-theia","text":"Eclipse Theia is a cloud and desktop IDE framework. Its primary aim is to be a modular, vendor-agnostic version of VS Code. It is not a fork or a one-to-one copy of VS Code but it is API (Application Programming Interface) compatible with it and shares a lot of its components. While it can be used as an IDE, it is an IDE framework which means that it is used as a base for creating other IDEs. It is best suited for people who need to develop their own custom IDE, without reinventing the wheel.","title":"Eclipse Theia"},{"location":"2022/01/14/dirigible-vscode-theia-custom-editors/#one-extension-to-rule-them-all","text":"\u201cExtension\u201d is the official name used by VS Code. In Dirigible, the same thing is referred to as a \u201cmodule\u201d. The equivalent in Theia is called \u201cplug-in\u201d. All three platforms are built using web technologies such as HTML, CSS and JavaScript, so my initial reaction was that I could take the Dirigible module and make it run in the other two by making some minor changes. I tested that hypothesis, and while it can be achieved by making some sacrifices, I would not recommend it. Here is a screenshot of my attempt at running an unmodified Dirigible module inside a VS Code extension serving as a container: It does run but the first and most obvious problem is that the user interface does not react to the theme selected in VS Code. This makes the extension feel very out of place. Another problem I encountered is that input fields created by Dirigible\u2019s UI framework disable the save action in VS Code, when focused. This is probably caused by the input field model in AngularJS, but I did not spend too much time trying to figure it out. After seeing those problems, I decided that the best way to go about this is to have two separate extensions. One for Dirigible and one for the other two. Theia and other editors based on Theia are, as I said, API compatible with VS Code, so from an extension point of view they are the same. This reduces the maintenance burden significantly. Something to note here is that Theia has something called \u201cextensions\u201d, but they are not the same thing as the extensions found in VS Code and I will not be talking about them as they serve a different use case. As mentioned earlier, in Theia, VS Code extensions are referred to as \u201cplug-ins\u201d.","title":"One extension to rule them all"},{"location":"2022/01/14/dirigible-vscode-theia-custom-editors/#dirigible-view-modules-and-theming","text":"Every view module in Dirigible has a few basic components. Each view is contained in its own iframe window. For the view itself, Dirigible provides its own version of Bootstrap as a CSS framework combined with AngularJS as a front-end framework. This means that Dirigible provides ready-to-use widgets and a developer can quickly create a view module. Those components, however, are not mandatory. If developers want to, they can use their own framework and make the UI however they like. Everything is permitted as long as it is contained inside the iframe of the view. Theming in Dirigible is done by having each theme implement its own colors, fonts and widget sizes, in its own CSS file, packaged inside a theme module. The only rule is that CSS classes and IDs must have the same names as the default theme . When a view requests the IDE stylesheet, the back end responds with the CSS file of the currently selected theme. This means that a view is never aware of what theme is being used . Currently, this is being reworked as we move away from Bootstrap and adopt the \u201cfundamental-styles\u201d open-source project initiated by SAP. Modules can communicate with other modules by making use of something called MessageHub. It is an abstraction layer for the \u2018postMessage\u2019 publisher-subscriber system found in every major browser. When communicating with the back end , modules use the Dirigible RESTful API. View modules are stateful , meaning that if they are created and active, they will not lose their state even if the user moves their focus to a different view in another tab and they will not have to be redrawn when focus is returned to them.","title":"Dirigible view modules and theming"},{"location":"2022/01/14/dirigible-vscode-theia-custom-editors/#developing-an-extension-in-dirigible","text":"In Dirigible, modules are dynamically loaded. You just create a normal project, then create a project.json file which points to the folder containing the module and Dirigible will detect and load it based on its content. No special development host is needed. When you make a change, all you must do is refresh the view. This allows for rapid development but depending on what view you are working on, it could also mean that it can stop Dirigible from rendering its UI when there is a significant problem with the view. If you want to see examples of Dirigible views and more detailed information, you can take a look at the following GitHub repository: https://github.com/dirigiblelabs/sample-ide-perspective .","title":"Developing an extension in Dirigible"},{"location":"2022/01/14/dirigible-vscode-theia-custom-editors/#custom-editors-in-dirigible","text":"When you create a custom editor in Dirigible, your communication with the back end must be kept to a minimum . After all, Dirigible is a cloud IDE and frequent requests can lead to a bad user experience. When a user opens a file, the editor receives the contents of the file from the back end and all editing and unsaved changes are done and saved on the client machine. When editing is done and the user saves the file, its contents are sent to the back end, where the old file will be replaced. Dirigible does not provide a universal API to create a custom editor. At least not yet. This means that functionalities such as undo and redo have to be implemented by the custom editor itself.","title":"Custom editors in Dirigible"},{"location":"2022/01/14/dirigible-vscode-theia-custom-editors/#theiavs-code-extensions-and-theming","text":"In VS Code, and therefore Theia, extensions are done in a very different way . In fact, it\u2019s almost the exact opposite of Dirigible. Most extensions do not create their own UI. Instead, they use the VS Code API which creates the UI for them, which limits where the extension can be shown and what the UI can do. Most extensions are small add-ons to the status, activity, or side bar. If your extension is more advanced, like a custom file editor, or you need more visual space and a custom UI, your only option is to use something called WebViews . This splits the extension into two parts. Front end and back end. Like in Dirigible, WebViews are iframes but have some strict content policies applied to them. At the time of writing, there is no UI framework provided by VS Code that you can use, so it is only plain HTML and CSS. The only thing you will have as a helping hand are the default VS Code colors in the form of CSS variables, which will be injected into your WebView. Technically speaking, you can use Angular or React but as I said, WebViews have some strict content policies, so they do not fully work out-of-the-box . This makes WebView extensions inconsistent and hard to implement, especially if you want your extensions to look at home inside the IDE. There has been some recent work on developing an official UI Toolkit but at the time of writing, it is just a public preview. The back-end part of the extension communicates with the front end using the WebView API which looks and feels very similar to MessageHub. WebViews are also stateless . This means that once a user focuses on another editor and the WebView is no longer visible, its UI is destroyed. When a user focuses back, the UI is created again. This happens even if there are unsaved changes. To not lose those changes, you can use the WebView state API which stores a JavaScript object describing the last known state of the WebView. There is an option which you can enable, that will make your WebView stateful like in Dirigible, but it is not recommended as there are some performance penalties and should be used only if there is no other option. Finally, WebViews are aware of themes. The colors from the current theme are injected into the WebView and your body element will have a special CSS class assigned to it, which will tell you if the theme is dark or light. Most of the time, your UI will work without problems regardless of themes, but in some small edge cases, you may need to implement special rules based on the theme selected.","title":"Theia/VS Code extensions and theming"},{"location":"2022/01/14/dirigible-vscode-theia-custom-editors/#developing-an-extension-in-theiavs-code","text":"Extensions in VS Code and Theia are not loaded dynamically , at least not in the same way they are in Dirigible. When developing an extension, before you could test it, you must compile it first, then start something called an \u201cExtension Development Host\u201d. It is a special instance of the IDE that runs your extension. Every time you make a change, you must recompile and restart the development host . It does not take a lot of time, but it is something that slows you down. On the plus side, if there is something very wrong with your extension, it will not affect the non-development host.","title":"Developing an extension in Theia/VS Code"},{"location":"2022/01/14/dirigible-vscode-theia-custom-editors/#custom-editors-in-theiavs-code","text":"In the case of a custom editor, when a user opens a file, the back end sends the file contents to the front end and every change, no matter small or big, must be send back. Once the file is saved, it is again sent to the front end, which is redrawn. This means that unlike Dirigible, actual editing and all unsaved changes take place in the back end back-end front end just displays its current state . VS Code also provides a custom editor API, simplifying the process. Functionalities such as save, undo, and redo are handled by the IDE. That being said, the developer (or developers) can create their own editor API from scratch if they need to.","title":"Custom editors in Theia/VS Code"},{"location":"2022/01/14/dirigible-vscode-theia-custom-editors/#summary","text":"To summarize everything, VS Code and Theia have a different design from Dirigible. VS Code can be a bit more intimidating in the beginning and has a steep learning curve but once you get the hang of it, it is quite easy to develop extensions for it. The biggest problem it has is that it does not have a proper UI framework. Dirigible is easier to start with, loads modules dynamically and has a proper UI framework, but lacks more advanced APIs and you may end up having to write your own functionality for certain things. As I said in the beginning of this post, you can make Dirigible modules run inside VS Code and Theia, but you will be making some sacrifices. The maintenance burden will be bigger, and you may encounter some unexpected bugs. If you need to make an extension which supports all three, make one for Dirigible and one for the other two. It will take more time when starting out, but it will prove to be the better choice in the long run. The main question, of course, is do you really need to support all three? In fact, VS Code and Theia target efficient coding experience, while Dirigible is focused on RAD/LCNC tooling, so depending on your scenario you can choose one of these complementary frameworks as a basis for your tooling.","title":"Summary"},{"location":"2022/02/13/news-new-release-6-2/","text":"New version 6.2 has been released. Release is of Type A Features Add ability to customize the generated SQL for OData Update Tomcat version Replace status labels inside ide-problems with icons Problems - Cause to be expanded on click Problems - Location to be clickable Add extension for ESM services Introduce Artefact State Metadata JSDoc comments in *d.ts files Introduce corresponding types for the supported artefacts Keycloak integration on trial Adopt latest monaco version Update acorn.js version in ide-monaco and specify ECMA version on parse Add loading overview when loading or saving files Format code automatically when save action is triggered Enable css formatting in editor DAO - create table in SystemDB Update kubernetes version for Trial CSVIM Synchronizer Show modified lines in the editor Make Monaco show the difference between commited and modified files in edit mode Add option for creating a new csvim file Hide technical implementation details CLI package for test purposes Eclipse Vert.x package to be provided XSOdata files not loaded in Preview view Implement GraalVM file system for ES6 modules resolution Add Monaco editor support for ES6 modules Add .d.ts files for each Dirigible JS API Loading indicator Safety closing connections opened from user code XSK Web IDE and Runtime Hangs Expose Git API Fix the logs location in the Docker deployments Incorrect Content Encoding header User schema search for DB artefacts Extension points for custom Publish handlers Support for transaction handling in SQL Processor Batch support for OData Sorting with pagination and expand not working ide-bpm does not have modules.json and could not be imported with the ESM syntax Mail configuration provider Improve ZIP Import REST API functionality Option to publish/unpublish file selection Make all editors take advantage of the new frame parameter functionality OpenAPI descriptors collector service Ordered Synchronizer Disable cache by default, except for Runtime distributions Documentation and Samples Sample for *.changelog integration Exec API Database Perspective Perspective Git API Docker/Helm - Security Report Overwrite images is not working Fixes CSV path in CSVIM files should not contain the workspace name Make 'workspace' the default workspace CSVIM does not select the current workspace Error handling and proper alerts Alerts not working Delete file to close editor tab Not showing local or remote branches Preview downloads files .hdbtable indeces type in not taken into account .hdbtable tableType is not taken into account Console view not working locally in Safari BPMN Modeller has to use older version of AngularJS Can't close welcome screen Cut operation in workbench is crashing the whole IDE Monaco not formatting HTML correctly Roles editor writes $$hashKey to json on save ES6 Truffle File System has wrong handling of paths on windows DAO - Insert into table fails \"command + x\" is not executing all or selected sql statements XML files are not formatted Navigation to calculation view end up in SQL error Multiple CWE-200 vulnerabilities Errors about missing favicons Disabled SCE causing a cross-site scripting vulnerability Incorrect property metadata Replace var with let/const Add d.ts files for ext-modules Synonym target objects search now works only with a given schema Some files don't have an 'Open' option on right click Check internal dirigible reference dependency versions Git facade is not included in the API JavaScript maven group Parent stack objects not visible Git - Default branch when cloning is expected to be \"master\", clone fails if it is \"main\" OData for table synonyms doesn't work Debugger is not working locally Git - Unstaged files are tracked per push attempt, not per successful push CSVIM Editor not opening csv files in the csv editor Nested expand not working Debugger - JS files debugging is weird Configuration credentials logged XSJS service NPE through Postman Minor fixes Statistics 69K+ Users 99K+ Sessions 188 Countries 462 Repositories in DirigibleLabs Operational Available packages for download - https://github.com/eclipse/dirigible/releases/tag/v6.2.0 Docker images at Docker Hub under DirigibleLabs organization: https://hub.docker.com/u/dirigiblelabs/ Maven Central artifacts by org.eclipse.dirigible namespace: https://search.maven.org/search?q=org.eclipse.dirigible The full list of bug-fixes and enhancements can be found here: https://github.com/eclipse/dirigible/milestone/51?closed=1 The source code is available at GitHub repository here: https://github.com/eclipse/dirigible/tree/6.2.0 The instant trial is updated accordingly with the released version here: http://trial.dirigible.io Enjoy!","title":"Release 6.2"},{"location":"2022/02/13/news-new-release-6-2/#features","text":"Add ability to customize the generated SQL for OData Update Tomcat version Replace status labels inside ide-problems with icons Problems - Cause to be expanded on click Problems - Location to be clickable Add extension for ESM services Introduce Artefact State Metadata JSDoc comments in *d.ts files Introduce corresponding types for the supported artefacts Keycloak integration on trial Adopt latest monaco version Update acorn.js version in ide-monaco and specify ECMA version on parse Add loading overview when loading or saving files Format code automatically when save action is triggered Enable css formatting in editor DAO - create table in SystemDB Update kubernetes version for Trial CSVIM Synchronizer Show modified lines in the editor Make Monaco show the difference between commited and modified files in edit mode Add option for creating a new csvim file Hide technical implementation details CLI package for test purposes Eclipse Vert.x package to be provided XSOdata files not loaded in Preview view Implement GraalVM file system for ES6 modules resolution Add Monaco editor support for ES6 modules Add .d.ts files for each Dirigible JS API Loading indicator Safety closing connections opened from user code XSK Web IDE and Runtime Hangs Expose Git API Fix the logs location in the Docker deployments Incorrect Content Encoding header User schema search for DB artefacts Extension points for custom Publish handlers Support for transaction handling in SQL Processor Batch support for OData Sorting with pagination and expand not working ide-bpm does not have modules.json and could not be imported with the ESM syntax Mail configuration provider Improve ZIP Import REST API functionality Option to publish/unpublish file selection Make all editors take advantage of the new frame parameter functionality OpenAPI descriptors collector service Ordered Synchronizer Disable cache by default, except for Runtime distributions","title":"Features"},{"location":"2022/02/13/news-new-release-6-2/#documentation-and-samples","text":"Sample for *.changelog integration Exec API Database Perspective Perspective Git API Docker/Helm - Security Report Overwrite images is not working","title":"Documentation and Samples"},{"location":"2022/02/13/news-new-release-6-2/#fixes","text":"CSV path in CSVIM files should not contain the workspace name Make 'workspace' the default workspace CSVIM does not select the current workspace Error handling and proper alerts Alerts not working Delete file to close editor tab Not showing local or remote branches Preview downloads files .hdbtable indeces type in not taken into account .hdbtable tableType is not taken into account Console view not working locally in Safari BPMN Modeller has to use older version of AngularJS Can't close welcome screen Cut operation in workbench is crashing the whole IDE Monaco not formatting HTML correctly Roles editor writes $$hashKey to json on save ES6 Truffle File System has wrong handling of paths on windows DAO - Insert into table fails \"command + x\" is not executing all or selected sql statements XML files are not formatted Navigation to calculation view end up in SQL error Multiple CWE-200 vulnerabilities Errors about missing favicons Disabled SCE causing a cross-site scripting vulnerability Incorrect property metadata Replace var with let/const Add d.ts files for ext-modules Synonym target objects search now works only with a given schema Some files don't have an 'Open' option on right click Check internal dirigible reference dependency versions Git facade is not included in the API JavaScript maven group Parent stack objects not visible Git - Default branch when cloning is expected to be \"master\", clone fails if it is \"main\" OData for table synonyms doesn't work Debugger is not working locally Git - Unstaged files are tracked per push attempt, not per successful push CSVIM Editor not opening csv files in the csv editor Nested expand not working Debugger - JS files debugging is weird Configuration credentials logged XSJS service NPE through Postman Minor fixes","title":"Fixes"},{"location":"2022/02/13/news-new-release-6-2/#statistics","text":"69K+ Users 99K+ Sessions 188 Countries 462 Repositories in DirigibleLabs","title":"Statistics"},{"location":"2022/02/13/news-new-release-6-2/#operational","text":"Available packages for download - https://github.com/eclipse/dirigible/releases/tag/v6.2.0 Docker images at Docker Hub under DirigibleLabs organization: https://hub.docker.com/u/dirigiblelabs/ Maven Central artifacts by org.eclipse.dirigible namespace: https://search.maven.org/search?q=org.eclipse.dirigible The full list of bug-fixes and enhancements can be found here: https://github.com/eclipse/dirigible/milestone/51?closed=1 The source code is available at GitHub repository here: https://github.com/eclipse/dirigible/tree/6.2.0 The instant trial is updated accordingly with the released version here: http://trial.dirigible.io","title":"Operational"},{"location":"2022/02/13/news-new-release-6-2/#enjoy","text":"","title":"Enjoy!"},{"location":"2022/08/10/gcp-gke-dns-istio-letsencrypt-postgresql-keycloak/","text":"Overview In this article we are going to setup a custom domain for a Dirigible application in a GKE cluster with GCP Cloud DNS , GCP Cloud SQL Postgre , Istio , Let's Encrypt , Keycloak . Components: Kubernetes GCP Cloud DNS GCP Cloud SQL Postgre Istio Let's Encrypt Cert-manager Keycloak Overview Kubernetes is an open-source system for automating deployment, scaling, and management of containerized applications in a cluster environment. You can read more about Kubernetes at www.kubernetes.io . Overview Reliable, resilient, low-latency DNS serving from Google's worldwide network provides you with everything you need to register, manage, and serve your domains. For more information, see Cloud DNS . Overview Fully managed relational database service for MySQL, PostgreSQL, and SQL Server with rich extension collections, configuration flags, and developer ecosystems. For more information, see GCP Cloud SQL Postgreere . Overview Istio is an open-source service mesh that layers transparently onto existing distributed applications. Istio\u2019s powerful features provide a uniform and more efficient way to secure, connect, and monitor services. For more information, see Istio . Overview Istio is an open-source service mesh that layers transparently onto existing distributed applications. Istio\u2019s powerful features provide a uniform and more efficient way to secure, connect, and monitor services. For more information, see Let's Encrypt . Overview Cert-manager is a powerful and extensible X.509 certificate controller for Kubernetes and OpenShift workloads. It will obtain certificates from a variety of Issuers, both popular public Issuers as well as private Issuers, and ensure the certificates are valid and up-to-date, and will attempt to renew certificates at a configured time before expiry. For more information, see Cert-manager . Overview Keycloak is an open source Identity and Access Management system for applications and services.For more information, see Keycloak . Prerequisites In this article, we assume that you already have a GCP account and added billing account. GKE Cluster Configuration Prerequisites Install the gcloud CLI Install kubectl and configure cluster access Install Helm Create project Go to create your project . Set name, organization and billing account. Enable Engine API To be able to create a cluster, we need to enable Kubernetes Api. Go to enable Kubernetes API Create GKE cluster You can create standard and an autopilot cluster. In ths article, we will create the standard cluster. At this time you have two options to create a cluster: manually or by Use a setup guide . Manually Use a setup guide In this article we will use a setup guide and cost-optimized cluster . Choose a suitable location and name your cluster. Set a release channel. We are going to set Regular channel . This version have passed internal validation and are considered production-quality. Choose a cluster size. In this article we are going to keep the default size. Verify the machine type. Advanced settings: In this article we will use Optimize utilization . Prioritize optimizing utilization over keeping spare resources in the cluster. When selected, the cluster autoscaler scales down the cluster more aggressively: it can remove more nodes, and remove nodes faster. For cluster autoscaler you can configure how many maximum nodes to scale. It depends on your requirements. For this article we are going to keep this configuration maximum nodes 3 . Vertical Pod Autoscaling will ensure that the pods will be deployed on the right node. Configure usage metering. In this article we are not using metering. Enable Workload Identity We need a workload identity to allow our Dirigible pod to access PostgreSQL. Cluster Workload Identity Node Workload Identity Istio Configuration Note In this article we will configure istioctl to use the configmaps from the 1-14-3 revision. We can run multiple versions of Istio concurrently and can specify exactly which revision gets applied in the tooling. Initialize or reinitialize gcloud - check this url for more information. gcloud init Enable the specific GKE cluster as the default cluster to be used for the remaining commands. Note You need to replace dirigible with your cluster name and europe-north1-a with your region . gcloud container clusters get-credentials dirigible \\ --region europe-north1-a Create istio-system namespace and add label istio-injection. kubectl create namespace istio-system kubectl label namespace istio-system istio-injection=enabled --overwrite Create Istio control plane service istiod. kubectl apply -f - <<EOF apiVersion : v1 kind : Service metadata : labels : app : istiod istio : pilot release : istio name : istiod namespace : istio-system spec : type : ClusterIP ports : - name : grpc-xds port : 15010 - name : https-dns port : 15012 - name : https-webhook port : 443 targetPort : 15017 - name : http-monitoring port : 15014 selector : app : istiod EOF Install minimal control plane. istioctl install -y -n istio-system --revision 1-14-3 -f - <<EOF apiVersion : install.istio.io/v1alpha1 kind : IstioOperator metadata : name : control-plane spec : profile : minimal values : gateways : istio-ingressgateway : autoscaleEnabled : true components : pilot : k8s : env : - name : PILOT_FILTER_GATEWAY_CLUSTER_CONFIG value : \"true\" meshConfig : defaultConfig : proxyMetadata : ISTIO_META_DNS_CAPTURE : \"true\" enablePrometheusMerge : true EOF Enable the istio-ingressgateway component. Install the istio-ingress gateway in a namespace that is different from istiod and add the istio-injection tag. kubectl create namespace istio-ingress kubectl label namespace istio-ingress istio-injection=enabled --overwrite Install it with a revision that matches the control plane in the istio-system namespace. istioctl install -y -n istio-ingress --revision 1-14-3 -f - <<EOF apiVersion : install.istio.io/v1alpha1 kind : IstioOperator metadata : name : istio-ingress-gw-install spec : profile : empty values : gateways : istio-ingressgateway : autoscaleEnabled : true components : ingressGateways : - name : istio-ingressgateway namespace : istio-ingress enabled : true k8s : overlays : - apiVersion : apps/v1 kind : Deployment name : istio-ingressgateway patches : - path : spec.template.spec.containers[name:istio-proxy].lifecycle value : preStop : exec : command : [ \"sh\" , \"-c\" , \"sleep 5\" ] EOF Apply Strict mTLS Encrypt the traffic between services in the mesh with mutual TLS. kubectl apply --namespace istio-system -f - <<EOF apiVersion : security.istio.io/v1beta1 kind : PeerAuthentication metadata : name : default spec : mtls : mode : STRICT EOF GCP Cloud DNS Configuration Enable Cloud DNS API. Go to page and choose Enable to enable the API. Create Cloud DNS Zone. Go to page Copy the generated DNS name servers for your zone and add them to your domain, if your control is not in Google Clod DNS. The generated DNS name servers should look like this: ns-cloud-e1.googledomains.com. ns-cloud-e2.googledomains.com. ns-cloud-e3.googledomains.com. ns-cloud-e4.googledomains.com. Create an A record for Dirigible and Keycloak. We need Istio Gateway IP . kubectl get svc -n istio-ingress istio-ingressgateway -o jsonpath=\"{.status.loadBalancer.ingress[0].ip}\" A static external IP address is the IP address that is reserved for your project until you decide to release it. You need to create the IP address in your region. gcloud compute addresses create demo --addresses=<YOUR-GATEWAY-IP> \\ --region=europe-north1 Set the IP for Dirigible. Set the IP for Keycloak. Let's Encrypt Configuration Install Cert-manager. Check for last version Add cert-manager helm repo. helm repo add jetstack https://charts.jetstack.io helm repo update Install Cert-Manager. helm install \\ cert-manager jetstack/cert-manager \\ --namespace cert-manager \\ --create-namespace \\ --version v1.9.1 \\ --set installCRDs=true Create ClusterIssuer. Note You need to replace <YOUR-EMAIL-ADDRESS> with your valid email address. kubectl apply -f - <<EOF apiVersion : cert-manager.io/v1 kind : ClusterIssuer metadata : name : letsencrypt namespace : cert-manager spec : acme : server : https://acme-v02.api.letsencrypt.org/directory email : <YOUR-EMAIL-ADDRESS> privateKeySecretRef : name : letsencrypt solvers : - selector : {} http01 : ingress : class : istio EOF GCP Cloud SQL Postgre Configuration Enable Cloud SQL API and create an instance. Go to page Enable Cloud SQL Admin API. Go to page Choose PostgreSQL database engine. Note For this article we will create separate instances for Dirigible and Keycloak. You can follow these steps for Dirigible and Keycloak. Create an instance. Set instance info, production. Set region, machine type, storage. Set connections. We need to Enable Service Networking API Set automatically allocated IP range. Set data protection and maintenance. After you create the instance update the configuration for connections to allow only SSL connection. Set Up a Dirigible Database Note Create the same way a database and a user for Keycloak. Create a database Go to your PostgreSQL instance and create the database. Create a user Go to your PostgreSQL instance and create the user. Create a service account for Dirigible and Keycloak. Add a role for the service account. Create a Dirigible and Keycloak Kubernetes Service Account Create the namespace dirigible-demo . kubectl create namespace dirigible-demo Add an Istio injection. kubectl label namespace dirigible-demo istio-injection=enabled --overwrite Configure a Kubernetes service account binding to the Google Cloud service account using Workload Identity. kubectl create sa dirigible-sa -n dirigible-demo kubectl create sa keycloak-sa -n dirigible-demo Add a new binding between your gcp service account and kubernetes service account Note You need to replace dirigible-gke-demo with your project id . Dirigible gcloud iam service-accounts add-iam-policy-binding \\ --role=\"roles/iam.workloadIdentityUser\" \\ --member=\"serviceAccount:dirigible-gke-demo.svc.id.goog[dirigible-demo/dirigible-sa]\" \\ dirigible-gcp-sa@dirigible-gke-demo.iam.gserviceaccount.com Keycloak gcloud iam service-accounts add-iam-policy-binding \\ --role=\"roles/iam.workloadIdentityUser\" \\ --member=\"serviceAccount:dirigible-gke-demo.svc.id.goog[dirigible-demo/keycloak-sa]\" \\ keycloak-gcp-sa@dirigible-gke-demo.iam.gserviceaccount.com Annotate the Kubernetes Service Account with the new binding. Note You need to replace dirigible-gke-demo with your project id . Dirigible kubectl annotate serviceaccount -n dirigible-demo \\ dirigible-sa \\ iam.gke.io/gcp-service-account=dirigible-gcp-sa@dirigible-gke-demo.iam.gserviceaccount.com Keycloak kubectl annotate serviceaccount -n dirigible-demo \\ keycloak-sa \\ iam.gke.io/gcp-service-account=keycloak-gcp-sa@dirigible-gke-demo.iam.gserviceaccount.com Create secrets for Kubernetes service accounts. Dirigible kubectl create secret generic dirigible-db -n dirigible-demo \\ --from-literal=username=dirigible_user \\ --from-literal=password=<your-password> \\ --from-literal=database=dirigible \\ --from-literal=postgre_url=jdbc:postgresql://127.0.0.1:5432/dirigible Keycloak kubectl create secret generic keycloak-db -n dirigible-demo \\ --from-literal=username=keycloak_user \\ --from-literal=password=<your-password> \\ --from-literal=database=keycloak \\ --from-literal=postgre_url=jdbc:postgresql://127.0.0.1:5432/keycloak Dirigible Deployment When you run this Dirigible helm chart with these sets, it will create volume , enable https , install Keycloak , create Istio gateway and virtualservice , enable usages for GCP Cloud SQL . You don't need to create a service account for Dirigible annd Keycloak, because it was already created in the previous steps. You need to provide gke.projectId , gke.region , ingress.host . helm repo add dirigible https://eclipse.github.io/dirigible helm repo update Note You need to replace: dirigible-gke-demo with your-project-id . europe-north1 with your-region . demo.apps.dirigible.io with your domain . dirigible-demo with your namespace . helm upgrade --install dirigible dirigible/dirigible -n dirigible-demo \\ --set volume.enabled=true \\ --set serviceAccount.create=false \\ --set keycloak.serviceAccountCreate=false \\ --set ingress.tls=true \\ --set keycloak.enabled=true \\ --set keycloak.install=true \\ --set istio.enabled=true \\ --set istio.enableHttps=true \\ --set gke.cloudSQL=true \\ --set gke.projectId=dirigible-gke-demo \\ --set gke.region=europe-north1 \\ --set ingress.host=demo.apps.dirigible.io \\ --set dirigible.image=dirigiblelabs/dirigible-keycloak:latest Check the Logs on the Cert-Manager Pod Wait for 3-5 minutes and check the logs. kubectl logs -n cert-manager -lapp=cert-manager | grep -i \"READY\" You should see something telling you that the certificate is ready and you can redirect http traffic to https. I0809 13:58:22.750528 1 conditions.go:190] Found status change for Certificate \"keycloak\" condition \"Ready\": \"False\" -> \"True\"; setting lastTransitionTime to 2022-08-09 13:58:22.750516762 +0000 UTC m=+18939.377721330 I0809 13:58:22.781247 1 conditions.go:190] Found status change for Certificate \"keycloak\" condition \"Ready\": \"False\" -> \"True\"; setting lastTransitionTime to 2022-08-09 13:58:22.781230149 +0000 UTC m=+18939.408434691 I0809 13:58:23.193897 1 conditions.go:250] Found status change for CertificateRequest \"dirigible-spnjm\" condition \"Ready\": \"False\" -> \"True\"; setting lastTransitionTime to 2022-08-09 13:58:23.193882791 +0000 UTC m=+18939.821087330 I0809 13:58:23.347574 1 conditions.go:190] Found status change for Certificate \"dirigible\" condition \"Ready\": \"False\" -> \"True\"; setting lastTransitionTime to 2022-08-09 13:58:23.347561322 +0000 UTC m=+18939.974765874 Now you can set httpsRedirect: true to redirect HTTP traffic to HTTPS . --set istio.httpsRedirect=true Keycloak Configuration Note You need to replace demo.apps.dirigible.io with your domain. When you first open https://dirigible.demo.apps.dirigible.io , you will see . We need to create clientId dirigible that's why go to https://keycloak.demo.apps.dirigible.io/auth/admin/master/console/#/realms/master/clients and login with username admin and password admin . Add Role \u2013 Open a new client and add the new roles Developer, Operator, Everyone. Add Default Roles \u2013 Roles->Default Roles add all roles from the previous step. Add User \u2013 By default, the new user should have the default roles assigned to it. Go to page to create the new user. Add a password. Set a valid redirect URL. Finally access Dirigible at https://dirigible.demo.apps.dirigible.io and log in with the password that we used for our user password. We can see that we have database connection to Cloud SQL PostgreSQL and we have assigned a certificate.","title":"Custom Domain in Google Kubernetes Engine with GCP Cloud DNS, Cloud SQL, Istio, Lets Encrypt, PostgreSQL and Keycloak"},{"location":"2022/08/10/gcp-gke-dns-istio-letsencrypt-postgresql-keycloak/#overview","text":"In this article we are going to setup a custom domain for a Dirigible application in a GKE cluster with GCP Cloud DNS , GCP Cloud SQL Postgre , Istio , Let's Encrypt , Keycloak . Components: Kubernetes GCP Cloud DNS GCP Cloud SQL Postgre Istio Let's Encrypt Cert-manager Keycloak Overview Kubernetes is an open-source system for automating deployment, scaling, and management of containerized applications in a cluster environment. You can read more about Kubernetes at www.kubernetes.io . Overview Reliable, resilient, low-latency DNS serving from Google's worldwide network provides you with everything you need to register, manage, and serve your domains. For more information, see Cloud DNS . Overview Fully managed relational database service for MySQL, PostgreSQL, and SQL Server with rich extension collections, configuration flags, and developer ecosystems. For more information, see GCP Cloud SQL Postgreere . Overview Istio is an open-source service mesh that layers transparently onto existing distributed applications. Istio\u2019s powerful features provide a uniform and more efficient way to secure, connect, and monitor services. For more information, see Istio . Overview Istio is an open-source service mesh that layers transparently onto existing distributed applications. Istio\u2019s powerful features provide a uniform and more efficient way to secure, connect, and monitor services. For more information, see Let's Encrypt . Overview Cert-manager is a powerful and extensible X.509 certificate controller for Kubernetes and OpenShift workloads. It will obtain certificates from a variety of Issuers, both popular public Issuers as well as private Issuers, and ensure the certificates are valid and up-to-date, and will attempt to renew certificates at a configured time before expiry. For more information, see Cert-manager . Overview Keycloak is an open source Identity and Access Management system for applications and services.For more information, see Keycloak .","title":"Overview"},{"location":"2022/08/10/gcp-gke-dns-istio-letsencrypt-postgresql-keycloak/#prerequisites","text":"In this article, we assume that you already have a GCP account and added billing account.","title":"Prerequisites"},{"location":"2022/08/10/gcp-gke-dns-istio-letsencrypt-postgresql-keycloak/#gke-cluster-configuration","text":"Prerequisites Install the gcloud CLI Install kubectl and configure cluster access Install Helm Create project Go to create your project . Set name, organization and billing account. Enable Engine API To be able to create a cluster, we need to enable Kubernetes Api. Go to enable Kubernetes API Create GKE cluster You can create standard and an autopilot cluster. In ths article, we will create the standard cluster. At this time you have two options to create a cluster: manually or by Use a setup guide . Manually Use a setup guide In this article we will use a setup guide and cost-optimized cluster . Choose a suitable location and name your cluster. Set a release channel. We are going to set Regular channel . This version have passed internal validation and are considered production-quality. Choose a cluster size. In this article we are going to keep the default size. Verify the machine type. Advanced settings: In this article we will use Optimize utilization . Prioritize optimizing utilization over keeping spare resources in the cluster. When selected, the cluster autoscaler scales down the cluster more aggressively: it can remove more nodes, and remove nodes faster. For cluster autoscaler you can configure how many maximum nodes to scale. It depends on your requirements. For this article we are going to keep this configuration maximum nodes 3 . Vertical Pod Autoscaling will ensure that the pods will be deployed on the right node. Configure usage metering. In this article we are not using metering.","title":"GKE Cluster Configuration"},{"location":"2022/08/10/gcp-gke-dns-istio-letsencrypt-postgresql-keycloak/#enable-workload-identity","text":"We need a workload identity to allow our Dirigible pod to access PostgreSQL. Cluster Workload Identity Node Workload Identity","title":"Enable Workload Identity"},{"location":"2022/08/10/gcp-gke-dns-istio-letsencrypt-postgresql-keycloak/#istio-configuration","text":"Note In this article we will configure istioctl to use the configmaps from the 1-14-3 revision. We can run multiple versions of Istio concurrently and can specify exactly which revision gets applied in the tooling. Initialize or reinitialize gcloud - check this url for more information. gcloud init Enable the specific GKE cluster as the default cluster to be used for the remaining commands. Note You need to replace dirigible with your cluster name and europe-north1-a with your region . gcloud container clusters get-credentials dirigible \\ --region europe-north1-a Create istio-system namespace and add label istio-injection. kubectl create namespace istio-system kubectl label namespace istio-system istio-injection=enabled --overwrite Create Istio control plane service istiod. kubectl apply -f - <<EOF apiVersion : v1 kind : Service metadata : labels : app : istiod istio : pilot release : istio name : istiod namespace : istio-system spec : type : ClusterIP ports : - name : grpc-xds port : 15010 - name : https-dns port : 15012 - name : https-webhook port : 443 targetPort : 15017 - name : http-monitoring port : 15014 selector : app : istiod EOF Install minimal control plane. istioctl install -y -n istio-system --revision 1-14-3 -f - <<EOF apiVersion : install.istio.io/v1alpha1 kind : IstioOperator metadata : name : control-plane spec : profile : minimal values : gateways : istio-ingressgateway : autoscaleEnabled : true components : pilot : k8s : env : - name : PILOT_FILTER_GATEWAY_CLUSTER_CONFIG value : \"true\" meshConfig : defaultConfig : proxyMetadata : ISTIO_META_DNS_CAPTURE : \"true\" enablePrometheusMerge : true EOF Enable the istio-ingressgateway component. Install the istio-ingress gateway in a namespace that is different from istiod and add the istio-injection tag. kubectl create namespace istio-ingress kubectl label namespace istio-ingress istio-injection=enabled --overwrite Install it with a revision that matches the control plane in the istio-system namespace. istioctl install -y -n istio-ingress --revision 1-14-3 -f - <<EOF apiVersion : install.istio.io/v1alpha1 kind : IstioOperator metadata : name : istio-ingress-gw-install spec : profile : empty values : gateways : istio-ingressgateway : autoscaleEnabled : true components : ingressGateways : - name : istio-ingressgateway namespace : istio-ingress enabled : true k8s : overlays : - apiVersion : apps/v1 kind : Deployment name : istio-ingressgateway patches : - path : spec.template.spec.containers[name:istio-proxy].lifecycle value : preStop : exec : command : [ \"sh\" , \"-c\" , \"sleep 5\" ] EOF Apply Strict mTLS Encrypt the traffic between services in the mesh with mutual TLS. kubectl apply --namespace istio-system -f - <<EOF apiVersion : security.istio.io/v1beta1 kind : PeerAuthentication metadata : name : default spec : mtls : mode : STRICT EOF","title":"Istio Configuration"},{"location":"2022/08/10/gcp-gke-dns-istio-letsencrypt-postgresql-keycloak/#gcp-cloud-dns-configuration","text":"Enable Cloud DNS API. Go to page and choose Enable to enable the API. Create Cloud DNS Zone. Go to page Copy the generated DNS name servers for your zone and add them to your domain, if your control is not in Google Clod DNS. The generated DNS name servers should look like this: ns-cloud-e1.googledomains.com. ns-cloud-e2.googledomains.com. ns-cloud-e3.googledomains.com. ns-cloud-e4.googledomains.com. Create an A record for Dirigible and Keycloak. We need Istio Gateway IP . kubectl get svc -n istio-ingress istio-ingressgateway -o jsonpath=\"{.status.loadBalancer.ingress[0].ip}\" A static external IP address is the IP address that is reserved for your project until you decide to release it. You need to create the IP address in your region. gcloud compute addresses create demo --addresses=<YOUR-GATEWAY-IP> \\ --region=europe-north1 Set the IP for Dirigible. Set the IP for Keycloak.","title":"GCP Cloud DNS Configuration"},{"location":"2022/08/10/gcp-gke-dns-istio-letsencrypt-postgresql-keycloak/#lets-encrypt-configuration","text":"Install Cert-manager. Check for last version Add cert-manager helm repo. helm repo add jetstack https://charts.jetstack.io helm repo update Install Cert-Manager. helm install \\ cert-manager jetstack/cert-manager \\ --namespace cert-manager \\ --create-namespace \\ --version v1.9.1 \\ --set installCRDs=true Create ClusterIssuer. Note You need to replace <YOUR-EMAIL-ADDRESS> with your valid email address. kubectl apply -f - <<EOF apiVersion : cert-manager.io/v1 kind : ClusterIssuer metadata : name : letsencrypt namespace : cert-manager spec : acme : server : https://acme-v02.api.letsencrypt.org/directory email : <YOUR-EMAIL-ADDRESS> privateKeySecretRef : name : letsencrypt solvers : - selector : {} http01 : ingress : class : istio EOF","title":"Let's Encrypt Configuration"},{"location":"2022/08/10/gcp-gke-dns-istio-letsencrypt-postgresql-keycloak/#gcp-cloud-sql-postgre-configuration","text":"Enable Cloud SQL API and create an instance. Go to page Enable Cloud SQL Admin API. Go to page Choose PostgreSQL database engine. Note For this article we will create separate instances for Dirigible and Keycloak. You can follow these steps for Dirigible and Keycloak. Create an instance. Set instance info, production. Set region, machine type, storage. Set connections. We need to Enable Service Networking API Set automatically allocated IP range. Set data protection and maintenance. After you create the instance update the configuration for connections to allow only SSL connection.","title":"GCP Cloud SQL Postgre Configuration"},{"location":"2022/08/10/gcp-gke-dns-istio-letsencrypt-postgresql-keycloak/#set-up-a-dirigible-database","text":"Note Create the same way a database and a user for Keycloak. Create a database Go to your PostgreSQL instance and create the database. Create a user Go to your PostgreSQL instance and create the user. Create a service account for Dirigible and Keycloak. Add a role for the service account.","title":"Set Up a Dirigible Database"},{"location":"2022/08/10/gcp-gke-dns-istio-letsencrypt-postgresql-keycloak/#create-a-dirigible-and-keycloak-kubernetes-service-account","text":"Create the namespace dirigible-demo . kubectl create namespace dirigible-demo Add an Istio injection. kubectl label namespace dirigible-demo istio-injection=enabled --overwrite Configure a Kubernetes service account binding to the Google Cloud service account using Workload Identity. kubectl create sa dirigible-sa -n dirigible-demo kubectl create sa keycloak-sa -n dirigible-demo Add a new binding between your gcp service account and kubernetes service account Note You need to replace dirigible-gke-demo with your project id . Dirigible gcloud iam service-accounts add-iam-policy-binding \\ --role=\"roles/iam.workloadIdentityUser\" \\ --member=\"serviceAccount:dirigible-gke-demo.svc.id.goog[dirigible-demo/dirigible-sa]\" \\ dirigible-gcp-sa@dirigible-gke-demo.iam.gserviceaccount.com Keycloak gcloud iam service-accounts add-iam-policy-binding \\ --role=\"roles/iam.workloadIdentityUser\" \\ --member=\"serviceAccount:dirigible-gke-demo.svc.id.goog[dirigible-demo/keycloak-sa]\" \\ keycloak-gcp-sa@dirigible-gke-demo.iam.gserviceaccount.com Annotate the Kubernetes Service Account with the new binding. Note You need to replace dirigible-gke-demo with your project id . Dirigible kubectl annotate serviceaccount -n dirigible-demo \\ dirigible-sa \\ iam.gke.io/gcp-service-account=dirigible-gcp-sa@dirigible-gke-demo.iam.gserviceaccount.com Keycloak kubectl annotate serviceaccount -n dirigible-demo \\ keycloak-sa \\ iam.gke.io/gcp-service-account=keycloak-gcp-sa@dirigible-gke-demo.iam.gserviceaccount.com Create secrets for Kubernetes service accounts. Dirigible kubectl create secret generic dirigible-db -n dirigible-demo \\ --from-literal=username=dirigible_user \\ --from-literal=password=<your-password> \\ --from-literal=database=dirigible \\ --from-literal=postgre_url=jdbc:postgresql://127.0.0.1:5432/dirigible Keycloak kubectl create secret generic keycloak-db -n dirigible-demo \\ --from-literal=username=keycloak_user \\ --from-literal=password=<your-password> \\ --from-literal=database=keycloak \\ --from-literal=postgre_url=jdbc:postgresql://127.0.0.1:5432/keycloak","title":"Create a Dirigible and Keycloak Kubernetes Service Account"},{"location":"2022/08/10/gcp-gke-dns-istio-letsencrypt-postgresql-keycloak/#dirigible-deployment","text":"When you run this Dirigible helm chart with these sets, it will create volume , enable https , install Keycloak , create Istio gateway and virtualservice , enable usages for GCP Cloud SQL . You don't need to create a service account for Dirigible annd Keycloak, because it was already created in the previous steps. You need to provide gke.projectId , gke.region , ingress.host . helm repo add dirigible https://eclipse.github.io/dirigible helm repo update Note You need to replace: dirigible-gke-demo with your-project-id . europe-north1 with your-region . demo.apps.dirigible.io with your domain . dirigible-demo with your namespace . helm upgrade --install dirigible dirigible/dirigible -n dirigible-demo \\ --set volume.enabled=true \\ --set serviceAccount.create=false \\ --set keycloak.serviceAccountCreate=false \\ --set ingress.tls=true \\ --set keycloak.enabled=true \\ --set keycloak.install=true \\ --set istio.enabled=true \\ --set istio.enableHttps=true \\ --set gke.cloudSQL=true \\ --set gke.projectId=dirigible-gke-demo \\ --set gke.region=europe-north1 \\ --set ingress.host=demo.apps.dirigible.io \\ --set dirigible.image=dirigiblelabs/dirigible-keycloak:latest","title":"Dirigible Deployment"},{"location":"2022/08/10/gcp-gke-dns-istio-letsencrypt-postgresql-keycloak/#check-the-logs-on-the-cert-manager-pod","text":"Wait for 3-5 minutes and check the logs. kubectl logs -n cert-manager -lapp=cert-manager | grep -i \"READY\" You should see something telling you that the certificate is ready and you can redirect http traffic to https. I0809 13:58:22.750528 1 conditions.go:190] Found status change for Certificate \"keycloak\" condition \"Ready\": \"False\" -> \"True\"; setting lastTransitionTime to 2022-08-09 13:58:22.750516762 +0000 UTC m=+18939.377721330 I0809 13:58:22.781247 1 conditions.go:190] Found status change for Certificate \"keycloak\" condition \"Ready\": \"False\" -> \"True\"; setting lastTransitionTime to 2022-08-09 13:58:22.781230149 +0000 UTC m=+18939.408434691 I0809 13:58:23.193897 1 conditions.go:250] Found status change for CertificateRequest \"dirigible-spnjm\" condition \"Ready\": \"False\" -> \"True\"; setting lastTransitionTime to 2022-08-09 13:58:23.193882791 +0000 UTC m=+18939.821087330 I0809 13:58:23.347574 1 conditions.go:190] Found status change for Certificate \"dirigible\" condition \"Ready\": \"False\" -> \"True\"; setting lastTransitionTime to 2022-08-09 13:58:23.347561322 +0000 UTC m=+18939.974765874 Now you can set httpsRedirect: true to redirect HTTP traffic to HTTPS . --set istio.httpsRedirect=true","title":"Check the Logs on the Cert-Manager Pod"},{"location":"2022/08/10/gcp-gke-dns-istio-letsencrypt-postgresql-keycloak/#keycloak-configuration","text":"Note You need to replace demo.apps.dirigible.io with your domain. When you first open https://dirigible.demo.apps.dirigible.io , you will see . We need to create clientId dirigible that's why go to https://keycloak.demo.apps.dirigible.io/auth/admin/master/console/#/realms/master/clients and login with username admin and password admin . Add Role \u2013 Open a new client and add the new roles Developer, Operator, Everyone. Add Default Roles \u2013 Roles->Default Roles add all roles from the previous step. Add User \u2013 By default, the new user should have the default roles assigned to it. Go to page to create the new user. Add a password. Set a valid redirect URL. Finally access Dirigible at https://dirigible.demo.apps.dirigible.io and log in with the password that we used for our user password. We can see that we have database connection to Cloud SQL PostgreSQL and we have assigned a certificate.","title":"Keycloak Configuration"},{"location":"2022/09/12/sendgrid-smtp-relay-setup/","text":"Recent changes in Gmail 's policies allows Eclipse Dirigible users to send emails only via Workspace enabled accounts in G Suite and require workspace administration privileges. By connecting Eclipse Dirigible with Twilio SendGrid's SMTP Relay feature you can send emails with your personal gmail account. Note SendGrid is a 3rd party service and charges/limits apply. Here you can find more information about their Email API Plans . Setup SendGrid Account Create a SendGrid account at https://sendgrid.com . Login at https://app.sendgrid.com . Verify a single sender email: Click Settings \u2192 Sender Authentication \u2192 Verify a Single Sender . Enter the details of the email address that Eclipse Dirigible mails will be sent from. Setup SMTP Relay: Click Email API \u2192 Integration Guide \u2192 SMTP Relay . Enter an API Key Name and click Create Key to get an API Key for your SendGrid SMTP Relay. Notice the Configure your application section, the credentials from it will be used to configure the mail client. Setup Eclipse Dirigible Prerequisites You can follow the Setup guide on how to deploy Eclipse Dirigible locally or in the cloud. Add the following environment variables to your deployment: DIRIGIBLE_MAIL_USERNAME=apikey DIRIGIBLE_MAIL_PASSWORD=<YOUR_API_KEY_HERE> DIRIGIBLE_MAIL_TRANSPORT_PROTOCOL=smtps DIRIGIBLE_MAIL_SMTPS_HOST=smtp.sendgrid.net DIRIGIBLE_MAIL_SMTPS_PORT=465 Note Replace the <YOUR_API_KEY_HERE> placeholder with the SendGrid SMTP Relay API key. Restart the Eclipse Dirigible instance in order to apply the new environment variables. Environment Variables To get a complete list of all environment variables navigate to the Environment Variables page. Send an Email with SendGrid SMTP Relay Login to your Eclipse Dirigible instance. Create new project. Create new Javascript ESM Service . Use the following sinippet to send emails: import { client as mail } from \"sdk/mail\" ; const from = \"<YOUR_VERIFIED_SENDER_EMAIL_HERE>\" ; const to = \"<YOUR_RECIPIENT_EMAIL_HERE>\" ; const subject = \"Subject\" ; const content = \"Hello World!\" ; const subType = \"html\" ; mail . send ( from , to , subject , content , subType ); Note Replace the <YOUR_VERIFIED_SENDER_EMAIL_HERE> and the <YOUR_RECIPIENT_EMAIL_HERE> placeholders with valid email addresses.","title":"Connecting Eclipse Dirigible with SendGrid SMTP Relay"},{"location":"2022/09/12/sendgrid-smtp-relay-setup/#setup-sendgrid-account","text":"Create a SendGrid account at https://sendgrid.com . Login at https://app.sendgrid.com . Verify a single sender email: Click Settings \u2192 Sender Authentication \u2192 Verify a Single Sender . Enter the details of the email address that Eclipse Dirigible mails will be sent from. Setup SMTP Relay: Click Email API \u2192 Integration Guide \u2192 SMTP Relay . Enter an API Key Name and click Create Key to get an API Key for your SendGrid SMTP Relay. Notice the Configure your application section, the credentials from it will be used to configure the mail client.","title":"Setup SendGrid Account"},{"location":"2022/09/12/sendgrid-smtp-relay-setup/#setup-eclipse-dirigible","text":"Prerequisites You can follow the Setup guide on how to deploy Eclipse Dirigible locally or in the cloud. Add the following environment variables to your deployment: DIRIGIBLE_MAIL_USERNAME=apikey DIRIGIBLE_MAIL_PASSWORD=<YOUR_API_KEY_HERE> DIRIGIBLE_MAIL_TRANSPORT_PROTOCOL=smtps DIRIGIBLE_MAIL_SMTPS_HOST=smtp.sendgrid.net DIRIGIBLE_MAIL_SMTPS_PORT=465 Note Replace the <YOUR_API_KEY_HERE> placeholder with the SendGrid SMTP Relay API key. Restart the Eclipse Dirigible instance in order to apply the new environment variables. Environment Variables To get a complete list of all environment variables navigate to the Environment Variables page.","title":"Setup Eclipse Dirigible"},{"location":"2022/09/12/sendgrid-smtp-relay-setup/#send-an-email-with-sendgrid-smtp-relay","text":"Login to your Eclipse Dirigible instance. Create new project. Create new Javascript ESM Service . Use the following sinippet to send emails: import { client as mail } from \"sdk/mail\" ; const from = \"<YOUR_VERIFIED_SENDER_EMAIL_HERE>\" ; const to = \"<YOUR_RECIPIENT_EMAIL_HERE>\" ; const subject = \"Subject\" ; const content = \"Hello World!\" ; const subType = \"html\" ; mail . send ( from , to , subject , content , subType ); Note Replace the <YOUR_VERIFIED_SENDER_EMAIL_HERE> and the <YOUR_RECIPIENT_EMAIL_HERE> placeholders with valid email addresses.","title":"Send an Email with SendGrid SMTP Relay"},{"location":"2022/09/26/qldb-repository-api-guide/","text":"In this blog you will learn how to use Amazon Quantum Ledger Database within Eclipse Dirigible projects. What is QLDB? Amazon Quantum Ledger Database (QLDB) is a fully managed database running over a ledger that provides a transparent, immutable, and cryptographically verifiable transaction log. What is the QLDB Repository API and why is it useful for Eclipse Dirigible projects? The QLDB Repository API in Eclipse Dirigible adds a clean and low code JavaScript interface for work with AWS QLDB. It simplifies it's use and allows Eclipse Dirigible projects to use QLDB's secure transaction log to store many different kind of critical data. Such as, financial transactions or in supply chain systems to store transactions and details of every batch manufactured, shipped, stored, and sold from facility to store. See more use cases at AWS QLDB and AWS QLDB FAQs . What are the limitations when using QLDB? Although QLDB automatically scales to support the demands of your application and you don't need to worry about provisioning capacity or configuring read and write limits, there are some limits that you might want to read Quotas and limits in Amazon QLDB and Amazon QLDB endpoints and quotas . Setup AWS Account with QLDB Enabled Sign up for AWS or use an existing account. Create AWS IAM User To create AWS Identity and Access Management (IAM) user, sign in to the IAM console as the account owner by choosing Root user and entering your AWS account email address. On the next page, enter your password: In the navigation pane, choose Users and then choose Add users. For User name, enter dirigible_qldb_user . Select the check box next to AWS Management Console access. Then select Password - AWS Management Console access and then enter your new user password in the text box. (Optional) By default, AWS requires the new user to create a new password when first signing in. You can clear the check box next to User must create a new password at next sign-in to allow the new user to reset their password after they sign in. Choose Next: Permissions. Under Set permissions , choose Add user to group . Choose Create group . In the Create group dialog box, for Group name enter dirigible_qldb_group . Choose in the Filter policies input, search for the term qldb . Put checkboxes on AmazonQLDBReadOnly , AmazonQLDBFullAccess and AmazonQLDBConsoleFullAccess . Then click on Create group . Back in the list of groups, select the check box for your new group. Choose Refresh if necessary to see the group in the list. Choose Next: Tags . (Optional) Add metadata to the user by attaching tags as key-value pairs. For more information about using tags in IAM, see Tagging IAM entities in the IAM User Guide. Choose Next: Review to see the list of group memberships to be added to the new user. When you are ready to proceed, choose Create user . Note You can read more in the AWS documentation How to Create an IAM User . Get an IAM Access Key The Access Key is used by the QLDB Driver in Eclipse Dirigible to establish connections securely. Go back to the IAM console . In the navigation pane, choose Users . Click on the name of the user you created in the previous step. Choose the Security credentials tab. In the Access keys section, choose Create access key . To view the new access key pair, choose Show. You will not have access to the secret access key again after this dialog box closes. Copy and remember the Access key ID and Secret access key they will be used in the next step. Note Your credentials will look something like this: Access key ID: AKIAIOSFODNN7EXAMPLE Secret access key: wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY You can read more in the AWS documentation How to Get an IAM Access Key . Credentials and Region Setup Setup the credentials and region on the machine you are running Eclipse Dirigible. Note Create a file ~/.aws/credentials , where the tilde character (~) represents your home directory: [default] region = eu-west-2 aws_access_key_id = <your_access_key_id> aws_secret_access_key = <your_secret_access_key> Replace ( eu-west-2 , your_access_key_id , your_secret_access_key ) with your credentials from the last step. Setup a Ledger To create a ledger, sign in to the AWS Management Console, and open the Amazon QLDB console : In the navigation pane, choose Getting started . On the Create your first ledger card, choose Create Ledger. For Ledger information \u2013 The Ledger name should be pre-populated with vehicle-registration , change that to myTestLedger . For Permission mode - choose Standard \u2013 (Recommended) (A permissions mode that enables access control with finer granularity for ledgers, tables, and PartiQL commands.) For Encrypt data at rest \u2013 choose Use AWS owned KMS key (Use a KMS key that is owned and managed by AWS on your behalf. This is the default option and requires no additional setup.) Tags \u2013 (Optional) Add metadata to the ledger by attaching tags as key-value pairs. You can add tags to your ledger to help organize and identify them. For more information, see Tagging Amazon QLDB resources . Choose Create ledger . In the list of Ledgers, locate myTestLedger and wait for the ledger's status to become Active. Note You can read more in the AWS QLDB documentation How to Setup a Ledger . Build Custom Eclipse Dirigible stack with AWS QLDB support To create a Custom Stack follow the steps here Custom Stack documentation . After that replace the content of the releng/pom.xml file (described in the first step of the Custom Stack documentation ) with: <project xmlns= \"http://maven.apache.org/POM/4.0.0\" xmlns:xsi= \"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation= \"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd\" > <modelVersion> 4.0.0 </modelVersion> <parent> <groupId> io.dirigible.custom.stack </groupId> <artifactId> custom-stack-parent </artifactId> <version> 1.0.0-SNAPSHOT </version> <relativePath> ../pom.xml </relativePath> </parent> <name> Custom Stack - Releng - Spring Boot </name> <artifactId> custom-stack-spring-boot </artifactId> <version> 1.0.0-SNAPSHOT </version> <packaging> jar </packaging> <build> <plugins> <plugin> <groupId> org.springframework.boot </groupId> <artifactId> spring-boot-maven-plugin </artifactId> <version> ${spring.boot.version} </version> <configuration> <mainClass> io.dirigible.custom.platform.CustomPlatformApplication </mainClass> </configuration> <executions> <execution> <goals> <goal> repackage </goal> </goals> </execution> </executions> </plugin> </plugins> <resources> <resource> <directory> src/main/resources </directory> <filtering> true </filtering> </resource> </resources> </build> <dependencies> <!-- Dirigible --> <dependency> <groupId> org.eclipse.dirigible </groupId> <artifactId> dirigible-server-spring </artifactId> <version> ${dirigible.version} </version> </dependency> <!-- Dirigible \u0415XT --> <dependency> <groupId> org.eclipse.dirigible </groupId> <artifactId> dirigible-ext </artifactId> <version> 7.0.0-SNAPSHOT </version> </dependency> <!-- Platform --> <dependency> <groupId> org.slf4j </groupId> <artifactId> slf4j-api </artifactId> <version> ${slf4j.version} </version> <scope> compile </scope> </dependency> <dependency> <groupId> ch.qos.logback </groupId> <artifactId> logback-core </artifactId> <version> ${logback.version} </version> <scope> compile </scope> </dependency> <dependency> <groupId> ch.qos.logback </groupId> <artifactId> logback-classic </artifactId> <version> ${logback.version} </version> <scope> compile </scope> </dependency> <dependency> <groupId> org.springframework.boot </groupId> <artifactId> spring-boot-configuration-processor </artifactId> <optional> true </optional> <version> ${spring.boot.version} </version> </dependency> </dependencies> </project> Create Eclipse Dirigible Project with AWS QLDB Create a new Project. Add a qldb-sample.js or qldb-sample.mjs file to the project. Add the following content with an example usage of the QLDBRepository API to the file: qldb-sample.js qldb-sample.mjs const QLDBRepository = require ( \"qldb/QLDBRepository\" ); // 1. Create a repository for the ledger 'myTestLedger' that works with a table 'tableName' const qldb = new QLDBRepository ( \"myTestLedger\" , \"tableName\" ); // 2. [OPTIONAL] Create the table as it doesn't exist in your ledger, // on the next execution of this script - comment out this line or it will fail. qldb . createTable (); // 3. Insert a JS Object as a record. let inserted = qldb . insert ({ email : \"test@mail.com\" , number : 123 , status : false }); // Notice: The inserted object now has a 'documentId' property, // which is the id of the record generated by QLDB console . log ( \"Inserted entry: \" + inserted ); // 4.1 Update a record inserted . email = \"q@mail.com\" ; inserted . number = 5 ; inserted . status = false ; let updated = qldb . update ( inserted ); console . log ( \"Updated entry: \" + updated ); // 4.2 [OPTIONAL] Update a record with an object // let updatedRaw = qldb.update({ // email: \"text@mail.com\", // number: 50000, // status: true, // documentId: \"7ekJBB1FEm1EmhJBqH0WLX\" // }); // Notice: Unlike insertion where the 'documentId' is generated by QLDB, // in 'update' the object must have a 'documentId' property defined // with value - a valid documentId of an entry in your table. // 5. Get all current records in the repository. let allRecords = qldb . getAll (); console . log ( \"allRecords: \" + allRecords ); // 6.1 Delete a record let deletedId = qldb . delete ( updated ); console . log ( \"Deleted entry with id: \" + deletedId ); // 6.2 [OPTIONAL] Delete a record by ID // deletedId = qldb.delete(updated.documentId); // console.log(\"Deleted entry with id: \" + deletedId); // 7. Get array with all transactions for the table let transactionHistory = qldb . getHistory (); console . log ( \"Transaction History:\" + transactionHistory ); // 8. [OPTIONAL] Drop the table // qldb.dropTable(); // Notice: In QLDB dropping a table simply inactivates it, // you can reactivate a table that you have dropped by running // an SQL UNDROP statement in PartiQL import { QLDBRepository } from \"sdk/qldb\" // 1. Create a repository for the ledger 'myTestLedger' that works with a table 'tableName' const qldb = new QLDBRepository ( \"myTestLedger\" , \"tableName\" ); // 2. [OPTIONAL] Create the table as it doesn't exist in your ledger, // on the next execution of this script - comment out this line or it will fail. qldb . createTable (); // 3. Insert a JS Object as a record. let inserted = qldb . insert ({ email : \"test@mail.com\" , number : 123 , status : false }); // Notice: The inserted object now has a 'documentId' property, // which is the id of the record generated by QLDB console . log ( \"Inserted entry: \" + inserted ); // 4.1 Update a record inserted . email = \"q@mail.com\" ; inserted . number = 5 ; inserted . status = false ; let updated = qldb . update ( inserted ); console . log ( \"Updated entry: \" + updated ); // 4.2 [OPTIONAL] Update a record with an object // let updatedRaw = qldb.update({ // email: \"text@mail.com\", // number: 50000, // status: true, // documentId: \"7ekJBB1FEm1EmhJBqH0WLX\" // }); // Notice: Unlike insertion where the 'documentId' is generated by QLDB, // in 'update' the object must have a 'documentId' property defined // with value - a valid documentId of an entry in your table. // 5. Get all current records in the repository. let allRecords = qldb . getAll (); console . log ( \"allRecords: \" + allRecords ); // 6.1 Delete a record let deletedId = qldb . delete ( updated ); console . log ( \"Deleted entry with id: \" + deletedId ); // 6.2 [OPTIONAL] Delete a record by ID // deletedId = qldb.delete(updated.documentId); // console.log(\"Deleted entry with id: \" + deletedId); // 7. Get array with all transactions for the table let transactionHistory = qldb . getHistory (); console . log ( \"Transaction History:\" + transactionHistory ); // 8. [OPTIONAL] Drop the table // qldb.dropTable(); // Notice: In QLDB dropping a table simply inactivates it, // you can reactivate a table that you have dropped by running // an SQL UNDROP statement in PartiQL (Optional) Manually Run PartiQL queries against your ledger Sign in to the AWS Management Console, and open the Amazon QLDB console . In the navigation pane choose PartiQL editor . In the editor's Choose a ledger dropdown select myTestLedger . You can now write and execute queries to your database manually. Note This can be useful if you want to create, delete or restore deleted tables. Read more at Getting started with PartiQL for DynamoDB .","title":"Amazon Quantum Ledger Database with Eclipse Dirigible"},{"location":"2022/09/26/qldb-repository-api-guide/#setup-aws-account-with-qldb-enabled","text":"Sign up for AWS or use an existing account.","title":"Setup AWS Account with QLDB Enabled"},{"location":"2022/09/26/qldb-repository-api-guide/#create-aws-iam-user","text":"To create AWS Identity and Access Management (IAM) user, sign in to the IAM console as the account owner by choosing Root user and entering your AWS account email address. On the next page, enter your password: In the navigation pane, choose Users and then choose Add users. For User name, enter dirigible_qldb_user . Select the check box next to AWS Management Console access. Then select Password - AWS Management Console access and then enter your new user password in the text box. (Optional) By default, AWS requires the new user to create a new password when first signing in. You can clear the check box next to User must create a new password at next sign-in to allow the new user to reset their password after they sign in. Choose Next: Permissions. Under Set permissions , choose Add user to group . Choose Create group . In the Create group dialog box, for Group name enter dirigible_qldb_group . Choose in the Filter policies input, search for the term qldb . Put checkboxes on AmazonQLDBReadOnly , AmazonQLDBFullAccess and AmazonQLDBConsoleFullAccess . Then click on Create group . Back in the list of groups, select the check box for your new group. Choose Refresh if necessary to see the group in the list. Choose Next: Tags . (Optional) Add metadata to the user by attaching tags as key-value pairs. For more information about using tags in IAM, see Tagging IAM entities in the IAM User Guide. Choose Next: Review to see the list of group memberships to be added to the new user. When you are ready to proceed, choose Create user . Note You can read more in the AWS documentation How to Create an IAM User .","title":"Create AWS IAM User"},{"location":"2022/09/26/qldb-repository-api-guide/#get-an-iam-access-key","text":"The Access Key is used by the QLDB Driver in Eclipse Dirigible to establish connections securely. Go back to the IAM console . In the navigation pane, choose Users . Click on the name of the user you created in the previous step. Choose the Security credentials tab. In the Access keys section, choose Create access key . To view the new access key pair, choose Show. You will not have access to the secret access key again after this dialog box closes. Copy and remember the Access key ID and Secret access key they will be used in the next step. Note Your credentials will look something like this: Access key ID: AKIAIOSFODNN7EXAMPLE Secret access key: wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY You can read more in the AWS documentation How to Get an IAM Access Key .","title":"Get an IAM Access Key"},{"location":"2022/09/26/qldb-repository-api-guide/#credentials-and-region-setup","text":"Setup the credentials and region on the machine you are running Eclipse Dirigible. Note Create a file ~/.aws/credentials , where the tilde character (~) represents your home directory: [default] region = eu-west-2 aws_access_key_id = <your_access_key_id> aws_secret_access_key = <your_secret_access_key> Replace ( eu-west-2 , your_access_key_id , your_secret_access_key ) with your credentials from the last step.","title":"Credentials and Region Setup"},{"location":"2022/09/26/qldb-repository-api-guide/#setup-a-ledger","text":"To create a ledger, sign in to the AWS Management Console, and open the Amazon QLDB console : In the navigation pane, choose Getting started . On the Create your first ledger card, choose Create Ledger. For Ledger information \u2013 The Ledger name should be pre-populated with vehicle-registration , change that to myTestLedger . For Permission mode - choose Standard \u2013 (Recommended) (A permissions mode that enables access control with finer granularity for ledgers, tables, and PartiQL commands.) For Encrypt data at rest \u2013 choose Use AWS owned KMS key (Use a KMS key that is owned and managed by AWS on your behalf. This is the default option and requires no additional setup.) Tags \u2013 (Optional) Add metadata to the ledger by attaching tags as key-value pairs. You can add tags to your ledger to help organize and identify them. For more information, see Tagging Amazon QLDB resources . Choose Create ledger . In the list of Ledgers, locate myTestLedger and wait for the ledger's status to become Active. Note You can read more in the AWS QLDB documentation How to Setup a Ledger .","title":"Setup a Ledger"},{"location":"2022/09/26/qldb-repository-api-guide/#build-custom-eclipse-dirigible-stack-with-aws-qldb-support","text":"To create a Custom Stack follow the steps here Custom Stack documentation . After that replace the content of the releng/pom.xml file (described in the first step of the Custom Stack documentation ) with: <project xmlns= \"http://maven.apache.org/POM/4.0.0\" xmlns:xsi= \"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation= \"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd\" > <modelVersion> 4.0.0 </modelVersion> <parent> <groupId> io.dirigible.custom.stack </groupId> <artifactId> custom-stack-parent </artifactId> <version> 1.0.0-SNAPSHOT </version> <relativePath> ../pom.xml </relativePath> </parent> <name> Custom Stack - Releng - Spring Boot </name> <artifactId> custom-stack-spring-boot </artifactId> <version> 1.0.0-SNAPSHOT </version> <packaging> jar </packaging> <build> <plugins> <plugin> <groupId> org.springframework.boot </groupId> <artifactId> spring-boot-maven-plugin </artifactId> <version> ${spring.boot.version} </version> <configuration> <mainClass> io.dirigible.custom.platform.CustomPlatformApplication </mainClass> </configuration> <executions> <execution> <goals> <goal> repackage </goal> </goals> </execution> </executions> </plugin> </plugins> <resources> <resource> <directory> src/main/resources </directory> <filtering> true </filtering> </resource> </resources> </build> <dependencies> <!-- Dirigible --> <dependency> <groupId> org.eclipse.dirigible </groupId> <artifactId> dirigible-server-spring </artifactId> <version> ${dirigible.version} </version> </dependency> <!-- Dirigible \u0415XT --> <dependency> <groupId> org.eclipse.dirigible </groupId> <artifactId> dirigible-ext </artifactId> <version> 7.0.0-SNAPSHOT </version> </dependency> <!-- Platform --> <dependency> <groupId> org.slf4j </groupId> <artifactId> slf4j-api </artifactId> <version> ${slf4j.version} </version> <scope> compile </scope> </dependency> <dependency> <groupId> ch.qos.logback </groupId> <artifactId> logback-core </artifactId> <version> ${logback.version} </version> <scope> compile </scope> </dependency> <dependency> <groupId> ch.qos.logback </groupId> <artifactId> logback-classic </artifactId> <version> ${logback.version} </version> <scope> compile </scope> </dependency> <dependency> <groupId> org.springframework.boot </groupId> <artifactId> spring-boot-configuration-processor </artifactId> <optional> true </optional> <version> ${spring.boot.version} </version> </dependency> </dependencies> </project>","title":"Build Custom Eclipse Dirigible stack with AWS QLDB support"},{"location":"2022/09/26/qldb-repository-api-guide/#create-eclipse-dirigible-project-with-aws-qldb","text":"Create a new Project. Add a qldb-sample.js or qldb-sample.mjs file to the project. Add the following content with an example usage of the QLDBRepository API to the file: qldb-sample.js qldb-sample.mjs const QLDBRepository = require ( \"qldb/QLDBRepository\" ); // 1. Create a repository for the ledger 'myTestLedger' that works with a table 'tableName' const qldb = new QLDBRepository ( \"myTestLedger\" , \"tableName\" ); // 2. [OPTIONAL] Create the table as it doesn't exist in your ledger, // on the next execution of this script - comment out this line or it will fail. qldb . createTable (); // 3. Insert a JS Object as a record. let inserted = qldb . insert ({ email : \"test@mail.com\" , number : 123 , status : false }); // Notice: The inserted object now has a 'documentId' property, // which is the id of the record generated by QLDB console . log ( \"Inserted entry: \" + inserted ); // 4.1 Update a record inserted . email = \"q@mail.com\" ; inserted . number = 5 ; inserted . status = false ; let updated = qldb . update ( inserted ); console . log ( \"Updated entry: \" + updated ); // 4.2 [OPTIONAL] Update a record with an object // let updatedRaw = qldb.update({ // email: \"text@mail.com\", // number: 50000, // status: true, // documentId: \"7ekJBB1FEm1EmhJBqH0WLX\" // }); // Notice: Unlike insertion where the 'documentId' is generated by QLDB, // in 'update' the object must have a 'documentId' property defined // with value - a valid documentId of an entry in your table. // 5. Get all current records in the repository. let allRecords = qldb . getAll (); console . log ( \"allRecords: \" + allRecords ); // 6.1 Delete a record let deletedId = qldb . delete ( updated ); console . log ( \"Deleted entry with id: \" + deletedId ); // 6.2 [OPTIONAL] Delete a record by ID // deletedId = qldb.delete(updated.documentId); // console.log(\"Deleted entry with id: \" + deletedId); // 7. Get array with all transactions for the table let transactionHistory = qldb . getHistory (); console . log ( \"Transaction History:\" + transactionHistory ); // 8. [OPTIONAL] Drop the table // qldb.dropTable(); // Notice: In QLDB dropping a table simply inactivates it, // you can reactivate a table that you have dropped by running // an SQL UNDROP statement in PartiQL import { QLDBRepository } from \"sdk/qldb\" // 1. Create a repository for the ledger 'myTestLedger' that works with a table 'tableName' const qldb = new QLDBRepository ( \"myTestLedger\" , \"tableName\" ); // 2. [OPTIONAL] Create the table as it doesn't exist in your ledger, // on the next execution of this script - comment out this line or it will fail. qldb . createTable (); // 3. Insert a JS Object as a record. let inserted = qldb . insert ({ email : \"test@mail.com\" , number : 123 , status : false }); // Notice: The inserted object now has a 'documentId' property, // which is the id of the record generated by QLDB console . log ( \"Inserted entry: \" + inserted ); // 4.1 Update a record inserted . email = \"q@mail.com\" ; inserted . number = 5 ; inserted . status = false ; let updated = qldb . update ( inserted ); console . log ( \"Updated entry: \" + updated ); // 4.2 [OPTIONAL] Update a record with an object // let updatedRaw = qldb.update({ // email: \"text@mail.com\", // number: 50000, // status: true, // documentId: \"7ekJBB1FEm1EmhJBqH0WLX\" // }); // Notice: Unlike insertion where the 'documentId' is generated by QLDB, // in 'update' the object must have a 'documentId' property defined // with value - a valid documentId of an entry in your table. // 5. Get all current records in the repository. let allRecords = qldb . getAll (); console . log ( \"allRecords: \" + allRecords ); // 6.1 Delete a record let deletedId = qldb . delete ( updated ); console . log ( \"Deleted entry with id: \" + deletedId ); // 6.2 [OPTIONAL] Delete a record by ID // deletedId = qldb.delete(updated.documentId); // console.log(\"Deleted entry with id: \" + deletedId); // 7. Get array with all transactions for the table let transactionHistory = qldb . getHistory (); console . log ( \"Transaction History:\" + transactionHistory ); // 8. [OPTIONAL] Drop the table // qldb.dropTable(); // Notice: In QLDB dropping a table simply inactivates it, // you can reactivate a table that you have dropped by running // an SQL UNDROP statement in PartiQL","title":"Create Eclipse Dirigible Project with AWS QLDB"},{"location":"2022/09/26/qldb-repository-api-guide/#optional-manually-run-partiql-queries-against-your-ledger","text":"Sign in to the AWS Management Console, and open the Amazon QLDB console . In the navigation pane choose PartiQL editor . In the editor's Choose a ledger dropdown select myTestLedger . You can now write and execute queries to your database manually. Note This can be useful if you want to create, delete or restore deleted tables. Read more at Getting started with PartiQL for DynamoDB .","title":"(Optional) Manually Run PartiQL queries against your ledger"},{"location":"2022/09/29/news-fundamentals-conf-2022/","text":"Stan is a UI designer, software developer and system administrator at Quanterall, making use of various languages and UI toolkits. He has designed and developed software solutions for workstations, Kiosk systems, Internet of Things, Web and mobile. He has been a part of many open and closed source projects since the early 2010s. Personal interests include reading, music, vintage electronics, retro cars and restoration projects. On Fundamentals Conf 2022 Stan came with a new revamped and modernized Eclipse Dirigible Web IDE, to level it up for enterprise users. Why Fundamental Styles? Developed by a trustworthy team Theme support Enterprise focused Rich component library Can be used with any UI framework Renewed Components Shell Layout manager MessageHub Form Controls Slides Recording Congrats!","title":"Fundamentals Conf 2022"},{"location":"2022/09/29/news-fundamentals-conf-2022/#why-fundamental-styles","text":"Developed by a trustworthy team Theme support Enterprise focused Rich component library Can be used with any UI framework","title":"Why Fundamental Styles?"},{"location":"2022/09/29/news-fundamentals-conf-2022/#renewed-components","text":"Shell Layout manager MessageHub Form Controls Slides Recording","title":"Renewed Components"},{"location":"2022/09/29/news-fundamentals-conf-2022/#congrats","text":"","title":"Congrats!"},{"location":"2022/10/06/cloud-tool-time-building-white-label-platforms/","text":"In this session Yordan Pavlov (CTO of codbex ) shared his experience from building \"white-label\" platforms on top of Eclipse Dirigible. White-label Business Model Manufacturer: Creates generic (whilte-label) products. Retailer: Buys, rebrands and re-sells white-label products. End Customer: Buy directly from retailer branded products. Results Expand your offering Attract and close more customers Stand out from the competition Steady revenue Focus on what matters Slides Recording Congrats","title":"Cloud Tool Time - Building white-label platforms"},{"location":"2022/10/06/cloud-tool-time-building-white-label-platforms/#white-label-business-model","text":"Manufacturer: Creates generic (whilte-label) products. Retailer: Buys, rebrands and re-sells white-label products. End Customer: Buy directly from retailer branded products.","title":"White-label Business Model"},{"location":"2022/10/06/cloud-tool-time-building-white-label-platforms/#results","text":"Expand your offering Attract and close more customers Stand out from the competition Steady revenue Focus on what matters Slides Recording","title":"Results"},{"location":"2022/10/06/cloud-tool-time-building-white-label-platforms/#congrats","text":"","title":"Congrats"},{"location":"2022/10/15/openfestbg-2022-hackaton/","text":"Last week at OpenFest Bulgaria codbex ' and Quanterall 's developers came together to demo the Low-Code power of Eclipse Dirigible. The technics were demonstrated also with the real products such as AVERATO and GenHub products. Congrats","title":"Open Fest 2022 - Low-Code Hackaton"},{"location":"2022/10/15/openfestbg-2022-hackaton/#congrats","text":"","title":"Congrats"},{"location":"2022/12/24/news-new-release-7-0/","text":"New version 7.0 has been released. Release is of Type B Features Adapting Fundamantals Styles library for the User Interface GraalJS integration optimizations OData engine improvements Debugger integration stabilization ECMA 2022 support Jobs perspective BPM Perspective Improvements & Fixes Add 'Ctrl+S' work on all editors Multiple \"Table Prefix\" during generation Form dialog doesn't remove hidden inputs from the required items Documents perspective is broken under macOS Form Base Editors to respond to Save All Event Improve front-end performance Configure an Object from configurations parameters The first input in the form dialog should be automatically focused Insert Data for Entities that had CSV data leads to records being deleted OAuth - Expired Token Issue OAuth - AWS Cognito Integration Pdf generation API gives an error when the 'rows' array is empty DAO Count Details Error on PostgreSQL Use IRestExceptionHandler instead of AbstractExceptionHandler Use IDirigibleModule instead of AbstractDirigibleModule Table prefix parameter to be used in preprocessing in custom queries in the model at generation Exception caused during runtime of dirigible Preserve Generation Metadata Processing of CSVIM database metadata leads to error on PostgreSQL Extract resources from ide-core to resources-core Use h2 in AbstractDirigibleTest Update Static Pages with Fundamental Styles Restrict the Entity Name to not contain spaces (and special symbols?) Disabled SCE causing a cross-site scripting vulnerability Add Caption property (in User Interface tab), to be used in the home page (launchpad) section Modified files displayed as newly added on the 'Difference' view Unrecoverable crash when right-clicking on a file in the Debugger perspective Spring - NoClassDefFoundError - StaticLoggerBinder Skip Generation for Non-Feed Entities In master-details, create detail function must be disabled if no master is selected In master-details, master key property to be hidden by default from table view UI template with Fundamentals EDM - Generator Refactoring Template Presentation (Listing) Enable/Disable Auto Formatting action Remove Derby entirely and replace it with H2 Logging improvements - reduce unnecessary garbage allocations Attempt to clone a huge project leads to infinite error messaging File -> Export All shows error When creating a new module in the Web IDE with the wrong path, Dirigible stops loading all modules Layout - Add right side view panel Server shuts down on wrong project.json Add create new blank file feature Base64 and Hex encode/decode methods do not operate as expected Move ide-templating to the right place Move api-facade-templating to the right place Create the new git views Add GraalVM Context out redirect Alter existing database tables, if modified in the model Enable uploading of more than one file at the same time Expand git branch API Jasmine and QUnit do not work API tests do not run Nested projects git status is not reported correctly Workspace - upload multiple files into a project Git status is not returned in most situations Showing more informative result in Result View Open file is not working Wiki Synchronizer Ignore Paths Files Explorer View Properties does not have any affect when selected Make a menu service CSVIM - Schema Should be Optional Move file collapses tree Cannot create new js service if file.js already exists CSVIM - Database type BIT not supported CSVIM Batch Processing of Large Content Creating a new file or folder should focus it Context menu should always be visible When creating a new file or folder, the directory tree collapses and has to be expanded manually Fix Check for Update in the Help drop-down menu Workspace - Add notification to unpublish on delete Copy Entity from External Model CSVIM not working on PostgreSQL Predelivered CSVIM/CSVIM not processed Defined Database Type Column Names are Missing in the Result View Remove unnecessary sliders from the Web IDE in Chrome (Windows 10) Link the \"Workspace\" dropdown boxes for Workspace and Import views Renaming a file makes a copy and does not unpublish the old one Error at the bottom does not disappear once the problem is fixed Folder and files in it are not saved to disk on move Mark modified/new/deleted files in Workspace View Workspace cannot be deleted Confirmation popups to not be browser based Can't move editor above console Show view menu overflows screen Menu does not close after changing focus Allow one workspace refresh at a time Extendable icons for files Refactor the menu json object Create file collapses tree Import files from zip, does not limit by file type Importing files from ZIP does not work Search view does not work When renaming a file, there are no restrictions which could result in multiple files and folders being created When multiple files with same name are opened in tabs, project name should be shown in the tab's title No error messages for unsuccessful cloning of projects Git statuses are not reported correctly for files Imported projects, folders and files should be automatically published Multiselect dropdown hides on each option change Some views should not be lazy loaded Datasource HikariCP Missing New File Options Spring - Keycloak Integration Import project view, does not limit by file type Show the latest execution status, message and time of a Job Enhance the Job API to support logging of a message which will be retained Retention period of the logs to be configurable Kebap menu in Workbench, Projects doesn't undisplay as expected Job Parameters handling Choices support for Job parameters Share project at root level Fix broken links in the Samples page Manually Set Job Parameters support Manually Triggering Job Preview showing ignored files Preview sometimes not updating Projects view - Fix rename file type change Projects view - fix path for child files and folders on rename Generate project.json for non-dirigible projects Layout - Left pane views not expanded when called BPMN - Open Editor Issue Job Parameters - Form Based Editor enhancement Job Parameters - Model and Persistence Fundamental Styles integration Workspace REST service should return metadata at any level Add base webjars required by the new design Renaming a folder in the workspace does not have any effect on registry Share Project Issues Change of Log Location Projects with root project.json issues Java 18 Support - Cannot build project Database - Simple data export to CSV Import projects with project.json Workspace is created in the users directory CSV Editor - Total Records Count js source code is exposed with /services/v4/web/ url prefix Introduce 'exposes' functionality Introduce Job Log entity Serialize correctly Null and Binary objects Introduce a Cleanup Service Registry API to be aware of 'webjars' as well Create combo service Scripting Exception Handler Spring Issue with Serialization Manage state of the available jobs from jobs view OData explicit and derived aggregation support Exclude root folders starting with '.' during project import Monaco - Pluggable file extensions support Monaco - Support for Freemarker Template Language Separate Perspective creation in the model File status feature Properties reorder Save button in extension editor doesn't work Separate dependent classes for Spring for reuse Websocket Handler is null in Spring Boot package Spring Boot package failed to load acorn.js module Put all the generated artefacts under a 'gen' folder Support for DOUBLE PRECISION Move the monaco editor to a webjar OData now uses row_num value as ID for HANA views Wrong URL for Launchpad template Table type in h2 is not supported SQL Type CHARACTER is not supported Wrong location of the launchpad files Enumerating files ignores the soft links Relation filed generation is incorrect OData join clause mapping table Copy existing to show prompt SearchIndex are not processed Procedure - Null Dates Issue Procedures - Support for nullable values Delete many to prompt only once Unable to pull changes from origin Close Connection Issue Git remote URL is not visible to the user Bearer authorization header is not recognized Minor fixes Statistics 79K+ Users 113K+ Sessions 195 Countries 499 Repositories in DirigibleLabs Operational Available packages for download - https://github.com/eclipse/dirigible/releases/tag/v7.0.0 Docker images at Docker Hub under DirigibleLabs organization: https://hub.docker.com/u/dirigiblelabs/ Maven Central artifacts by org.eclipse.dirigible namespace: https://search.maven.org/search?q=org.eclipse.dirigible The full list of bug-fixes and enhancements can be found here: https://github.com/eclipse/dirigible/milestone/48?closed=1 The source code is available at GitHub repository here: https://github.com/eclipse/dirigible/tree/7.0.0 The instant trial is updated accordingly with the released version here: http://trial.dirigible.io Enjoy!","title":"Release 7.0"},{"location":"2022/12/24/news-new-release-7-0/#features","text":"Adapting Fundamantals Styles library for the User Interface GraalJS integration optimizations OData engine improvements Debugger integration stabilization ECMA 2022 support Jobs perspective BPM Perspective","title":"Features"},{"location":"2022/12/24/news-new-release-7-0/#improvements-fixes","text":"Add 'Ctrl+S' work on all editors Multiple \"Table Prefix\" during generation Form dialog doesn't remove hidden inputs from the required items Documents perspective is broken under macOS Form Base Editors to respond to Save All Event Improve front-end performance Configure an Object from configurations parameters The first input in the form dialog should be automatically focused Insert Data for Entities that had CSV data leads to records being deleted OAuth - Expired Token Issue OAuth - AWS Cognito Integration Pdf generation API gives an error when the 'rows' array is empty DAO Count Details Error on PostgreSQL Use IRestExceptionHandler instead of AbstractExceptionHandler Use IDirigibleModule instead of AbstractDirigibleModule Table prefix parameter to be used in preprocessing in custom queries in the model at generation Exception caused during runtime of dirigible Preserve Generation Metadata Processing of CSVIM database metadata leads to error on PostgreSQL Extract resources from ide-core to resources-core Use h2 in AbstractDirigibleTest Update Static Pages with Fundamental Styles Restrict the Entity Name to not contain spaces (and special symbols?) Disabled SCE causing a cross-site scripting vulnerability Add Caption property (in User Interface tab), to be used in the home page (launchpad) section Modified files displayed as newly added on the 'Difference' view Unrecoverable crash when right-clicking on a file in the Debugger perspective Spring - NoClassDefFoundError - StaticLoggerBinder Skip Generation for Non-Feed Entities In master-details, create detail function must be disabled if no master is selected In master-details, master key property to be hidden by default from table view UI template with Fundamentals EDM - Generator Refactoring Template Presentation (Listing) Enable/Disable Auto Formatting action Remove Derby entirely and replace it with H2 Logging improvements - reduce unnecessary garbage allocations Attempt to clone a huge project leads to infinite error messaging File -> Export All shows error When creating a new module in the Web IDE with the wrong path, Dirigible stops loading all modules Layout - Add right side view panel Server shuts down on wrong project.json Add create new blank file feature Base64 and Hex encode/decode methods do not operate as expected Move ide-templating to the right place Move api-facade-templating to the right place Create the new git views Add GraalVM Context out redirect Alter existing database tables, if modified in the model Enable uploading of more than one file at the same time Expand git branch API Jasmine and QUnit do not work API tests do not run Nested projects git status is not reported correctly Workspace - upload multiple files into a project Git status is not returned in most situations Showing more informative result in Result View Open file is not working Wiki Synchronizer Ignore Paths Files Explorer View Properties does not have any affect when selected Make a menu service CSVIM - Schema Should be Optional Move file collapses tree Cannot create new js service if file.js already exists CSVIM - Database type BIT not supported CSVIM Batch Processing of Large Content Creating a new file or folder should focus it Context menu should always be visible When creating a new file or folder, the directory tree collapses and has to be expanded manually Fix Check for Update in the Help drop-down menu Workspace - Add notification to unpublish on delete Copy Entity from External Model CSVIM not working on PostgreSQL Predelivered CSVIM/CSVIM not processed Defined Database Type Column Names are Missing in the Result View Remove unnecessary sliders from the Web IDE in Chrome (Windows 10) Link the \"Workspace\" dropdown boxes for Workspace and Import views Renaming a file makes a copy and does not unpublish the old one Error at the bottom does not disappear once the problem is fixed Folder and files in it are not saved to disk on move Mark modified/new/deleted files in Workspace View Workspace cannot be deleted Confirmation popups to not be browser based Can't move editor above console Show view menu overflows screen Menu does not close after changing focus Allow one workspace refresh at a time Extendable icons for files Refactor the menu json object Create file collapses tree Import files from zip, does not limit by file type Importing files from ZIP does not work Search view does not work When renaming a file, there are no restrictions which could result in multiple files and folders being created When multiple files with same name are opened in tabs, project name should be shown in the tab's title No error messages for unsuccessful cloning of projects Git statuses are not reported correctly for files Imported projects, folders and files should be automatically published Multiselect dropdown hides on each option change Some views should not be lazy loaded Datasource HikariCP Missing New File Options Spring - Keycloak Integration Import project view, does not limit by file type Show the latest execution status, message and time of a Job Enhance the Job API to support logging of a message which will be retained Retention period of the logs to be configurable Kebap menu in Workbench, Projects doesn't undisplay as expected Job Parameters handling Choices support for Job parameters Share project at root level Fix broken links in the Samples page Manually Set Job Parameters support Manually Triggering Job Preview showing ignored files Preview sometimes not updating Projects view - Fix rename file type change Projects view - fix path for child files and folders on rename Generate project.json for non-dirigible projects Layout - Left pane views not expanded when called BPMN - Open Editor Issue Job Parameters - Form Based Editor enhancement Job Parameters - Model and Persistence Fundamental Styles integration Workspace REST service should return metadata at any level Add base webjars required by the new design Renaming a folder in the workspace does not have any effect on registry Share Project Issues Change of Log Location Projects with root project.json issues Java 18 Support - Cannot build project Database - Simple data export to CSV Import projects with project.json Workspace is created in the users directory CSV Editor - Total Records Count js source code is exposed with /services/v4/web/ url prefix Introduce 'exposes' functionality Introduce Job Log entity Serialize correctly Null and Binary objects Introduce a Cleanup Service Registry API to be aware of 'webjars' as well Create combo service Scripting Exception Handler Spring Issue with Serialization Manage state of the available jobs from jobs view OData explicit and derived aggregation support Exclude root folders starting with '.' during project import Monaco - Pluggable file extensions support Monaco - Support for Freemarker Template Language Separate Perspective creation in the model File status feature Properties reorder Save button in extension editor doesn't work Separate dependent classes for Spring for reuse Websocket Handler is null in Spring Boot package Spring Boot package failed to load acorn.js module Put all the generated artefacts under a 'gen' folder Support for DOUBLE PRECISION Move the monaco editor to a webjar OData now uses row_num value as ID for HANA views Wrong URL for Launchpad template Table type in h2 is not supported SQL Type CHARACTER is not supported Wrong location of the launchpad files Enumerating files ignores the soft links Relation filed generation is incorrect OData join clause mapping table Copy existing to show prompt SearchIndex are not processed Procedure - Null Dates Issue Procedures - Support for nullable values Delete many to prompt only once Unable to pull changes from origin Close Connection Issue Git remote URL is not visible to the user Bearer authorization header is not recognized Minor fixes","title":"Improvements &amp; Fixes"},{"location":"2022/12/24/news-new-release-7-0/#statistics","text":"79K+ Users 113K+ Sessions 195 Countries 499 Repositories in DirigibleLabs","title":"Statistics"},{"location":"2022/12/24/news-new-release-7-0/#operational","text":"Available packages for download - https://github.com/eclipse/dirigible/releases/tag/v7.0.0 Docker images at Docker Hub under DirigibleLabs organization: https://hub.docker.com/u/dirigiblelabs/ Maven Central artifacts by org.eclipse.dirigible namespace: https://search.maven.org/search?q=org.eclipse.dirigible The full list of bug-fixes and enhancements can be found here: https://github.com/eclipse/dirigible/milestone/48?closed=1 The source code is available at GitHub repository here: https://github.com/eclipse/dirigible/tree/7.0.0 The instant trial is updated accordingly with the released version here: http://trial.dirigible.io","title":"Operational"},{"location":"2022/12/24/news-new-release-7-0/#enjoy","text":"","title":"Enjoy!"},{"location":"2023/01/16/http-decorators/","text":"Eclipse Dirigible supports JavaScript decorators? Although decorators support is something new in Dirigible yet to be documented, we have plans to use them more and more. You may ask, how did we add support for them? Well, the secret ingredient is that internally GraalJS is used for executing JavaScript. If you have read my blog post about decorators you should have a basic idea of how we've done it. What do we use JavaScript decorators for? For some time now, we have been thinking of an easier-to-code and easier-to-read solution for writing REST APIs. The current way of writing RESTful services is via the rs module . At a first glance, this is pretty similar to the plain old NodeJS Express. We have a router and we define some routes: import { rs } from \"sdk/http\" // or if you use the CJS modules support // const rs = require(\"http/v4/rs\"); rs . service () . get ( \"/hello\" , ( ctx , req , res ) => res . println ( \"Hello there!\" );) . execute (); This approach has been working well but we've been hearing more and more about people wanting to write APIs in a way similar to Java Spring's and NestJS's annotation/decorator definitions. When the new GraalJS version supporting decorators was released, we decided to create a PoC for decorator-based APIs. The first thing we tried out was something like the following: import { Controller , Get } from \"sdk/http\" // or if you use the CJS modules support // const { Controller, Get } = require(\"http/v4/rs/decorators\"); @ Controller class MyApi { @ Get ( \"/test\" ) onGet ( req , res , ctx ) { res . println ( \"Hello there!\" ); } } While this was good enough for a PoC, it was still a bit more verbose than necessary for simple APIs. From what we have seen, people most often write an API that receives some request data and respond with some other data. So, we changed our design to the following: import { Controller , Get , Post } from \"sdk/http\" // or if you use the CJS modules support // const { Controller, Get, Post } = require(\"http/v4/rs/decorators\"); @ Controller class MyApi { @ Get ( \"/test\" ) onGet () { return \"Hello there!\" ; } @ Post ( \"/test\" ) onPost ( body ) { return { some : \"data\" } } } This change made writing simple APIs a lot easier - you just receive some data, and return some data. But what if you need to read some query parameters? Or headers? Or something that we have still not added support via just decorators? Well, you could still write your request handler like this: @ Post ( \"/test/:id\" ) onPost ( body , ctx ) { const id = ctx . req . params . id ; return { some : \"data\" , id : id } } By using the ctx argument of the request handler you can access the underlying request with ctx.req or the response object with ctx.res . Wrap up Whether using decorators for declaring REST APIs is the best way, of course, is debatable. Some people like using decorators, and some people like defining routes like in Express. Personally, I believe both solutions have their pros and cons and it's the developer's responsibility to choose the best approach for a given REST API. If you want to see all this for yourself, go ahead and try it out at Dirigible Trial .","title":"JavaScript Decorators in Eclipse Dirigible"},{"location":"2023/01/16/http-decorators/#eclipse-dirigible-supports-javascript-decorators","text":"Although decorators support is something new in Dirigible yet to be documented, we have plans to use them more and more. You may ask, how did we add support for them? Well, the secret ingredient is that internally GraalJS is used for executing JavaScript. If you have read my blog post about decorators you should have a basic idea of how we've done it.","title":"Eclipse Dirigible supports JavaScript decorators?"},{"location":"2023/01/16/http-decorators/#what-do-we-use-javascript-decorators-for","text":"For some time now, we have been thinking of an easier-to-code and easier-to-read solution for writing REST APIs. The current way of writing RESTful services is via the rs module . At a first glance, this is pretty similar to the plain old NodeJS Express. We have a router and we define some routes: import { rs } from \"sdk/http\" // or if you use the CJS modules support // const rs = require(\"http/v4/rs\"); rs . service () . get ( \"/hello\" , ( ctx , req , res ) => res . println ( \"Hello there!\" );) . execute (); This approach has been working well but we've been hearing more and more about people wanting to write APIs in a way similar to Java Spring's and NestJS's annotation/decorator definitions. When the new GraalJS version supporting decorators was released, we decided to create a PoC for decorator-based APIs. The first thing we tried out was something like the following: import { Controller , Get } from \"sdk/http\" // or if you use the CJS modules support // const { Controller, Get } = require(\"http/v4/rs/decorators\"); @ Controller class MyApi { @ Get ( \"/test\" ) onGet ( req , res , ctx ) { res . println ( \"Hello there!\" ); } } While this was good enough for a PoC, it was still a bit more verbose than necessary for simple APIs. From what we have seen, people most often write an API that receives some request data and respond with some other data. So, we changed our design to the following: import { Controller , Get , Post } from \"sdk/http\" // or if you use the CJS modules support // const { Controller, Get, Post } = require(\"http/v4/rs/decorators\"); @ Controller class MyApi { @ Get ( \"/test\" ) onGet () { return \"Hello there!\" ; } @ Post ( \"/test\" ) onPost ( body ) { return { some : \"data\" } } } This change made writing simple APIs a lot easier - you just receive some data, and return some data. But what if you need to read some query parameters? Or headers? Or something that we have still not added support via just decorators? Well, you could still write your request handler like this: @ Post ( \"/test/:id\" ) onPost ( body , ctx ) { const id = ctx . req . params . id ; return { some : \"data\" , id : id } } By using the ctx argument of the request handler you can access the underlying request with ctx.req or the response object with ctx.res .","title":"What do we use JavaScript decorators for?"},{"location":"2023/01/16/http-decorators/#wrap-up","text":"Whether using decorators for declaring REST APIs is the best way, of course, is debatable. Some people like using decorators, and some people like defining routes like in Express. Personally, I believe both solutions have their pros and cons and it's the developer's responsibility to choose the best approach for a given REST API. If you want to see all this for yourself, go ahead and try it out at Dirigible Trial .","title":"Wrap up"},{"location":"2023/03/31/news-new-release-8-0/","text":"New version 8.0 has been released. Release is of Type \u0410 Features Migrating backend services to Spring Boot Improvements & Fixes Migration of Configuraiton Service Migration of Extensions Service Unification of endpoint handling and URIs Migration of DataSources configuration Migration of DataSource Management Service Migration of Repository Service Migration of Registry Service Migration of Synchronization Service with full reimplementation Migration of Table Synchronizer Migration of View Synchronizer Migration of Schema Service Migration of Jobs Service Migration of Jobs Synchronizer Migration of Listeners Service Migration of Listeners Synchronizer Migration of Web Engine Service Migration of Expose Synchronizer Generic Data Store implementation based on Hibernate framework Migration of Assert API Migration of Test Runner and QUnit API Migration of Utils API Migration of BPM API Migration of CMS API Migration of Security API Migration of Extensions API Migration of Workspace Service Migration to JUnit5 Migration of Publisher Service Migration of Indexing API Migration of Websockets Service Migration of Messaging API Migration of Template API Deprecate Dynamic DataSources in favor of Declarative DataSources Migration of Security modules - Basic & Keycloak Migration of Wiki Service Migration of Confluence Synchronizer Migration of Markdown Synchronizer Migration of OData Service Migration of Docker images and deprecated old ones Migration of Web IDE Perspectives and Views Minor fixes Statistics 84K+ Users 120K+ Sessions 195 Countries Operational Available packages for download - https://github.com/eclipse/dirigible/releases/tag/v8.0.0 Docker images at Docker Hub under DirigibleLabs organization: https://hub.docker.com/u/dirigiblelabs/ Maven Central artifacts by org.eclipse.dirigible namespace: https://search.maven.org/search?q=org.eclipse.dirigible The full list of bug-fixes and enhancements can be found here: https://github.com/eclipse/dirigible/milestone/49?closed=1 The source code is available at GitHub repository here: https://github.com/eclipse/dirigible/tree/8.0.0 The instant trial is updated accordingly with the released version here: http://trial.dirigible.io Enjoy!","title":"Release 8.0"},{"location":"2023/03/31/news-new-release-8-0/#features","text":"Migrating backend services to Spring Boot","title":"Features"},{"location":"2023/03/31/news-new-release-8-0/#improvements-fixes","text":"Migration of Configuraiton Service Migration of Extensions Service Unification of endpoint handling and URIs Migration of DataSources configuration Migration of DataSource Management Service Migration of Repository Service Migration of Registry Service Migration of Synchronization Service with full reimplementation Migration of Table Synchronizer Migration of View Synchronizer Migration of Schema Service Migration of Jobs Service Migration of Jobs Synchronizer Migration of Listeners Service Migration of Listeners Synchronizer Migration of Web Engine Service Migration of Expose Synchronizer Generic Data Store implementation based on Hibernate framework Migration of Assert API Migration of Test Runner and QUnit API Migration of Utils API Migration of BPM API Migration of CMS API Migration of Security API Migration of Extensions API Migration of Workspace Service Migration to JUnit5 Migration of Publisher Service Migration of Indexing API Migration of Websockets Service Migration of Messaging API Migration of Template API Deprecate Dynamic DataSources in favor of Declarative DataSources Migration of Security modules - Basic & Keycloak Migration of Wiki Service Migration of Confluence Synchronizer Migration of Markdown Synchronizer Migration of OData Service Migration of Docker images and deprecated old ones Migration of Web IDE Perspectives and Views Minor fixes","title":"Improvements &amp; Fixes"},{"location":"2023/03/31/news-new-release-8-0/#statistics","text":"84K+ Users 120K+ Sessions 195 Countries","title":"Statistics"},{"location":"2023/03/31/news-new-release-8-0/#operational","text":"Available packages for download - https://github.com/eclipse/dirigible/releases/tag/v8.0.0 Docker images at Docker Hub under DirigibleLabs organization: https://hub.docker.com/u/dirigiblelabs/ Maven Central artifacts by org.eclipse.dirigible namespace: https://search.maven.org/search?q=org.eclipse.dirigible The full list of bug-fixes and enhancements can be found here: https://github.com/eclipse/dirigible/milestone/49?closed=1 The source code is available at GitHub repository here: https://github.com/eclipse/dirigible/tree/8.0.0 The instant trial is updated accordingly with the released version here: http://trial.dirigible.io","title":"Operational"},{"location":"2023/03/31/news-new-release-8-0/#enjoy","text":"","title":"Enjoy!"},{"location":"2023/09/26/java-and-graaljs-update/","text":"In the dynamic world of software development, staying up-to-date is key. Eclipse Dirigible, the popular open-source cloud development platform, has just taken a big leap by adopting Java 21 and GraalJS 23.1.0. Java 21 - Empowering Developers: Java 21 brings enhanced performance, security, and language features to Eclipse Dirigible, ensuring your projects run faster and more securely. You can explore the details in the Java 21 Release Notes . GraalJS 23.1.0 - JavaScript Excellence: GraalJS 23.1.0 boosts JavaScript execution speed and compatibility. It optimizes resource usage and supports polyglot programming. Dive into the specifics in the GraalJS 23.1.0 Changelog . Eclipse Dirigible's adoption of these technologies promises faster, more secure, and efficient cloud development for contributors. Try it out and experience the enhanced capabilities! Stay tuned for more updates from this open-source platform.","title":"Update to Java 21 and GraalJS 23.1.0"},{"location":"2023/09/26/java-and-graaljs-update/#java-21-empowering-developers","text":"Java 21 brings enhanced performance, security, and language features to Eclipse Dirigible, ensuring your projects run faster and more securely. You can explore the details in the Java 21 Release Notes .","title":"Java 21 - Empowering Developers:"},{"location":"2023/09/26/java-and-graaljs-update/#graaljs-2310-javascript-excellence","text":"GraalJS 23.1.0 boosts JavaScript execution speed and compatibility. It optimizes resource usage and supports polyglot programming. Dive into the specifics in the GraalJS 23.1.0 Changelog . Eclipse Dirigible's adoption of these technologies promises faster, more secure, and efficient cloud development for contributors. Try it out and experience the enhanced capabilities! Stay tuned for more updates from this open-source platform.","title":"GraalJS 23.1.0 - JavaScript Excellence:"},{"location":"2023/09/27/typescript-support/","text":"In the ever-evolving world of web development, staying on top of the latest technologies is crucial for success. Eclipse Dirigible, the open-source cloud development platform, has always been at the forefront of enabling developers to build innovative applications effortlessly. Now, we are thrilled to announce a major enhancement that will revolutionize your development experience: support for TypeScript! TypeScript in Eclipse Dirigible TypeScript is a statically typed superset of JavaScript that offers better tooling, enhanced code quality, and improved developer productivity. Its adoption has skyrocketed, making it a staple in modern web development. Eclipse Dirigible recognized the need for TypeScript support and has seamlessly integrated it into the platform. Lightning-Fast Compilation with esbuild Efficiency in the development cycle is essential, and at Eclipse Dirigible, we've seamlessly integrated esbuild , an ultra-fast JavaScript bundler and minifier, while preserving our in-system development model. This approach allows us to compile TypeScript code in a fraction of the time compared to other tools, ensuring that you can iterate quickly and see the results of your changes instantly. By preserving the in-system development model, we've not only enhanced the efficiency of the development process but also maintained the familiar workflow that our users value - just \"Save\" and see your code running. Execution with GraalJS Compiled TypeScript code is executed by GraalJS, a high-performance JavaScript runtime. This combination ensures that your applications run smoothly and efficiently, providing excellent runtime performance and a responsive user experience. No Configuration Hassles One of the most significant advantages of using TypeScript in Eclipse Dirigible is that you don't need to worry about configuring your project. There's no need to create custom tsconfig.json files or mess around with complex project configurations. You can jump right into writing your TypeScript code and focus on what matters most: building great applications. Effortless TypeScript Debugging Debugging TypeScript in Eclipse Dirigible is just as intuitive and efficient as debugging JavaScript. Our integrated development environment (IDE) provides a seamless debugging experience. Set breakpoints, inspect variables, and step through your TypeScript code effortlessly. Whether you're an experienced developer or new to TypeScript, our debugging capabilities simplify issue identification and resolution, ensuring you can create high-quality applications with confidence. Getting Started with TypeScript in Eclipse Dirigible To start writing TypeScript in Eclipse Dirigible, follow these simple steps: Create a New Project : If you don't already have a project, create a new one in Eclipse Dirigible. Create a TypeScript Service : Inside your project, create a new TypeScript Service using our predefined template. You should now have a file with the following content: import { response } from \"sdk/http\" ; response . println ( \"Hello World!\" ); Save : On Save, Eclipse Dirigible will automatically detect the TypeScript code and use esbuild to compile it into JavaScript. With the compiled JavaScript code ready, you can see your application running in the Preview component: Benefits of Using TypeScript in Eclipse Dirigible Improved Code Quality : TypeScript's static typing helps catch errors at compile-time, reducing runtime errors and enhancing code quality. Enhanced Tooling : Eclipse Dirigible's TypeScript support includes robust tooling, making development more efficient and less error-prone. Faster Development : The combination of esbuild and GraalJS means faster compilation and execution, enabling quicker development cycles. Simplified Setup : Say goodbye to complex configurations and focus on writing code. In Conclusion Eclipse Dirigible's support for TypeScript, powered by esbuild and GraalJS, is a game-changer for web developers. Whether you're building web applications, APIs, or microservices, you can now harness the benefits of TypeScript without the usual configuration hassles. Elevate your development experience and build high-quality applications with ease using Eclipse Dirigible. Ready to get started? Head over to the Eclipse Dirigible website and explore the possibilities of TypeScript development in this powerful cloud development platform. Happy coding!","title":"TypeScript support"},{"location":"2023/09/27/typescript-support/#typescript-in-eclipse-dirigible","text":"TypeScript is a statically typed superset of JavaScript that offers better tooling, enhanced code quality, and improved developer productivity. Its adoption has skyrocketed, making it a staple in modern web development. Eclipse Dirigible recognized the need for TypeScript support and has seamlessly integrated it into the platform.","title":"TypeScript in Eclipse Dirigible"},{"location":"2023/09/27/typescript-support/#lightning-fast-compilation-with-esbuild","text":"Efficiency in the development cycle is essential, and at Eclipse Dirigible, we've seamlessly integrated esbuild , an ultra-fast JavaScript bundler and minifier, while preserving our in-system development model. This approach allows us to compile TypeScript code in a fraction of the time compared to other tools, ensuring that you can iterate quickly and see the results of your changes instantly. By preserving the in-system development model, we've not only enhanced the efficiency of the development process but also maintained the familiar workflow that our users value - just \"Save\" and see your code running.","title":"Lightning-Fast Compilation with esbuild"},{"location":"2023/09/27/typescript-support/#execution-with-graaljs","text":"Compiled TypeScript code is executed by GraalJS, a high-performance JavaScript runtime. This combination ensures that your applications run smoothly and efficiently, providing excellent runtime performance and a responsive user experience.","title":"Execution with GraalJS"},{"location":"2023/09/27/typescript-support/#no-configuration-hassles","text":"One of the most significant advantages of using TypeScript in Eclipse Dirigible is that you don't need to worry about configuring your project. There's no need to create custom tsconfig.json files or mess around with complex project configurations. You can jump right into writing your TypeScript code and focus on what matters most: building great applications.","title":"No Configuration Hassles"},{"location":"2023/09/27/typescript-support/#effortless-typescript-debugging","text":"Debugging TypeScript in Eclipse Dirigible is just as intuitive and efficient as debugging JavaScript. Our integrated development environment (IDE) provides a seamless debugging experience. Set breakpoints, inspect variables, and step through your TypeScript code effortlessly. Whether you're an experienced developer or new to TypeScript, our debugging capabilities simplify issue identification and resolution, ensuring you can create high-quality applications with confidence.","title":"Effortless TypeScript Debugging"},{"location":"2023/09/27/typescript-support/#getting-started-with-typescript-in-eclipse-dirigible","text":"To start writing TypeScript in Eclipse Dirigible, follow these simple steps: Create a New Project : If you don't already have a project, create a new one in Eclipse Dirigible. Create a TypeScript Service : Inside your project, create a new TypeScript Service using our predefined template. You should now have a file with the following content: import { response } from \"sdk/http\" ; response . println ( \"Hello World!\" ); Save : On Save, Eclipse Dirigible will automatically detect the TypeScript code and use esbuild to compile it into JavaScript. With the compiled JavaScript code ready, you can see your application running in the Preview component:","title":"Getting Started with TypeScript in Eclipse Dirigible"},{"location":"2023/09/27/typescript-support/#benefits-of-using-typescript-in-eclipse-dirigible","text":"Improved Code Quality : TypeScript's static typing helps catch errors at compile-time, reducing runtime errors and enhancing code quality. Enhanced Tooling : Eclipse Dirigible's TypeScript support includes robust tooling, making development more efficient and less error-prone. Faster Development : The combination of esbuild and GraalJS means faster compilation and execution, enabling quicker development cycles. Simplified Setup : Say goodbye to complex configurations and focus on writing code.","title":"Benefits of Using TypeScript in Eclipse Dirigible"},{"location":"2023/09/27/typescript-support/#in-conclusion","text":"Eclipse Dirigible's support for TypeScript, powered by esbuild and GraalJS, is a game-changer for web developers. Whether you're building web applications, APIs, or microservices, you can now harness the benefits of TypeScript without the usual configuration hassles. Elevate your development experience and build high-quality applications with ease using Eclipse Dirigible. Ready to get started? Head over to the Eclipse Dirigible website and explore the possibilities of TypeScript development in this powerful cloud development platform. Happy coding!","title":"In Conclusion"},{"location":"2023/12/19/news-new-release-9-0/","text":"New version 9.0 has been released. Release is of Type \u0410 Features Data Store (backed by Hibernate) Applications Launchpad Subview Component MongoDB Support Snowflake Support Integrations Engine (backed by Apache Camel) Integrations Modeler (backed by Apache Karavan) FTP/SFTP Server Support for CMS S3 Support for CMS Modeler Improvements (regenerate) Data Import/Export in CSV (RDBMS) Data Import/Export in JSON (noSQL) Data Anonymization Support TypeScript Support Python Support ABAP Support Improvements & Fixes Custom Actions in Project Custom Actions for Entities Report Entity Improvements Filter Entity Support Contributing Details Entity in external Master Artefacts View Product Switch Component Centralized dependency management Selenide integrated for Tests Listeners message handling improvements New Widgets and Layouts React template for UI OAuth2 flow direct support Streaming API used for data export Minor fixes Operational Available packages for download - https://github.com/eclipse/dirigible/releases/tag/v9.0.0 Docker images at Docker Hub under DirigibleLabs organization: https://hub.docker.com/u/dirigiblelabs/ Maven Central artifacts by org.eclipse.dirigible namespace: https://search.maven.org/search?q=org.eclipse.dirigible The full list of bug-fixes and enhancements can be found here: https://github.com/eclipse/dirigible/milestone/52?closed=1 The source code is available at GitHub repository here: https://github.com/eclipse/dirigible/tree/9.0.0 The instant trial is updated accordingly with the released version here: http://trial.dirigible.io Enjoy!","title":"Release 9.0"},{"location":"2023/12/19/news-new-release-9-0/#features","text":"Data Store (backed by Hibernate) Applications Launchpad Subview Component MongoDB Support Snowflake Support Integrations Engine (backed by Apache Camel) Integrations Modeler (backed by Apache Karavan) FTP/SFTP Server Support for CMS S3 Support for CMS Modeler Improvements (regenerate) Data Import/Export in CSV (RDBMS) Data Import/Export in JSON (noSQL) Data Anonymization Support TypeScript Support Python Support ABAP Support","title":"Features"},{"location":"2023/12/19/news-new-release-9-0/#improvements-fixes","text":"Custom Actions in Project Custom Actions for Entities Report Entity Improvements Filter Entity Support Contributing Details Entity in external Master Artefacts View Product Switch Component Centralized dependency management Selenide integrated for Tests Listeners message handling improvements New Widgets and Layouts React template for UI OAuth2 flow direct support Streaming API used for data export Minor fixes","title":"Improvements &amp; Fixes"},{"location":"2023/12/19/news-new-release-9-0/#operational","text":"Available packages for download - https://github.com/eclipse/dirigible/releases/tag/v9.0.0 Docker images at Docker Hub under DirigibleLabs organization: https://hub.docker.com/u/dirigiblelabs/ Maven Central artifacts by org.eclipse.dirigible namespace: https://search.maven.org/search?q=org.eclipse.dirigible The full list of bug-fixes and enhancements can be found here: https://github.com/eclipse/dirigible/milestone/52?closed=1 The source code is available at GitHub repository here: https://github.com/eclipse/dirigible/tree/9.0.0 The instant trial is updated accordingly with the released version here: http://trial.dirigible.io","title":"Operational"},{"location":"2023/12/19/news-new-release-9-0/#enjoy","text":"","title":"Enjoy!"},{"location":"2024/03/26/multitenancy/","text":"Multitenancy in Eclipse Dirigible Multitenancy is becoming increasingly essential in cloud-based applications, enabling multiple users or organizations (tenants) to securely share the same resources while maintaining isolation. Usually, it takes a lot of time and effort to achieve multitenancy in your application. You must be really careful when you design and implement your application to ensure proper isolation between the tenants. Recently, we added multitenancy support in Eclipse Dirigible which helps you to achieve secure and reliable multitenancy with zero effort from your side. Since version 10.2.0 , Eclipse Dirigible is multitenant by default . We made all the essential application resources multitenant. This includes the following resources: - tables ( *.table ) - views ( *.view ) - schemas ( *.schema ) - CSVIMs ( *.csvim ) - datasources ( *.datasource ) - jobs ( *.job ) - Messaging API - listeners ( *.listener ) - Documents API (CMS) - OData ( *.odata ) If your existing applications use the above resources, they are already multitenant . All other resources are not multitenant and must be carefully used in multitenant scenarios. If you need some other resource type to become a multitenant, please create a new feature request in Eclipse Dirigible project. Current tenant determination Eclipse Dirigible determines the current tenant based on the used subdomain. For example, if your application's host is my-application.com and you open it via mytenant1.my-application.com , the current tenant which is resolved is the one which is registered for subdomain mytenant1 . If the tenant subdomain cannot be determined, the request is considered to be executed in the context of the default tenant. By default, the regex which is used to get the subdomain is ^([^\\.]+)\\..+$ . If you have more complex host, you can configure the regex using the dedicated configuration DIRIGIBLE_TENANT_SUBDOMAIN_REGEX . Tenant provisioning Registered tenants are stored in the Dirigible's system database. To register a new tenant, you simply have to insert a new entry in the corresponding table. An automated provisioning job will execute all the necessary work to provision the newly added tenant. You may need to wait a few minutes until the job is executed since it is executed regularly. Currently, it is configured to execute with initial delay of 30 seconds after start of the application and after that, it will execute at 15 minutes intervals. As part of the automated provisioning process, a dedicated default database random user, schema and datasource will be created for each tenant. To register a new tenant, follow the steps bellow: Add a new tenant INSERT INTO DIRIGIBLE_TENANTS (TENANT_ID, TENANT_NAME, TENANT_STATUS, TENANT_SUBDOMAIN) VALUES ('10e90b9f-94e5-4840-bb45-b7dd95082ba3', 'My Tenant 1', 'INITIAL', 'mytenant1' ); Add tenant users To be able to access the tenant using the registered subdomain, you have to register a user for your tenant. INSERT INTO DIRIGIBLE_USERS (USER_ID, USER_PASSWORD, USER_USERNAME, USER_TENANT_ID) VALUES ('93d2f6b5-3f6e-4d20-a1fa-1c9788761139', '$2a$10$R35KSyhNwEph..nS3RDJReXqcpGmE.oQtyCo5jZ.I3z1sb8X7dTYO', 'myuser1', '10e90b9f-94e5-4840-bb45-b7dd95082ba3'); Note: use BCrypt to encode the user's password. To automate the above steps, you can define these entries in *.csv files and register the files in a *.csvim file. Multitenant resources Tables, views and schemas Using these resources, you can describe the structures of your application's database. Once the resources are published, they are automatically created in the default tenant databases. CSVIMs CSVIMs are used to import predefined data into tables. Each csvim is imported in each tenant, once published. Datasources These resources are used to define datasources which later could be used by your application. For the default database, a dedicated datasource is created for each tenant as part of the provisioning tenant as described in tenant provisioning section . When you use the default datasource with name DefaultDB in your code, you actually use the dedicated tenant datasource. For all other datasource, you have to provide a separate *.datasource resource for each tenant with tenant id prefix in its name. For example, if you have a datasource with name MyDB and you use it from the context of a tenant with id 10e90b9f-94e5-4840-bb45-b7dd95082ba3 , a datasource with name 10e90b9f-94e5-4840-bb45-b7dd95082ba3_MyDB will be used. For backwards compatibility, the default tenant uses datasources without prefix. Jobs Jobs are used to schedule a background execution of a logic which is triggered based on the defined cron expression. For each job, a dedicated job is triggered for each tenant. Job execution log UI was enhanced to collect data for each tenant. Messaging API Using Eclipse Dirigible messaging API you can send/receive messages to/from queues and topics in synchronous manner. Depending on the current tenant context, messages are sent/received to/from dedicated tenant queues and topics. A tenant specific prefix is used for the destination names. For example, if you send a message to a topic with name mytopic and the current tenant is with id 10e90b9f-94e5-4840-bb45-b7dd95082ba3 , it will be sent to topic with name 10e90b9f-94e5-4840-bb45-b7dd95082ba3###mytopic . For backwards compatibility, such a prefix is not added for the default tenant. Listeners Listener resources are used to configure asynchronous code logic which will be executed when a new message is sent to queue or topic. The execution is executed in the context of the tenant for which the message is sent. Documents API (CMS) Documents API is used to manage documents. In the internal Eclipse Dirigible implementation, the file system is used. DIRIGIBLE_CMS_INTERNAL_ROOT_FOLDER configuration property could be provided to set the internal folder path. Tenant documents are isolated using a dedicated folder for each tenant. In the Amazon S3 scenario, a separate folder for each tenant is created in the configured bucket to achieve tenant isolation. The documents API will automatically use the corresponding tenant's folder. OData OData resources are used to expose your data using the OData protocol. All requests to the OData service are routed to the corresponding DefaultDB datasource for the current tenant. This way the OData works in tenant isolation. If you prefer the REST protocol, you can implement it using our API which is described here . In the implementation, you can use our databse APIs . Traceability To improve the logs traceability, current tenant id was added to the logs pattern. If a code is executed in non-tenant context, background is used in the logs for tenant id. Conclusion Using Eclipse Dirigible, you can achieve multitenancy with zero effort from your side. Enjoy low-code development using Eclipse Dirigible like never before! Resources Dirigible API documentation Dirigible repository Multitenancy wikipedia","title":"Multitenant applications with zero effort"},{"location":"2024/03/26/multitenancy/#multitenancy-in-eclipse-dirigible","text":"Multitenancy is becoming increasingly essential in cloud-based applications, enabling multiple users or organizations (tenants) to securely share the same resources while maintaining isolation. Usually, it takes a lot of time and effort to achieve multitenancy in your application. You must be really careful when you design and implement your application to ensure proper isolation between the tenants. Recently, we added multitenancy support in Eclipse Dirigible which helps you to achieve secure and reliable multitenancy with zero effort from your side. Since version 10.2.0 , Eclipse Dirigible is multitenant by default . We made all the essential application resources multitenant. This includes the following resources: - tables ( *.table ) - views ( *.view ) - schemas ( *.schema ) - CSVIMs ( *.csvim ) - datasources ( *.datasource ) - jobs ( *.job ) - Messaging API - listeners ( *.listener ) - Documents API (CMS) - OData ( *.odata ) If your existing applications use the above resources, they are already multitenant . All other resources are not multitenant and must be carefully used in multitenant scenarios. If you need some other resource type to become a multitenant, please create a new feature request in Eclipse Dirigible project.","title":"Multitenancy in Eclipse Dirigible"},{"location":"2024/03/26/multitenancy/#current-tenant-determination","text":"Eclipse Dirigible determines the current tenant based on the used subdomain. For example, if your application's host is my-application.com and you open it via mytenant1.my-application.com , the current tenant which is resolved is the one which is registered for subdomain mytenant1 . If the tenant subdomain cannot be determined, the request is considered to be executed in the context of the default tenant. By default, the regex which is used to get the subdomain is ^([^\\.]+)\\..+$ . If you have more complex host, you can configure the regex using the dedicated configuration DIRIGIBLE_TENANT_SUBDOMAIN_REGEX .","title":"Current tenant determination"},{"location":"2024/03/26/multitenancy/#tenant-provisioning","text":"Registered tenants are stored in the Dirigible's system database. To register a new tenant, you simply have to insert a new entry in the corresponding table. An automated provisioning job will execute all the necessary work to provision the newly added tenant. You may need to wait a few minutes until the job is executed since it is executed regularly. Currently, it is configured to execute with initial delay of 30 seconds after start of the application and after that, it will execute at 15 minutes intervals. As part of the automated provisioning process, a dedicated default database random user, schema and datasource will be created for each tenant. To register a new tenant, follow the steps bellow: Add a new tenant INSERT INTO DIRIGIBLE_TENANTS (TENANT_ID, TENANT_NAME, TENANT_STATUS, TENANT_SUBDOMAIN) VALUES ('10e90b9f-94e5-4840-bb45-b7dd95082ba3', 'My Tenant 1', 'INITIAL', 'mytenant1' ); Add tenant users To be able to access the tenant using the registered subdomain, you have to register a user for your tenant. INSERT INTO DIRIGIBLE_USERS (USER_ID, USER_PASSWORD, USER_USERNAME, USER_TENANT_ID) VALUES ('93d2f6b5-3f6e-4d20-a1fa-1c9788761139', '$2a$10$R35KSyhNwEph..nS3RDJReXqcpGmE.oQtyCo5jZ.I3z1sb8X7dTYO', 'myuser1', '10e90b9f-94e5-4840-bb45-b7dd95082ba3'); Note: use BCrypt to encode the user's password. To automate the above steps, you can define these entries in *.csv files and register the files in a *.csvim file.","title":"Tenant provisioning"},{"location":"2024/03/26/multitenancy/#multitenant-resources","text":"","title":"Multitenant resources"},{"location":"2024/03/26/multitenancy/#tables-views-and-schemas","text":"Using these resources, you can describe the structures of your application's database. Once the resources are published, they are automatically created in the default tenant databases.","title":"Tables, views and schemas"},{"location":"2024/03/26/multitenancy/#csvims","text":"CSVIMs are used to import predefined data into tables. Each csvim is imported in each tenant, once published.","title":"CSVIMs"},{"location":"2024/03/26/multitenancy/#datasources","text":"These resources are used to define datasources which later could be used by your application. For the default database, a dedicated datasource is created for each tenant as part of the provisioning tenant as described in tenant provisioning section . When you use the default datasource with name DefaultDB in your code, you actually use the dedicated tenant datasource. For all other datasource, you have to provide a separate *.datasource resource for each tenant with tenant id prefix in its name. For example, if you have a datasource with name MyDB and you use it from the context of a tenant with id 10e90b9f-94e5-4840-bb45-b7dd95082ba3 , a datasource with name 10e90b9f-94e5-4840-bb45-b7dd95082ba3_MyDB will be used. For backwards compatibility, the default tenant uses datasources without prefix.","title":"Datasources"},{"location":"2024/03/26/multitenancy/#jobs","text":"Jobs are used to schedule a background execution of a logic which is triggered based on the defined cron expression. For each job, a dedicated job is triggered for each tenant. Job execution log UI was enhanced to collect data for each tenant.","title":"Jobs"},{"location":"2024/03/26/multitenancy/#messaging-api","text":"Using Eclipse Dirigible messaging API you can send/receive messages to/from queues and topics in synchronous manner. Depending on the current tenant context, messages are sent/received to/from dedicated tenant queues and topics. A tenant specific prefix is used for the destination names. For example, if you send a message to a topic with name mytopic and the current tenant is with id 10e90b9f-94e5-4840-bb45-b7dd95082ba3 , it will be sent to topic with name 10e90b9f-94e5-4840-bb45-b7dd95082ba3###mytopic . For backwards compatibility, such a prefix is not added for the default tenant.","title":"Messaging API"},{"location":"2024/03/26/multitenancy/#listeners","text":"Listener resources are used to configure asynchronous code logic which will be executed when a new message is sent to queue or topic. The execution is executed in the context of the tenant for which the message is sent.","title":"Listeners"},{"location":"2024/03/26/multitenancy/#documents-api-cms","text":"Documents API is used to manage documents. In the internal Eclipse Dirigible implementation, the file system is used. DIRIGIBLE_CMS_INTERNAL_ROOT_FOLDER configuration property could be provided to set the internal folder path. Tenant documents are isolated using a dedicated folder for each tenant. In the Amazon S3 scenario, a separate folder for each tenant is created in the configured bucket to achieve tenant isolation. The documents API will automatically use the corresponding tenant's folder.","title":"Documents API (CMS)"},{"location":"2024/03/26/multitenancy/#odata","text":"OData resources are used to expose your data using the OData protocol. All requests to the OData service are routed to the corresponding DefaultDB datasource for the current tenant. This way the OData works in tenant isolation. If you prefer the REST protocol, you can implement it using our API which is described here . In the implementation, you can use our databse APIs .","title":"OData"},{"location":"2024/03/26/multitenancy/#traceability","text":"To improve the logs traceability, current tenant id was added to the logs pattern. If a code is executed in non-tenant context, background is used in the logs for tenant id.","title":"Traceability"},{"location":"2024/03/26/multitenancy/#conclusion","text":"Using Eclipse Dirigible, you can achieve multitenancy with zero effort from your side. Enjoy low-code development using Eclipse Dirigible like never before!","title":"Conclusion"},{"location":"2024/03/26/multitenancy/#resources","text":"Dirigible API documentation Dirigible repository Multitenancy wikipedia","title":"Resources"},{"location":"2024/04/05/custom-stack/","text":"Building Your Own Eclipse Dirigible Stack: A Step-by-Step Guide In the realm of enterprise development, customization often leads to optimization. Eclipse Dirigible, a cloud development platform, offers immense flexibility, allowing developers to tailor their development environments to specific needs. One such capability is creating a custom Eclipse Dirigible stack. This tutorial will walk you through the process of building your own stack from scratch. Overview What is a Custom Stack? A custom stack in Eclipse Dirigible is essentially a personalized environment tailored to your project's requirements. It involves setting up your development environment with custom configurations, branding, and additional functionalities as per your project needs. Follow the steps here to build your Eclipse Dirigible Custom Stack. Getting Started Prerequisites Before diving into the customization process, ensure you have the following prerequisites installed on your system: JDK 21+ (OpenJDK versions are also supported) Maven 3.5+ Node.js 18+ and npm esbuild 0.19+ TypeScript Compiler (tsc) 5.2+ Build Your Custom Stack Project Structure The first step is to create the project structure for your custom stack. This includes setting up Maven pom.xml files, static content resources, application.properties configuration files, and a Spring Boot Java class. Refer to the tutorial here for detailed instructions on creating the project structure. Build and Run Once the project structure is set up, navigate to the root folder of your project in the terminal and execute the following commands: To build the custom stack: mvn clean install To run the custom stack: java --add-opens java.base/java.lang=ALL-UNNAMED --add-opens java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED -jar application/target/custom-stack-application-*.jar You can access your custom stack at http://localhost:8080. Customization Steps Branding Customizing the branding of your custom stack adds a personal touch to your development environment. Follow the instructions here to rebrand your Eclipse Dirigible Custom Stack. Facade Creating Java Facade and TypeScript API enhances the functionality of your custom stack. The tutorial provides detailed steps on creating APIs Maven Module, Java Facade, and TypeScript API. Check out the tutorial here for a step-by-step guide. Advanced Facade Dive deeper into creating a TypeScript API for your custom stack with different versions of Java Facades. Learn about the native Java and TypeScript ways of implementing APIs. Refer to the tutorial here for detailed instructions. Dependency Integrating external Maven dependencies adds extra functionalities to your custom stack. Follow the steps in the tutorial here to add external Maven dependency for generating barcodes and using it in your Eclipse Dirigible Custom Stack. Conclusion By following this tutorial, you have successfully built your own Eclipse Dirigible stack tailored to your project's needs. With custom branding, APIs, and additional dependencies, your development environment is now optimized for efficient development. For more detailed instructions and resources, refer to the complete tutorial here . Start customizing and unleash the full potential of Eclipse Dirigible for your projects!","title":"Building Your Own Eclipse Dirigible Stack"},{"location":"2024/04/05/custom-stack/#building-your-own-eclipse-dirigible-stack-a-step-by-step-guide","text":"In the realm of enterprise development, customization often leads to optimization. Eclipse Dirigible, a cloud development platform, offers immense flexibility, allowing developers to tailor their development environments to specific needs. One such capability is creating a custom Eclipse Dirigible stack. This tutorial will walk you through the process of building your own stack from scratch.","title":"Building Your Own Eclipse Dirigible Stack: A Step-by-Step Guide"},{"location":"2024/04/05/custom-stack/#overview","text":"","title":"Overview"},{"location":"2024/04/05/custom-stack/#what-is-a-custom-stack","text":"A custom stack in Eclipse Dirigible is essentially a personalized environment tailored to your project's requirements. It involves setting up your development environment with custom configurations, branding, and additional functionalities as per your project needs. Follow the steps here to build your Eclipse Dirigible Custom Stack.","title":"What is a Custom Stack?"},{"location":"2024/04/05/custom-stack/#getting-started","text":"","title":"Getting Started"},{"location":"2024/04/05/custom-stack/#prerequisites","text":"Before diving into the customization process, ensure you have the following prerequisites installed on your system: JDK 21+ (OpenJDK versions are also supported) Maven 3.5+ Node.js 18+ and npm esbuild 0.19+ TypeScript Compiler (tsc) 5.2+","title":"Prerequisites"},{"location":"2024/04/05/custom-stack/#build-your-custom-stack","text":"","title":"Build Your Custom Stack"},{"location":"2024/04/05/custom-stack/#project-structure","text":"The first step is to create the project structure for your custom stack. This includes setting up Maven pom.xml files, static content resources, application.properties configuration files, and a Spring Boot Java class. Refer to the tutorial here for detailed instructions on creating the project structure.","title":"Project Structure"},{"location":"2024/04/05/custom-stack/#build-and-run","text":"Once the project structure is set up, navigate to the root folder of your project in the terminal and execute the following commands: To build the custom stack: mvn clean install To run the custom stack: java --add-opens java.base/java.lang=ALL-UNNAMED --add-opens java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED -jar application/target/custom-stack-application-*.jar You can access your custom stack at http://localhost:8080.","title":"Build and Run"},{"location":"2024/04/05/custom-stack/#customization-steps","text":"","title":"Customization Steps"},{"location":"2024/04/05/custom-stack/#branding","text":"Customizing the branding of your custom stack adds a personal touch to your development environment. Follow the instructions here to rebrand your Eclipse Dirigible Custom Stack.","title":"Branding"},{"location":"2024/04/05/custom-stack/#facade","text":"Creating Java Facade and TypeScript API enhances the functionality of your custom stack. The tutorial provides detailed steps on creating APIs Maven Module, Java Facade, and TypeScript API. Check out the tutorial here for a step-by-step guide.","title":"Facade"},{"location":"2024/04/05/custom-stack/#advanced-facade","text":"Dive deeper into creating a TypeScript API for your custom stack with different versions of Java Facades. Learn about the native Java and TypeScript ways of implementing APIs. Refer to the tutorial here for detailed instructions.","title":"Advanced Facade"},{"location":"2024/04/05/custom-stack/#dependency","text":"Integrating external Maven dependencies adds extra functionalities to your custom stack. Follow the steps in the tutorial here to add external Maven dependency for generating barcodes and using it in your Eclipse Dirigible Custom Stack.","title":"Dependency"},{"location":"2024/04/05/custom-stack/#conclusion","text":"By following this tutorial, you have successfully built your own Eclipse Dirigible stack tailored to your project's needs. With custom branding, APIs, and additional dependencies, your development environment is now optimized for efficient development. For more detailed instructions and resources, refer to the complete tutorial here . Start customizing and unleash the full potential of Eclipse Dirigible for your projects!","title":"Conclusion"},{"location":"2024/10/21/reports/","text":"Making Reports in Eclipse Dirigible: Step-by-Step Tutorial This sample demonstrates how to create a basic application with reports. It includes database tables, report queries, and the report model itself. Sections: Database tables Queries Report models Database tables This section shows how to create the database tables for the Reports application. Create a project named reports-sample-project . Navigate to the Database Perspective . In the SQL View enter the following script: CREATE TABLE PRODUCT ( PRODUCT_ID INT PRIMARY KEY AUTO_INCREMENT , PRODUCT_NAME VARCHAR ( 100 ) NOT NULL , PRODUCT_CATEGORY VARCHAR ( 100 ), PRODUCT_PRICE DECIMAL ( 10 , 2 ) NOT NULL , PRODUCT_STOCKQUANTITY INT DEFAULT 0 ); CREATE TABLE SALE ( SALE_ID INT PRIMARY KEY AUTO_INCREMENT , SALE_PRODUCT INT , SALE_CUSTOMER VARCHAR ( 100 ), SALE_DATE DATE NOT NULL , SALE_QUANTITYSOLD INT NOT NULL , SALE_TOTALAMOUNT DECIMAL ( 10 , 2 ) NOT NULL , FOREIGN KEY ( SALE_PRODUCT ) REFERENCES PRODUCT ( PRODUCT_ID )); Press the Run icon to execute the SQL script. Press the Refresh button to see the PRODUCT and SALE tables. Table content Right-click on the PRODUCT or SALE tables and select Show Contents . The table data would be displayed in the Result View . As the table is empty, there should be no data: In the SQL View enter the following script: INSERT INTO PRODUCT ( PRODUCT_NAME , PRODUCT_CATEGORY , PRODUCT_PRICE , PRODUCT_STOCKQUANTITY ) VALUES ( 'Apple' , 'Fruits' , 0 . 50 , 100 ), ( 'Banana' , 'Fruits' , 0 . 30 , 150 ), ( 'Milk' , 'Dairy' , 1 . 20 , 50 ), ( 'Bread' , 'Bakery' , 2 . 00 , 80 ), ( 'Cheese' , 'Dairy' , 3 . 50 , 40 ), ( 'Orange Juice' , 'Beverages' , 2 . 50 , 60 ); INSERT INTO SALE ( SALE_PRODUCT , SALE_CUSTOMER , SALE_DATE , SALE_QUANTITYSOLD , SALE_TOTALAMOUNT ) VALUES ( 1 , 'John Doe' , '2024-10-01' , 5 , 2 . 50 ), ( 2 , 'Jane Smith' , '2024-10-02' , 10 , 3 . 00 ), ( 3 , 'Emily Johnson' , '2024-10-03' , 2 , 2 . 40 ), ( 4 , 'Michael Brown' , '2024-10-04' , 1 , 2 . 00 ), ( 5 , 'Emma Wilson' , '2024-10-05' , 3 , 10 . 50 ), ( 6 , 'James Lee' , '2024-10-06' , 2 , 5 . 00 ); Press the Run icon to execute the SQL script. Right-click on the PRODUCT or SALE tables and select Show Contents . You should see the data inside. Queries The next step is to define the purpose of your reports. It\u2019s essential to create your queries early and verify that they function correctly. You can test this by pasting them into the Database perspective and ensuring they run without errors. Total sales by product SELECT P . PRODUCT_NAME , SUM ( S . SALE_QUANTITYSOLD ) AS TOTAL_QUANTITY_SOLD , SUM ( S . SALE_TOTALAMOUNT ) AS TOTAL_SALES_AMOUNT FROM SALE S JOIN PRODUCT P ON S . SALE_PRODUCT = P . PRODUCT_ID GROUP BY P . PRODUCT_NAME ORDER BY TOTAL_SALES_AMOUNT DESC ; Sales on a specific date SELECT P . PRODUCT_NAME , S . SALE_CUSTOMER , S . SALE_QUANTITYSOLD , S . SALE_TOTALAMOUNT FROM SALE S JOIN PRODUCT P ON S . SALE_PRODUCT = P . PRODUCT_ID WHERE S . SALE_DATE = : parameter ; Report models Total sales by product Right click on the Project -> New -> Report Model. Open the report-model.report file and assign a name to the report. Select the main table for the report; in our case, it\u2019s SALE. In the columns section, remove any columns you don\u2019t want to include in the report and set the aggregate functions. In the Joins section, define the joins by specifying their type and conditions. In the Ordering section, specify the column and the order for displaying the results. After completing these steps, a query is generated for the report. You can review it and make any necessary adjustments, adding or removing elements as needed. Report generation Right click ot .report file and choose generate Choose Application Report - Table for template and enter needed information in the next dialog Publish the project Open the index.html and view the report You can also print the report Sales on a specific date Right click on the Project -> New -> Report Model. Open the report-model.report file and assign a name to the report. Select the main table for the report; in our case, it\u2019s SALE. In the columns section, remove any columns you don\u2019t want to include in the report. In the Joins section, define the joins by specifying their type and conditions. In the Conditions section, define the criteria for filtering the results.. Note: ':date' is dynamic parameter which will be configured in step 7 In the Parameters section, specify their names, types, and initial values. After completing these steps, a query is generated for the report. You can review it and make any necessary adjustments, adding or removing elements as needed. Report generation Right click ot .report file and choose generate Choose Application Report - Table for template and enter needed information in the next dialog Publish the project Open the index.html and view the report You can now filter by date Conclusion We covered the benefits of using Dirigible's report builder, including ease of creating templates, integrating data sources, filtering with parameters, and generating customizable outputs like PDF files.","title":"Making Reports in Eclipse Dirigible"},{"location":"2024/10/21/reports/#making-reports-in-eclipse-dirigible-step-by-step-tutorial","text":"This sample demonstrates how to create a basic application with reports. It includes database tables, report queries, and the report model itself.","title":"Making Reports in Eclipse Dirigible: Step-by-Step Tutorial"},{"location":"2024/10/21/reports/#sections","text":"Database tables Queries Report models","title":"Sections:"},{"location":"2024/10/21/reports/#database-tables","text":"This section shows how to create the database tables for the Reports application. Create a project named reports-sample-project . Navigate to the Database Perspective . In the SQL View enter the following script: CREATE TABLE PRODUCT ( PRODUCT_ID INT PRIMARY KEY AUTO_INCREMENT , PRODUCT_NAME VARCHAR ( 100 ) NOT NULL , PRODUCT_CATEGORY VARCHAR ( 100 ), PRODUCT_PRICE DECIMAL ( 10 , 2 ) NOT NULL , PRODUCT_STOCKQUANTITY INT DEFAULT 0 ); CREATE TABLE SALE ( SALE_ID INT PRIMARY KEY AUTO_INCREMENT , SALE_PRODUCT INT , SALE_CUSTOMER VARCHAR ( 100 ), SALE_DATE DATE NOT NULL , SALE_QUANTITYSOLD INT NOT NULL , SALE_TOTALAMOUNT DECIMAL ( 10 , 2 ) NOT NULL , FOREIGN KEY ( SALE_PRODUCT ) REFERENCES PRODUCT ( PRODUCT_ID )); Press the Run icon to execute the SQL script. Press the Refresh button to see the PRODUCT and SALE tables.","title":"Database tables"},{"location":"2024/10/21/reports/#table-content","text":"Right-click on the PRODUCT or SALE tables and select Show Contents . The table data would be displayed in the Result View . As the table is empty, there should be no data: In the SQL View enter the following script: INSERT INTO PRODUCT ( PRODUCT_NAME , PRODUCT_CATEGORY , PRODUCT_PRICE , PRODUCT_STOCKQUANTITY ) VALUES ( 'Apple' , 'Fruits' , 0 . 50 , 100 ), ( 'Banana' , 'Fruits' , 0 . 30 , 150 ), ( 'Milk' , 'Dairy' , 1 . 20 , 50 ), ( 'Bread' , 'Bakery' , 2 . 00 , 80 ), ( 'Cheese' , 'Dairy' , 3 . 50 , 40 ), ( 'Orange Juice' , 'Beverages' , 2 . 50 , 60 ); INSERT INTO SALE ( SALE_PRODUCT , SALE_CUSTOMER , SALE_DATE , SALE_QUANTITYSOLD , SALE_TOTALAMOUNT ) VALUES ( 1 , 'John Doe' , '2024-10-01' , 5 , 2 . 50 ), ( 2 , 'Jane Smith' , '2024-10-02' , 10 , 3 . 00 ), ( 3 , 'Emily Johnson' , '2024-10-03' , 2 , 2 . 40 ), ( 4 , 'Michael Brown' , '2024-10-04' , 1 , 2 . 00 ), ( 5 , 'Emma Wilson' , '2024-10-05' , 3 , 10 . 50 ), ( 6 , 'James Lee' , '2024-10-06' , 2 , 5 . 00 ); Press the Run icon to execute the SQL script. Right-click on the PRODUCT or SALE tables and select Show Contents . You should see the data inside.","title":"Table content"},{"location":"2024/10/21/reports/#queries","text":"The next step is to define the purpose of your reports. It\u2019s essential to create your queries early and verify that they function correctly. You can test this by pasting them into the Database perspective and ensuring they run without errors. Total sales by product SELECT P . PRODUCT_NAME , SUM ( S . SALE_QUANTITYSOLD ) AS TOTAL_QUANTITY_SOLD , SUM ( S . SALE_TOTALAMOUNT ) AS TOTAL_SALES_AMOUNT FROM SALE S JOIN PRODUCT P ON S . SALE_PRODUCT = P . PRODUCT_ID GROUP BY P . PRODUCT_NAME ORDER BY TOTAL_SALES_AMOUNT DESC ; Sales on a specific date SELECT P . PRODUCT_NAME , S . SALE_CUSTOMER , S . SALE_QUANTITYSOLD , S . SALE_TOTALAMOUNT FROM SALE S JOIN PRODUCT P ON S . SALE_PRODUCT = P . PRODUCT_ID WHERE S . SALE_DATE = : parameter ;","title":"Queries"},{"location":"2024/10/21/reports/#report-models","text":"","title":"Report models"},{"location":"2024/10/21/reports/#total-sales-by-product","text":"Right click on the Project -> New -> Report Model. Open the report-model.report file and assign a name to the report. Select the main table for the report; in our case, it\u2019s SALE. In the columns section, remove any columns you don\u2019t want to include in the report and set the aggregate functions. In the Joins section, define the joins by specifying their type and conditions. In the Ordering section, specify the column and the order for displaying the results. After completing these steps, a query is generated for the report. You can review it and make any necessary adjustments, adding or removing elements as needed. Report generation Right click ot .report file and choose generate Choose Application Report - Table for template and enter needed information in the next dialog Publish the project Open the index.html and view the report You can also print the report","title":"Total sales by product"},{"location":"2024/10/21/reports/#sales-on-a-specific-date","text":"Right click on the Project -> New -> Report Model. Open the report-model.report file and assign a name to the report. Select the main table for the report; in our case, it\u2019s SALE. In the columns section, remove any columns you don\u2019t want to include in the report. In the Joins section, define the joins by specifying their type and conditions. In the Conditions section, define the criteria for filtering the results.. Note: ':date' is dynamic parameter which will be configured in step 7 In the Parameters section, specify their names, types, and initial values. After completing these steps, a query is generated for the report. You can review it and make any necessary adjustments, adding or removing elements as needed. Report generation Right click ot .report file and choose generate Choose Application Report - Table for template and enter needed information in the next dialog Publish the project Open the index.html and view the report You can now filter by date","title":"Sales on a specific date"},{"location":"2024/10/21/reports/#conclusion","text":"We covered the benefits of using Dirigible's report builder, including ease of creating templates, integrating data sources, filtering with parameters, and generating customizable outputs like PDF files.","title":"Conclusion"},{"location":"2024/11/18/build-and-release/","text":"Building and Releasing a Docker Image for an Eclipse Dirigible Application This blog post will guide you through the process of building and releasing a Docker image for an Eclipse Dirigible application. Prerequisites This guide assumes you already have created an Eclipse Dirigible application. Building the Docker Image A Docker image is the foundation for deploying your application. Below is an example Dockerfile of how to build your application. Dockerfile FROM dirigiblelabs/dirigible:latest COPY application target/dirigible/repository/root/registry/public/application # COPY application/node_modules/ target/dirigible/repository/root/registry/public/ ENV DIRIGIBLE_HOME_URL = /services/web/application/gen/application/index.html The first line in the Dockerfile sets up the Eclipse Dirigible Docker image as a base image. Note This is not a runtime image, meaning that Eclipse Dirigible\u2019s Web IDE will be incorporated into your application. The COPY command transfers your project directory (e.g., application ) to the public Registry , where the published content resides. (Optional) The second COPY command copies npm dependency packages listed in package.json . NPM Dependencies If your application doesn't have NPM dependencies, delete this line. If it does, run npm install before triggering the Docker build. The final line in the Dockerfile uses a Dirigible environment variable (see the Environment Variables Guide ) to set up the main page of your application. Handling Dependencies If your application requires NPM dependencies (otherwise, skip this step) , you\u2019ll need a package.json file. Eclipse Dirigible's Web IDE generates a project.json file by default. However, this file is Eclipse Dirigible-specific. You'll need to manually create a package.json file to declare your NPM dependencies. To install the dependencies, run npm install in the project directory. Note You can also use the Terminal view in Eclipse Dirigible to execute commands. project.json The project.json file, combined with the tsconfig.json , enables seamless builds of TypeScript files in your project. Additional commands can be declared in project.json and executed at different stages of the development lifecycle. It's important to note that project.json is only a design-time artifact, meaning its commands are executed only during development in Eclipse Dirigible's Web IDE. For more details, see Eclipse Dirigible Core Concepts . { \"guid\" : \"your-application-name\" , \"dependencies\" : [ { \"guid\" : \"first-dirigible-module\" , \"type\" : \"git\" , \"url\" : \"link-to-git-repo\" , \"branch\" : \"main\" }, { \"guid\" : \"second-dirigible-module\" , \"type\" : \"git\" , \"url\" : \"link-to-git-repo\" , \"branch\" : \"main\" } ], \"actions\" : [ { \"name\" : \"Build TypeScript\" , \"commands\" : [ { \"os\" : \"unix\" , \"command\" : \"tsc\" }, { \"os\" : \"windows\" , \"command\" : \"cmd /c tsc\" } ], \"registry\" : \"true\" } ] } package.json { \"name\" : \"@<github-org-name>/<application-name>\" , \"version\" : \"0.1.0\" , \"repository\" : { \"url\" : \"https://github.com/<github-org-name>/<application-repository>.git\" , \"type\" : \"git\" }, \"publishConfig\" : { \"registry\" : \"https://npm.pkg.github.com\" }, \"dependencies\" : { \"@<github-org-name>/<dependency-name>\" : \"0.1.0\" } } package.json Learn more about the package.json specification here . Build Workflow To automate the build process, create a .github/workflows/build.yaml file inside your GitHub repository. This GitHub Action will activate whenever changes are pushed to the main branch. GitHub Actions This guide assumes you are setting up CI/CD pipelines with GitHub Actions . If you use a different CI/CD tool, you can still adapt the steps below. Key Steps Install Node.js : Set up the Node.js environment. Install Dependencies : Download necessary NPM packages. If your application doesn\u2019t use dependencies, delete this step. TypeScript Build : Compile TypeScript files without errors. Docker Buildx : Build and push a multi-architecture Docker image. build.yaml name : Build - Application on : push : branches : - main jobs : main : runs-on : ubuntu-latest steps : - name : Checkout Repository uses : actions/checkout@v3 - name : Install NodeJS uses : actions/setup-node@v4 with : node-version : 18 - name : Install TypeScript compiler run : npm i -g typescript - name : TypeScript Build run : | cd path/to/your/tsconfig.json tsc --pretty > tsc-output.log 2>&1 || true grep -v 'TS2688' tsc-output.log > filtered-tsc-output.log cat filtered-tsc-output.log if grep -q 'error TS' filtered-tsc-output.log; then exit 1 fi - name : Install Dependencies run : | cd path/to/your/package.json echo \"registry=https://npm.pkg.github.com //npm.pkg.github.com/:_authToken=${{ secrets.DOCKER_PASSWORD }}\" > .npmrc npm install rm -rf .npmrc - name : Initialize Buildx run : | docker buildx create --name builder || true docker buildx use builder - name : Build and Push Docker Image run : | echo ${{ secrets.DOCKER_PASSWORD }} | docker login ghcr.io -u ${{ secrets.DOCKER_USERNAME }} --password-stdin docker buildx build --push --tag ghcr.io/your-github-username/your-application-name:latest -o type=image --platform=linux/arm64,linux/amd64 . Pull-Request Workflow This workflow validates Pull Requests by ensuring builds aren\u2019t disrupted. The build process is identical, but the image is not pushed to a registry. pull-request.yaml name : Pull Request - Application on : pull_request : branches : - main jobs : main : runs-on : ubuntu-latest steps : - name : Checkout Repository uses : actions/checkout@v3 - name : Install NodeJS uses : actions/setup-node@v4 with : node-version : 18 - name : Install TypeScript compiler run : npm i -g typescript - name : TypeScript Build run : | cd path/to/your/tsconfig.json tsc --pretty > tsc-output.log 2>&1 || true grep -v 'TS2688' tsc-output.log > filtered-tsc-output.log cat filtered-tsc-output.log if grep -q 'error TS' filtered-tsc-output.log; then exit 1 fi - name : Install Dependencies run : | cd path/to/your/package.json echo \"registry=https://npm.pkg.github.com //npm.pkg.github.com/:_authToken=${{ secrets.DOCKER_PASSWORD }}\" > .npmrc npm install rm -rf .npmrc - name : Initialize Buildx run : | docker buildx create --name builder || true docker buildx use builder - name : Build Docker Image run : | docker buildx build --tag your-application-name -o type=image --platform=linux/arm64,linux/amd64 . Release Workflow This workflow allows to manually trigger a release and tag the Docker image with a specific version. Key Steps Inputs : Accepts a release version as input. Git Operations : Creates a release branch and tags the repository. GitHub Release : Generates a GitHub release with metadata. Note Note that this workflow expects you to have a correct DOCKER_USERNAME and DOCKER_PASSWORD repository secrets that should be respectively your GitHub username and access token with enabled permissions to read and write. release.yaml name : Release - Application on : workflow_dispatch : inputs : release-version : description : Release Version required : true default : 1.0.0 run-name : 'version set to ${{ inputs.release-version }} for release' jobs : main : runs-on : ubuntu-latest steps : - name : Checkout Repository uses : actions/checkout@v3 with : fetch-depth : 0 - name : Install NodeJS uses : actions/setup-node@v4 with : node-version : 18 - name : Install TypeScript compiler run : npm i -g typescript - name : TypeScript Build run : | cd path/to/your/tsconfig.json tsc --pretty > tsc-output.log 2>&1 || true grep -v 'TS2688' tsc-output.log > filtered-tsc-output.log cat filtered-tsc-output.log if grep -q 'error TS' filtered-tsc-output.log; then exit 1 fi - name : Install Dependencies run : | cd path/to/your/package.json echo \"registry=https://npm.pkg.github.com //npm.pkg.github.com/:_authToken=${{ secrets.DOCKER_PASSWORD }}\" > .npmrc npm install rm -rf .npmrc - name : \"Configure Git\" run : | git fetch git checkout main # Checkout the branch you want to release from git config user.name \"$GITHUB_ACTOR\" git config user.email \"$GITHUB_ACTOR@users.noreply.github.com\" - name : Initialize Buildx run : | docker buildx create --name builder || true docker buildx use builder - name : Build and Push Docker Image run : | echo ${{ secrets.DOCKER_PASSWORD }} | docker login ghcr.io -u ${{ secrets.DOCKER_USERNAME }} --password-stdin docker buildx build --tag your-application-name -o type=image --platform=linux/arm64,linux/amd64 . docker buildx build --push --tag ghcr.io/your-github-username/your-application-name:${{ inputs.release-version }} -o type=image --platform=linux/arm64,linux/amd64 . - name : Create and Push Release Branch run : | git checkout -b release/${{ inputs.release-version }} git push --set-upstream origin release/${{ inputs.release-version }} - name : \"Create GitHub Release\" uses : softprops/action-gh-release@v1 with : token : ${{ secrets.GITHUB_TOKEN }} tag_name : v${{ inputs.release-version }} name : ${{ inputs.release-version }} draft : false prerelease : false files : | LICENSE body : | ## Release - ${{ inputs.release-version }} Activating the Release To trigger the release: Go to the Actions tab in your GitHub repository. Select the Release workflow. Click the Run workflow button. Enter the desired release version (e.g., 1.0.0 ) . Monitor the workflow for successful completion. Conclusion By combining Docker and GitHub Actions, you can automate the building, testing, and releasing of Docker images for Eclipse Dirigible applications, ensuring a consistent and efficient development pipeline.","title":"Building and releasing Docker image for Eclipse Dirigible Application"},{"location":"2024/11/18/build-and-release/#building-and-releasing-a-docker-image-for-an-eclipse-dirigible-application","text":"This blog post will guide you through the process of building and releasing a Docker image for an Eclipse Dirigible application. Prerequisites This guide assumes you already have created an Eclipse Dirigible application.","title":"Building and Releasing a Docker Image for an Eclipse Dirigible Application"},{"location":"2024/11/18/build-and-release/#building-the-docker-image","text":"A Docker image is the foundation for deploying your application. Below is an example Dockerfile of how to build your application.","title":"Building the Docker Image"},{"location":"2024/11/18/build-and-release/#dockerfile","text":"FROM dirigiblelabs/dirigible:latest COPY application target/dirigible/repository/root/registry/public/application # COPY application/node_modules/ target/dirigible/repository/root/registry/public/ ENV DIRIGIBLE_HOME_URL = /services/web/application/gen/application/index.html The first line in the Dockerfile sets up the Eclipse Dirigible Docker image as a base image. Note This is not a runtime image, meaning that Eclipse Dirigible\u2019s Web IDE will be incorporated into your application. The COPY command transfers your project directory (e.g., application ) to the public Registry , where the published content resides. (Optional) The second COPY command copies npm dependency packages listed in package.json . NPM Dependencies If your application doesn't have NPM dependencies, delete this line. If it does, run npm install before triggering the Docker build. The final line in the Dockerfile uses a Dirigible environment variable (see the Environment Variables Guide ) to set up the main page of your application.","title":"Dockerfile"},{"location":"2024/11/18/build-and-release/#handling-dependencies","text":"If your application requires NPM dependencies (otherwise, skip this step) , you\u2019ll need a package.json file. Eclipse Dirigible's Web IDE generates a project.json file by default. However, this file is Eclipse Dirigible-specific. You'll need to manually create a package.json file to declare your NPM dependencies. To install the dependencies, run npm install in the project directory. Note You can also use the Terminal view in Eclipse Dirigible to execute commands. project.json The project.json file, combined with the tsconfig.json , enables seamless builds of TypeScript files in your project. Additional commands can be declared in project.json and executed at different stages of the development lifecycle. It's important to note that project.json is only a design-time artifact, meaning its commands are executed only during development in Eclipse Dirigible's Web IDE. For more details, see Eclipse Dirigible Core Concepts . { \"guid\" : \"your-application-name\" , \"dependencies\" : [ { \"guid\" : \"first-dirigible-module\" , \"type\" : \"git\" , \"url\" : \"link-to-git-repo\" , \"branch\" : \"main\" }, { \"guid\" : \"second-dirigible-module\" , \"type\" : \"git\" , \"url\" : \"link-to-git-repo\" , \"branch\" : \"main\" } ], \"actions\" : [ { \"name\" : \"Build TypeScript\" , \"commands\" : [ { \"os\" : \"unix\" , \"command\" : \"tsc\" }, { \"os\" : \"windows\" , \"command\" : \"cmd /c tsc\" } ], \"registry\" : \"true\" } ] }","title":"Handling Dependencies"},{"location":"2024/11/18/build-and-release/#packagejson","text":"{ \"name\" : \"@<github-org-name>/<application-name>\" , \"version\" : \"0.1.0\" , \"repository\" : { \"url\" : \"https://github.com/<github-org-name>/<application-repository>.git\" , \"type\" : \"git\" }, \"publishConfig\" : { \"registry\" : \"https://npm.pkg.github.com\" }, \"dependencies\" : { \"@<github-org-name>/<dependency-name>\" : \"0.1.0\" } } package.json Learn more about the package.json specification here .","title":"package.json"},{"location":"2024/11/18/build-and-release/#build-workflow","text":"To automate the build process, create a .github/workflows/build.yaml file inside your GitHub repository. This GitHub Action will activate whenever changes are pushed to the main branch. GitHub Actions This guide assumes you are setting up CI/CD pipelines with GitHub Actions . If you use a different CI/CD tool, you can still adapt the steps below.","title":"Build Workflow"},{"location":"2024/11/18/build-and-release/#key-steps","text":"Install Node.js : Set up the Node.js environment. Install Dependencies : Download necessary NPM packages. If your application doesn\u2019t use dependencies, delete this step. TypeScript Build : Compile TypeScript files without errors. Docker Buildx : Build and push a multi-architecture Docker image.","title":"Key Steps"},{"location":"2024/11/18/build-and-release/#buildyaml","text":"name : Build - Application on : push : branches : - main jobs : main : runs-on : ubuntu-latest steps : - name : Checkout Repository uses : actions/checkout@v3 - name : Install NodeJS uses : actions/setup-node@v4 with : node-version : 18 - name : Install TypeScript compiler run : npm i -g typescript - name : TypeScript Build run : | cd path/to/your/tsconfig.json tsc --pretty > tsc-output.log 2>&1 || true grep -v 'TS2688' tsc-output.log > filtered-tsc-output.log cat filtered-tsc-output.log if grep -q 'error TS' filtered-tsc-output.log; then exit 1 fi - name : Install Dependencies run : | cd path/to/your/package.json echo \"registry=https://npm.pkg.github.com //npm.pkg.github.com/:_authToken=${{ secrets.DOCKER_PASSWORD }}\" > .npmrc npm install rm -rf .npmrc - name : Initialize Buildx run : | docker buildx create --name builder || true docker buildx use builder - name : Build and Push Docker Image run : | echo ${{ secrets.DOCKER_PASSWORD }} | docker login ghcr.io -u ${{ secrets.DOCKER_USERNAME }} --password-stdin docker buildx build --push --tag ghcr.io/your-github-username/your-application-name:latest -o type=image --platform=linux/arm64,linux/amd64 .","title":"build.yaml"},{"location":"2024/11/18/build-and-release/#pull-request-workflow","text":"This workflow validates Pull Requests by ensuring builds aren\u2019t disrupted. The build process is identical, but the image is not pushed to a registry.","title":"Pull-Request Workflow"},{"location":"2024/11/18/build-and-release/#pull-requestyaml","text":"name : Pull Request - Application on : pull_request : branches : - main jobs : main : runs-on : ubuntu-latest steps : - name : Checkout Repository uses : actions/checkout@v3 - name : Install NodeJS uses : actions/setup-node@v4 with : node-version : 18 - name : Install TypeScript compiler run : npm i -g typescript - name : TypeScript Build run : | cd path/to/your/tsconfig.json tsc --pretty > tsc-output.log 2>&1 || true grep -v 'TS2688' tsc-output.log > filtered-tsc-output.log cat filtered-tsc-output.log if grep -q 'error TS' filtered-tsc-output.log; then exit 1 fi - name : Install Dependencies run : | cd path/to/your/package.json echo \"registry=https://npm.pkg.github.com //npm.pkg.github.com/:_authToken=${{ secrets.DOCKER_PASSWORD }}\" > .npmrc npm install rm -rf .npmrc - name : Initialize Buildx run : | docker buildx create --name builder || true docker buildx use builder - name : Build Docker Image run : | docker buildx build --tag your-application-name -o type=image --platform=linux/arm64,linux/amd64 .","title":"pull-request.yaml"},{"location":"2024/11/18/build-and-release/#release-workflow","text":"This workflow allows to manually trigger a release and tag the Docker image with a specific version.","title":"Release Workflow"},{"location":"2024/11/18/build-and-release/#key-steps_1","text":"Inputs : Accepts a release version as input. Git Operations : Creates a release branch and tags the repository. GitHub Release : Generates a GitHub release with metadata. Note Note that this workflow expects you to have a correct DOCKER_USERNAME and DOCKER_PASSWORD repository secrets that should be respectively your GitHub username and access token with enabled permissions to read and write.","title":"Key Steps"},{"location":"2024/11/18/build-and-release/#releaseyaml","text":"name : Release - Application on : workflow_dispatch : inputs : release-version : description : Release Version required : true default : 1.0.0 run-name : 'version set to ${{ inputs.release-version }} for release' jobs : main : runs-on : ubuntu-latest steps : - name : Checkout Repository uses : actions/checkout@v3 with : fetch-depth : 0 - name : Install NodeJS uses : actions/setup-node@v4 with : node-version : 18 - name : Install TypeScript compiler run : npm i -g typescript - name : TypeScript Build run : | cd path/to/your/tsconfig.json tsc --pretty > tsc-output.log 2>&1 || true grep -v 'TS2688' tsc-output.log > filtered-tsc-output.log cat filtered-tsc-output.log if grep -q 'error TS' filtered-tsc-output.log; then exit 1 fi - name : Install Dependencies run : | cd path/to/your/package.json echo \"registry=https://npm.pkg.github.com //npm.pkg.github.com/:_authToken=${{ secrets.DOCKER_PASSWORD }}\" > .npmrc npm install rm -rf .npmrc - name : \"Configure Git\" run : | git fetch git checkout main # Checkout the branch you want to release from git config user.name \"$GITHUB_ACTOR\" git config user.email \"$GITHUB_ACTOR@users.noreply.github.com\" - name : Initialize Buildx run : | docker buildx create --name builder || true docker buildx use builder - name : Build and Push Docker Image run : | echo ${{ secrets.DOCKER_PASSWORD }} | docker login ghcr.io -u ${{ secrets.DOCKER_USERNAME }} --password-stdin docker buildx build --tag your-application-name -o type=image --platform=linux/arm64,linux/amd64 . docker buildx build --push --tag ghcr.io/your-github-username/your-application-name:${{ inputs.release-version }} -o type=image --platform=linux/arm64,linux/amd64 . - name : Create and Push Release Branch run : | git checkout -b release/${{ inputs.release-version }} git push --set-upstream origin release/${{ inputs.release-version }} - name : \"Create GitHub Release\" uses : softprops/action-gh-release@v1 with : token : ${{ secrets.GITHUB_TOKEN }} tag_name : v${{ inputs.release-version }} name : ${{ inputs.release-version }} draft : false prerelease : false files : | LICENSE body : | ## Release - ${{ inputs.release-version }}","title":"release.yaml"},{"location":"2024/11/18/build-and-release/#activating-the-release","text":"To trigger the release: Go to the Actions tab in your GitHub repository. Select the Release workflow. Click the Run workflow button. Enter the desired release version (e.g., 1.0.0 ) . Monitor the workflow for successful completion.","title":"Activating the Release"},{"location":"2024/11/18/build-and-release/#conclusion","text":"By combining Docker and GitHub Actions, you can automate the building, testing, and releasing of Docker images for Eclipse Dirigible applications, ensuring a consistent and efficient development pipeline.","title":"Conclusion"},{"location":"2024/11/20/dependson/","text":"The Depends on Feature in Eclipse Dirigible In this blog post, we introduce a new feature for building models in Eclipse Dirigible: the \"Depends on\" functionality. Previously, Dirigible allowed for visualising dropdowns based on key-value pairs, often displaying data by ID and showing the corresponding name or number. However, as we encountered more complex use cases, we realised the need for more advanced connections and filtering of options based on a specific indicator. One such use case was filtering a list of cities by the selected country. Scenarios Filtering Cities by Country Automatically Setting the Unit of Measurement (UoM) Expanding the \"Depends on\" Feature to work with different types of fields Filtering Cities by Country To explore this in more detail, consider the following model structure: Each city has a reference to the country it belongs to, typically stored as an ID. The solution we implemented was to filter the list of cities based on the selected country ID. This is where the \"Depends on\" section was introduced in the user interface properties of the modeller, allowing us to filter the list of cities based on the selected country. This solved the issue for simple relationships where the filter value was a direct part of the filtered entity. What this feature does is simply filter the cities list by the value of \"Country\" in the current entity. The dropdown for cities now functions with the following logic: \"Take the value from the Country property in the current entity, link it to the Country entity, retrieve the ID of the selected country, and filter the list of cities where City.Country matches Country.Id.\" Filtering Cities by Country To illustrate this, consider the following example. Suppose we have two countries in the application: Bulgaria ( ID 1 ) and Greece ( ID 2 ) . The city Sofia references Bulgaria, so its Country property is set to 1 . On the other hand, Athens references Greece, so its Country value is set to 2 . When Bulgaria is selected from the countries dropdown, the cities list is filtered by this choice. Dirigible uses the value from the Country property ( 1 ) , finds the corresponding Country entity with ID 1 , and filters the cities list where City.Country = Country.Id . Automatically Setting the Unit of Measurement (UoM) The next step is to define the purpose of your reports. The issue arose when we wanted to automatically set the unit of measurement (UoM) for a product when it was chosen in a sales order. The Product entity has a BaseUnit property, which is a reference to the primary unit of measurement for the product. However, when adding items to a sales order, we couldn't link the BaseUnit to the expected UoM because the \"Depends on\" feature could only filter entities by a field they contained (e.g., City by Country), not the other way around (e.g., UoM by Product). The solution was to define the property of the current entity whose value was needed, then identify the entity and property we aimed to reach. In this case, the logic was as follows: \"Take the value from the SalesOrderItem's Product, find the corresponding product entity, retrieve the value from the BaseUnit property, and filter the current UoM list where the ID matches the selected BaseUnit .\" Expanding the \"Depends on\" Feature to Work with Different Types of Field The next step was to expand the functionality of the \"Depends on\" feature, not only for dropdowns but also for other fields like text boxes, numbers, and more. By applying the same logic, we can now transfer product details such as price and VAT directly into the order items. These values can also be edited if necessary. The \"Filter by\" option is primarily used for lists, where the value from the selected property is not directly used but rather employed to filter the available options. Conclusion The introduction of the \"Depends on\" feature in Eclipse Dirigible significantly enhances the flexibility and usability of the platform, enabling more complex data relationships and dynamic filtering. Whether filtering cities by country, setting UoM for products, or transferring product details directly into order items, this feature provides a streamlined and efficient approach for handling interrelated entities. By expanding this functionality beyond dropdowns to other field types, Dirigible opens up new possibilities for creating robust and user-friendly applications.","title":"Depends On feature in Eclipse Dirigible"},{"location":"2024/11/20/dependson/#the-depends-on-feature-in-eclipse-dirigible","text":"In this blog post, we introduce a new feature for building models in Eclipse Dirigible: the \"Depends on\" functionality. Previously, Dirigible allowed for visualising dropdowns based on key-value pairs, often displaying data by ID and showing the corresponding name or number. However, as we encountered more complex use cases, we realised the need for more advanced connections and filtering of options based on a specific indicator. One such use case was filtering a list of cities by the selected country.","title":"The Depends on Feature in Eclipse Dirigible"},{"location":"2024/11/20/dependson/#scenarios","text":"Filtering Cities by Country Automatically Setting the Unit of Measurement (UoM) Expanding the \"Depends on\" Feature to work with different types of fields","title":"Scenarios"},{"location":"2024/11/20/dependson/#filtering-cities-by-country","text":"To explore this in more detail, consider the following model structure: Each city has a reference to the country it belongs to, typically stored as an ID. The solution we implemented was to filter the list of cities based on the selected country ID. This is where the \"Depends on\" section was introduced in the user interface properties of the modeller, allowing us to filter the list of cities based on the selected country. This solved the issue for simple relationships where the filter value was a direct part of the filtered entity. What this feature does is simply filter the cities list by the value of \"Country\" in the current entity. The dropdown for cities now functions with the following logic: \"Take the value from the Country property in the current entity, link it to the Country entity, retrieve the ID of the selected country, and filter the list of cities where City.Country matches Country.Id.\" Filtering Cities by Country To illustrate this, consider the following example. Suppose we have two countries in the application: Bulgaria ( ID 1 ) and Greece ( ID 2 ) . The city Sofia references Bulgaria, so its Country property is set to 1 . On the other hand, Athens references Greece, so its Country value is set to 2 . When Bulgaria is selected from the countries dropdown, the cities list is filtered by this choice. Dirigible uses the value from the Country property ( 1 ) , finds the corresponding Country entity with ID 1 , and filters the cities list where City.Country = Country.Id .","title":"Filtering Cities by Country"},{"location":"2024/11/20/dependson/#automatically-setting-the-unit-of-measurement-uom","text":"The next step is to define the purpose of your reports. The issue arose when we wanted to automatically set the unit of measurement (UoM) for a product when it was chosen in a sales order. The Product entity has a BaseUnit property, which is a reference to the primary unit of measurement for the product. However, when adding items to a sales order, we couldn't link the BaseUnit to the expected UoM because the \"Depends on\" feature could only filter entities by a field they contained (e.g., City by Country), not the other way around (e.g., UoM by Product). The solution was to define the property of the current entity whose value was needed, then identify the entity and property we aimed to reach. In this case, the logic was as follows: \"Take the value from the SalesOrderItem's Product, find the corresponding product entity, retrieve the value from the BaseUnit property, and filter the current UoM list where the ID matches the selected BaseUnit .\"","title":"Automatically Setting the Unit of Measurement (UoM)"},{"location":"2024/11/20/dependson/#expanding-the-depends-on-feature-to-work-with-different-types-of-field","text":"The next step was to expand the functionality of the \"Depends on\" feature, not only for dropdowns but also for other fields like text boxes, numbers, and more. By applying the same logic, we can now transfer product details such as price and VAT directly into the order items. These values can also be edited if necessary. The \"Filter by\" option is primarily used for lists, where the value from the selected property is not directly used but rather employed to filter the available options.","title":"Expanding the \"Depends on\" Feature to Work with Different Types of Field"},{"location":"2024/11/20/dependson/#conclusion","text":"The introduction of the \"Depends on\" feature in Eclipse Dirigible significantly enhances the flexibility and usability of the platform, enabling more complex data relationships and dynamic filtering. Whether filtering cities by country, setting UoM for products, or transferring product details directly into order items, this feature provides a streamlined and efficient approach for handling interrelated entities. By expanding this functionality beyond dropdowns to other field types, Dirigible opens up new possibilities for creating robust and user-friendly applications.","title":"Conclusion"},{"location":"2024/12/03/open-telemetry/","text":"Overview In today\u2019s fast-paced software development landscape, observability has become a cornerstone of resilient and high-performing systems. Observability is more than just logs , metrics , and traces \u2014 it\u2019s about gaining actionable insights into how your software behaves in production. That\u2019s where OpenTelemetry comes in, a powerful, vendor-neutral framework that simplifies collecting telemetry data and integrates seamlessly with major providers like Google Cloud Platform, AWS, and Azure. In our Eclipse Dirigible project, we embraced OpenTelemetry to enhance our observability practices. By instrumenting components such as Quartz jobs, Flowable BPM processes, Apache Camel routes, and TypeScript/JavaScript script executions, we achieved a comprehensive view of our system\u2019s behavior. Additionally, we exposed Spring Boot Actuator Metrics to provide even deeper insights into application health and performance. In this blog, we showcase the architecture of our local setup, provide step-by-step instructions to run it locally, and share examples of traces, metrics, and logs generated from a sample Dirigible project. Local OpenTelemetry stack As part of our observability implementation, we prepared a local OpenTelemetry stack implemented with Docker Compose , featuring OpenTelemetry Collector , Jaeger , Prometheus , Loki , and Grafana . While this setup enables powerful local monitoring, OpenTelemetry is versatile and can be integrated with any OpenTelemetry-compliant stack that supports it. Architecture To better understand how the components interact within our local setup, let's take a look at the architecture. The following diagram illustrates the flow of telemetry data through the system, showcasing how OpenTelemetry Collector integrates with Jaeger, Prometheus, Loki, and Grafana for comprehensive monitoring. Run steps There are different Docker Compose profiles which helps you to run the local OpenTelemetry stack depending on your scenario. In this blog we will run the profile which starts OpenTelemetry Collector, Jaeger, Prometheus, Loki, Grafana and latest Eclipse Dirigible image with configured OpenTelemetry Agent . More details about the different profiles could be found in this README . git clone --branch 10 .6.34 https://github.com/eclipse/dirigible.git dirigible cd dirigible/open-telemetry docker compose --profile dirigible-latest-image-with-agent up --detach --build Once started, all containers could be accessed using the following URLs: Container URL Eclipse Dirigible http://localhost:8080 Prometheus http://localhost:16686 Jaeger http://localhost:9090 Loki http://localhost:3100 Grafana http://localhost:3000/grafana Sample Eclipse Dirigible project We will use a sample Eclipse Dirigible project to demonstrate the observability functionalities. The project is located in this GitHub repository . It contains some common functionalities used in Eclipse Dirigible projects - REST endpoint, BPM (Flowable) process, asynchronous job (Quartz) and Camel routes. To run the application, follow the steps: Open Eclipse Dirigible UI at http://localhost:8080 and login using the default credentials admin / admin Go to Git perspective Click on Clone button Set https://github.com/dirigiblelabs/sample-open-telemetry.git for URL and click on Clone button Go back to the Workbench perspective Click on Publish All button The sample application is now published and ready to be explored. Out-of-the-Box telemetry data OpenTelemetry\u2019s agent instrumentation makes it remarkably easy to capture telemetry data with minimal effort. It provides built-in support for monitoring and collecting telemetry from many popular libraries and frameworks out of the box. It supports frameworks like Apache HttpClient, Quartz, Camel, Spring Web MVC, Java JDBC and so on. For a complete and up-to-date list of frameworks and libraries supported by the OpenTelemetry agent, visit the OpenTelemetry Java Instrumentation GitHub repository . The following JSON examples showcase the generated traces and metrics, captured for our sample Eclipse Dirigible application, by our observability setup. Traces The traces were exported using the Jaeger API endpoint . For a more detailed exploration, visit the Grafana dashboard or view them through the Jaeger UI . Click to expand the traces in JSON { \"data\" : [ { \"name\" : \"CREATE TABLE ./target/dirigible/h2/systemdb.QRTZ_LOCKS\" , \"spanKind\" : \"client\" }, { \"name\" : \"INSERT ./target/dirigible/h2/systemdb.ACT_GE_BYTEARRAY\" , \"spanKind\" : \"client\" }, { \"name\" : \"MarkdownRepository.findAll\" , \"spanKind\" : \"internal\" }, { \"name\" : \"Session.persist org.eclipse.dirigible.components.engine.camel.domain.Camel\" , \"spanKind\" : \"internal\" }, { \"name\" : \"synchronizer_BpmnSynchronizer_parse_execution\" , \"spanKind\" : \"internal\" }, { \"name\" : \"synchronizer_CamelSynchronizer_complete_execution\" , \"spanKind\" : \"internal\" }, { \"name\" : \"UPDATE ./target/dirigible/h2/systemdb.DIRIGIBLE_JOBS\" , \"spanKind\" : \"client\" }, { \"name\" : \"SELECT ./target/dirigible/h2/systemdb.DIRIGIBLE_EXTENSION_POINTS\" , \"spanKind\" : \"client\" }, { \"name\" : \"SELECT ./target/dirigible/h2/systemdb.DIRIGIBLE_SECURITY_ROLES\" , \"spanKind\" : \"client\" }, { \"name\" : \"SELECT ./target/dirigible/h2/systemdb.DIRIGIBLE_JOB_EMAILS\" , \"spanKind\" : \"client\" }, { \"name\" : \"GET /**\" , \"spanKind\" : \"server\" }, { \"name\" : \"GET /services/js/{projectName}/{*projectFilePath}\" , \"spanKind\" : \"server\" }, { \"name\" : \"SELECT ./target/dirigible/h2/systemdb.DIRIGIBLE_PROBLEMS\" , \"spanKind\" : \"client\" }, { \"name\" : \"GET /services/data/sources\" , \"spanKind\" : \"server\" }, { \"name\" : \"Session.persist org.eclipse.dirigible.components.jobs.domain.Job\" , \"spanKind\" : \"internal\" }, { \"name\" : \"SELECT org.eclipse.dirigible.components.tenants.domain.Tenant\" , \"spanKind\" : \"internal\" }, { \"name\" : \"SELECT org.eclipse.dirigible.components.data.store.domain.Entity\" , \"spanKind\" : \"internal\" }, { \"name\" : \"SELECT ./target/dirigible/h2/systemdb.DIRIGIBLE_DATA_VIEWS\" , \"spanKind\" : \"client\" }, { \"name\" : \"SELECT ./target/dirigible/h2/systemdb.DIRIGIBLE_ODATA\" , \"spanKind\" : \"client\" }, { \"name\" : \"TypeScriptEndpoint.get\" , \"spanKind\" : \"internal\" }, { \"name\" : \"SELECT ./target/dirigible/h2/systemdb.ACTIVEMQ_MSGS\" , \"spanKind\" : \"client\" }, { \"name\" : \"SELECT ./target/dirigible/h2/systemdb.DIRIGIBLE_CSVIM\" , \"spanKind\" : \"client\" }, { \"name\" : \"Session.merge org.eclipse.dirigible.components.data.store.domain.Entity\" , \"spanKind\" : \"internal\" }, { \"name\" : \"SELECT ./target/dirigible/h2/systemdb.DIRIGIBLE_DATA_SCHEMAS\" , \"spanKind\" : \"client\" }, { \"name\" : \"CREATE TABLE ./target/dirigible/h2/systemdb.QRTZ_TRIGGERS\" , \"spanKind\" : \"client\" }, { \"name\" : \"INSERT ./target/dirigible/h2/systemdb.QRTZ_CRON_TRIGGERS\" , \"spanKind\" : \"client\" }, { \"name\" : \"EntityRepository.findAll\" , \"spanKind\" : \"internal\" }, { \"name\" : \"JavascriptEndpoint.get\" , \"spanKind\" : \"internal\" }, { \"name\" : \"UPDATE ./target/dirigible/h2/systemdb.DIRIGIBLE_OPENAPI\" , \"spanKind\" : \"client\" }, { \"name\" : \"ODataRepository.findAll\" , \"spanKind\" : \"internal\" }, { \"name\" : \"Session.merge org.eclipse.dirigible.components.openapi.domain.OpenAPI\" , \"spanKind\" : \"internal\" }, { \"name\" : \"INSERT ./target/dirigible/h2/systemdb.QRTZ_FIRED_TRIGGERS\" , \"spanKind\" : \"client\" }, { \"name\" : \"Session.merge org.eclipse.dirigible.components.engine.camel.domain.Camel\" , \"spanKind\" : \"internal\" }, { \"name\" : \"ALTER TABLE ./target/dirigible/h2/systemdb.QRTZ_PAUSED_TRIGGER_GRPS\" , \"spanKind\" : \"client\" }, { \"name\" : \"ALTER TABLE ./target/dirigible/h2/systemdb.QRTZ_CALENDARS\" , \"spanKind\" : \"client\" }, { \"name\" : \"SELECT ./target/dirigible/h2/systemdb.DIRIGIBLE_TENANTS\" , \"spanKind\" : \"client\" }, { \"name\" : \"WebsocketRepository.saveAndFlush\" , \"spanKind\" : \"internal\" }, { \"name\" : \"UserRoleAssignmentRepository.findByUser\" , \"spanKind\" : \"internal\" }, { \"name\" : \"SELECT\" , \"spanKind\" : \"internal\" }, { \"name\" : \"INSERT ./target/dirigible/h2/systemdb.DIRIGIBLE_CAMEL\" , \"spanKind\" : \"client\" }, { \"name\" : \"INSERT ./target/dirigible/h2/systemdb.DIRIGIBLE_JOB_LOGS\" , \"spanKind\" : \"client\" }, { \"name\" : \"./target/dirigible/h2/systemdb\" , \"spanKind\" : \"client\" }, { \"name\" : \"CREATE INDEX ./target/dirigible/h2/systemdb\" , \"spanKind\" : \"client\" }, { \"name\" : \"defined.synchronize\" , \"spanKind\" : \"internal\" }, { \"name\" : \"GET /services/ide/problems/search\" , \"spanKind\" : \"server\" }, { \"name\" : \"SELECT ./target/dirigible/h2/systemdb.DIRIGIBLE_DEFINITIONS\" , \"spanKind\" : \"client\" }, { \"name\" : \"Session.persist org.eclipse.dirigible.components.engine.bpm.flowable.domain.Bpmn\" , \"spanKind\" : \"internal\" }, { \"name\" : \"JobRepository.findByName\" , \"spanKind\" : \"internal\" }, { \"name\" : \"SELECT org.eclipse.dirigible.components.data.sources.domain.DataSource\" , \"spanKind\" : \"internal\" }, { \"name\" : \"UPDATE ./target/dirigible/h2/systemdb.QRTZ_TRIGGERS\" , \"spanKind\" : \"client\" }, { \"name\" : \"synchronizer_WebsocketsSynchronizer_complete_execution\" , \"spanKind\" : \"internal\" }, { \"name\" : \"GET\" , \"spanKind\" : \"client\" }, { \"name\" : \"CamelRepository.findByKey\" , \"spanKind\" : \"internal\" }, { \"name\" : \"cron\" , \"spanKind\" : \"server\" }, { \"name\" : \"synchronizer_BpmnSynchronizer_complete_execution\" , \"spanKind\" : \"internal\" }, { \"name\" : \"CREATE TABLE ./target/dirigible/h2/systemdb.QRTZ_JOB_DETAILS\" , \"spanKind\" : \"client\" }, { \"name\" : \"SELECT ./target/dirigible/h2/systemdb.DIRIGIBLE_CONFLUENCE\" , \"spanKind\" : \"client\" }, { \"name\" : \"synchronizer_OpenAPISynchronizer_complete_execution\" , \"spanKind\" : \"internal\" }, { \"name\" : \"HttpServletResponseWrapper.sendError\" , \"spanKind\" : \"internal\" }, { \"name\" : \"DELETE ./target/dirigible/h2/systemdb.QRTZ_FIRED_TRIGGERS\" , \"spanKind\" : \"client\" }, { \"name\" : \"GET /services/data/definition/{datasource}\" , \"spanKind\" : \"server\" }, { \"name\" : \"ExtensionRepository.saveAndFlush\" , \"spanKind\" : \"internal\" }, { \"name\" : \"SchemaRepository.findAll\" , \"spanKind\" : \"internal\" }, { \"name\" : \"DataSourceRepository.saveAndFlush\" , \"spanKind\" : \"internal\" }, { \"name\" : \"SELECT ./target/dirigible/h2/systemdb.DIRIGIBLE_LISTENERS\" , \"spanKind\" : \"client\" }, { \"name\" : \"synchronizer_JobSynchronizer_complete_execution\" , \"spanKind\" : \"internal\" }, { \"name\" : \"OpenAPIRepository.findAll\" , \"spanKind\" : \"internal\" }, { \"name\" : \"ProblemRepository.count\" , \"spanKind\" : \"internal\" }, { \"name\" : \"TopologicalDepleter.deplete\" , \"spanKind\" : \"internal\" }, { \"name\" : \"SELECT org.eclipse.dirigible.components.extensions.domain.Extension\" , \"spanKind\" : \"internal\" }, { \"name\" : \"GET /services/data/metadata/{datasource}\" , \"spanKind\" : \"server\" }, { \"name\" : \"SELECT org.eclipse.dirigible.components.initializers.definition.Definition\" , \"spanKind\" : \"internal\" }, { \"name\" : \"ListenerRepository.findAll\" , \"spanKind\" : \"internal\" }, { \"name\" : \"INSERT ./target/dirigible/h2/systemdb.QRTZ_SIMPLE_TRIGGERS\" , \"spanKind\" : \"client\" }, { \"name\" : \"synchronizer_DataSourcesSynchronizer_complete_execution\" , \"spanKind\" : \"internal\" }, { \"name\" : \"OnCommittedResponseWrapper.sendRedirect\" , \"spanKind\" : \"internal\" }, { \"name\" : \"SELECT org.eclipse.dirigible.components.engine.wiki.domain.Markdown\" , \"spanKind\" : \"internal\" }, { \"name\" : \"CREATE ./target/dirigible/h2/defaultdb\" , \"spanKind\" : \"client\" }, { \"name\" : \"SELECT ./target/dirigible/h2/systemdb.ACT_HI_TASKINST\" , \"spanKind\" : \"client\" }, { \"name\" : \"ALTER TABLE ./target/dirigible/h2/systemdb.QRTZ_SIMPROP_TRIGGERS\" , \"spanKind\" : \"client\" }, { \"name\" : \"JobLogRepository.saveAndFlush\" , \"spanKind\" : \"internal\" }, { \"name\" : \"TableRepository.findAll\" , \"spanKind\" : \"internal\" }, { \"name\" : \"SELECT org.eclipse.dirigible.components.engine.camel.domain.Camel\" , \"spanKind\" : \"internal\" }, { \"name\" : \"SELECT ./target/dirigible/h2/systemdb.DIRIGIBLE_BPMN\" , \"spanKind\" : \"client\" }, { \"name\" : \"UPDATE ./target/dirigible/h2/systemdb.ACTIVEMQ_LOCK\" , \"spanKind\" : \"client\" }, { \"name\" : \"POST /*\" , \"spanKind\" : \"server\" }, { \"name\" : \"INSERT ./target/dirigible/h2/systemdb.DIRIGIBLE_DEFINITIONS\" , \"spanKind\" : \"client\" }, { \"name\" : \"ALTER table ./target/dirigible/h2/systemdb\" , \"spanKind\" : \"client\" }, { \"name\" : \"synchronizer_ExtensionsSynchronizer_complete_execution\" , \"spanKind\" : \"internal\" }, { \"name\" : \"UPDATE ./target/dirigible/h2/systemdb.QRTZ_SIMPLE_TRIGGERS\" , \"spanKind\" : \"client\" }, { \"name\" : \"UPDATE ./target/dirigible/h2/systemdb.DIRIGIBLE_SECURITY_ACCESS\" , \"spanKind\" : \"client\" }, { \"name\" : \"ViewRepository.findAll\" , \"spanKind\" : \"internal\" }, { \"name\" : \"UPDATE ./target/dirigible/h2/systemdb.DIRIGIBLE_ENTITIES\" , \"spanKind\" : \"client\" }, { \"name\" : \"BpmnRepository.saveAndFlush\" , \"spanKind\" : \"internal\" }, { \"name\" : \"SELECT org.eclipse.dirigible.components.data.structures.domain.Table\" , \"spanKind\" : \"internal\" }, { \"name\" : \"SELECT org.eclipse.dirigible.components.odata.domain.OData\" , \"spanKind\" : \"internal\" }, { \"name\" : \"Session.merge org.eclipse.dirigible.components.data.sources.domain.DataSource\" , \"spanKind\" : \"internal\" }, { \"name\" : \"synchronizer_ExtensionPointsSynchronizer_complete_execution\" , \"spanKind\" : \"internal\" }, { \"name\" : \"Transaction.commit\" , \"spanKind\" : \"internal\" }, { \"name\" : \"SELECT org.eclipse.dirigible.components.extensions.domain.ExtensionPoint\" , \"spanKind\" : \"internal\" }, { \"name\" : \"UPDATE ./target/dirigible/h2/systemdb.DIRIGIBLE_CAMEL\" , \"spanKind\" : \"client\" }, { \"name\" : \"UPDATE ./target/dirigible/h2/systemdb.DIRIGIBLE_EXTENSIONS\" , \"spanKind\" : \"client\" }, { \"name\" : \"SELECT ./target/dirigible/h2/systemdb.DIRIGIBLE_WEBSOCKETS\" , \"spanKind\" : \"client\" }, { \"name\" : \"Session.merge org.eclipse.dirigible.components.engine.bpm.flowable.domain.Bpmn\" , \"spanKind\" : \"internal\" }, { \"name\" : \"EntityRepository.saveAndFlush\" , \"spanKind\" : \"internal\" }, { \"name\" : \"SELECT ./target/dirigible/h2/systemdb.ACT_RU_TASK\" , \"spanKind\" : \"client\" }, { \"name\" : \"GET /services/data/metadata/\" , \"spanKind\" : \"server\" }, { \"name\" : \"defined.test-job\" , \"spanKind\" : \"internal\" }, { \"name\" : \"SELECT ./target/dirigible/h2/systemdb.DIRIGIBLE_DATA_TABLES\" , \"spanKind\" : \"client\" }, { \"name\" : \"GET /services/js/all-dts\" , \"spanKind\" : \"server\" }, { \"name\" : \"SELECT org.eclipse.dirigible.components.data.csvim.domain.Csvim\" , \"spanKind\" : \"internal\" }, { \"name\" : \"ProblemRepository.findProblemsByConditionAndLimit\" , \"spanKind\" : \"internal\" }, { \"name\" : \"INSERT ./target/dirigible/h2/systemdb.DIRIGIBLE_JOBS\" , \"spanKind\" : \"client\" }, { \"name\" : \"INSERT ./target/dirigible/h2/systemdb.DIRIGIBLE_BPMN\" , \"spanKind\" : \"client\" }, { \"name\" : \"WebsocketRepository.findAll\" , \"spanKind\" : \"internal\" }, { \"name\" : \"GET /public/js/{projectName}/{*projectFilePath}\" , \"spanKind\" : \"server\" }, { \"name\" : \"SELECT DIRIGIBLE_PROBLEMS\" , \"spanKind\" : \"internal\" }, { \"name\" : \"CREATE TABLE ./target/dirigible/h2/systemdb.QRTZ_SIMPLE_TRIGGERS\" , \"spanKind\" : \"client\" }, { \"name\" : \"SELECT org.eclipse.dirigible.components.jobs.domain.Job\" , \"spanKind\" : \"internal\" }, { \"name\" : \"CsvimRepository.findAll\" , \"spanKind\" : \"internal\" }, { \"name\" : \"SELECT ./target/dirigible/h2/systemdb.ACT_RU_JOB\" , \"spanKind\" : \"client\" }, { \"name\" : \"SELECT ./target/dirigible/h2/systemdb.ACT_RE_PROCDEF\" , \"spanKind\" : \"client\" }, { \"name\" : \"POST\" , \"spanKind\" : \"client\" }, { \"name\" : \"SELECT ./target/dirigible/h2/systemdb.ACT_GE_PROPERTY\" , \"spanKind\" : \"client\" }, { \"name\" : \"SELECT org.eclipse.dirigible.components.listeners.domain.Listener\" , \"spanKind\" : \"internal\" }, { \"name\" : \"SELECT ./target/dirigible/h2/systemdb.DIRIGIBLE_OPENAPI\" , \"spanKind\" : \"client\" }, { \"name\" : \"CREATE table ./target/dirigible/h2/defaultdb\" , \"spanKind\" : \"client\" }, { \"name\" : \"JobEmailRepository.findAll\" , \"spanKind\" : \"internal\" }, { \"name\" : \"ALTER TABLE ./target/dirigible/h2/systemdb.QRTZ_FIRED_TRIGGERS\" , \"spanKind\" : \"client\" }, { \"name\" : \"CREATE TABLE ./target/dirigible/h2/systemdb.QRTZ_CALENDARS\" , \"spanKind\" : \"client\" }, { \"name\" : \"SELECT org.eclipse.dirigible.components.openapi.domain.OpenAPI\" , \"spanKind\" : \"internal\" }, { \"name\" : \"UPDATE ./target/dirigible/h2/systemdb.DIRIGIBLE_DEFINITIONS\" , \"spanKind\" : \"client\" }, { \"name\" : \"CREATE TABLE ./target/dirigible/h2/systemdb.QRTZ_BLOB_TRIGGERS\" , \"spanKind\" : \"client\" }, { \"name\" : \"SELECT ./target/dirigible/h2/systemdb.DIRIGIBLE_SECURITY_ACCESS\" , \"spanKind\" : \"client\" }, { \"name\" : \"SELECT org.eclipse.dirigible.components.data.structures.domain.View\" , \"spanKind\" : \"internal\" }, { \"name\" : \"DataSourceRepository.findAll\" , \"spanKind\" : \"internal\" }, { \"name\" : \"ALTER TABLE ./target/dirigible/h2/systemdb.ACTIVEMQ_ACKS\" , \"spanKind\" : \"client\" }, { \"name\" : \"INSERT ./target/dirigible/h2/systemdb.QRTZ_TRIGGERS\" , \"spanKind\" : \"client\" }, { \"name\" : \"system.TenantsProvisioningJob\" , \"spanKind\" : \"internal\" }, { \"name\" : \"AccessRepository.findAll\" , \"spanKind\" : \"internal\" }, { \"name\" : \"SELECT ./target/dirigible/h2/systemdb.ACTIVEMQ_ACKS\" , \"spanKind\" : \"client\" }, { \"name\" : \"RoleRepository.findAll\" , \"spanKind\" : \"internal\" }, { \"name\" : \"SELECT ./target/dirigible/h2/systemdb.QRTZ_LOCKS\" , \"spanKind\" : \"client\" }, { \"name\" : \"SELECT ./target/dirigible/h2/systemdb.DIRIGIBLE_JOB_PARAMETERS\" , \"spanKind\" : \"client\" }, { \"name\" : \"SELECT org.eclipse.dirigible.components.security.domain.Access\" , \"spanKind\" : \"internal\" }, { \"name\" : \"SELECT ./target/dirigible/h2/systemdb.ACT_PROCDEF_INFO\" , \"spanKind\" : \"client\" }, { \"name\" : \"INSERT ./target/dirigible/h2/systemdb.QRTZ_LOCKS\" , \"spanKind\" : \"client\" }, { \"name\" : \"UPDATE ./target/dirigible/h2/systemdb.DIRIGIBLE_WEBSOCKETS\" , \"spanKind\" : \"client\" }, { \"name\" : \"UPDATE ./target/dirigible/h2/systemdb.QRTZ_SCHEDULER_STATE\" , \"spanKind\" : \"client\" }, { \"name\" : \"ConfluenceRepository.findAll\" , \"spanKind\" : \"internal\" }, { \"name\" : \"SELECT ./target/dirigible/h2/systemdb.DIRIGIBLE_DATA_SOURCE_PROPERTIES\" , \"spanKind\" : \"client\" }, { \"name\" : \"SELECT ./target/dirigible/h2/systemdb.ACT_HI_ACTINST\" , \"spanKind\" : \"client\" }, { \"name\" : \"CREATE TABLE ./target/dirigible/h2/systemdb.ACTIVEMQ_ACKS\" , \"spanKind\" : \"client\" }, { \"name\" : \"OpenAPIRepository.saveAndFlush\" , \"spanKind\" : \"internal\" }, { \"name\" : \"synchronizer_RolesSynchronizer_cleanup_execution\" , \"spanKind\" : \"internal\" }, { \"name\" : \"DefinitionRepository.saveAndFlush\" , \"spanKind\" : \"internal\" }, { \"name\" : \"OnCommittedResponseWrapper.sendError\" , \"spanKind\" : \"internal\" }, { \"name\" : \"ALTER TABLE ./target/dirigible/h2/systemdb.QRTZ_JOB_DETAILS\" , \"spanKind\" : \"client\" }, { \"name\" : \"SELECT org.eclipse.dirigible.components.websockets.domain.Websocket\" , \"spanKind\" : \"internal\" }, { \"name\" : \"GET /services/web/{*path}\" , \"spanKind\" : \"server\" }, { \"name\" : \"SELECT ./target/dirigible/h2/systemdb.DIRIGIBLE_USERS\" , \"spanKind\" : \"client\" }, { \"name\" : \"CamelRepository.findAll\" , \"spanKind\" : \"internal\" }, { \"name\" : \"synchronizer_EntitySynchronizer_complete_execution\" , \"spanKind\" : \"internal\" }, { \"name\" : \"SELECT INFORMATION_SCHEMA.SEQUENCES\" , \"spanKind\" : \"client\" }, { \"name\" : \"SELECT ./target/dirigible/h2/systemdb\" , \"spanKind\" : \"client\" }, { \"name\" : \"TenantRepository.findByStatus\" , \"spanKind\" : \"internal\" }, { \"name\" : \"WebSocketMessageBrokerStats$$Lambda.run\" , \"spanKind\" : \"internal\" }, { \"name\" : \"CREATE TABLE ./target/dirigible/h2/systemdb.ACTIVEMQ_MSGS\" , \"spanKind\" : \"client\" }, { \"name\" : \"JobRepository.findAll\" , \"spanKind\" : \"internal\" }, { \"name\" : \"SELECT org.eclipse.dirigible.components.jobs.domain.JobEmail\" , \"spanKind\" : \"internal\" }, { \"name\" : \"GET /services/ide/workspaces\" , \"spanKind\" : \"server\" }, { \"name\" : \"SELECT org.eclipse.dirigible.components.ide.problems.domain.Problem\" , \"spanKind\" : \"internal\" }, { \"name\" : \"AccessRepository.saveAndFlush\" , \"spanKind\" : \"internal\" }, { \"name\" : \"SpringCronConsumer.run\" , \"spanKind\" : \"internal\" }, { \"name\" : \"GET /services/data/\" , \"spanKind\" : \"server\" }, { \"name\" : \"GET /services/data/definition/\" , \"spanKind\" : \"server\" }, { \"name\" : \"ALTER TABLE ./target/dirigible/h2/systemdb.QRTZ_SCHEDULER_STATE\" , \"spanKind\" : \"client\" }, { \"name\" : \"ExtensionPointRepository.findAll\" , \"spanKind\" : \"internal\" }, { \"name\" : \"Session.merge org.eclipse.dirigible.components.jobs.domain.Job\" , \"spanKind\" : \"internal\" }, { \"name\" : \"GET /webjars/**\" , \"spanKind\" : \"server\" }, { \"name\" : \"Session.persist org.eclipse.dirigible.components.initializers.definition.Definition\" , \"spanKind\" : \"internal\" }, { \"name\" : \"DefinitionRepository.findAll\" , \"spanKind\" : \"internal\" }, { \"name\" : \"JobRepository.saveAndFlush\" , \"spanKind\" : \"internal\" }, { \"name\" : \"SELECT ./target/dirigible/h2/systemdb.DIRIGIBLE_DATA_SOURCES\" , \"spanKind\" : \"client\" }, { \"name\" : \"UPDATE ./target/dirigible/h2/systemdb.QRTZ_FIRED_TRIGGERS\" , \"spanKind\" : \"client\" }, { \"name\" : \"UserRepository.findUserByUsernameAndTenantId\" , \"spanKind\" : \"internal\" }, { \"name\" : \"ALTER TABLE ./target/dirigible/h2/systemdb.QRTZ_LOCKS\" , \"spanKind\" : \"client\" }, { \"name\" : \"CREATE TABLE ./target/dirigible/h2/systemdb.QRTZ_FIRED_TRIGGERS\" , \"spanKind\" : \"client\" }, { \"name\" : \"SELECT org.eclipse.dirigible.components.data.structures.domain.Schema\" , \"spanKind\" : \"internal\" }, { \"name\" : \"SELECT ./target/dirigible/h2/systemdb.QRTZ_SCHEDULER_STATE\" , \"spanKind\" : \"client\" }, { \"name\" : \"CREATE TABLE ./target/dirigible/h2/systemdb.QRTZ_SIMPROP_TRIGGERS\" , \"spanKind\" : \"client\" }, { \"name\" : \"ALTER TABLE ./target/dirigible/h2/systemdb.QRTZ_CRON_TRIGGERS\" , \"spanKind\" : \"client\" }, { \"name\" : \"SELECT ./target/dirigible/h2/systemdb.QRTZ_JOB_DETAILS\" , \"spanKind\" : \"client\" }, { \"name\" : \"GET /websockets/ide/console\" , \"spanKind\" : \"server\" }, { \"name\" : \"SELECT ./target/dirigible/h2/systemdb.QRTZ_PAUSED_TRIGGER_GRPS\" , \"spanKind\" : \"client\" }, { \"name\" : \"SELECT ./target/dirigible/h2/systemdb.DIRIGIBLE_JOBS\" , \"spanKind\" : \"client\" }, { \"name\" : \"SELECT ./target/dirigible/h2/systemdb.DIRIGIBLE_ENTITIES\" , \"spanKind\" : \"client\" }, { \"name\" : \"SELECT org.eclipse.dirigible.components.security.domain.Role\" , \"spanKind\" : \"internal\" }, { \"name\" : \"ALTER TABLE ./target/dirigible/h2/systemdb.QRTZ_TRIGGERS\" , \"spanKind\" : \"client\" }, { \"name\" : \"ALTER TABLE ./target/dirigible/h2/systemdb.ACTIVEMQ_MSGS\" , \"spanKind\" : \"client\" }, { \"name\" : \"CREATE TABLE ./target/dirigible/h2/systemdb.ACTIVEMQ_LOCK\" , \"spanKind\" : \"client\" }, { \"name\" : \"Session.merge org.eclipse.dirigible.components.extensions.domain.Extension\" , \"spanKind\" : \"internal\" }, { \"name\" : \"DefinitionRepository.findOne\" , \"spanKind\" : \"internal\" }, { \"name\" : \"UPDATE ./target/dirigible/h2/systemdb.ACT_GE_PROPERTY\" , \"spanKind\" : \"client\" }, { \"name\" : \"Session.merge org.eclipse.dirigible.components.initializers.definition.Definition\" , \"spanKind\" : \"internal\" }, { \"name\" : \"INSERT ./target/dirigible/h2/systemdb.QRTZ_JOB_DETAILS\" , \"spanKind\" : \"client\" }, { \"name\" : \"UPDATE ./target/dirigible/h2/systemdb.QRTZ_CRON_TRIGGERS\" , \"spanKind\" : \"client\" }, { \"name\" : \"GET /*\" , \"spanKind\" : \"server\" }, { \"name\" : \"SELECT information_schema.sequences\" , \"spanKind\" : \"client\" }, { \"name\" : \"CREATE table ./target/dirigible/h2/systemdb\" , \"spanKind\" : \"client\" }, { \"name\" : \"POST /services/ide/git/{workspace}/clone\" , \"spanKind\" : \"server\" }, { \"name\" : \"UPDATE ./target/dirigible/h2/systemdb.DIRIGIBLE_DATA_SOURCES\" , \"spanKind\" : \"client\" }, { \"name\" : \"script_execution\" , \"spanKind\" : \"internal\" }, { \"name\" : \"SELECT org.eclipse.dirigible.components.engine.wiki.domain.Confluence\" , \"spanKind\" : \"internal\" }, { \"name\" : \"SELECT ./target/dirigible/h2/systemdb.ACT_RU_EXTERNAL_JOB\" , \"spanKind\" : \"client\" }, { \"name\" : \"UPDATE ./target/dirigible/h2/systemdb.DIRIGIBLE_BPMN\" , \"spanKind\" : \"client\" }, { \"name\" : \"CREATE TABLE ./target/dirigible/h2/systemdb.QRTZ_CRON_TRIGGERS\" , \"spanKind\" : \"client\" }, { \"name\" : \"system.SynchronizationJob\" , \"spanKind\" : \"internal\" }, { \"name\" : \"SELECT ./target/dirigible/h2/systemdb.DIRIGIBLE_MARKDOWN\" , \"spanKind\" : \"client\" }, { \"name\" : \"JobRepository.findByKey\" , \"spanKind\" : \"internal\" }, { \"name\" : \"CREATE TABLE ./target/dirigible/h2/systemdb.QRTZ_PAUSED_TRIGGER_GRPS\" , \"spanKind\" : \"client\" }, { \"name\" : \"INSERT ./target/dirigible/h2/systemdb.ACTIVEMQ_LOCK\" , \"spanKind\" : \"client\" }, { \"name\" : \"POST /services/ide/publisher/{workspace}/{project}/{*path}\" , \"spanKind\" : \"server\" }, { \"name\" : \"dirigible-java-script\" , \"spanKind\" : \"client\" }, { \"name\" : \"SELECT ./target/dirigible/h2/systemdb.DIRIGIBLE_EXTENSIONS\" , \"spanKind\" : \"client\" }, { \"name\" : \"BpmnRepository.findAll\" , \"spanKind\" : \"internal\" }, { \"name\" : \"SELECT ./target/dirigible/h2/systemdb.QRTZ_SIMPLE_TRIGGERS\" , \"spanKind\" : \"client\" }, { \"name\" : \"synchronizer_JobSynchronizer_parse_execution\" , \"spanKind\" : \"internal\" }, { \"name\" : \"SELECT ./target/dirigible/h2/systemdb.DIRIGIBLE_CAMEL\" , \"spanKind\" : \"client\" }, { \"name\" : \"GET /services/ide/workspaces/{workspace}\" , \"spanKind\" : \"server\" }, { \"name\" : \"INSERT ./target/dirigible/h2/systemdb.ACT_RE_PROCDEF\" , \"spanKind\" : \"client\" }, { \"name\" : \"CREATE TABLE ./target/dirigible/h2/systemdb.QRTZ_SCHEDULER_STATE\" , \"spanKind\" : \"client\" }, { \"name\" : \"SELECT ./target/dirigible/h2/systemdb.ACTIVEMQ_LOCK\" , \"spanKind\" : \"client\" }, { \"name\" : \"SELECT org.eclipse.dirigible.components.engine.bpm.flowable.domain.Bpmn\" , \"spanKind\" : \"internal\" }, { \"name\" : \"Session.persist org.eclipse.dirigible.components.jobs.domain.JobLog\" , \"spanKind\" : \"internal\" }, { \"name\" : \"GET /services/ts/{projectName}/{*projectFilePath}\" , \"spanKind\" : \"server\" }, { \"name\" : \"DELETE ./target/dirigible/h2/systemdb.ACTIVEMQ_MSGS\" , \"spanKind\" : \"client\" }, { \"name\" : \"Session.merge org.eclipse.dirigible.components.security.domain.Access\" , \"spanKind\" : \"internal\" }, { \"name\" : \"GET /services/ide/git/{workspace}/\" , \"spanKind\" : \"server\" }, { \"name\" : \"BpmnRepository.findByKey\" , \"spanKind\" : \"internal\" }, { \"name\" : \"synchronizer_AccessSynchronizer_complete_execution\" , \"spanKind\" : \"internal\" }, { \"name\" : \"SELECT org.eclipse.dirigible.components.tenants.domain.UserRoleAssignment\" , \"spanKind\" : \"internal\" }, { \"name\" : \"SELECT ./target/dirigible/h2/systemdb.DIRIGIBLE_USER_ROLE_ASSIGNMENTS\" , \"spanKind\" : \"client\" }, { \"name\" : \"INSERT ./target/dirigible/h2/systemdb.ACT_RE_DEPLOYMENT\" , \"spanKind\" : \"client\" }, { \"name\" : \"GET /services/ide/git/{workspace}/{repositoryName}/diff\" , \"spanKind\" : \"server\" }, { \"name\" : \"ALTER TABLE ./target/dirigible/h2/systemdb.QRTZ_SIMPLE_TRIGGERS\" , \"spanKind\" : \"client\" }, { \"name\" : \"ExtensionRepository.findAll\" , \"spanKind\" : \"internal\" }, { \"name\" : \"Session.merge org.eclipse.dirigible.components.websockets.domain.Websocket\" , \"spanKind\" : \"internal\" }, { \"name\" : \"SELECT ./target/dirigible/h2/systemdb.QRTZ_CRON_TRIGGERS\" , \"spanKind\" : \"client\" }, { \"name\" : \"GET /services/ide/workspaces/{workspace}/{project}/{*path}\" , \"spanKind\" : \"server\" }, { \"name\" : \"SELECT ./target/dirigible/h2/systemdb.QRTZ_TRIGGERS\" , \"spanKind\" : \"client\" }, { \"name\" : \"SELECT ./target/dirigible/h2/systemdb.ACT_RU_TIMER_JOB\" , \"spanKind\" : \"client\" }, { \"name\" : \"CamelRepository.saveAndFlush\" , \"spanKind\" : \"internal\" }, { \"name\" : \"synchronizer_CamelSynchronizer_parse_execution\" , \"spanKind\" : \"internal\" } ], \"total\" : 254 , \"limit\" : 0 , \"offset\" : 0 , \"errors\" : null } Grafana trace example: Metrics The metrics were exported using the Prometheus API endpoint . For a more detailed exploration, visit the Grafana metrics dashboard or view them through the Prometheus UI . Click to expand the metrics in JSON { \"status\" : \"success\" , \"data\" : [ \"application_ready_time_seconds\" , \"application_started_time_seconds\" , \"camel_exchange_event_notifier_max_seconds\" , \"camel_exchange_event_notifier_seconds_bucket\" , \"camel_exchange_event_notifier_seconds_count\" , \"camel_exchange_event_notifier_seconds_sum\" , \"camel_exchanges_inflight\" , \"camel_exchanges_succeeded_total\" , \"camel_exchanges_total\" , \"camel_route_policy_max_seconds\" , \"camel_route_policy_seconds_bucket\" , \"camel_route_policy_seconds_count\" , \"camel_route_policy_seconds_sum\" , \"camel_routes_added\" , \"camel_routes_reloaded\" , \"camel_routes_running\" , \"db_client_connections_create_time_milliseconds_bucket\" , \"db_client_connections_create_time_milliseconds_count\" , \"db_client_connections_create_time_milliseconds_sum\" , \"db_client_connections_idle_min\" , \"db_client_connections_max\" , \"db_client_connections_pending_requests\" , \"db_client_connections_usage\" , \"db_client_connections_use_time_milliseconds_bucket\" , \"db_client_connections_use_time_milliseconds_count\" , \"db_client_connections_use_time_milliseconds_sum\" , \"db_client_connections_wait_time_milliseconds_bucket\" , \"db_client_connections_wait_time_milliseconds_count\" , \"db_client_connections_wait_time_milliseconds_sum\" , \"disk_free_bytes\" , \"disk_total_bytes\" , \"executor_active_threads\" , \"executor_completed_tasks_total\" , \"executor_pool_core_threads\" , \"executor_pool_max_threads\" , \"executor_pool_size_threads\" , \"executor_queue_remaining_tasks\" , \"executor_queued_tasks\" , \"flowable_completedActivities\" , \"flowable_completedProcessInstanceCount\" , \"flowable_completedTaskCount\" , \"flowable_completedTaskCountToday\" , \"flowable_openTaskCount\" , \"flowable_processDefinitionCount\" , \"flowable_runningProcessInstanceCount\" , \"hikaricp_connections\" , \"hikaricp_connections_acquire_max_seconds\" , \"hikaricp_connections_acquire_seconds_bucket\" , \"hikaricp_connections_acquire_seconds_count\" , \"hikaricp_connections_acquire_seconds_sum\" , \"hikaricp_connections_active\" , \"hikaricp_connections_creation_max_seconds\" , \"hikaricp_connections_idle\" , \"hikaricp_connections_max\" , \"hikaricp_connections_min\" , \"hikaricp_connections_pending\" , \"hikaricp_connections_usage_max_seconds\" , \"hikaricp_connections_usage_seconds_bucket\" , \"hikaricp_connections_usage_seconds_count\" , \"hikaricp_connections_usage_seconds_sum\" , \"http_client_request_duration_seconds_bucket\" , \"http_client_request_duration_seconds_count\" , \"http_client_request_duration_seconds_sum\" , \"http_server_request_duration_seconds_bucket\" , \"http_server_request_duration_seconds_count\" , \"http_server_request_duration_seconds_sum\" , \"http_server_requests_active_active\" , \"http_server_requests_active_duration_seconds\" , \"http_server_requests_max_seconds\" , \"http_server_requests_seconds_bucket\" , \"http_server_requests_seconds_count\" , \"http_server_requests_seconds_sum\" , \"jvm_buffer_count_buffers\" , \"jvm_buffer_memory_used_bytes\" , \"jvm_buffer_total_capacity_bytes\" , \"jvm_class_count\" , \"jvm_class_loaded_total\" , \"jvm_class_unloaded_total\" , \"jvm_classes_loaded\" , \"jvm_classes_unloaded_total\" , \"jvm_compilation_time_milliseconds_total\" , \"jvm_cpu_count\" , \"jvm_cpu_recent_utilization_ratio\" , \"jvm_cpu_time_seconds_total\" , \"jvm_gc_concurrent_phase_time_max_seconds\" , \"jvm_gc_concurrent_phase_time_seconds_bucket\" , \"jvm_gc_concurrent_phase_time_seconds_count\" , \"jvm_gc_concurrent_phase_time_seconds_sum\" , \"jvm_gc_duration_seconds_bucket\" , \"jvm_gc_duration_seconds_count\" , \"jvm_gc_duration_seconds_sum\" , \"jvm_gc_live_data_size_bytes\" , \"jvm_gc_max_data_size_bytes\" , \"jvm_gc_memory_allocated_bytes_total\" , \"jvm_gc_memory_promoted_bytes_total\" , \"jvm_gc_overhead\" , \"jvm_gc_pause_max_seconds\" , \"jvm_gc_pause_seconds_bucket\" , \"jvm_gc_pause_seconds_count\" , \"jvm_gc_pause_seconds_sum\" , \"jvm_info\" , \"jvm_memory_committed_bytes\" , \"jvm_memory_limit_bytes\" , \"jvm_memory_max_bytes\" , \"jvm_memory_usage_after_gc\" , \"jvm_memory_used_after_last_gc_bytes\" , \"jvm_memory_used_bytes\" , \"jvm_thread_count\" , \"jvm_threads_daemon\" , \"jvm_threads_live\" , \"jvm_threads_peak\" , \"jvm_threads_started_total\" , \"jvm_threads_states\" , \"logback_events_total\" , \"otlp_exporter_exported_total\" , \"otlp_exporter_seen_total\" , \"process_cpu_time_nanoseconds_total\" , \"process_cpu_usage\" , \"process_files_max\" , \"process_files_open\" , \"process_start_time_seconds\" , \"process_uptime_seconds\" , \"processedLogs_total\" , \"processedSpans_total\" , \"quartz_job_executed_count_total\" , \"quartz_job_execution_time_bucket\" , \"quartz_job_execution_time_count\" , \"quartz_job_execution_time_sum\" , \"quartz_job_failed_count_total\" , \"quartz_scheduler_running_jobs\" , \"queueSize_ratio\" , \"scrape_duration_seconds\" , \"scrape_samples_post_metric_relabeling\" , \"scrape_samples_scraped\" , \"scrape_series_added\" , \"spring_data_repository_invocations_max_seconds\" , \"spring_data_repository_invocations_seconds_bucket\" , \"spring_data_repository_invocations_seconds_count\" , \"spring_data_repository_invocations_seconds_sum\" , \"spring_security_authentications_active_active\" , \"spring_security_authentications_active_duration_seconds\" , \"spring_security_authentications_max_seconds\" , \"spring_security_authentications_seconds_bucket\" , \"spring_security_authentications_seconds_count\" , \"spring_security_authentications_seconds_sum\" , \"spring_security_authorizations_active_active\" , \"spring_security_authorizations_active_duration_seconds\" , \"spring_security_authorizations_max_seconds\" , \"spring_security_authorizations_seconds_bucket\" , \"spring_security_authorizations_seconds_count\" , \"spring_security_authorizations_seconds_sum\" , \"spring_security_filterchains_DefaultResourcesFilter_after_total\" , \"spring_security_filterchains_DefaultResourcesFilter_before_total\" , \"spring_security_filterchains_TenantContextInitFilter_after_total\" , \"spring_security_filterchains_TenantContextInitFilter_before_total\" , \"spring_security_filterchains_access_exceptions_after_total\" , \"spring_security_filterchains_access_exceptions_before_total\" , \"spring_security_filterchains_active_active\" , \"spring_security_filterchains_active_duration_seconds\" , \"spring_security_filterchains_authentication_anonymous_after_total\" , \"spring_security_filterchains_authentication_anonymous_before_total\" , \"spring_security_filterchains_authentication_basic_after_total\" , \"spring_security_filterchains_authentication_basic_before_total\" , \"spring_security_filterchains_authentication_form_after_total\" , \"spring_security_filterchains_authentication_form_before_total\" , \"spring_security_filterchains_authorization_after_total\" , \"spring_security_filterchains_authorization_before_total\" , \"spring_security_filterchains_context_async_after_total\" , \"spring_security_filterchains_context_async_before_total\" , \"spring_security_filterchains_context_holder_after_total\" , \"spring_security_filterchains_context_holder_before_total\" , \"spring_security_filterchains_context_servlet_after_total\" , \"spring_security_filterchains_context_servlet_before_total\" , \"spring_security_filterchains_cors_after_total\" , \"spring_security_filterchains_cors_before_total\" , \"spring_security_filterchains_header_after_total\" , \"spring_security_filterchains_header_before_total\" , \"spring_security_filterchains_logout_after_total\" , \"spring_security_filterchains_logout_before_total\" , \"spring_security_filterchains_max_seconds\" , \"spring_security_filterchains_page_login_after_total\" , \"spring_security_filterchains_page_login_before_total\" , \"spring_security_filterchains_page_logout_after_total\" , \"spring_security_filterchains_page_logout_before_total\" , \"spring_security_filterchains_requestcache_after_total\" , \"spring_security_filterchains_requestcache_before_total\" , \"spring_security_filterchains_seconds_bucket\" , \"spring_security_filterchains_seconds_count\" , \"spring_security_filterchains_seconds_sum\" , \"spring_security_filterchains_session_urlencoding_after_total\" , \"spring_security_filterchains_session_urlencoding_before_total\" , \"spring_security_http_secured_requests_active_active\" , \"spring_security_http_secured_requests_active_duration_seconds\" , \"spring_security_http_secured_requests_max_seconds\" , \"spring_security_http_secured_requests_seconds_bucket\" , \"spring_security_http_secured_requests_seconds_count\" , \"spring_security_http_secured_requests_seconds_sum\" , \"system_cpu_count\" , \"system_cpu_usage\" , \"system_load_average_1m\" , \"target_info\" , \"tomcat_sessions_active_current\" , \"tomcat_sessions_active_max\" , \"tomcat_sessions_alive_max_seconds\" , \"tomcat_sessions_created_total\" , \"tomcat_sessions_expired_total\" , \"tomcat_sessions_rejected_total\" , \"up\" ] } Grafana metrics dashboard: Custom Telemetry using OpenTelemetry API In this section, we explore the custom implementations of traces and metrics for different scenarios within our sample Eclipse Dirigible application, utilizing the OpenTelemetry API . This way, we are able to monitor and troubleshoot each scenario effectively, ensuring enhanced observability and performance tuning capabilities for the application. REST API In Eclipse Dirigible applications, monitoring and tracing REST API requests is essential to understanding how our application handles external communications. By using OpenTelemetry, we were able to instrument the REST endpoints and capture key telemetry data, providing visibility into every request and response. In our sample application, there is a sample REST API which calls external API to get sample data using Eclipse Dirigible HTTP Client API . The REST API is implemented in file open-telemetry-sample-project/api/test-api.ts . Let's make a GET request to http://localhost:8080/services/ts/open-telemetry-sample-project/api/test-api.ts/data . To explore the related traces: Go to Grafana UI Select Explore Choose Jaeger data source from the dropdown Select Search for Query Type Select Eclipse Dirigible service Chose GET /services/ts/{projectName}/{*projectFilePath} for Operation Name Click on Run query button Select the latest trace You can see details about the different spans by selecting on them and expanding the attributes You can also navigate to the logs related to it by clicking on Logs for this span Jobs This sample showcases a Quartz job that periodically calls an external API. Using OpenTelemetry, we captured telemetry data such as execution times, API request and response details, and job status. These traces provide valuable insights into the job's performance and its interaction with the external API, helping to identify bottlenecks or failures effectively. The sample job is defined in file open-telemetry-sample-project/jobs/test-job.job . It triggers every 30 seconds, so it is not needed to trigger it manually. Traces To explore job traces: Go to Grafana UI Select Explore Choose Jaeger data source from the dropdown Select Search for Query Type Select Eclipse Dirigible service Chose defined.test-job for Operation Name Click on Run query button Select the latest trace You can see details about the trace and related logs Metrics We added custom metrics to monitor the execution of Quartz jobs within our application. By exposing these metrics through OpenTelemetry, we enable proactive monitoring and performance tuning for scheduled tasks. To see all quartz related metrics: Go to Grafana UI Select Explore Select Metrics Click on New metric exploration Type quartz in Search metrics BPM processes We instrumented Flowable BPM processes to capture traces and metrics for each workflow execution. This observability helps monitor process efficiency and troubleshoot workflow bottlenecks effectively. The sample process is defined in file open-telemetry-sample-project/bpm/test-process.bpmn . To trigger a process execution, send POST request to the dedicated API implemented in open-telemetry-sample-project/bpm/process-trigger-service.ts . curl --location --request POST 'http://localhost:8080/services/ts/open-telemetry-sample-project/bpm/process-trigger-service.ts' \\ --header 'Authorization: Basic YWRtaW46YWRtaW4=' Traces To explore job traces: Go to Grafana UI Select Explore Choose Jaeger data source from the dropdown Select Search for Query Type Select Eclipse Dirigible service Chose flowable_task_execution for Operation Name Click on Run query button Select the latest trace You can see details about the trace and related logs Metrics In addition to tracing, we added custom metrics to monitor Flowable BPM processes. To see all Flwoable related metrics: Go to Grafana UI Select Explore Select Metrics Click on New metric exploration Type flowable in Search metrics Camel routes We enabled tracing and metrics for Apache Camel routes to gain insights into their execution and performance. There are two camel routes in the sample application. One http route defined in open-telemetry-sample-project/camel/http-route.camel and one cron route in open-telemetry-sample-project/camel/cron-route.camel Http route traces To trigger the route execution, send GET request to http://localhost:8080/services/integrations/test-camel-route . To explore route traces: Go to Grafana UI Select Explore Choose Jaeger data source from the dropdown Select Search for Query Type Select Eclipse Dirigible service Chose GET /services/integrations/test-camel-route for Operation Name Click on Run query button Select the latest trace You can see details about the trace and related logs Cron route traces Cron route triggers every 20 seconds, so you don't need to trigger it explicitly. To explore route traces: Go to Grafana UI Select Explore Choose Jaeger data source from the dropdown Select Search for Query Type Select Eclipse Dirigible service Chose SpringCronConsumer.run for Operation Name Click on Run query button Select the latest trace You can see details about the trace and related logs Metrics In addition to tracing, we added custom metrics to monitor Camel. To see all Camel related metrics: Go to Grafana UI Select Explore Select Metrics Click on New metric exploration Type camel in Search metrics Logs Our local observability setup incorporates Loki to manage and analyze logs generated by the application. Logs provide essential contextual information, capturing detailed runtime events that complement traces and metrics. With Loki's seamless integration into Grafana, we can query, visualize, and correlate logs with other telemetry data, enabling efficient debugging and performance optimization. To explore the logs: Go to Grafana UI Select Explore Select Logs Select Eclipse Dirigible service You can click on Open in Explore button to open the explore view. There you can write more advanced search queries. Unified Observability with Grafana Dashboards and Alerts Grafana serves as the central hub for visualizing and analyzing telemetry data in our observability stack. By integrating traces, metrics, and logs from sources like Jaeger, Prometheus, and Loki, it enables the creation of custom dashboards tailored to specific monitoring needs. Additionally, Grafana supports setting up real-time alerts based on predefined thresholds or anomalies, ensuring proactive issue resolution and system reliability. This unified view empowers teams to monitor, troubleshoot, and optimize application performance seamlessly. Summary Integrating OpenTelemetry into the Eclipse Dirigible project significantly enhances its enterprise readiness by providing deep observability into the application's performance and behavior. With custom traces and metrics for key components like REST endpoints, Quartz jobs, Flowable processes, and Apache Camel routes, the integration allows for precise monitoring and troubleshooting. Grafana plays a crucial role by enabling the creation of custom dashboards and real-time alerts, providing a unified view of the system\u2019s health. This setup not only supports proactive issue resolution but also empowers teams to optimize performance, ensuring that Eclipse Dirigible meets the demanding needs of enterprise environments.","title":"Eclipse Dirigible Observability Unlocked Using OpenTelemetry"},{"location":"2024/12/03/open-telemetry/#overview","text":"In today\u2019s fast-paced software development landscape, observability has become a cornerstone of resilient and high-performing systems. Observability is more than just logs , metrics , and traces \u2014 it\u2019s about gaining actionable insights into how your software behaves in production. That\u2019s where OpenTelemetry comes in, a powerful, vendor-neutral framework that simplifies collecting telemetry data and integrates seamlessly with major providers like Google Cloud Platform, AWS, and Azure. In our Eclipse Dirigible project, we embraced OpenTelemetry to enhance our observability practices. By instrumenting components such as Quartz jobs, Flowable BPM processes, Apache Camel routes, and TypeScript/JavaScript script executions, we achieved a comprehensive view of our system\u2019s behavior. Additionally, we exposed Spring Boot Actuator Metrics to provide even deeper insights into application health and performance. In this blog, we showcase the architecture of our local setup, provide step-by-step instructions to run it locally, and share examples of traces, metrics, and logs generated from a sample Dirigible project.","title":"Overview"},{"location":"2024/12/03/open-telemetry/#local-opentelemetry-stack","text":"As part of our observability implementation, we prepared a local OpenTelemetry stack implemented with Docker Compose , featuring OpenTelemetry Collector , Jaeger , Prometheus , Loki , and Grafana . While this setup enables powerful local monitoring, OpenTelemetry is versatile and can be integrated with any OpenTelemetry-compliant stack that supports it.","title":"Local OpenTelemetry stack"},{"location":"2024/12/03/open-telemetry/#architecture","text":"To better understand how the components interact within our local setup, let's take a look at the architecture. The following diagram illustrates the flow of telemetry data through the system, showcasing how OpenTelemetry Collector integrates with Jaeger, Prometheus, Loki, and Grafana for comprehensive monitoring.","title":"Architecture"},{"location":"2024/12/03/open-telemetry/#run-steps","text":"There are different Docker Compose profiles which helps you to run the local OpenTelemetry stack depending on your scenario. In this blog we will run the profile which starts OpenTelemetry Collector, Jaeger, Prometheus, Loki, Grafana and latest Eclipse Dirigible image with configured OpenTelemetry Agent . More details about the different profiles could be found in this README . git clone --branch 10 .6.34 https://github.com/eclipse/dirigible.git dirigible cd dirigible/open-telemetry docker compose --profile dirigible-latest-image-with-agent up --detach --build Once started, all containers could be accessed using the following URLs: Container URL Eclipse Dirigible http://localhost:8080 Prometheus http://localhost:16686 Jaeger http://localhost:9090 Loki http://localhost:3100 Grafana http://localhost:3000/grafana","title":"Run steps"},{"location":"2024/12/03/open-telemetry/#sample-eclipse-dirigible-project","text":"We will use a sample Eclipse Dirigible project to demonstrate the observability functionalities. The project is located in this GitHub repository . It contains some common functionalities used in Eclipse Dirigible projects - REST endpoint, BPM (Flowable) process, asynchronous job (Quartz) and Camel routes. To run the application, follow the steps: Open Eclipse Dirigible UI at http://localhost:8080 and login using the default credentials admin / admin Go to Git perspective Click on Clone button Set https://github.com/dirigiblelabs/sample-open-telemetry.git for URL and click on Clone button Go back to the Workbench perspective Click on Publish All button The sample application is now published and ready to be explored.","title":"Sample Eclipse Dirigible project"},{"location":"2024/12/03/open-telemetry/#out-of-the-box-telemetry-data","text":"OpenTelemetry\u2019s agent instrumentation makes it remarkably easy to capture telemetry data with minimal effort. It provides built-in support for monitoring and collecting telemetry from many popular libraries and frameworks out of the box. It supports frameworks like Apache HttpClient, Quartz, Camel, Spring Web MVC, Java JDBC and so on. For a complete and up-to-date list of frameworks and libraries supported by the OpenTelemetry agent, visit the OpenTelemetry Java Instrumentation GitHub repository . The following JSON examples showcase the generated traces and metrics, captured for our sample Eclipse Dirigible application, by our observability setup. Traces The traces were exported using the Jaeger API endpoint . For a more detailed exploration, visit the Grafana dashboard or view them through the Jaeger UI . Click to expand the traces in JSON { \"data\" : [ { \"name\" : \"CREATE TABLE ./target/dirigible/h2/systemdb.QRTZ_LOCKS\" , \"spanKind\" : \"client\" }, { \"name\" : \"INSERT ./target/dirigible/h2/systemdb.ACT_GE_BYTEARRAY\" , \"spanKind\" : \"client\" }, { \"name\" : \"MarkdownRepository.findAll\" , \"spanKind\" : \"internal\" }, { \"name\" : \"Session.persist org.eclipse.dirigible.components.engine.camel.domain.Camel\" , \"spanKind\" : \"internal\" }, { \"name\" : \"synchronizer_BpmnSynchronizer_parse_execution\" , \"spanKind\" : \"internal\" }, { \"name\" : \"synchronizer_CamelSynchronizer_complete_execution\" , \"spanKind\" : \"internal\" }, { \"name\" : \"UPDATE ./target/dirigible/h2/systemdb.DIRIGIBLE_JOBS\" , \"spanKind\" : \"client\" }, { \"name\" : \"SELECT ./target/dirigible/h2/systemdb.DIRIGIBLE_EXTENSION_POINTS\" , \"spanKind\" : \"client\" }, { \"name\" : \"SELECT ./target/dirigible/h2/systemdb.DIRIGIBLE_SECURITY_ROLES\" , \"spanKind\" : \"client\" }, { \"name\" : \"SELECT ./target/dirigible/h2/systemdb.DIRIGIBLE_JOB_EMAILS\" , \"spanKind\" : \"client\" }, { \"name\" : \"GET /**\" , \"spanKind\" : \"server\" }, { \"name\" : \"GET /services/js/{projectName}/{*projectFilePath}\" , \"spanKind\" : \"server\" }, { \"name\" : \"SELECT ./target/dirigible/h2/systemdb.DIRIGIBLE_PROBLEMS\" , \"spanKind\" : \"client\" }, { \"name\" : \"GET /services/data/sources\" , \"spanKind\" : \"server\" }, { \"name\" : \"Session.persist org.eclipse.dirigible.components.jobs.domain.Job\" , \"spanKind\" : \"internal\" }, { \"name\" : \"SELECT org.eclipse.dirigible.components.tenants.domain.Tenant\" , \"spanKind\" : \"internal\" }, { \"name\" : \"SELECT org.eclipse.dirigible.components.data.store.domain.Entity\" , \"spanKind\" : \"internal\" }, { \"name\" : \"SELECT ./target/dirigible/h2/systemdb.DIRIGIBLE_DATA_VIEWS\" , \"spanKind\" : \"client\" }, { \"name\" : \"SELECT ./target/dirigible/h2/systemdb.DIRIGIBLE_ODATA\" , \"spanKind\" : \"client\" }, { \"name\" : \"TypeScriptEndpoint.get\" , \"spanKind\" : \"internal\" }, { \"name\" : \"SELECT ./target/dirigible/h2/systemdb.ACTIVEMQ_MSGS\" , \"spanKind\" : \"client\" }, { \"name\" : \"SELECT ./target/dirigible/h2/systemdb.DIRIGIBLE_CSVIM\" , \"spanKind\" : \"client\" }, { \"name\" : \"Session.merge org.eclipse.dirigible.components.data.store.domain.Entity\" , \"spanKind\" : \"internal\" }, { \"name\" : \"SELECT ./target/dirigible/h2/systemdb.DIRIGIBLE_DATA_SCHEMAS\" , \"spanKind\" : \"client\" }, { \"name\" : \"CREATE TABLE ./target/dirigible/h2/systemdb.QRTZ_TRIGGERS\" , \"spanKind\" : \"client\" }, { \"name\" : \"INSERT ./target/dirigible/h2/systemdb.QRTZ_CRON_TRIGGERS\" , \"spanKind\" : \"client\" }, { \"name\" : \"EntityRepository.findAll\" , \"spanKind\" : \"internal\" }, { \"name\" : \"JavascriptEndpoint.get\" , \"spanKind\" : \"internal\" }, { \"name\" : \"UPDATE ./target/dirigible/h2/systemdb.DIRIGIBLE_OPENAPI\" , \"spanKind\" : \"client\" }, { \"name\" : \"ODataRepository.findAll\" , \"spanKind\" : \"internal\" }, { \"name\" : \"Session.merge org.eclipse.dirigible.components.openapi.domain.OpenAPI\" , \"spanKind\" : \"internal\" }, { \"name\" : \"INSERT ./target/dirigible/h2/systemdb.QRTZ_FIRED_TRIGGERS\" , \"spanKind\" : \"client\" }, { \"name\" : \"Session.merge org.eclipse.dirigible.components.engine.camel.domain.Camel\" , \"spanKind\" : \"internal\" }, { \"name\" : \"ALTER TABLE ./target/dirigible/h2/systemdb.QRTZ_PAUSED_TRIGGER_GRPS\" , \"spanKind\" : \"client\" }, { \"name\" : \"ALTER TABLE ./target/dirigible/h2/systemdb.QRTZ_CALENDARS\" , \"spanKind\" : \"client\" }, { \"name\" : \"SELECT ./target/dirigible/h2/systemdb.DIRIGIBLE_TENANTS\" , \"spanKind\" : \"client\" }, { \"name\" : \"WebsocketRepository.saveAndFlush\" , \"spanKind\" : \"internal\" }, { \"name\" : \"UserRoleAssignmentRepository.findByUser\" , \"spanKind\" : \"internal\" }, { \"name\" : \"SELECT\" , \"spanKind\" : \"internal\" }, { \"name\" : \"INSERT ./target/dirigible/h2/systemdb.DIRIGIBLE_CAMEL\" , \"spanKind\" : \"client\" }, { \"name\" : \"INSERT ./target/dirigible/h2/systemdb.DIRIGIBLE_JOB_LOGS\" , \"spanKind\" : \"client\" }, { \"name\" : \"./target/dirigible/h2/systemdb\" , \"spanKind\" : \"client\" }, { \"name\" : \"CREATE INDEX ./target/dirigible/h2/systemdb\" , \"spanKind\" : \"client\" }, { \"name\" : \"defined.synchronize\" , \"spanKind\" : \"internal\" }, { \"name\" : \"GET /services/ide/problems/search\" , \"spanKind\" : \"server\" }, { \"name\" : \"SELECT ./target/dirigible/h2/systemdb.DIRIGIBLE_DEFINITIONS\" , \"spanKind\" : \"client\" }, { \"name\" : \"Session.persist org.eclipse.dirigible.components.engine.bpm.flowable.domain.Bpmn\" , \"spanKind\" : \"internal\" }, { \"name\" : \"JobRepository.findByName\" , \"spanKind\" : \"internal\" }, { \"name\" : \"SELECT org.eclipse.dirigible.components.data.sources.domain.DataSource\" , \"spanKind\" : \"internal\" }, { \"name\" : \"UPDATE ./target/dirigible/h2/systemdb.QRTZ_TRIGGERS\" , \"spanKind\" : \"client\" }, { \"name\" : \"synchronizer_WebsocketsSynchronizer_complete_execution\" , \"spanKind\" : \"internal\" }, { \"name\" : \"GET\" , \"spanKind\" : \"client\" }, { \"name\" : \"CamelRepository.findByKey\" , \"spanKind\" : \"internal\" }, { \"name\" : \"cron\" , \"spanKind\" : \"server\" }, { \"name\" : \"synchronizer_BpmnSynchronizer_complete_execution\" , \"spanKind\" : \"internal\" }, { \"name\" : \"CREATE TABLE ./target/dirigible/h2/systemdb.QRTZ_JOB_DETAILS\" , \"spanKind\" : \"client\" }, { \"name\" : \"SELECT ./target/dirigible/h2/systemdb.DIRIGIBLE_CONFLUENCE\" , \"spanKind\" : \"client\" }, { \"name\" : \"synchronizer_OpenAPISynchronizer_complete_execution\" , \"spanKind\" : \"internal\" }, { \"name\" : \"HttpServletResponseWrapper.sendError\" , \"spanKind\" : \"internal\" }, { \"name\" : \"DELETE ./target/dirigible/h2/systemdb.QRTZ_FIRED_TRIGGERS\" , \"spanKind\" : \"client\" }, { \"name\" : \"GET /services/data/definition/{datasource}\" , \"spanKind\" : \"server\" }, { \"name\" : \"ExtensionRepository.saveAndFlush\" , \"spanKind\" : \"internal\" }, { \"name\" : \"SchemaRepository.findAll\" , \"spanKind\" : \"internal\" }, { \"name\" : \"DataSourceRepository.saveAndFlush\" , \"spanKind\" : \"internal\" }, { \"name\" : \"SELECT ./target/dirigible/h2/systemdb.DIRIGIBLE_LISTENERS\" , \"spanKind\" : \"client\" }, { \"name\" : \"synchronizer_JobSynchronizer_complete_execution\" , \"spanKind\" : \"internal\" }, { \"name\" : \"OpenAPIRepository.findAll\" , \"spanKind\" : \"internal\" }, { \"name\" : \"ProblemRepository.count\" , \"spanKind\" : \"internal\" }, { \"name\" : \"TopologicalDepleter.deplete\" , \"spanKind\" : \"internal\" }, { \"name\" : \"SELECT org.eclipse.dirigible.components.extensions.domain.Extension\" , \"spanKind\" : \"internal\" }, { \"name\" : \"GET /services/data/metadata/{datasource}\" , \"spanKind\" : \"server\" }, { \"name\" : \"SELECT org.eclipse.dirigible.components.initializers.definition.Definition\" , \"spanKind\" : \"internal\" }, { \"name\" : \"ListenerRepository.findAll\" , \"spanKind\" : \"internal\" }, { \"name\" : \"INSERT ./target/dirigible/h2/systemdb.QRTZ_SIMPLE_TRIGGERS\" , \"spanKind\" : \"client\" }, { \"name\" : \"synchronizer_DataSourcesSynchronizer_complete_execution\" , \"spanKind\" : \"internal\" }, { \"name\" : \"OnCommittedResponseWrapper.sendRedirect\" , \"spanKind\" : \"internal\" }, { \"name\" : \"SELECT org.eclipse.dirigible.components.engine.wiki.domain.Markdown\" , \"spanKind\" : \"internal\" }, { \"name\" : \"CREATE ./target/dirigible/h2/defaultdb\" , \"spanKind\" : \"client\" }, { \"name\" : \"SELECT ./target/dirigible/h2/systemdb.ACT_HI_TASKINST\" , \"spanKind\" : \"client\" }, { \"name\" : \"ALTER TABLE ./target/dirigible/h2/systemdb.QRTZ_SIMPROP_TRIGGERS\" , \"spanKind\" : \"client\" }, { \"name\" : \"JobLogRepository.saveAndFlush\" , \"spanKind\" : \"internal\" }, { \"name\" : \"TableRepository.findAll\" , \"spanKind\" : \"internal\" }, { \"name\" : \"SELECT org.eclipse.dirigible.components.engine.camel.domain.Camel\" , \"spanKind\" : \"internal\" }, { \"name\" : \"SELECT ./target/dirigible/h2/systemdb.DIRIGIBLE_BPMN\" , \"spanKind\" : \"client\" }, { \"name\" : \"UPDATE ./target/dirigible/h2/systemdb.ACTIVEMQ_LOCK\" , \"spanKind\" : \"client\" }, { \"name\" : \"POST /*\" , \"spanKind\" : \"server\" }, { \"name\" : \"INSERT ./target/dirigible/h2/systemdb.DIRIGIBLE_DEFINITIONS\" , \"spanKind\" : \"client\" }, { \"name\" : \"ALTER table ./target/dirigible/h2/systemdb\" , \"spanKind\" : \"client\" }, { \"name\" : \"synchronizer_ExtensionsSynchronizer_complete_execution\" , \"spanKind\" : \"internal\" }, { \"name\" : \"UPDATE ./target/dirigible/h2/systemdb.QRTZ_SIMPLE_TRIGGERS\" , \"spanKind\" : \"client\" }, { \"name\" : \"UPDATE ./target/dirigible/h2/systemdb.DIRIGIBLE_SECURITY_ACCESS\" , \"spanKind\" : \"client\" }, { \"name\" : \"ViewRepository.findAll\" , \"spanKind\" : \"internal\" }, { \"name\" : \"UPDATE ./target/dirigible/h2/systemdb.DIRIGIBLE_ENTITIES\" , \"spanKind\" : \"client\" }, { \"name\" : \"BpmnRepository.saveAndFlush\" , \"spanKind\" : \"internal\" }, { \"name\" : \"SELECT org.eclipse.dirigible.components.data.structures.domain.Table\" , \"spanKind\" : \"internal\" }, { \"name\" : \"SELECT org.eclipse.dirigible.components.odata.domain.OData\" , \"spanKind\" : \"internal\" }, { \"name\" : \"Session.merge org.eclipse.dirigible.components.data.sources.domain.DataSource\" , \"spanKind\" : \"internal\" }, { \"name\" : \"synchronizer_ExtensionPointsSynchronizer_complete_execution\" , \"spanKind\" : \"internal\" }, { \"name\" : \"Transaction.commit\" , \"spanKind\" : \"internal\" }, { \"name\" : \"SELECT org.eclipse.dirigible.components.extensions.domain.ExtensionPoint\" , \"spanKind\" : \"internal\" }, { \"name\" : \"UPDATE ./target/dirigible/h2/systemdb.DIRIGIBLE_CAMEL\" , \"spanKind\" : \"client\" }, { \"name\" : \"UPDATE ./target/dirigible/h2/systemdb.DIRIGIBLE_EXTENSIONS\" , \"spanKind\" : \"client\" }, { \"name\" : \"SELECT ./target/dirigible/h2/systemdb.DIRIGIBLE_WEBSOCKETS\" , \"spanKind\" : \"client\" }, { \"name\" : \"Session.merge org.eclipse.dirigible.components.engine.bpm.flowable.domain.Bpmn\" , \"spanKind\" : \"internal\" }, { \"name\" : \"EntityRepository.saveAndFlush\" , \"spanKind\" : \"internal\" }, { \"name\" : \"SELECT ./target/dirigible/h2/systemdb.ACT_RU_TASK\" , \"spanKind\" : \"client\" }, { \"name\" : \"GET /services/data/metadata/\" , \"spanKind\" : \"server\" }, { \"name\" : \"defined.test-job\" , \"spanKind\" : \"internal\" }, { \"name\" : \"SELECT ./target/dirigible/h2/systemdb.DIRIGIBLE_DATA_TABLES\" , \"spanKind\" : \"client\" }, { \"name\" : \"GET /services/js/all-dts\" , \"spanKind\" : \"server\" }, { \"name\" : \"SELECT org.eclipse.dirigible.components.data.csvim.domain.Csvim\" , \"spanKind\" : \"internal\" }, { \"name\" : \"ProblemRepository.findProblemsByConditionAndLimit\" , \"spanKind\" : \"internal\" }, { \"name\" : \"INSERT ./target/dirigible/h2/systemdb.DIRIGIBLE_JOBS\" , \"spanKind\" : \"client\" }, { \"name\" : \"INSERT ./target/dirigible/h2/systemdb.DIRIGIBLE_BPMN\" , \"spanKind\" : \"client\" }, { \"name\" : \"WebsocketRepository.findAll\" , \"spanKind\" : \"internal\" }, { \"name\" : \"GET /public/js/{projectName}/{*projectFilePath}\" , \"spanKind\" : \"server\" }, { \"name\" : \"SELECT DIRIGIBLE_PROBLEMS\" , \"spanKind\" : \"internal\" }, { \"name\" : \"CREATE TABLE ./target/dirigible/h2/systemdb.QRTZ_SIMPLE_TRIGGERS\" , \"spanKind\" : \"client\" }, { \"name\" : \"SELECT org.eclipse.dirigible.components.jobs.domain.Job\" , \"spanKind\" : \"internal\" }, { \"name\" : \"CsvimRepository.findAll\" , \"spanKind\" : \"internal\" }, { \"name\" : \"SELECT ./target/dirigible/h2/systemdb.ACT_RU_JOB\" , \"spanKind\" : \"client\" }, { \"name\" : \"SELECT ./target/dirigible/h2/systemdb.ACT_RE_PROCDEF\" , \"spanKind\" : \"client\" }, { \"name\" : \"POST\" , \"spanKind\" : \"client\" }, { \"name\" : \"SELECT ./target/dirigible/h2/systemdb.ACT_GE_PROPERTY\" , \"spanKind\" : \"client\" }, { \"name\" : \"SELECT org.eclipse.dirigible.components.listeners.domain.Listener\" , \"spanKind\" : \"internal\" }, { \"name\" : \"SELECT ./target/dirigible/h2/systemdb.DIRIGIBLE_OPENAPI\" , \"spanKind\" : \"client\" }, { \"name\" : \"CREATE table ./target/dirigible/h2/defaultdb\" , \"spanKind\" : \"client\" }, { \"name\" : \"JobEmailRepository.findAll\" , \"spanKind\" : \"internal\" }, { \"name\" : \"ALTER TABLE ./target/dirigible/h2/systemdb.QRTZ_FIRED_TRIGGERS\" , \"spanKind\" : \"client\" }, { \"name\" : \"CREATE TABLE ./target/dirigible/h2/systemdb.QRTZ_CALENDARS\" , \"spanKind\" : \"client\" }, { \"name\" : \"SELECT org.eclipse.dirigible.components.openapi.domain.OpenAPI\" , \"spanKind\" : \"internal\" }, { \"name\" : \"UPDATE ./target/dirigible/h2/systemdb.DIRIGIBLE_DEFINITIONS\" , \"spanKind\" : \"client\" }, { \"name\" : \"CREATE TABLE ./target/dirigible/h2/systemdb.QRTZ_BLOB_TRIGGERS\" , \"spanKind\" : \"client\" }, { \"name\" : \"SELECT ./target/dirigible/h2/systemdb.DIRIGIBLE_SECURITY_ACCESS\" , \"spanKind\" : \"client\" }, { \"name\" : \"SELECT org.eclipse.dirigible.components.data.structures.domain.View\" , \"spanKind\" : \"internal\" }, { \"name\" : \"DataSourceRepository.findAll\" , \"spanKind\" : \"internal\" }, { \"name\" : \"ALTER TABLE ./target/dirigible/h2/systemdb.ACTIVEMQ_ACKS\" , \"spanKind\" : \"client\" }, { \"name\" : \"INSERT ./target/dirigible/h2/systemdb.QRTZ_TRIGGERS\" , \"spanKind\" : \"client\" }, { \"name\" : \"system.TenantsProvisioningJob\" , \"spanKind\" : \"internal\" }, { \"name\" : \"AccessRepository.findAll\" , \"spanKind\" : \"internal\" }, { \"name\" : \"SELECT ./target/dirigible/h2/systemdb.ACTIVEMQ_ACKS\" , \"spanKind\" : \"client\" }, { \"name\" : \"RoleRepository.findAll\" , \"spanKind\" : \"internal\" }, { \"name\" : \"SELECT ./target/dirigible/h2/systemdb.QRTZ_LOCKS\" , \"spanKind\" : \"client\" }, { \"name\" : \"SELECT ./target/dirigible/h2/systemdb.DIRIGIBLE_JOB_PARAMETERS\" , \"spanKind\" : \"client\" }, { \"name\" : \"SELECT org.eclipse.dirigible.components.security.domain.Access\" , \"spanKind\" : \"internal\" }, { \"name\" : \"SELECT ./target/dirigible/h2/systemdb.ACT_PROCDEF_INFO\" , \"spanKind\" : \"client\" }, { \"name\" : \"INSERT ./target/dirigible/h2/systemdb.QRTZ_LOCKS\" , \"spanKind\" : \"client\" }, { \"name\" : \"UPDATE ./target/dirigible/h2/systemdb.DIRIGIBLE_WEBSOCKETS\" , \"spanKind\" : \"client\" }, { \"name\" : \"UPDATE ./target/dirigible/h2/systemdb.QRTZ_SCHEDULER_STATE\" , \"spanKind\" : \"client\" }, { \"name\" : \"ConfluenceRepository.findAll\" , \"spanKind\" : \"internal\" }, { \"name\" : \"SELECT ./target/dirigible/h2/systemdb.DIRIGIBLE_DATA_SOURCE_PROPERTIES\" , \"spanKind\" : \"client\" }, { \"name\" : \"SELECT ./target/dirigible/h2/systemdb.ACT_HI_ACTINST\" , \"spanKind\" : \"client\" }, { \"name\" : \"CREATE TABLE ./target/dirigible/h2/systemdb.ACTIVEMQ_ACKS\" , \"spanKind\" : \"client\" }, { \"name\" : \"OpenAPIRepository.saveAndFlush\" , \"spanKind\" : \"internal\" }, { \"name\" : \"synchronizer_RolesSynchronizer_cleanup_execution\" , \"spanKind\" : \"internal\" }, { \"name\" : \"DefinitionRepository.saveAndFlush\" , \"spanKind\" : \"internal\" }, { \"name\" : \"OnCommittedResponseWrapper.sendError\" , \"spanKind\" : \"internal\" }, { \"name\" : \"ALTER TABLE ./target/dirigible/h2/systemdb.QRTZ_JOB_DETAILS\" , \"spanKind\" : \"client\" }, { \"name\" : \"SELECT org.eclipse.dirigible.components.websockets.domain.Websocket\" , \"spanKind\" : \"internal\" }, { \"name\" : \"GET /services/web/{*path}\" , \"spanKind\" : \"server\" }, { \"name\" : \"SELECT ./target/dirigible/h2/systemdb.DIRIGIBLE_USERS\" , \"spanKind\" : \"client\" }, { \"name\" : \"CamelRepository.findAll\" , \"spanKind\" : \"internal\" }, { \"name\" : \"synchronizer_EntitySynchronizer_complete_execution\" , \"spanKind\" : \"internal\" }, { \"name\" : \"SELECT INFORMATION_SCHEMA.SEQUENCES\" , \"spanKind\" : \"client\" }, { \"name\" : \"SELECT ./target/dirigible/h2/systemdb\" , \"spanKind\" : \"client\" }, { \"name\" : \"TenantRepository.findByStatus\" , \"spanKind\" : \"internal\" }, { \"name\" : \"WebSocketMessageBrokerStats$$Lambda.run\" , \"spanKind\" : \"internal\" }, { \"name\" : \"CREATE TABLE ./target/dirigible/h2/systemdb.ACTIVEMQ_MSGS\" , \"spanKind\" : \"client\" }, { \"name\" : \"JobRepository.findAll\" , \"spanKind\" : \"internal\" }, { \"name\" : \"SELECT org.eclipse.dirigible.components.jobs.domain.JobEmail\" , \"spanKind\" : \"internal\" }, { \"name\" : \"GET /services/ide/workspaces\" , \"spanKind\" : \"server\" }, { \"name\" : \"SELECT org.eclipse.dirigible.components.ide.problems.domain.Problem\" , \"spanKind\" : \"internal\" }, { \"name\" : \"AccessRepository.saveAndFlush\" , \"spanKind\" : \"internal\" }, { \"name\" : \"SpringCronConsumer.run\" , \"spanKind\" : \"internal\" }, { \"name\" : \"GET /services/data/\" , \"spanKind\" : \"server\" }, { \"name\" : \"GET /services/data/definition/\" , \"spanKind\" : \"server\" }, { \"name\" : \"ALTER TABLE ./target/dirigible/h2/systemdb.QRTZ_SCHEDULER_STATE\" , \"spanKind\" : \"client\" }, { \"name\" : \"ExtensionPointRepository.findAll\" , \"spanKind\" : \"internal\" }, { \"name\" : \"Session.merge org.eclipse.dirigible.components.jobs.domain.Job\" , \"spanKind\" : \"internal\" }, { \"name\" : \"GET /webjars/**\" , \"spanKind\" : \"server\" }, { \"name\" : \"Session.persist org.eclipse.dirigible.components.initializers.definition.Definition\" , \"spanKind\" : \"internal\" }, { \"name\" : \"DefinitionRepository.findAll\" , \"spanKind\" : \"internal\" }, { \"name\" : \"JobRepository.saveAndFlush\" , \"spanKind\" : \"internal\" }, { \"name\" : \"SELECT ./target/dirigible/h2/systemdb.DIRIGIBLE_DATA_SOURCES\" , \"spanKind\" : \"client\" }, { \"name\" : \"UPDATE ./target/dirigible/h2/systemdb.QRTZ_FIRED_TRIGGERS\" , \"spanKind\" : \"client\" }, { \"name\" : \"UserRepository.findUserByUsernameAndTenantId\" , \"spanKind\" : \"internal\" }, { \"name\" : \"ALTER TABLE ./target/dirigible/h2/systemdb.QRTZ_LOCKS\" , \"spanKind\" : \"client\" }, { \"name\" : \"CREATE TABLE ./target/dirigible/h2/systemdb.QRTZ_FIRED_TRIGGERS\" , \"spanKind\" : \"client\" }, { \"name\" : \"SELECT org.eclipse.dirigible.components.data.structures.domain.Schema\" , \"spanKind\" : \"internal\" }, { \"name\" : \"SELECT ./target/dirigible/h2/systemdb.QRTZ_SCHEDULER_STATE\" , \"spanKind\" : \"client\" }, { \"name\" : \"CREATE TABLE ./target/dirigible/h2/systemdb.QRTZ_SIMPROP_TRIGGERS\" , \"spanKind\" : \"client\" }, { \"name\" : \"ALTER TABLE ./target/dirigible/h2/systemdb.QRTZ_CRON_TRIGGERS\" , \"spanKind\" : \"client\" }, { \"name\" : \"SELECT ./target/dirigible/h2/systemdb.QRTZ_JOB_DETAILS\" , \"spanKind\" : \"client\" }, { \"name\" : \"GET /websockets/ide/console\" , \"spanKind\" : \"server\" }, { \"name\" : \"SELECT ./target/dirigible/h2/systemdb.QRTZ_PAUSED_TRIGGER_GRPS\" , \"spanKind\" : \"client\" }, { \"name\" : \"SELECT ./target/dirigible/h2/systemdb.DIRIGIBLE_JOBS\" , \"spanKind\" : \"client\" }, { \"name\" : \"SELECT ./target/dirigible/h2/systemdb.DIRIGIBLE_ENTITIES\" , \"spanKind\" : \"client\" }, { \"name\" : \"SELECT org.eclipse.dirigible.components.security.domain.Role\" , \"spanKind\" : \"internal\" }, { \"name\" : \"ALTER TABLE ./target/dirigible/h2/systemdb.QRTZ_TRIGGERS\" , \"spanKind\" : \"client\" }, { \"name\" : \"ALTER TABLE ./target/dirigible/h2/systemdb.ACTIVEMQ_MSGS\" , \"spanKind\" : \"client\" }, { \"name\" : \"CREATE TABLE ./target/dirigible/h2/systemdb.ACTIVEMQ_LOCK\" , \"spanKind\" : \"client\" }, { \"name\" : \"Session.merge org.eclipse.dirigible.components.extensions.domain.Extension\" , \"spanKind\" : \"internal\" }, { \"name\" : \"DefinitionRepository.findOne\" , \"spanKind\" : \"internal\" }, { \"name\" : \"UPDATE ./target/dirigible/h2/systemdb.ACT_GE_PROPERTY\" , \"spanKind\" : \"client\" }, { \"name\" : \"Session.merge org.eclipse.dirigible.components.initializers.definition.Definition\" , \"spanKind\" : \"internal\" }, { \"name\" : \"INSERT ./target/dirigible/h2/systemdb.QRTZ_JOB_DETAILS\" , \"spanKind\" : \"client\" }, { \"name\" : \"UPDATE ./target/dirigible/h2/systemdb.QRTZ_CRON_TRIGGERS\" , \"spanKind\" : \"client\" }, { \"name\" : \"GET /*\" , \"spanKind\" : \"server\" }, { \"name\" : \"SELECT information_schema.sequences\" , \"spanKind\" : \"client\" }, { \"name\" : \"CREATE table ./target/dirigible/h2/systemdb\" , \"spanKind\" : \"client\" }, { \"name\" : \"POST /services/ide/git/{workspace}/clone\" , \"spanKind\" : \"server\" }, { \"name\" : \"UPDATE ./target/dirigible/h2/systemdb.DIRIGIBLE_DATA_SOURCES\" , \"spanKind\" : \"client\" }, { \"name\" : \"script_execution\" , \"spanKind\" : \"internal\" }, { \"name\" : \"SELECT org.eclipse.dirigible.components.engine.wiki.domain.Confluence\" , \"spanKind\" : \"internal\" }, { \"name\" : \"SELECT ./target/dirigible/h2/systemdb.ACT_RU_EXTERNAL_JOB\" , \"spanKind\" : \"client\" }, { \"name\" : \"UPDATE ./target/dirigible/h2/systemdb.DIRIGIBLE_BPMN\" , \"spanKind\" : \"client\" }, { \"name\" : \"CREATE TABLE ./target/dirigible/h2/systemdb.QRTZ_CRON_TRIGGERS\" , \"spanKind\" : \"client\" }, { \"name\" : \"system.SynchronizationJob\" , \"spanKind\" : \"internal\" }, { \"name\" : \"SELECT ./target/dirigible/h2/systemdb.DIRIGIBLE_MARKDOWN\" , \"spanKind\" : \"client\" }, { \"name\" : \"JobRepository.findByKey\" , \"spanKind\" : \"internal\" }, { \"name\" : \"CREATE TABLE ./target/dirigible/h2/systemdb.QRTZ_PAUSED_TRIGGER_GRPS\" , \"spanKind\" : \"client\" }, { \"name\" : \"INSERT ./target/dirigible/h2/systemdb.ACTIVEMQ_LOCK\" , \"spanKind\" : \"client\" }, { \"name\" : \"POST /services/ide/publisher/{workspace}/{project}/{*path}\" , \"spanKind\" : \"server\" }, { \"name\" : \"dirigible-java-script\" , \"spanKind\" : \"client\" }, { \"name\" : \"SELECT ./target/dirigible/h2/systemdb.DIRIGIBLE_EXTENSIONS\" , \"spanKind\" : \"client\" }, { \"name\" : \"BpmnRepository.findAll\" , \"spanKind\" : \"internal\" }, { \"name\" : \"SELECT ./target/dirigible/h2/systemdb.QRTZ_SIMPLE_TRIGGERS\" , \"spanKind\" : \"client\" }, { \"name\" : \"synchronizer_JobSynchronizer_parse_execution\" , \"spanKind\" : \"internal\" }, { \"name\" : \"SELECT ./target/dirigible/h2/systemdb.DIRIGIBLE_CAMEL\" , \"spanKind\" : \"client\" }, { \"name\" : \"GET /services/ide/workspaces/{workspace}\" , \"spanKind\" : \"server\" }, { \"name\" : \"INSERT ./target/dirigible/h2/systemdb.ACT_RE_PROCDEF\" , \"spanKind\" : \"client\" }, { \"name\" : \"CREATE TABLE ./target/dirigible/h2/systemdb.QRTZ_SCHEDULER_STATE\" , \"spanKind\" : \"client\" }, { \"name\" : \"SELECT ./target/dirigible/h2/systemdb.ACTIVEMQ_LOCK\" , \"spanKind\" : \"client\" }, { \"name\" : \"SELECT org.eclipse.dirigible.components.engine.bpm.flowable.domain.Bpmn\" , \"spanKind\" : \"internal\" }, { \"name\" : \"Session.persist org.eclipse.dirigible.components.jobs.domain.JobLog\" , \"spanKind\" : \"internal\" }, { \"name\" : \"GET /services/ts/{projectName}/{*projectFilePath}\" , \"spanKind\" : \"server\" }, { \"name\" : \"DELETE ./target/dirigible/h2/systemdb.ACTIVEMQ_MSGS\" , \"spanKind\" : \"client\" }, { \"name\" : \"Session.merge org.eclipse.dirigible.components.security.domain.Access\" , \"spanKind\" : \"internal\" }, { \"name\" : \"GET /services/ide/git/{workspace}/\" , \"spanKind\" : \"server\" }, { \"name\" : \"BpmnRepository.findByKey\" , \"spanKind\" : \"internal\" }, { \"name\" : \"synchronizer_AccessSynchronizer_complete_execution\" , \"spanKind\" : \"internal\" }, { \"name\" : \"SELECT org.eclipse.dirigible.components.tenants.domain.UserRoleAssignment\" , \"spanKind\" : \"internal\" }, { \"name\" : \"SELECT ./target/dirigible/h2/systemdb.DIRIGIBLE_USER_ROLE_ASSIGNMENTS\" , \"spanKind\" : \"client\" }, { \"name\" : \"INSERT ./target/dirigible/h2/systemdb.ACT_RE_DEPLOYMENT\" , \"spanKind\" : \"client\" }, { \"name\" : \"GET /services/ide/git/{workspace}/{repositoryName}/diff\" , \"spanKind\" : \"server\" }, { \"name\" : \"ALTER TABLE ./target/dirigible/h2/systemdb.QRTZ_SIMPLE_TRIGGERS\" , \"spanKind\" : \"client\" }, { \"name\" : \"ExtensionRepository.findAll\" , \"spanKind\" : \"internal\" }, { \"name\" : \"Session.merge org.eclipse.dirigible.components.websockets.domain.Websocket\" , \"spanKind\" : \"internal\" }, { \"name\" : \"SELECT ./target/dirigible/h2/systemdb.QRTZ_CRON_TRIGGERS\" , \"spanKind\" : \"client\" }, { \"name\" : \"GET /services/ide/workspaces/{workspace}/{project}/{*path}\" , \"spanKind\" : \"server\" }, { \"name\" : \"SELECT ./target/dirigible/h2/systemdb.QRTZ_TRIGGERS\" , \"spanKind\" : \"client\" }, { \"name\" : \"SELECT ./target/dirigible/h2/systemdb.ACT_RU_TIMER_JOB\" , \"spanKind\" : \"client\" }, { \"name\" : \"CamelRepository.saveAndFlush\" , \"spanKind\" : \"internal\" }, { \"name\" : \"synchronizer_CamelSynchronizer_parse_execution\" , \"spanKind\" : \"internal\" } ], \"total\" : 254 , \"limit\" : 0 , \"offset\" : 0 , \"errors\" : null } Grafana trace example: Metrics The metrics were exported using the Prometheus API endpoint . For a more detailed exploration, visit the Grafana metrics dashboard or view them through the Prometheus UI . Click to expand the metrics in JSON { \"status\" : \"success\" , \"data\" : [ \"application_ready_time_seconds\" , \"application_started_time_seconds\" , \"camel_exchange_event_notifier_max_seconds\" , \"camel_exchange_event_notifier_seconds_bucket\" , \"camel_exchange_event_notifier_seconds_count\" , \"camel_exchange_event_notifier_seconds_sum\" , \"camel_exchanges_inflight\" , \"camel_exchanges_succeeded_total\" , \"camel_exchanges_total\" , \"camel_route_policy_max_seconds\" , \"camel_route_policy_seconds_bucket\" , \"camel_route_policy_seconds_count\" , \"camel_route_policy_seconds_sum\" , \"camel_routes_added\" , \"camel_routes_reloaded\" , \"camel_routes_running\" , \"db_client_connections_create_time_milliseconds_bucket\" , \"db_client_connections_create_time_milliseconds_count\" , \"db_client_connections_create_time_milliseconds_sum\" , \"db_client_connections_idle_min\" , \"db_client_connections_max\" , \"db_client_connections_pending_requests\" , \"db_client_connections_usage\" , \"db_client_connections_use_time_milliseconds_bucket\" , \"db_client_connections_use_time_milliseconds_count\" , \"db_client_connections_use_time_milliseconds_sum\" , \"db_client_connections_wait_time_milliseconds_bucket\" , \"db_client_connections_wait_time_milliseconds_count\" , \"db_client_connections_wait_time_milliseconds_sum\" , \"disk_free_bytes\" , \"disk_total_bytes\" , \"executor_active_threads\" , \"executor_completed_tasks_total\" , \"executor_pool_core_threads\" , \"executor_pool_max_threads\" , \"executor_pool_size_threads\" , \"executor_queue_remaining_tasks\" , \"executor_queued_tasks\" , \"flowable_completedActivities\" , \"flowable_completedProcessInstanceCount\" , \"flowable_completedTaskCount\" , \"flowable_completedTaskCountToday\" , \"flowable_openTaskCount\" , \"flowable_processDefinitionCount\" , \"flowable_runningProcessInstanceCount\" , \"hikaricp_connections\" , \"hikaricp_connections_acquire_max_seconds\" , \"hikaricp_connections_acquire_seconds_bucket\" , \"hikaricp_connections_acquire_seconds_count\" , \"hikaricp_connections_acquire_seconds_sum\" , \"hikaricp_connections_active\" , \"hikaricp_connections_creation_max_seconds\" , \"hikaricp_connections_idle\" , \"hikaricp_connections_max\" , \"hikaricp_connections_min\" , \"hikaricp_connections_pending\" , \"hikaricp_connections_usage_max_seconds\" , \"hikaricp_connections_usage_seconds_bucket\" , \"hikaricp_connections_usage_seconds_count\" , \"hikaricp_connections_usage_seconds_sum\" , \"http_client_request_duration_seconds_bucket\" , \"http_client_request_duration_seconds_count\" , \"http_client_request_duration_seconds_sum\" , \"http_server_request_duration_seconds_bucket\" , \"http_server_request_duration_seconds_count\" , \"http_server_request_duration_seconds_sum\" , \"http_server_requests_active_active\" , \"http_server_requests_active_duration_seconds\" , \"http_server_requests_max_seconds\" , \"http_server_requests_seconds_bucket\" , \"http_server_requests_seconds_count\" , \"http_server_requests_seconds_sum\" , \"jvm_buffer_count_buffers\" , \"jvm_buffer_memory_used_bytes\" , \"jvm_buffer_total_capacity_bytes\" , \"jvm_class_count\" , \"jvm_class_loaded_total\" , \"jvm_class_unloaded_total\" , \"jvm_classes_loaded\" , \"jvm_classes_unloaded_total\" , \"jvm_compilation_time_milliseconds_total\" , \"jvm_cpu_count\" , \"jvm_cpu_recent_utilization_ratio\" , \"jvm_cpu_time_seconds_total\" , \"jvm_gc_concurrent_phase_time_max_seconds\" , \"jvm_gc_concurrent_phase_time_seconds_bucket\" , \"jvm_gc_concurrent_phase_time_seconds_count\" , \"jvm_gc_concurrent_phase_time_seconds_sum\" , \"jvm_gc_duration_seconds_bucket\" , \"jvm_gc_duration_seconds_count\" , \"jvm_gc_duration_seconds_sum\" , \"jvm_gc_live_data_size_bytes\" , \"jvm_gc_max_data_size_bytes\" , \"jvm_gc_memory_allocated_bytes_total\" , \"jvm_gc_memory_promoted_bytes_total\" , \"jvm_gc_overhead\" , \"jvm_gc_pause_max_seconds\" , \"jvm_gc_pause_seconds_bucket\" , \"jvm_gc_pause_seconds_count\" , \"jvm_gc_pause_seconds_sum\" , \"jvm_info\" , \"jvm_memory_committed_bytes\" , \"jvm_memory_limit_bytes\" , \"jvm_memory_max_bytes\" , \"jvm_memory_usage_after_gc\" , \"jvm_memory_used_after_last_gc_bytes\" , \"jvm_memory_used_bytes\" , \"jvm_thread_count\" , \"jvm_threads_daemon\" , \"jvm_threads_live\" , \"jvm_threads_peak\" , \"jvm_threads_started_total\" , \"jvm_threads_states\" , \"logback_events_total\" , \"otlp_exporter_exported_total\" , \"otlp_exporter_seen_total\" , \"process_cpu_time_nanoseconds_total\" , \"process_cpu_usage\" , \"process_files_max\" , \"process_files_open\" , \"process_start_time_seconds\" , \"process_uptime_seconds\" , \"processedLogs_total\" , \"processedSpans_total\" , \"quartz_job_executed_count_total\" , \"quartz_job_execution_time_bucket\" , \"quartz_job_execution_time_count\" , \"quartz_job_execution_time_sum\" , \"quartz_job_failed_count_total\" , \"quartz_scheduler_running_jobs\" , \"queueSize_ratio\" , \"scrape_duration_seconds\" , \"scrape_samples_post_metric_relabeling\" , \"scrape_samples_scraped\" , \"scrape_series_added\" , \"spring_data_repository_invocations_max_seconds\" , \"spring_data_repository_invocations_seconds_bucket\" , \"spring_data_repository_invocations_seconds_count\" , \"spring_data_repository_invocations_seconds_sum\" , \"spring_security_authentications_active_active\" , \"spring_security_authentications_active_duration_seconds\" , \"spring_security_authentications_max_seconds\" , \"spring_security_authentications_seconds_bucket\" , \"spring_security_authentications_seconds_count\" , \"spring_security_authentications_seconds_sum\" , \"spring_security_authorizations_active_active\" , \"spring_security_authorizations_active_duration_seconds\" , \"spring_security_authorizations_max_seconds\" , \"spring_security_authorizations_seconds_bucket\" , \"spring_security_authorizations_seconds_count\" , \"spring_security_authorizations_seconds_sum\" , \"spring_security_filterchains_DefaultResourcesFilter_after_total\" , \"spring_security_filterchains_DefaultResourcesFilter_before_total\" , \"spring_security_filterchains_TenantContextInitFilter_after_total\" , \"spring_security_filterchains_TenantContextInitFilter_before_total\" , \"spring_security_filterchains_access_exceptions_after_total\" , \"spring_security_filterchains_access_exceptions_before_total\" , \"spring_security_filterchains_active_active\" , \"spring_security_filterchains_active_duration_seconds\" , \"spring_security_filterchains_authentication_anonymous_after_total\" , \"spring_security_filterchains_authentication_anonymous_before_total\" , \"spring_security_filterchains_authentication_basic_after_total\" , \"spring_security_filterchains_authentication_basic_before_total\" , \"spring_security_filterchains_authentication_form_after_total\" , \"spring_security_filterchains_authentication_form_before_total\" , \"spring_security_filterchains_authorization_after_total\" , \"spring_security_filterchains_authorization_before_total\" , \"spring_security_filterchains_context_async_after_total\" , \"spring_security_filterchains_context_async_before_total\" , \"spring_security_filterchains_context_holder_after_total\" , \"spring_security_filterchains_context_holder_before_total\" , \"spring_security_filterchains_context_servlet_after_total\" , \"spring_security_filterchains_context_servlet_before_total\" , \"spring_security_filterchains_cors_after_total\" , \"spring_security_filterchains_cors_before_total\" , \"spring_security_filterchains_header_after_total\" , \"spring_security_filterchains_header_before_total\" , \"spring_security_filterchains_logout_after_total\" , \"spring_security_filterchains_logout_before_total\" , \"spring_security_filterchains_max_seconds\" , \"spring_security_filterchains_page_login_after_total\" , \"spring_security_filterchains_page_login_before_total\" , \"spring_security_filterchains_page_logout_after_total\" , \"spring_security_filterchains_page_logout_before_total\" , \"spring_security_filterchains_requestcache_after_total\" , \"spring_security_filterchains_requestcache_before_total\" , \"spring_security_filterchains_seconds_bucket\" , \"spring_security_filterchains_seconds_count\" , \"spring_security_filterchains_seconds_sum\" , \"spring_security_filterchains_session_urlencoding_after_total\" , \"spring_security_filterchains_session_urlencoding_before_total\" , \"spring_security_http_secured_requests_active_active\" , \"spring_security_http_secured_requests_active_duration_seconds\" , \"spring_security_http_secured_requests_max_seconds\" , \"spring_security_http_secured_requests_seconds_bucket\" , \"spring_security_http_secured_requests_seconds_count\" , \"spring_security_http_secured_requests_seconds_sum\" , \"system_cpu_count\" , \"system_cpu_usage\" , \"system_load_average_1m\" , \"target_info\" , \"tomcat_sessions_active_current\" , \"tomcat_sessions_active_max\" , \"tomcat_sessions_alive_max_seconds\" , \"tomcat_sessions_created_total\" , \"tomcat_sessions_expired_total\" , \"tomcat_sessions_rejected_total\" , \"up\" ] } Grafana metrics dashboard:","title":"Out-of-the-Box telemetry data"},{"location":"2024/12/03/open-telemetry/#custom-telemetry-using-opentelemetry-api","text":"In this section, we explore the custom implementations of traces and metrics for different scenarios within our sample Eclipse Dirigible application, utilizing the OpenTelemetry API . This way, we are able to monitor and troubleshoot each scenario effectively, ensuring enhanced observability and performance tuning capabilities for the application.","title":"Custom Telemetry using OpenTelemetry API"},{"location":"2024/12/03/open-telemetry/#rest-api","text":"In Eclipse Dirigible applications, monitoring and tracing REST API requests is essential to understanding how our application handles external communications. By using OpenTelemetry, we were able to instrument the REST endpoints and capture key telemetry data, providing visibility into every request and response. In our sample application, there is a sample REST API which calls external API to get sample data using Eclipse Dirigible HTTP Client API . The REST API is implemented in file open-telemetry-sample-project/api/test-api.ts . Let's make a GET request to http://localhost:8080/services/ts/open-telemetry-sample-project/api/test-api.ts/data . To explore the related traces: Go to Grafana UI Select Explore Choose Jaeger data source from the dropdown Select Search for Query Type Select Eclipse Dirigible service Chose GET /services/ts/{projectName}/{*projectFilePath} for Operation Name Click on Run query button Select the latest trace You can see details about the different spans by selecting on them and expanding the attributes You can also navigate to the logs related to it by clicking on Logs for this span","title":"REST API"},{"location":"2024/12/03/open-telemetry/#jobs","text":"This sample showcases a Quartz job that periodically calls an external API. Using OpenTelemetry, we captured telemetry data such as execution times, API request and response details, and job status. These traces provide valuable insights into the job's performance and its interaction with the external API, helping to identify bottlenecks or failures effectively. The sample job is defined in file open-telemetry-sample-project/jobs/test-job.job . It triggers every 30 seconds, so it is not needed to trigger it manually.","title":"Jobs"},{"location":"2024/12/03/open-telemetry/#traces","text":"To explore job traces: Go to Grafana UI Select Explore Choose Jaeger data source from the dropdown Select Search for Query Type Select Eclipse Dirigible service Chose defined.test-job for Operation Name Click on Run query button Select the latest trace You can see details about the trace and related logs","title":"Traces"},{"location":"2024/12/03/open-telemetry/#metrics","text":"We added custom metrics to monitor the execution of Quartz jobs within our application. By exposing these metrics through OpenTelemetry, we enable proactive monitoring and performance tuning for scheduled tasks. To see all quartz related metrics: Go to Grafana UI Select Explore Select Metrics Click on New metric exploration Type quartz in Search metrics","title":"Metrics"},{"location":"2024/12/03/open-telemetry/#bpm-processes","text":"We instrumented Flowable BPM processes to capture traces and metrics for each workflow execution. This observability helps monitor process efficiency and troubleshoot workflow bottlenecks effectively. The sample process is defined in file open-telemetry-sample-project/bpm/test-process.bpmn . To trigger a process execution, send POST request to the dedicated API implemented in open-telemetry-sample-project/bpm/process-trigger-service.ts . curl --location --request POST 'http://localhost:8080/services/ts/open-telemetry-sample-project/bpm/process-trigger-service.ts' \\ --header 'Authorization: Basic YWRtaW46YWRtaW4='","title":"BPM processes"},{"location":"2024/12/03/open-telemetry/#traces_1","text":"To explore job traces: Go to Grafana UI Select Explore Choose Jaeger data source from the dropdown Select Search for Query Type Select Eclipse Dirigible service Chose flowable_task_execution for Operation Name Click on Run query button Select the latest trace You can see details about the trace and related logs","title":"Traces"},{"location":"2024/12/03/open-telemetry/#metrics_1","text":"In addition to tracing, we added custom metrics to monitor Flowable BPM processes. To see all Flwoable related metrics: Go to Grafana UI Select Explore Select Metrics Click on New metric exploration Type flowable in Search metrics","title":"Metrics"},{"location":"2024/12/03/open-telemetry/#camel-routes","text":"We enabled tracing and metrics for Apache Camel routes to gain insights into their execution and performance. There are two camel routes in the sample application. One http route defined in open-telemetry-sample-project/camel/http-route.camel and one cron route in open-telemetry-sample-project/camel/cron-route.camel","title":"Camel routes"},{"location":"2024/12/03/open-telemetry/#http-route-traces","text":"To trigger the route execution, send GET request to http://localhost:8080/services/integrations/test-camel-route . To explore route traces: Go to Grafana UI Select Explore Choose Jaeger data source from the dropdown Select Search for Query Type Select Eclipse Dirigible service Chose GET /services/integrations/test-camel-route for Operation Name Click on Run query button Select the latest trace You can see details about the trace and related logs","title":"Http route traces"},{"location":"2024/12/03/open-telemetry/#cron-route-traces","text":"Cron route triggers every 20 seconds, so you don't need to trigger it explicitly. To explore route traces: Go to Grafana UI Select Explore Choose Jaeger data source from the dropdown Select Search for Query Type Select Eclipse Dirigible service Chose SpringCronConsumer.run for Operation Name Click on Run query button Select the latest trace You can see details about the trace and related logs","title":"Cron route traces"},{"location":"2024/12/03/open-telemetry/#metrics_2","text":"In addition to tracing, we added custom metrics to monitor Camel. To see all Camel related metrics: Go to Grafana UI Select Explore Select Metrics Click on New metric exploration Type camel in Search metrics","title":"Metrics"},{"location":"2024/12/03/open-telemetry/#logs","text":"Our local observability setup incorporates Loki to manage and analyze logs generated by the application. Logs provide essential contextual information, capturing detailed runtime events that complement traces and metrics. With Loki's seamless integration into Grafana, we can query, visualize, and correlate logs with other telemetry data, enabling efficient debugging and performance optimization. To explore the logs: Go to Grafana UI Select Explore Select Logs Select Eclipse Dirigible service You can click on Open in Explore button to open the explore view. There you can write more advanced search queries.","title":"Logs"},{"location":"2024/12/03/open-telemetry/#unified-observability-with-grafana-dashboards-and-alerts","text":"Grafana serves as the central hub for visualizing and analyzing telemetry data in our observability stack. By integrating traces, metrics, and logs from sources like Jaeger, Prometheus, and Loki, it enables the creation of custom dashboards tailored to specific monitoring needs. Additionally, Grafana supports setting up real-time alerts based on predefined thresholds or anomalies, ensuring proactive issue resolution and system reliability. This unified view empowers teams to monitor, troubleshoot, and optimize application performance seamlessly.","title":"Unified Observability with Grafana Dashboards and Alerts"},{"location":"2024/12/03/open-telemetry/#summary","text":"Integrating OpenTelemetry into the Eclipse Dirigible project significantly enhances its enterprise readiness by providing deep observability into the application's performance and behavior. With custom traces and metrics for key components like REST endpoints, Quartz jobs, Flowable processes, and Apache Camel routes, the integration allows for precise monitoring and troubleshooting. Grafana plays a crucial role by enabling the creation of custom dashboards and real-time alerts, providing a unified view of the system\u2019s health. This setup not only supports proactive issue resolution but also empowers teams to optimize performance, ensuring that Eclipse Dirigible meets the demanding needs of enterprise environments.","title":"Summary"}]}