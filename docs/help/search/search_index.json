{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome! How can we help? Build your first service with Eclipse Dirigible. Getting Started Read essential definitions. Concepts Understand the nuts and bolts. Architecture Find out what, why, and how. FAQ Review major features. Features Explore different setup options. Setup Learn more about Enterprise JavaScript API availability, versions, and status. API Try out sample apps. Samples","title":"Home"},{"location":"#welcome-how-can-we-help","text":"Build your first service with Eclipse Dirigible. Getting Started Read essential definitions. Concepts Understand the nuts and bolts. Architecture Find out what, why, and how. FAQ Review major features. Features Explore different setup options. Setup Learn more about Enterprise JavaScript API availability, versions, and status. API Try out sample apps. Samples","title":"Welcome! How can we help?"},{"location":"development/","text":"Getting Started Overview This guide explains how to setup an Eclipse Dirigible instance and how to use it to build your very first hello-world.js service. The references section below points to the documentation with more technical details for the different aspects of the platform and its components and capabilities. Setup In case you are using the shared trial.dirigible.io environment, you can skip this section. Get the binary In case you want to use a prebuild package, you can get the one built for your environment from the downloads section. To build Eclipse Dirigible from sources by yourself, just follow the instructions in the README . Choose the environment You can choose one of the setup options available to get an Eclipse Dirigible instance depending on your target environment. A shared trial instance is also available and can be accessed from here: trial.dirigible.io There are many configuration options , so you can connect to different databases, use different platforms, choose a specific set of plugins, and many more. Access the instance In case of the standard setup on Apache Tomcat on your local machine, you can point your browser to the location: http://localhost:8080 Hello World Application Create a hello-world.js service Once you have a running Eclipse Dirigible instance, you can start with your project: Choose File -> New -> Project . Enter a name and create the project. Right-click on the project icon in the Workspace view and choose New -> Javascript Service . Enter a name for the service. Double-click on the file icon to open the file in the editor on the right. The file already contains the hello world service implementation. Right-click on the project icon and choose Publish . With the file icon selected in the Workspace view, check the result of the execution of our fancy server-side Javascript service in the Preview view. Update the hello-world.js service Go to line 3 in the editor and change the Hello World! message to Hello Dirigible! . var response = require ( \"http/v4/response\" ); response . println ( \"Hello Dirigible!\" ); response . flush (); response . close (); Save the file: Ctrl + S for Windows, Cmd + S for macOS The output in the Preview view changes immediately. This is due to the default configuration of auto-publish on save . You can find more about this dynamic behavior in the concepts section: Dynamic Applications References So far we saw how easy it is to create and modify a RESTful service, but Dirigible capabilities goes way beyond that: You can explore the samples section for more scenarios. If you would like to build complex services, you can go to the API section. If you are curious what you can do with Eclipse Dirigible apart from writing server-side JavaScript services, you can have a look at the features section. In case you are interested in modeling and generation with the Low-Code/No-Code tooling of Eclipse Dirigible, you can read about entity data models and generation .","title":"Getting Started"},{"location":"development/#getting-started","text":"","title":"Getting Started"},{"location":"development/#overview","text":"This guide explains how to setup an Eclipse Dirigible instance and how to use it to build your very first hello-world.js service. The references section below points to the documentation with more technical details for the different aspects of the platform and its components and capabilities.","title":"Overview"},{"location":"development/#setup","text":"In case you are using the shared trial.dirigible.io environment, you can skip this section.","title":"Setup"},{"location":"development/#get-the-binary","text":"In case you want to use a prebuild package, you can get the one built for your environment from the downloads section. To build Eclipse Dirigible from sources by yourself, just follow the instructions in the README .","title":"Get the binary"},{"location":"development/#choose-the-environment","text":"You can choose one of the setup options available to get an Eclipse Dirigible instance depending on your target environment. A shared trial instance is also available and can be accessed from here: trial.dirigible.io There are many configuration options , so you can connect to different databases, use different platforms, choose a specific set of plugins, and many more.","title":"Choose the environment"},{"location":"development/#access-the-instance","text":"In case of the standard setup on Apache Tomcat on your local machine, you can point your browser to the location: http://localhost:8080","title":"Access the instance"},{"location":"development/#hello-world-application","text":"","title":"Hello World Application"},{"location":"development/#create-a-hello-worldjs-service","text":"Once you have a running Eclipse Dirigible instance, you can start with your project: Choose File -> New -> Project . Enter a name and create the project. Right-click on the project icon in the Workspace view and choose New -> Javascript Service . Enter a name for the service. Double-click on the file icon to open the file in the editor on the right. The file already contains the hello world service implementation. Right-click on the project icon and choose Publish . With the file icon selected in the Workspace view, check the result of the execution of our fancy server-side Javascript service in the Preview view.","title":"Create a hello-world.js service"},{"location":"development/#update-the-hello-worldjs-service","text":"Go to line 3 in the editor and change the Hello World! message to Hello Dirigible! . var response = require ( \"http/v4/response\" ); response . println ( \"Hello Dirigible!\" ); response . flush (); response . close (); Save the file: Ctrl + S for Windows, Cmd + S for macOS The output in the Preview view changes immediately. This is due to the default configuration of auto-publish on save . You can find more about this dynamic behavior in the concepts section: Dynamic Applications","title":"Update the hello-world.js service"},{"location":"development/#references","text":"So far we saw how easy it is to create and modify a RESTful service, but Dirigible capabilities goes way beyond that: You can explore the samples section for more scenarios. If you would like to build complex services, you can go to the API section. If you are curious what you can do with Eclipse Dirigible apart from writing server-side JavaScript services, you can have a look at the features section. In case you are interested in modeling and generation with the Low-Code/No-Code tooling of Eclipse Dirigible, you can read about entity data models and generation .","title":"References"},{"location":"development/devops/","text":"Development & Operations Providing a modern business applications in the Cloud nowadays requires a tight relation between the development and operations activities. Dirigible by promoting the in-system development for a full-stack applications needs to cover the both phases with the necessary tools and backend frameworks. Development The front-facing Web IDE component is a collection of plugins for project management, source code editing, modeling, SCM integration, database management and many more. Workbench Git Database Debugger Documents Search Import Preview Editor - Monaco BPMN Modeler Database Schema Modeler Entity Data Modeler Operations The functionality for import and export of projects or workspaces as well as cloning of a whole Dirigible instance, monitoring, document management, etc. are also integrated in the Web IDE component. Operations Database Repository Terminal Snapshot Logs Console","title":"Development & Operations"},{"location":"development/devops/#development-operations","text":"Providing a modern business applications in the Cloud nowadays requires a tight relation between the development and operations activities. Dirigible by promoting the in-system development for a full-stack applications needs to cover the both phases with the necessary tools and backend frameworks.","title":"Development &amp; Operations"},{"location":"development/devops/#development","text":"The front-facing Web IDE component is a collection of plugins for project management, source code editing, modeling, SCM integration, database management and many more. Workbench Git Database Debugger Documents Search Import Preview Editor - Monaco BPMN Modeler Database Schema Modeler Entity Data Modeler","title":"Development"},{"location":"development/devops/#operations","text":"The functionality for import and export of projects or workspaces as well as cloning of a whole Dirigible instance, monitoring, document management, etc. are also integrated in the Web IDE component. Operations Database Repository Terminal Snapshot Logs Console","title":"Operations"},{"location":"development/artifacts/","text":"Artifacts File extensions Database *.table - a JSON based database table descriptor file. Data structures synchroniser automatically reads all the available *.table files in the repository (including the classpath resources) and creates the underlying database tables into the default database. The definition supports also dependencies which gives the ability to the synchroniser to make a topological sorting before starting the creation of the database artefacts. Sample can be found here . *.view - a JSON based database table descriptor file. The synchroniser reads and creates the database views as defined in the model. Sample can be found here *.replace - a data file containing list of records to be imported with 'replace' mode to the corresponding database table. Sample file can be found here *.append - a data file containing list of records to be imported with 'append' mode to the corresponding database table. *.delete - a data file containing list of records to be deleted from the corresponding database table. For deleting all of the records use '*' symbol. *.update - a data file containing list of records to be imported with 'update' mode to the corresponding database table. Security *.access - security constraints file. It defines the access permissions for the given endpoints. Sample file can be found here . *.roles - roles definition file. Sample file can be found here . Flows *.listener - listener definition describing the link between the message queue or topic and the corresponding handler. Sample file can be found here . *.job - job definition describing the period in which the scheduled handler will be executed. Sample file can be found here . Scripting *.js - a Javascript file supposed to be executed either server side by the supported engine (GraalJS) or at the client side by the browser's built-in engine. *.md - a Markdown Wiki file. *.command - a Shell Command service Modeling *.dsm - an internal XML based format file containing a database schema model diagram. *.schema - a JSON descriptor for a database schema layout produced by the Database Schema Modeler *.edm - an internal XML based format file containing an entity data model diagram. *.model - a JSON descriptor for an entity data model produced by the Entity Data Modeler *.bpmn - a BPMN 2.0 XML file containing a definition of a business process.","title":"Artifacts"},{"location":"development/artifacts/#artifacts","text":"","title":"Artifacts"},{"location":"development/artifacts/#file-extensions","text":"","title":"File extensions"},{"location":"development/artifacts/#database","text":"*.table - a JSON based database table descriptor file. Data structures synchroniser automatically reads all the available *.table files in the repository (including the classpath resources) and creates the underlying database tables into the default database. The definition supports also dependencies which gives the ability to the synchroniser to make a topological sorting before starting the creation of the database artefacts. Sample can be found here . *.view - a JSON based database table descriptor file. The synchroniser reads and creates the database views as defined in the model. Sample can be found here *.replace - a data file containing list of records to be imported with 'replace' mode to the corresponding database table. Sample file can be found here *.append - a data file containing list of records to be imported with 'append' mode to the corresponding database table. *.delete - a data file containing list of records to be deleted from the corresponding database table. For deleting all of the records use '*' symbol. *.update - a data file containing list of records to be imported with 'update' mode to the corresponding database table.","title":"Database"},{"location":"development/artifacts/#security","text":"*.access - security constraints file. It defines the access permissions for the given endpoints. Sample file can be found here . *.roles - roles definition file. Sample file can be found here .","title":"Security"},{"location":"development/artifacts/#flows","text":"*.listener - listener definition describing the link between the message queue or topic and the corresponding handler. Sample file can be found here . *.job - job definition describing the period in which the scheduled handler will be executed. Sample file can be found here .","title":"Flows"},{"location":"development/artifacts/#scripting","text":"*.js - a Javascript file supposed to be executed either server side by the supported engine (GraalJS) or at the client side by the browser's built-in engine. *.md - a Markdown Wiki file. *.command - a Shell Command service","title":"Scripting"},{"location":"development/artifacts/#modeling","text":"*.dsm - an internal XML based format file containing a database schema model diagram. *.schema - a JSON descriptor for a database schema layout produced by the Database Schema Modeler *.edm - an internal XML based format file containing an entity data model diagram. *.model - a JSON descriptor for an entity data model produced by the Entity Data Modeler *.bpmn - a BPMN 2.0 XML file containing a definition of a business process.","title":"Modeling"},{"location":"development/artifacts/data-files/","text":"Data Files Delimiter Separated Values *.dsv data files are used for importing test data during development or for defining static content for e.g. nomenclatures. The data file name has to be the same as the target table name. The delimiter uses the | char, and the order of the data fields should be the same as the natural order in the target table. Be careful when using static data in tables. Entity Services (generated by the templates) use sequence algorithm to identity columns starting from 1 . The automatic re-initialization of static content from the data file can be achieved when you create a *.dsv file in your project. To make it more flexible it is introduced semantic files as follows: REPLACE (*.replace) - the rows in the database table always correspond to the lines in the data file. Processing of this type of files means - first delete all the records in the database table and insert the rows from the file. This is the behavior of the initial format - DSV (*.dsv). The processing is triggered on restart of the App/Web Server or on publishing of the project containing these files. APPEND (*.append) - the rows from these files are imported only once into the corresponding database tables. If the tables already contain some records the inserting is skipped. After the initial import the corresponding sequence is set to the max ID of the table, so that this table can be used afterwards as persistence storage for the e.g. standard CRUD JavaScript Services. DELETE (*.delete) - if the file contains * as the only line, the whole table is cleaned up. Otherwise only the listed records got deleted by the ID (first column = ID = primary key) . UPDATE (*.update) - the records in the database table got updated with the corresponding lines in the data files. The first column is the ID = primary key used as selection parameter for the update clause. The existing records in the table are not deleted in advance as at the REPLACE case. If no record exist by the given ID , it got inserted.","title":"Data Files"},{"location":"development/artifacts/data-files/#data-files","text":"Delimiter Separated Values *.dsv data files are used for importing test data during development or for defining static content for e.g. nomenclatures. The data file name has to be the same as the target table name. The delimiter uses the | char, and the order of the data fields should be the same as the natural order in the target table. Be careful when using static data in tables. Entity Services (generated by the templates) use sequence algorithm to identity columns starting from 1 . The automatic re-initialization of static content from the data file can be achieved when you create a *.dsv file in your project. To make it more flexible it is introduced semantic files as follows: REPLACE (*.replace) - the rows in the database table always correspond to the lines in the data file. Processing of this type of files means - first delete all the records in the database table and insert the rows from the file. This is the behavior of the initial format - DSV (*.dsv). The processing is triggered on restart of the App/Web Server or on publishing of the project containing these files. APPEND (*.append) - the rows from these files are imported only once into the corresponding database tables. If the tables already contain some records the inserting is skipped. After the initial import the corresponding sequence is set to the max ID of the table, so that this table can be used afterwards as persistence storage for the e.g. standard CRUD JavaScript Services. DELETE (*.delete) - if the file contains * as the only line, the whole table is cleaned up. Otherwise only the listed records got deleted by the ID (first column = ID = primary key) . UPDATE (*.update) - the records in the database table got updated with the corresponding lines in the data files. The first column is the ID = primary key used as selection parameter for the update clause. The existing records in the table are not deleted in advance as at the REPLACE case. If no record exist by the given ID , it got inserted.","title":"Data Files"},{"location":"development/artifacts/database-table/","text":"Database Table Table Model is a JSON formatted *.table descriptor. It represents the layout of the database table, which will be created during the activation process. Data structures synchroniser automatically reads all the available *.table files in the repository (including the classpath resources) and creates the underlying database tables into the default database. The definition supports also dependencies which gives the ability to the synchroniser to make a topological sorting before starting the creation of the database artifacts. Example descriptor: { \"tableName\" : \"TEST001\" , \"columns\" : [ { \"name\" : \"ID\" , \"type\" : \"INTEGER\" , \"length\" : \"0\" , \"notNull\" : \"true\" , \"primaryKey\" : \"true\" , \"defaultValue\" : \"\" }, { \"name\" : \"NAME\" , \"type\" : \"VARCHAR\" , \"length\" : \"20\" , \"notNull\" : \"false\" , \"primaryKey\" : \"false\" , \"defaultValue\" : \"\" }, { \"name\" : \"DATEOFBIRTH\" , \"type\" : \"DATE\" , \"length\" : \"0\" , \"notNull\" : \"false\" , \"primaryKey\" : \"false\" , \"defaultValue\" : \"\" }, { \"name\" : \"SALARY\" , \"type\" : \"DOUBLE\" , \"length\" : \"0\" , \"notNull\" : \"false\" , \"primaryKey\" : \"false\" , \"defaultValue\" : \"\" } ] } The supported database types are: VARCHAR - for text-based fields long up to 2K characters CHAR - for text-based fields with fixed length of up to 255 characters INTEGER - 32 bit BIGINT - 64 bit SMALLINT - 16 bit REAL - 7 digits of mantissa DOUBLE - 15 digits of mantissa DATE - represents a date consisting of day, month, and year TIME - represents a time consisting of hours, minutes, and seconds TIMESTAMP - represents DATE, TIME, a nanosecond field, and a time zone BLOB - a binary object, such as an image, audio, etc. The activation of the table descriptor is the process of creating a database table in the target database. The activator constructs a CREATE TABLE SQL statement considering the dialect of the target database system. If a particular table name already exists, the activator checks whether there is a compatible change, such as adding new columns, and constructs an ALTER TABLE SQL statement. If the change is incompatible, the activator returns an error that has to be solved manually through the SQL Console .","title":"Database Table"},{"location":"development/artifacts/database-table/#database-table","text":"Table Model is a JSON formatted *.table descriptor. It represents the layout of the database table, which will be created during the activation process. Data structures synchroniser automatically reads all the available *.table files in the repository (including the classpath resources) and creates the underlying database tables into the default database. The definition supports also dependencies which gives the ability to the synchroniser to make a topological sorting before starting the creation of the database artifacts. Example descriptor: { \"tableName\" : \"TEST001\" , \"columns\" : [ { \"name\" : \"ID\" , \"type\" : \"INTEGER\" , \"length\" : \"0\" , \"notNull\" : \"true\" , \"primaryKey\" : \"true\" , \"defaultValue\" : \"\" }, { \"name\" : \"NAME\" , \"type\" : \"VARCHAR\" , \"length\" : \"20\" , \"notNull\" : \"false\" , \"primaryKey\" : \"false\" , \"defaultValue\" : \"\" }, { \"name\" : \"DATEOFBIRTH\" , \"type\" : \"DATE\" , \"length\" : \"0\" , \"notNull\" : \"false\" , \"primaryKey\" : \"false\" , \"defaultValue\" : \"\" }, { \"name\" : \"SALARY\" , \"type\" : \"DOUBLE\" , \"length\" : \"0\" , \"notNull\" : \"false\" , \"primaryKey\" : \"false\" , \"defaultValue\" : \"\" } ] } The supported database types are: VARCHAR - for text-based fields long up to 2K characters CHAR - for text-based fields with fixed length of up to 255 characters INTEGER - 32 bit BIGINT - 64 bit SMALLINT - 16 bit REAL - 7 digits of mantissa DOUBLE - 15 digits of mantissa DATE - represents a date consisting of day, month, and year TIME - represents a time consisting of hours, minutes, and seconds TIMESTAMP - represents DATE, TIME, a nanosecond field, and a time zone BLOB - a binary object, such as an image, audio, etc. The activation of the table descriptor is the process of creating a database table in the target database. The activator constructs a CREATE TABLE SQL statement considering the dialect of the target database system. If a particular table name already exists, the activator checks whether there is a compatible change, such as adding new columns, and constructs an ALTER TABLE SQL statement. If the change is incompatible, the activator returns an error that has to be solved manually through the SQL Console .","title":"Database Table"},{"location":"development/concepts/","text":"Concepts Dynamic Applications There are several must-know concepts that are implied in the cloud toolkit and have to be understood before getting started. Some of them are closely related to the dynamic applications nature and behavior, others just follow the best practices from the service architecture reflected also in the cloud applications. Repository First comes the concept of a repository . It is the place where the application's content is stored - such as a database for the Eclipse Dirigible's instance. Workspace Next is the concept of a workspace that is very similar to the well known workspace from desktop IDEs (e.g., Eclipse). The workspace can hold one or more projects. One user can have multiple workspaces, but can work in only one at a given moment of time. Registry Registry and the related publishing processes are taken from the SOA (UDDI) and recent API management trends to bring some of their strengths, such as discoverability, reusability, loose coupling, relevance, etc. Generation To boost the development productivity at the very initial phase, we introduced template-based generation of application artifacts via wizards. Entity Services The new Web 2.0 paradigm and the leveraged REST architectural style changed the way services should behave and be described. Although there is push for bilateral contracts only and free description of the services, we decided to introduce a more sophisticated kind of services for special purposes - entity services . Modeling This is the visual definition of database schema models, entity data models, and BPMN processes. In Eclipse Dirigible, modeling is enabled by several editors and modelers . REST framework Along with the low level HTTP request, response, and session handling, Eclipse Dirigible provides a higher level framework for building REST services. More information on how to use this framework can be found here . Web Content This is the client-side application code transported via the container web channel. More information can be found here . Mobile Apps Mobile application support in Eclipse Dirigible is achieved via Tabris.js . Extensions Extensibility is an important requirement for business applications built to follow custom processes in Line of Business(LoB) areas. In the cloud toolkit, a generic description of the extension points and extensions is provided without explicitly defining the contract. This a simple but powerful way to define extensions .","title":"Concepts"},{"location":"development/concepts/#concepts","text":"","title":"Concepts"},{"location":"development/concepts/#dynamic-applications","text":"There are several must-know concepts that are implied in the cloud toolkit and have to be understood before getting started. Some of them are closely related to the dynamic applications nature and behavior, others just follow the best practices from the service architecture reflected also in the cloud applications.","title":"Dynamic Applications"},{"location":"development/concepts/#repository","text":"First comes the concept of a repository . It is the place where the application's content is stored - such as a database for the Eclipse Dirigible's instance.","title":"Repository"},{"location":"development/concepts/#workspace","text":"Next is the concept of a workspace that is very similar to the well known workspace from desktop IDEs (e.g., Eclipse). The workspace can hold one or more projects. One user can have multiple workspaces, but can work in only one at a given moment of time.","title":"Workspace"},{"location":"development/concepts/#registry","text":"Registry and the related publishing processes are taken from the SOA (UDDI) and recent API management trends to bring some of their strengths, such as discoverability, reusability, loose coupling, relevance, etc.","title":"Registry"},{"location":"development/concepts/#generation","text":"To boost the development productivity at the very initial phase, we introduced template-based generation of application artifacts via wizards.","title":"Generation"},{"location":"development/concepts/#entity-services","text":"The new Web 2.0 paradigm and the leveraged REST architectural style changed the way services should behave and be described. Although there is push for bilateral contracts only and free description of the services, we decided to introduce a more sophisticated kind of services for special purposes - entity services .","title":"Entity Services"},{"location":"development/concepts/#modeling","text":"This is the visual definition of database schema models, entity data models, and BPMN processes. In Eclipse Dirigible, modeling is enabled by several editors and modelers .","title":"Modeling"},{"location":"development/concepts/#rest-framework","text":"Along with the low level HTTP request, response, and session handling, Eclipse Dirigible provides a higher level framework for building REST services. More information on how to use this framework can be found here .","title":"REST framework"},{"location":"development/concepts/#web-content","text":"This is the client-side application code transported via the container web channel. More information can be found here .","title":"Web Content"},{"location":"development/concepts/#mobile-apps","text":"Mobile application support in Eclipse Dirigible is achieved via Tabris.js .","title":"Mobile Apps"},{"location":"development/concepts/#extensions","text":"Extensibility is an important requirement for business applications built to follow custom processes in Line of Business(LoB) areas. In the cloud toolkit, a generic description of the extension points and extensions is provided without explicitly defining the contract. This a simple but powerful way to define extensions .","title":"Extensions"},{"location":"development/concepts/dynamic-applications/","text":"Dynamic Applications We introduced the term dynamic applications as one that narrows the scope of the target applications that can be created using Eclipse Dirigible. The overall process of building dynamic applications lies on well-known and proved principles: In-system development - known from microcontrollers to business software systems. A major benefit is working on a live system where all changes you make take effect immediately, hence the impact and side effects can be realized in the early stages of the development process. Content-centric - known from networking to development processes in the context of dynamic applications it comprises. All the artifacts are text-based models or executable scripts stored in a generic repository (along with the related binaries, such as images). This makes the life-cycle management of the application itself and the transport between the landscapes (Dev/Test/Prod) straight forward. In result, you can set up the whole system only by pulling the content from a remote source code repository such as git . Scripting languages - programming languages written for a special runtime environment that can interpret (rather than compile) the execution of tasks. Dynamic languages existing nowadays, as well as the existing smooth integration in the Web servers, make the rise of the in-system development in the cloud possible. Shortest turn-around time - the driving principle for our tooling because instant access and instant value are some of the most important requirements for the developers. In general, components of a dynamic application can be separated into the following categories: Data structures - The artifacts representing the domain model of the application. In our case, we have chosen the well-accepted JSON format for describing a normalized entity model. There is no intermediate adaptation layer, hence all entities represent directly the database artifacts - tables and views. Entity services - Once we have the domain model entities, next step is to expose them as Web services. Following the modern Web patterns, we provide the scripting capabilities so you can create your RESTful services in JavaScript, Ruby, and Groovy. Scripting services - During the development, you can use a rich set of APIs that give you access to the database and HTTP layer, utilities, and to the direct Java APIs underneath. Support for creating unit tests is important and is, therefore, integrated as an atomic part of the scripting support itself - you can use the same language for the tests as the one for the services themselves. User interface - Web 2.0 paradigm, as well as HTML5 specification, bring the Web UI to another level. There are already many cool client-side AJAX frameworks that you can use depending on the nature of your application. Integration services - Following the principle of atomicity, one dynamic application should be as self contained as possible. Unfortunately, in the real world there are always some external services that have to be integrated in your application - for data transfer, triggering external processes, lookup in external sources, etc. For this purpose, we provide capabilities for creating simple routing services and dynamic EIPs. Documentation - The documentation is integral part of your application. The target format for describing services and for overall development documentation is already well accepted - wiki .","title":"Dynamic Applications"},{"location":"development/concepts/dynamic-applications/#dynamic-applications","text":"We introduced the term dynamic applications as one that narrows the scope of the target applications that can be created using Eclipse Dirigible. The overall process of building dynamic applications lies on well-known and proved principles: In-system development - known from microcontrollers to business software systems. A major benefit is working on a live system where all changes you make take effect immediately, hence the impact and side effects can be realized in the early stages of the development process. Content-centric - known from networking to development processes in the context of dynamic applications it comprises. All the artifacts are text-based models or executable scripts stored in a generic repository (along with the related binaries, such as images). This makes the life-cycle management of the application itself and the transport between the landscapes (Dev/Test/Prod) straight forward. In result, you can set up the whole system only by pulling the content from a remote source code repository such as git . Scripting languages - programming languages written for a special runtime environment that can interpret (rather than compile) the execution of tasks. Dynamic languages existing nowadays, as well as the existing smooth integration in the Web servers, make the rise of the in-system development in the cloud possible. Shortest turn-around time - the driving principle for our tooling because instant access and instant value are some of the most important requirements for the developers. In general, components of a dynamic application can be separated into the following categories: Data structures - The artifacts representing the domain model of the application. In our case, we have chosen the well-accepted JSON format for describing a normalized entity model. There is no intermediate adaptation layer, hence all entities represent directly the database artifacts - tables and views. Entity services - Once we have the domain model entities, next step is to expose them as Web services. Following the modern Web patterns, we provide the scripting capabilities so you can create your RESTful services in JavaScript, Ruby, and Groovy. Scripting services - During the development, you can use a rich set of APIs that give you access to the database and HTTP layer, utilities, and to the direct Java APIs underneath. Support for creating unit tests is important and is, therefore, integrated as an atomic part of the scripting support itself - you can use the same language for the tests as the one for the services themselves. User interface - Web 2.0 paradigm, as well as HTML5 specification, bring the Web UI to another level. There are already many cool client-side AJAX frameworks that you can use depending on the nature of your application. Integration services - Following the principle of atomicity, one dynamic application should be as self contained as possible. Unfortunately, in the real world there are always some external services that have to be integrated in your application - for data transfer, triggering external processes, lookup in external sources, etc. For this purpose, we provide capabilities for creating simple routing services and dynamic EIPs. Documentation - The documentation is integral part of your application. The target format for describing services and for overall development documentation is already well accepted - wiki .","title":"Dynamic Applications"},{"location":"development/concepts/entity-service/","text":"Entity Service In general, the entity service is a fully capable RESTful service as it is defined by REST architectural style for performance, scalability, simplicity, and so on. It exposes the CRUD operations of a given domain model object. Underneath it, the database store is connected as a data transfer layer. The domain object management is the service pattern that is used most often when following the RESTful paradigm on business software components. In Eclipse Dirigible, the standard functionality of Web services is enhanced but without breaking the REST principles. This is useful for generic utilities and user interface generation. Standard functionality: GET method If the requested path points directly to the service endpoint (no additional parameters), it lists all the entities of this type (in this collection). If the request contains an id parameter, the service returns only the requested entity. POST method - creates an entity, getting the fields from the request body (JSON formatted) and auto-generated ID. PUT method - updates the entity, getting the ID from the request body (JSON formatted). DELETE method - deletes the entity by the provided ID parameter, which is mandatory. Enhancements to the standard functionality of GET with the following parameters: count - returns the number of the entities collection size. metadata - returns the simplified descriptor of the entity in JSON (see below). sort - indicates the order of the entities. desc - indicates the reverse order used with the above parameter. limit - used for paging, returns limited result set. offset - used for paging, result set starts from the offset value. Example metadata for an entity: { \"name\" : \"books\" , \"type\" : \"object\" , \"properties\" : [ { \"name\" : \"book_id\" , \"type\" : \"integer\" , \"key\" : \"true\" , \"required\" : \"true\" }, { \"name\" : \"book_isbn\" , \"type\" : \"string\" }, { \"name\" : \"book_title\" , \"type\" : \"string\" }, { \"name\" : \"book_author\" , \"type\" : \"string\" }, { \"name\" : \"book_editor\" , \"type\" : \"string\" }, { \"name\" : \"book_publisher\" , \"type\" : \"string\" }, { \"name\" : \"book_format\" , \"type\" : \"string\" }, { \"name\" : \"book_publication_date\" , \"type\" : \"date\" }, { \"name\" : \"book_price\" , \"type\" : \"double\" } ] } All these features of entity services are implied during the generation process. As an input, the template uses a database table and an entity service name that are entered in the Entity Data Modeler . Just select the *.entity artifact in the Workspace view. Choose Generate -> User Interface for Entity Service . Limitations for the table to be entity-service compliant: There should be only one column as a primary key that will be used for its identity . There should be only one set of database column types that are supported by default for generation (simple types only as clob and blob are not supported). Generic query methods are not generated because: * It will cover only very simple cases with reasonable performance. * For the complex queries, the introduction of an additional layer results in worse performance in comparison to the SQL script. Entity services are generated in JavaScript , hence they can be accessed right after generation and publishing on: <protocol>://<host>:<port>/services/v4/js/<project>/<entity-service-path> e.g. https://example.com/services/v4/js/bookstore/books.js Or just select them in the Workspace view and check the result in the Preview view.","title":"Entity Service"},{"location":"development/concepts/entity-service/#entity-service","text":"In general, the entity service is a fully capable RESTful service as it is defined by REST architectural style for performance, scalability, simplicity, and so on. It exposes the CRUD operations of a given domain model object. Underneath it, the database store is connected as a data transfer layer. The domain object management is the service pattern that is used most often when following the RESTful paradigm on business software components. In Eclipse Dirigible, the standard functionality of Web services is enhanced but without breaking the REST principles. This is useful for generic utilities and user interface generation. Standard functionality: GET method If the requested path points directly to the service endpoint (no additional parameters), it lists all the entities of this type (in this collection). If the request contains an id parameter, the service returns only the requested entity. POST method - creates an entity, getting the fields from the request body (JSON formatted) and auto-generated ID. PUT method - updates the entity, getting the ID from the request body (JSON formatted). DELETE method - deletes the entity by the provided ID parameter, which is mandatory. Enhancements to the standard functionality of GET with the following parameters: count - returns the number of the entities collection size. metadata - returns the simplified descriptor of the entity in JSON (see below). sort - indicates the order of the entities. desc - indicates the reverse order used with the above parameter. limit - used for paging, returns limited result set. offset - used for paging, result set starts from the offset value. Example metadata for an entity: { \"name\" : \"books\" , \"type\" : \"object\" , \"properties\" : [ { \"name\" : \"book_id\" , \"type\" : \"integer\" , \"key\" : \"true\" , \"required\" : \"true\" }, { \"name\" : \"book_isbn\" , \"type\" : \"string\" }, { \"name\" : \"book_title\" , \"type\" : \"string\" }, { \"name\" : \"book_author\" , \"type\" : \"string\" }, { \"name\" : \"book_editor\" , \"type\" : \"string\" }, { \"name\" : \"book_publisher\" , \"type\" : \"string\" }, { \"name\" : \"book_format\" , \"type\" : \"string\" }, { \"name\" : \"book_publication_date\" , \"type\" : \"date\" }, { \"name\" : \"book_price\" , \"type\" : \"double\" } ] } All these features of entity services are implied during the generation process. As an input, the template uses a database table and an entity service name that are entered in the Entity Data Modeler . Just select the *.entity artifact in the Workspace view. Choose Generate -> User Interface for Entity Service . Limitations for the table to be entity-service compliant: There should be only one column as a primary key that will be used for its identity . There should be only one set of database column types that are supported by default for generation (simple types only as clob and blob are not supported). Generic query methods are not generated because: * It will cover only very simple cases with reasonable performance. * For the complex queries, the introduction of an additional layer results in worse performance in comparison to the SQL script. Entity services are generated in JavaScript , hence they can be accessed right after generation and publishing on: <protocol>://<host>:<port>/services/v4/js/<project>/<entity-service-path> e.g. https://example.com/services/v4/js/bookstore/books.js Or just select them in the Workspace view and check the result in the Preview view.","title":"Entity Service"},{"location":"development/concepts/extensions/","text":"Extension Definitions Extensibility is an important requirement for business applications built to follow custom processes in Line of Business(LoB) areas. In the cloud toolkit, a generic description of the extension points and extensions is provided without explicitly defining the contract. This a simple but powerful way to define extensions. Extension Points An Extension Point is the place in the core module, which is expected to be enhanced by particular custom created modules. It is a simple JSON formated *.extensionpoint file and can be placed anywhere in your project. { \"extension-point\" : \"/project1/extensionPoint1\" , \"description\" : \"Description for Extension Point 1\" } Extensions An Extension is the plug-in in the custom module, which extends the core functionality. It is a simple JSON formated *.extension file and can be placed anywhere in your project. { \"extension\" : \"/project1/extension1\" , \"extension-point\" : \"/project1/extensionPoint1\" , \"description\" : \"Description for Extension 1\" } The extension parameter above should point to a valid JavaScript module . Calling Extensions Within the core module, you can iterate over the defined extensions and call theirs functions: let extensions = extensionManager . getExtensions ( \"/project1/extensionPoint1\" ); for ( let i = 0 ; i < extensions . length ; i ++ ) { let extension = require ( extensions [ i ]); response . println ( extension . enhanceProcess ()); } In the code above, the extension is a JavaScript module ( extension1.js ) within the same project, and it has exposed an enhanceProcess() function.","title":"Extension Definitions"},{"location":"development/concepts/extensions/#extension-definitions","text":"Extensibility is an important requirement for business applications built to follow custom processes in Line of Business(LoB) areas. In the cloud toolkit, a generic description of the extension points and extensions is provided without explicitly defining the contract. This a simple but powerful way to define extensions.","title":"Extension Definitions"},{"location":"development/concepts/extensions/#extension-points","text":"An Extension Point is the place in the core module, which is expected to be enhanced by particular custom created modules. It is a simple JSON formated *.extensionpoint file and can be placed anywhere in your project. { \"extension-point\" : \"/project1/extensionPoint1\" , \"description\" : \"Description for Extension Point 1\" }","title":"Extension Points"},{"location":"development/concepts/extensions/#extensions","text":"An Extension is the plug-in in the custom module, which extends the core functionality. It is a simple JSON formated *.extension file and can be placed anywhere in your project. { \"extension\" : \"/project1/extension1\" , \"extension-point\" : \"/project1/extensionPoint1\" , \"description\" : \"Description for Extension 1\" } The extension parameter above should point to a valid JavaScript module .","title":"Extensions"},{"location":"development/concepts/extensions/#calling-extensions","text":"Within the core module, you can iterate over the defined extensions and call theirs functions: let extensions = extensionManager . getExtensions ( \"/project1/extensionPoint1\" ); for ( let i = 0 ; i < extensions . length ; i ++ ) { let extension = require ( extensions [ i ]); response . println ( extension . enhanceProcess ()); } In the code above, the extension is a JavaScript module ( extension1.js ) within the same project, and it has exposed an enhanceProcess() function.","title":"Calling Extensions"},{"location":"development/concepts/generation/","text":"Generation Template-based generation of artifacts helps for developer productivity in the initial phase of building the application. There are several application components that have similar behavior and often very similar implementation. A prominent example is entity service . It has several predefined methods based on REST concepts and HTTP - GET , POST , PUT , DELETE on an entity level as well as a list of all entities. Additionally, the most notable storage for the entity data is the RDBMS provided by the platform. Another example are user interface templates based on patterns - list , master-detail , input form , etc. Templates can also be provided based on different frameworks for client-side interaction. Note: The generation here is a one-time process. Once you have the generated artifact, you can modify it based on your own requirements. In contrast to the approach above, in case of MDA , you can expect to regenerate the PSMs every time you make changes on PIMs . For this approach, we introduced the entity data modeler where you can define declaratively all the needed components and their attributes. Afterwards, you can use them to generate a complete full-stack data-driven application. Note: The enhancements in this case must go via extensions only.","title":"Generation"},{"location":"development/concepts/generation/#generation","text":"Template-based generation of artifacts helps for developer productivity in the initial phase of building the application. There are several application components that have similar behavior and often very similar implementation. A prominent example is entity service . It has several predefined methods based on REST concepts and HTTP - GET , POST , PUT , DELETE on an entity level as well as a list of all entities. Additionally, the most notable storage for the entity data is the RDBMS provided by the platform. Another example are user interface templates based on patterns - list , master-detail , input form , etc. Templates can also be provided based on different frameworks for client-side interaction. Note: The generation here is a one-time process. Once you have the generated artifact, you can modify it based on your own requirements. In contrast to the approach above, in case of MDA , you can expect to regenerate the PSMs every time you make changes on PIMs . For this approach, we introduced the entity data modeler where you can define declaratively all the needed components and their attributes. Afterwards, you can use them to generate a complete full-stack data-driven application. Note: The enhancements in this case must go via extensions only.","title":"Generation"},{"location":"development/concepts/mobile-apps/","text":"Mobile Applications Overview Mobile application support in Eclipse Dirigible is achieved via Tabris.js . It is a mobile framework that allows you to develop native iOS and Android mobile applications, written entirely in JavaScript . This framework provides native performance, native look and feel, and single code-base (JavaScript) . You can use existing JavaScript libraries and native extensions to extend the core functionality. Unlike other frameworks, which use webviews or cross-platform intermediate runtimes, Tabris.js executes the JavaScript directly on the device and renders everything using native widgets. Thanks to the framework capabilities, the developers can focus more on the mobile application development and less on the platform specifics (iOS and Android).","title":"Mobile Apps"},{"location":"development/concepts/mobile-apps/#mobile-applications","text":"","title":"Mobile Applications"},{"location":"development/concepts/mobile-apps/#overview","text":"Mobile application support in Eclipse Dirigible is achieved via Tabris.js . It is a mobile framework that allows you to develop native iOS and Android mobile applications, written entirely in JavaScript . This framework provides native performance, native look and feel, and single code-base (JavaScript) . You can use existing JavaScript libraries and native extensions to extend the core functionality. Unlike other frameworks, which use webviews or cross-platform intermediate runtimes, Tabris.js executes the JavaScript directly on the device and renders everything using native widgets. Thanks to the framework capabilities, the developers can focus more on the mobile application development and less on the platform specifics (iOS and Android).","title":"Overview"},{"location":"development/concepts/publishing/","text":"Publishing There is a conceptual separation between design-time and runtime phases of the development life cycle. During the design-time phase, the source artifacts are created and managed within the isolated developer's area - workspace . When you are ready with a given feature, you have to publish the project so that the application artifacts become available for the other users. The meaning of \"available\" depends on the type of artifact. For example, for JavaScript services this is the registration of a public endpoint, while for web and wiki content, it is just the access to the artifacts them self, etc. Publishing action is accessible from the context menu in the Workspace view. The space within the repository , where all the public artifact are placed, is called registry .","title":"Publishing"},{"location":"development/concepts/publishing/#publishing","text":"There is a conceptual separation between design-time and runtime phases of the development life cycle. During the design-time phase, the source artifacts are created and managed within the isolated developer's area - workspace . When you are ready with a given feature, you have to publish the project so that the application artifacts become available for the other users. The meaning of \"available\" depends on the type of artifact. For example, for JavaScript services this is the registration of a public endpoint, while for web and wiki content, it is just the access to the artifacts them self, etc. Publishing action is accessible from the context menu in the Workspace view. The space within the repository , where all the public artifact are placed, is called registry .","title":"Publishing"},{"location":"development/concepts/registry/","text":"Registry The registry is the entry point for searching and browsing for service endpoints, as well as for monitoring and administration at runtime. Technically, it is a space within the repository where all the published artifacts are placed.","title":"Registry"},{"location":"development/concepts/registry/#registry","text":"The registry is the entry point for searching and browsing for service endpoints, as well as for monitoring and administration at runtime. Technically, it is a space within the repository where all the published artifacts are placed.","title":"Registry"},{"location":"development/concepts/repository/","text":"Repository The repository component is the main place where all the project's artifacts are stored. It provides an abstract file-system-like structure with folder and files that can be backed by different underlying persistence storages - file system , relational database , noSQL database , etc. In a single repository instance there are several spaces holding different types of content - users' workspaces , public registry , search indices , git metadata , versions , etc.","title":"Repository"},{"location":"development/concepts/repository/#repository","text":"The repository component is the main place where all the project's artifacts are stored. It provides an abstract file-system-like structure with folder and files that can be backed by different underlying persistence storages - file system , relational database , noSQL database , etc. In a single repository instance there are several spaces holding different types of content - users' workspaces , public registry , search indices , git metadata , versions , etc.","title":"Repository"},{"location":"development/concepts/rest/","text":"REST The http-rs module is designed to define and run a broad range of HTTP REST services. A very simple example hello-api.js : var rs = require ( \"http/rs\" ); // serve GET HTTP requests sent to resource path \"\" (i.e. directly to hello-api.js) rs . service () . resource ( \"\" ) . get ( function ( ctx , request , response ){ response . println ( \"Hello there!\" ); }) . execute (); Sending a GET request to /services/v4/js/test/hello-api.js to the server and hosting the hello-api.js piece of code above in test/hello-api.js will return response body: Hello there! Overview Let\u2019s have a closer look at the methods shown in the example above. First, we requested a new REST service instance from the framework: rs.service() Next, we configured the instance to serve HTTP GET requests sent to root path (\"\") using the supplied function: . resource ( \"\" ) . get ( function ( ctx , request , response ){ response . println ( \"Hello there!\" ); }) Technically, configuration is not required to execute a service, but obviously it will do nothing, if you don't instruct it what to do. Finally, we run the service and it processes the HTTP request: .execute(); Now, this is a fairly simplistic example aiming to give you a hint of how you can bring up a REST API to life with http-rs . There is a whole lot more that we shall explore in the next sections. Creating REST services rs.service() Creating new service instances is as simple as invoking rs.service() . That returns a configurable and/or executable instance of the HttpController class. The controller API allows to: - start configuring REST service (method resource() ) - serve requests (method execute() ) - perform a couple of more advanced activities, which will be reviewed in the Advanced section below Additionally, the controller API features also shortcut factory methods that are useful for simplistic configurations (like the one in our initial example) such as get(sPath, fServe, arrConsume, arrProduces) . Read below for more examples how to use the methods. Serving requests execute() The mechanism for serving requests is implemented in the execute() method of the HttpController . It tries to match the request to the service API configuration. If the mechanism matches the request successfully, it triggers the execution flow of the callback functions. The execution flow processes the request and response. If the mechanism doesn't match the request successfully, it sends a Bad Request error to the client. The request and response objects are implicitly those that were used to request the script where the execute() method invocation occurred. But they can be exchanged for others as shown in the Advanced section. The execute() method is defined in the service instance (class HttpController ) obtained with rs.service() . The execute() method can be triggered with rs.service().execute() . The rs API configuration also provides numerous references to the method so you can invoke it on any stage. For example, rs . service (). get ( \"\" ). execute () rs . service (). resource ( \"\" ). get (). execute () rs . service (). resource ( \"\" ). get (). produces ([ \"text/json\" ]). execute () are all valid ways to serve requests. What you need to consider is that execute() must be the final method invocation. Even if you retain a reference to a configuration object and change it after that, it will be irrelevant since the response will be flushed and closed by then. Configuring services There are three options as far as configuration is concerned. You can start from scratch and build the configuration using the rs API. You can use configuration objects. They are holding the configuration that the rs API produces. You can start with a configuration object and then enhance or override the configuration using the rs API. Configuration objects A configuration object is a JS object with canonical structure that the http-rs can interpret. We will discuss its schema later on in this guide. For now, let's just consider that it's the same thing that the rs-fluent API will actually produce behind the scenes so it's a completely valid alternative and complement to the rs-fluent API configuration approach. Refer to the Advanced section for more details on using configuration objects. Defining service resources resource(sPath, oConfiguration?) Resources are the top-level configuration objects that represent an HTTP (server) resource , for which we will be defining a protocol. Each resource is identified by a URL on the server. You can have multiple resources per service configuration, provided that their URLs do not overlap. Resource vs Path vs Resource Path As per the REST terms, a resource is an abstraction or a server-side resource that can be a file, a dynamically generated content, or a procedure (although the last is considered heresy by purists). It's virtually anything hosted on a server that has an address and can be accessed with a standard HTTP method. It is often referred to as path or resource path due to its singular most notable identifying characteristic. But to be precise, path is only a property of the resource. As far as configuration is concerned, the resource defines the configuration scope for which we define method handlers and constraints, and is identifiable by its path property. Resource paths and path templates The sPath string parameter ( mandatory ) of the resource() method will serve as the resource URL. It is relative to the location where the JavaScript service is running (e.g. /services/v4/my-application/api/my-service.js ) . No path ( \"\" ) , request directly to the JavaScript service root ( \"\" ) path. The path can also be a URL template, i.e. parameterized. For example consider the path template: {id}/assets/{assetType}/{name} This will resolve request paths such as: /services/js/test.js/1/assets/longterm/building to service path: 1/assets/longterm/building If a request is matched to such path, the service mechanism will provide the resolved parameters as an object map to the function that handles the request. Using the sample path above the path parameters object will look like this: { \"id\" : 1 , \"assetType\" : \"longterm\" , \"name\" : \"building\" } Defining HTTP methods allowed for a resource resource . get () resource . post () resource . put () resource [ \"delete\" ]() and resource . remove () resource . method () By default, only the HTTP request methods that you have configured for a resource are allowed. The fluent API of Resource instances, obtained with the resource(sPath) method that we discussed above, exposes the most popular REST API methods ( get , post , put and delete ). They are simply aliases for the generic method method . Whichever we consider, we will receive a ResourceMethod instance from the invocation and its API will allow us to specify processing functions and further specify constraints on the request/response for which they are applicable: rs.resource('').get().produces([\"application/json\"]).serve(function(){}) Alternatively, as we have already seen, we can supply the serve callback function directly as first argument to the method, which comes in handy if we have nothing more to setup: rs.resource('').get(function(){}) We can also use configuration object as a third option and this will be discussed in the Advanced section. The samples here are all for configuring HTTP GET Method but the usage pattern is still the same for all: rs.resource('').post().consumes([\"application/json\"]).serve(function(){}) Shortcuts You already noticed that instead of explicitly using serve to configure callback for serving the requests we could directly provide the function as argument to the method configuring the HTTP method (e.g. get ). rs.resource('').get(function(){}) rs.resource('').get().serve(function(){}) So why bother provisioning an explicit serve() function in the first place then? The answer is that serve() configures only one of the callback functions that are triggered during the request processing flow. And this shortcut is handy if it is only serve() that you are interested into configuring. Of course, nothing prevents you also from using the shortcut and still configure the other callback functions, unless you find it confusing. These are all valid options. Find out more about configuring request processing callback functions in the section dedicated to this. When the controller API was discussed, it was mentioned that there are shortcut factory methods that combine a couple operations to produce directly a method handler for a resource path. Example rs . service () . get ( \"\" , function ( ctx , request , response ) { response . print ( 'ok' ); }) . execute (); That would be equivalent to the following: rs . service () . resource ( \"\" ) . get ( function ( ctx , request , response ){ response . print ( 'ok' ); }) . execute (); These shortcut methods share the same names with those in Resource that are used for defining HTTP method handlers: get , post , put , delete and its alias remove , but differ in signature (first argument is a string for the resource path) and the return type (the HttpController instance, instead of ResourceMethod ). They are useful as a compact mechanism if you intend to build something simple and simplistic, such as a single resource and one or few handler functions for it. You will not be able to go much further with this API so if you consider anything even slightly more sophisticated you should look into the fluent API of resource instead: rs.service().resource(\"\") . Note that the scope of these shortcut methods is the controller, not the resource. That has effect on the method chaining. For clean code, do not confuse despite the similar names and avoid mixing them. Defining content types that an API consumes and produces rs . resource ( \"\" ). get (). produces ( \"[application/json]\" ) rs . resource ( \"\" ). post (). consumes ( \"[application/json]\" ) rs . resource ( \"\" ). put (). consumes ( \"[application/json]\" ). produces ( \"[application/json]\" ) Optionally, but also quite likely, we will add some constraints on the data type consumed and produced by the resource method handler that we configure. At request processing runtime, these constraints will be matched for compatibility against the HTTP request headers before delegating to the handler processing function. You can use wildcards ( ) in the MIME types arguments both for type and sub-type and it will be considered as anything* during the execution: rs . resource ( \"\" ). post (). consumes ( \"[*/json]\" ) rs . resource ( \"\" ). post (). consumes ( \"[*/*]\" ) Request processing flow and events Before we continue, let us take a look at the request processing flow. The request is matched against the resource method handling definitions in the configuration and if there is a compatible one it is elicited for execution. Otherwise, a Bad request error is returned back to the client. The before callback function is invoked if any was configured. The serve callback function is invoked if any was configured. If an Error was thrown from the serve function, a catch callback function is invoked. The callback function is either configured or the default one. A finally (always executed) function is invoked if one was configured. Or in pseudocode: try { before ( ctx , request , response , resourceMethod , controller ); serve ( ctx , request , response , resourceMethod , controller ); } catch ( err ){ catch ( ctx , err , request , response , resourceMethod , controller ); } finally { finally (); } As evident form the flow, it is only the serve event callback handler function that is required to be setup. But if you require fine grained reaction to the other events, you can configure handlers for each of those you are interested in. Currently, the API supports a single handler function per event so in multiple invocation of a setup method on the same resource method only the last will matter. Defining event handling functions resource . get (). before ( function ( ctx , request , response , resourceMethod , controller ){ //Implements pre-processing logic }) resource . get (). serve ( function ( ctx , request , response , resourceMethod , controller ){ //Implements request-processing logic }) resource . get (). catch ( function ( ctx , error , request , response , resourceMethod , controller ){ //Implements error-processing logic overriding the default }) resource . get (). finally ( function (){ //Implements post-processing logic regardless of error or success of the serve function }) A valid, executable resource method configuration requires at least the serve callback function to be setup: resource . get (). serve ( function ( ctx , request , response ){ response . println ( 'OK' ); }); The rest are optional and/or have default implementations. Errors thrown from the before and serve callbacks are delegated to the catch callback. There is a default catch callback that sends formatted error back in the response and it can be overridden using the catch method to setup another error processing logic. The finally callback is invoked after the response has been flushed and closed (regardless if in error or success) and can be used to cleanup resources. Example: rs . service (). resource ( \"\" ) . get () . before ( function ( ctx , request , response ){ request . setHeader ( 'X-arestme-version' , '1.0' ); }) . serve ( function ( ctx , request , response ){ response . println ( 'Serving GET request' ); }) . catch ( function ( ctx , err , request , response ){ console . error ( err . message ); }) . finally ( function (){ console . info ( 'GET request processing finished' ); }) Advanced Using configuration objects Configuration objects are particularly useful when you are enhancing or overriding an existing protocol so you don't start configuring from scratch but rather amend or change pieces of the configuration. It is also useful when you are dealing with dynamically generated HTTP-based protocol configurations. For example, consider the simple sample that we started with. It is completely identical with this one, which uses a configuration object and provides it to the service function: rs . service ({ \"\" : { \"get\" : [{ \"serve\" : function ( ctx , request , response ){ response . println ( \"Hello there!\" ); } }] } }). execute (); It is also completely identical with this one: rs . service () . resource ( \"\" , { \"get\" : [{ \"serve\" : function ( ctx , request , response ){ response . println ( \"Hello there!\" ); } }] }). execute (); or this one: rs . service () . resource ( \"\" ) . get ([{ \"serve\" : function ( ctx , request , response ){ response . println ( \"Hello there!\" ); } }]). execute (); In fact, here is a sample how to define a whole API providing configuration directly to the service method and then enhance it. rs . service ({ \"\" : { \"get\" : [{ \"serve\" : function ( ctx , request , response ){ response . println ( \"Hello there!\" ); } }] } }) . resource ( \"\" ) . post () . serve ( function ( ctx , request , response ){ console . info ( request . readText ()); }) . execute (); In this way we essentially are exploiting the fluent API to configure a service but we will not start from scratch. Many of the API methods accept as a second argument configuration object and this doesn't prevent you to continue the API design with fluent API to enhance or override it. The sendError method in HttpController The HttpController class instances that we receive when rs.service() is invoked, features a sendError method. It implements the logic for formatting errors and returning them back to the client taking into account its type and content type preferences. Should you require to change this behavior globally you can redefine the function. If you require different behavior for particular resources or resource method handlers, then using the catch callback is the better approach. Sometimes it's useful to reuse the method and send error in your handler functions. The standard request processing mechanism in HttpController does not account for logical errors. It doesn't know for example that a parameter form a client input is out of valid range. For such cases you would normally implement validation either in before event handler or in serve. And if you need tighter control on what is sent back, e.g. the HTTP code you wouldn't simply throw an Error but invoke the sendError function with the right parameters yourself. For these purposes the last argument of each event handler function is conveniently the controller instance. rs . service (). resource ( \"\" ) . get () . before ( function ( ctx , request , response , methodHandler , controller ){ //check if requested file exists if ( ! file . exists ()){ controller . sendError (); } }) . serve ( function (){ //return file content }) Defining readonly APIs mappings.readonly() An obvious way of defining readonly APIs is to use only GET resource methods definitions. In some cases though APIs can be created from external configuration that also contains other resource method handlers, or we can receive an API instance from another module factory, or we want to support two instances of the same API, one readonly and one with edit capabilities, with minimal code. In such cases, we already have non-GET resource methods that we have to get rid of somehow. Here the readonly method steps in and does exactly this - removes all but the GET resource handlers if any. Example: rs . service () . resource ( \"\" ) . post () . serve ( function (){}); . get () . serve ( function (){}); . readonly () . execute (); If you inspect the configuration after .readonly() is invoked (use resource(\"\").configuration() ) you will notice that the post verb definition is gone. Consecutively, POST requests to this resource will end up in Bad Request (400). Note that for this to work, this must be the last configuration action for a resource. Otherwise, you are resetting the resource configuration to readonly, only to define write methods again. The readonly method is available both for ResourceMapping and Resource objects returned by either invocations of service mappings() method or retained references from configuration API invocations. Disabling a ResourceMethod Handler api.disable(sPath, sVerb, arrConsumesTypes, arrProducesTypes) Similar to the use cases explored for the readonly method above yo might not be in full control of the definition of the API, but rather takeover at some point. Similar to the readonly method, this one will remove the handler definition identified by the four parameters - resource path , resource verb , consumes constraint array (not necessarily in same order), produces constraint array (not necessarily in same order), but it will do it for any verb, not only 'GET'. In that sense readonly is a specialization of this one only for GET verbs. Example: var mappings = rs . service ({ \"\" : { \"post\" : [{ serve : function (){} }], \"get\" : [{ serve : function (){} }] } }). mappings (); mappings . disable ( \"\" , \"post\" ); With this API definition, invoking mappings.find(\"\",\"get\") will return a reference to the only get handler defined there and you can manage it. Note that you get a reference to the configuration and not an API. Example: // add produces constraint and redefine the serve callback var mappings = rs . service (). get ( function (){}). mappings (); //later in code var handler = mappings . find ( \"\" , \"get\" ); handler . produces = [ \"application/json\" ] handler . serve = function (){ console . info ( \"I was redefined\" ); } Executing service with explicit request/response arguments The request and response parameters of the execute method are optional. If you don't supply them, the service will take the request/response objects that were used to request the script. Most of the time this is what you want. However, supplying your own request and response arguments can be very handy for testing as you can easily mock and inspect them. Fluency for execute method The execute method is defined by the service instance ( HttpController ) obtained with rs.service() and can be executed with: rs.service().execute() . The fluent configuration API also provides references to the method, so you can actually invoke it on any stage. Examples: rs . service (). resource ( \"\" ). get ( function (){}). execute () rs . service (). resource ( \"\" ). get (). serve ( function (){}). execute () rs . service (). resource ( \"\" ). get (). produces ([ \"text/json\" ]). serve ( function (){}). execute () rs . service () . resource ( \"\" ) . produces ([ \"application/json\" ]) . get ( function (){}) . resource ( \"\" ) . consumes ([ \"*/json\" ]) . post ( function (){}) . execute () Mappings vs Configurations The API supplies two methods mappings() and configuration() that provide configuration in two forms. The mappings method supplies typed API objects such as Resource aggregating ResourceMethod instances. To get a reference to a service mappings, invoke mappings on the service instance: rs.service().mappings() With a reference to mappings you have their fluent API at disposal. This is useful when extending and enhancing the core rs functionality to build dedicated services. For example the HttpController constructor function is designed to accept mappings and if you extend or initialize it internally in another API you will likely need this form of configuration. An invocation of the configuration method on the other hand provides the underlying JS configuration object. It can be used to supply generic configurations that are used to initialize new types of services as the public fluent API is designed to accept this form of configuration. Both are represent configuration but while the mappings are sort of internal, parsed version, the configuration object is the version that the public api accepts and is also therefore kind of advanced public form of the internal configuration. It is also possible to convert between the two: rs . service ( jsConfig ). mappings () rs . service (). resource (). configuration () Finding a ResourceMethod rs.service().mappings().find(sPath, sMethod, arrConsumesTypes, arrProducesTypes) Suppose you want to redefine a handler definition to e.g. change the serve callback, add a before handler, change or add to the consumes media types constraint etc. To do that you need a reference to the handler, which is identified by the four parameters - resource path , resource method , consumes constraint array (not necessarily in same order), produces constraint array (not necessarily in same order). On a successful search hit you get a reference to the handler definition and can perform changes on it. Example: rs . service () . resource ( \"\" ) . get ( function (){}); With this API definition, invoking rs.service().mappings().find(\"\",\"get\") will return a reference to the only get handler defined there and you can manage it. Note that you get a reference to the configuration and not an API. Example: // add produces constraint and redefine the serve callback var handler = svc . mappings (). find ( \"\" , \"get\" ); handler . produces = [ \"application/json\" ] handler . serve = function (){ console . info ( \"I was redefined\" ); } With consumes and produces constraints on a resource method handler, getting a reference will require them specified too. Example: var svc = rs . service (); svc . mapings () . resource ( \"\" ) . post () . consumes ([ 'application/json' , 'text/json' ]) . produces ([ 'application/json' ]) . serve ( function (){}); var handler = svc . mapings (). find ( \"\" , \"post\" , [ 'text/json' , 'application/json' ], [ 'application/json' ]); Note, that the order of the MIME type string values in the consumes/produces array parameters is not significant. They will be sorted before matching the sorted corresponding arrays in the definition. Configuring resource with JS object Having defined a resource with path we have two options for configuring it. We can proceed using its fluent API or we can provision a configuration JS object as second argument to the resource method and have it done in one step. Considering the latter, we will be provisioning configuration for this resource only, so it should be an object with method definitions as root members. rs . service () . resource ( \"\" , { \"get\" : [{ \"serve\" : function ( ctx , request , response ){ response . println ( \"Hello there!\" ); } }] }). execute (); Refer to the next sections for comparison how to achieve the same, using fluent API and/or configuration objects on the lower levels. JS Configuration object schema In progress. Check back later. Schema: { pathString : { methodString : [{ \"consumes\" : [ \"types/subtype|*/subtype|type/*|*/*\" ] \"produces\" : [ \"types/subtype|*/subtype|type/*|*/*\" ] \"before\" : Function \"serve\" : Function \"catch\" : Function \"finally\" : Function }] } } pathString is a string that represents the resource path. There could be 0 or more such non-overlapping members. methodString is a string for the HTTP resource method. There could be 0 or more such non-overlapping members. The value of methodString is an array of 0 or more objects, each defining a request method processing that will be executed under unique conditions (constraints) that match the request. A component in the methodString array, can consist of constraints (consumes, produces) and request processing flow event handlers (before, serve, catch, finally) consumes value is an array of 0 or more strings, each a valid MIME type string formatted as types/subtype . Can be undefined. produces value is an array of 0 or more strings, each a valid MIME type string formatted as types/subtype . Can be undefined. before , serve , catch and finally values are functions. Except for the serve function, the rest can be undefined . Building a CRUD rest service The code snippet below shows a sample design for a REST API for simple CRUD file operations. It has illustrative purposes. The service design is to work with files in the HOME directory of the user that runs the dirigible instance currently. Users can create, read, update and delete files by sending corresponding POST, GET, PUT and DELETE requests using the file name as path segment (e.g. /services/js/file-serivce.js/test.json ) and they can also upload files if they don't specify file name but send multipart-form-data POST request directly to the service (e.g. /services/js/file-serivce.js ). Note how the before handler is used to validate user has permissions on resources and how it makes use of controller's sendError method. var LOGGER = require ( \"log/v4/logging\" ). getLogger ( 'http.filesvc' ); var rs = require ( \"http/v4/rs\" ); var upload = require ( 'http/v4/upload' ); var files = require ( 'io/v4/files' ); var user = require ( 'security/v4/user' ); var env = require ( 'core/v4/env' ); var validateRequest = function ( permissions , ctx , request , response , methodHandler , controller ){ var filePath = env . get ( 'HOME' ) + '/' + ctx . pathParameters . fileName ; if ( ! files . exists ( filePath )){ LOGGER . info ( \"Requested file \" + filePath + \" does not exist.\" ); controller . sendError ( response . NOT_FOUND , undefined , response . HttpCodesReasons . getReason ( String ( response . NOT_FOUND )), ctx . pathParameters . fileName + \" does not exist.\" ); return ; } if ( permissions ){ var resourcePermissions = files . getPermissions ( filePath ); if ( resourcePermissions !== null && resourcePermissions . indexOf ( permissions ) >- 1 ){ var loggedUser = user . getName (); LOGGER . error ( \"User {} does not have sufficient permissions[{}] for {}\" , loggedUser , files . getPermissions ( filePath ), filePath ); controller . sendError ( response . UNAUTHORIZED , undefined , response . HttpCodesReasons . getReason ( String ( response . UNAUTHORIZED )), \"User \" + loggedUser + \" does not have sufficient permissions for \" + ctx . pathParameters . fileName ); return ; } } LOGGER . error ( 'validation successfull' ); }; var postProcess = function ( operationName ){ LOGGER . info ( \"{} operation finished\" , operationName ); }; rs . service () . resource ( \"\" ) . post ( function ( ctx , request , response ){ var fileItems = upload . parseRequest (); for ( var i = 0 ; i < fileItems . size (); i ++ ) { var filePath = env . get ( 'HOME' ) + '/' ; var content ; var fileItem = fileItems . get ( i ); if ( ! fileItem . isFormField ()) { filePath += fileItem . getName (); content = String . fromCharCode . apply ( null , fileItem . getBytes ()); } else { filePath += fileItem . getFieldName (); content = fileItem . getText (); } LOGGER . debug ( \"Creating file\" + filePath ); files . writeText ( filePath , content ); } response . setStatus ( response . CREATED ); }) . before ( function ( ctx , request , response , methodHandler , controller ){ var loggedUser = user . getName (); if ( files . getOwner ( ctx . pathParameters . fileName ) !== loggedUser ) controller . sendError ( response . UNAUTHORIZED , undefined , response . HttpCodesReasons . getReason ( String ( response . UNAUTHORIZED )), loggedUser + \" is not owner of \" + ctx . pathParameters . fileName ); }) . finally ( postProcess . bind ( this , \"Upload\" )) . consumes ([ \"multipart/form-data\" ]) . resource ( \"{fileName}\" ) . post ( function ( ctx , request , response ){ var content = request . getText (); var filePath = env . get ( 'HOME' ) + '/' + ctx . pathParameters . fileName ; LOGGER . debug ( \"Creating file \" + filePath ); files . writeText ( filePath , content ); files . setPermissions ( filePath , 'rw' ); response . setStatus ( response . CREATED ); }) . finally ( postProcess . bind ( this , \"Create\" )) . consumes ([ \"application/json\" ]) . get ( function ( ctx , request , response ){ var filePath = env . get ( 'HOME' ) + '/' + ctx . pathParameters . fileName ; LOGGER . error ( \"Reading file \" + filePath ); var content = files . readText ( filePath ); response . setStatus ( response . OK ); response . print ( content ); }) . before ( validateRequest . bind ( this , 'r' )) . finally ( postProcess . bind ( this , \"Read\" )) . produces ([ \"application/json\" ]) . put ( function ( ctx , request , response ){ var filePath = env . get ( 'HOME' ) + '/' + ctx . pathParameters . fileName ; LOGGER . debug ( \"Updating file \" + filePath ); var content = request . getJSON (); files . deleteFile ( filePath ); files . writeText ( filePath , content ); response . setStatus ( response . ACCEPTED ); }) . finally ( postProcess . bind ( this , \"Update\" )) . before ( validateRequest . bind ( this , 'rw' )) . consumes ([ \"application/json\" ]) . remove ( function ( ctx , request , response ){ var filePath = env . get ( 'HOME' ) + '/' + ctx . pathParameters . fileName ; LOGGER . debug ( \"Removing file \" + filePath ); files . deleteFile ( filePath ); response . setStatus ( response . NO_CONTENT ); }) . before ( validateRequest . bind ( this , 'w' )) . finally ( postProcess . bind ( this , \"Delete\" )) . execute (); You can find the complete documentation for http/rs and http/rs-data under the API page .","title":"REST"},{"location":"development/concepts/rest/#rest","text":"The http-rs module is designed to define and run a broad range of HTTP REST services. A very simple example hello-api.js : var rs = require ( \"http/rs\" ); // serve GET HTTP requests sent to resource path \"\" (i.e. directly to hello-api.js) rs . service () . resource ( \"\" ) . get ( function ( ctx , request , response ){ response . println ( \"Hello there!\" ); }) . execute (); Sending a GET request to /services/v4/js/test/hello-api.js to the server and hosting the hello-api.js piece of code above in test/hello-api.js will return response body: Hello there!","title":"REST"},{"location":"development/concepts/rest/#overview","text":"Let\u2019s have a closer look at the methods shown in the example above. First, we requested a new REST service instance from the framework: rs.service() Next, we configured the instance to serve HTTP GET requests sent to root path (\"\") using the supplied function: . resource ( \"\" ) . get ( function ( ctx , request , response ){ response . println ( \"Hello there!\" ); }) Technically, configuration is not required to execute a service, but obviously it will do nothing, if you don't instruct it what to do. Finally, we run the service and it processes the HTTP request: .execute(); Now, this is a fairly simplistic example aiming to give you a hint of how you can bring up a REST API to life with http-rs . There is a whole lot more that we shall explore in the next sections.","title":"Overview"},{"location":"development/concepts/rest/#creating-rest-services","text":"rs.service() Creating new service instances is as simple as invoking rs.service() . That returns a configurable and/or executable instance of the HttpController class. The controller API allows to: - start configuring REST service (method resource() ) - serve requests (method execute() ) - perform a couple of more advanced activities, which will be reviewed in the Advanced section below Additionally, the controller API features also shortcut factory methods that are useful for simplistic configurations (like the one in our initial example) such as get(sPath, fServe, arrConsume, arrProduces) . Read below for more examples how to use the methods.","title":"Creating REST services"},{"location":"development/concepts/rest/#serving-requests","text":"execute() The mechanism for serving requests is implemented in the execute() method of the HttpController . It tries to match the request to the service API configuration. If the mechanism matches the request successfully, it triggers the execution flow of the callback functions. The execution flow processes the request and response. If the mechanism doesn't match the request successfully, it sends a Bad Request error to the client. The request and response objects are implicitly those that were used to request the script where the execute() method invocation occurred. But they can be exchanged for others as shown in the Advanced section. The execute() method is defined in the service instance (class HttpController ) obtained with rs.service() . The execute() method can be triggered with rs.service().execute() . The rs API configuration also provides numerous references to the method so you can invoke it on any stage. For example, rs . service (). get ( \"\" ). execute () rs . service (). resource ( \"\" ). get (). execute () rs . service (). resource ( \"\" ). get (). produces ([ \"text/json\" ]). execute () are all valid ways to serve requests. What you need to consider is that execute() must be the final method invocation. Even if you retain a reference to a configuration object and change it after that, it will be irrelevant since the response will be flushed and closed by then.","title":"Serving requests"},{"location":"development/concepts/rest/#configuring-services","text":"There are three options as far as configuration is concerned. You can start from scratch and build the configuration using the rs API. You can use configuration objects. They are holding the configuration that the rs API produces. You can start with a configuration object and then enhance or override the configuration using the rs API. Configuration objects A configuration object is a JS object with canonical structure that the http-rs can interpret. We will discuss its schema later on in this guide. For now, let's just consider that it's the same thing that the rs-fluent API will actually produce behind the scenes so it's a completely valid alternative and complement to the rs-fluent API configuration approach. Refer to the Advanced section for more details on using configuration objects.","title":"Configuring services"},{"location":"development/concepts/rest/#defining-service-resources","text":"resource(sPath, oConfiguration?) Resources are the top-level configuration objects that represent an HTTP (server) resource , for which we will be defining a protocol. Each resource is identified by a URL on the server. You can have multiple resources per service configuration, provided that their URLs do not overlap. Resource vs Path vs Resource Path As per the REST terms, a resource is an abstraction or a server-side resource that can be a file, a dynamically generated content, or a procedure (although the last is considered heresy by purists). It's virtually anything hosted on a server that has an address and can be accessed with a standard HTTP method. It is often referred to as path or resource path due to its singular most notable identifying characteristic. But to be precise, path is only a property of the resource. As far as configuration is concerned, the resource defines the configuration scope for which we define method handlers and constraints, and is identifiable by its path property.","title":"Defining service resources"},{"location":"development/concepts/rest/#resource-paths-and-path-templates","text":"The sPath string parameter ( mandatory ) of the resource() method will serve as the resource URL. It is relative to the location where the JavaScript service is running (e.g. /services/v4/my-application/api/my-service.js ) . No path ( \"\" ) , request directly to the JavaScript service root ( \"\" ) path. The path can also be a URL template, i.e. parameterized. For example consider the path template: {id}/assets/{assetType}/{name} This will resolve request paths such as: /services/js/test.js/1/assets/longterm/building to service path: 1/assets/longterm/building If a request is matched to such path, the service mechanism will provide the resolved parameters as an object map to the function that handles the request. Using the sample path above the path parameters object will look like this: { \"id\" : 1 , \"assetType\" : \"longterm\" , \"name\" : \"building\" }","title":"Resource paths and path templates"},{"location":"development/concepts/rest/#defining-http-methods-allowed-for-a-resource","text":"resource . get () resource . post () resource . put () resource [ \"delete\" ]() and resource . remove () resource . method () By default, only the HTTP request methods that you have configured for a resource are allowed. The fluent API of Resource instances, obtained with the resource(sPath) method that we discussed above, exposes the most popular REST API methods ( get , post , put and delete ). They are simply aliases for the generic method method . Whichever we consider, we will receive a ResourceMethod instance from the invocation and its API will allow us to specify processing functions and further specify constraints on the request/response for which they are applicable: rs.resource('').get().produces([\"application/json\"]).serve(function(){}) Alternatively, as we have already seen, we can supply the serve callback function directly as first argument to the method, which comes in handy if we have nothing more to setup: rs.resource('').get(function(){}) We can also use configuration object as a third option and this will be discussed in the Advanced section. The samples here are all for configuring HTTP GET Method but the usage pattern is still the same for all: rs.resource('').post().consumes([\"application/json\"]).serve(function(){}) Shortcuts You already noticed that instead of explicitly using serve to configure callback for serving the requests we could directly provide the function as argument to the method configuring the HTTP method (e.g. get ). rs.resource('').get(function(){}) rs.resource('').get().serve(function(){}) So why bother provisioning an explicit serve() function in the first place then? The answer is that serve() configures only one of the callback functions that are triggered during the request processing flow. And this shortcut is handy if it is only serve() that you are interested into configuring. Of course, nothing prevents you also from using the shortcut and still configure the other callback functions, unless you find it confusing. These are all valid options. Find out more about configuring request processing callback functions in the section dedicated to this. When the controller API was discussed, it was mentioned that there are shortcut factory methods that combine a couple operations to produce directly a method handler for a resource path. Example rs . service () . get ( \"\" , function ( ctx , request , response ) { response . print ( 'ok' ); }) . execute (); That would be equivalent to the following: rs . service () . resource ( \"\" ) . get ( function ( ctx , request , response ){ response . print ( 'ok' ); }) . execute (); These shortcut methods share the same names with those in Resource that are used for defining HTTP method handlers: get , post , put , delete and its alias remove , but differ in signature (first argument is a string for the resource path) and the return type (the HttpController instance, instead of ResourceMethod ). They are useful as a compact mechanism if you intend to build something simple and simplistic, such as a single resource and one or few handler functions for it. You will not be able to go much further with this API so if you consider anything even slightly more sophisticated you should look into the fluent API of resource instead: rs.service().resource(\"\") . Note that the scope of these shortcut methods is the controller, not the resource. That has effect on the method chaining. For clean code, do not confuse despite the similar names and avoid mixing them.","title":"Defining HTTP methods allowed for a resource"},{"location":"development/concepts/rest/#defining-content-types-that-an-api-consumes-and-produces","text":"rs . resource ( \"\" ). get (). produces ( \"[application/json]\" ) rs . resource ( \"\" ). post (). consumes ( \"[application/json]\" ) rs . resource ( \"\" ). put (). consumes ( \"[application/json]\" ). produces ( \"[application/json]\" ) Optionally, but also quite likely, we will add some constraints on the data type consumed and produced by the resource method handler that we configure. At request processing runtime, these constraints will be matched for compatibility against the HTTP request headers before delegating to the handler processing function. You can use wildcards ( ) in the MIME types arguments both for type and sub-type and it will be considered as anything* during the execution: rs . resource ( \"\" ). post (). consumes ( \"[*/json]\" ) rs . resource ( \"\" ). post (). consumes ( \"[*/*]\" )","title":"Defining content types that an API consumes and produces"},{"location":"development/concepts/rest/#request-processing-flow-and-events","text":"Before we continue, let us take a look at the request processing flow. The request is matched against the resource method handling definitions in the configuration and if there is a compatible one it is elicited for execution. Otherwise, a Bad request error is returned back to the client. The before callback function is invoked if any was configured. The serve callback function is invoked if any was configured. If an Error was thrown from the serve function, a catch callback function is invoked. The callback function is either configured or the default one. A finally (always executed) function is invoked if one was configured. Or in pseudocode: try { before ( ctx , request , response , resourceMethod , controller ); serve ( ctx , request , response , resourceMethod , controller ); } catch ( err ){ catch ( ctx , err , request , response , resourceMethod , controller ); } finally { finally (); } As evident form the flow, it is only the serve event callback handler function that is required to be setup. But if you require fine grained reaction to the other events, you can configure handlers for each of those you are interested in. Currently, the API supports a single handler function per event so in multiple invocation of a setup method on the same resource method only the last will matter.","title":"Request processing flow and events"},{"location":"development/concepts/rest/#defining-event-handling-functions","text":"resource . get (). before ( function ( ctx , request , response , resourceMethod , controller ){ //Implements pre-processing logic }) resource . get (). serve ( function ( ctx , request , response , resourceMethod , controller ){ //Implements request-processing logic }) resource . get (). catch ( function ( ctx , error , request , response , resourceMethod , controller ){ //Implements error-processing logic overriding the default }) resource . get (). finally ( function (){ //Implements post-processing logic regardless of error or success of the serve function }) A valid, executable resource method configuration requires at least the serve callback function to be setup: resource . get (). serve ( function ( ctx , request , response ){ response . println ( 'OK' ); }); The rest are optional and/or have default implementations. Errors thrown from the before and serve callbacks are delegated to the catch callback. There is a default catch callback that sends formatted error back in the response and it can be overridden using the catch method to setup another error processing logic. The finally callback is invoked after the response has been flushed and closed (regardless if in error or success) and can be used to cleanup resources. Example: rs . service (). resource ( \"\" ) . get () . before ( function ( ctx , request , response ){ request . setHeader ( 'X-arestme-version' , '1.0' ); }) . serve ( function ( ctx , request , response ){ response . println ( 'Serving GET request' ); }) . catch ( function ( ctx , err , request , response ){ console . error ( err . message ); }) . finally ( function (){ console . info ( 'GET request processing finished' ); })","title":"Defining event handling functions"},{"location":"development/concepts/rest/#advanced","text":"","title":"Advanced"},{"location":"development/concepts/rest/#using-configuration-objects","text":"Configuration objects are particularly useful when you are enhancing or overriding an existing protocol so you don't start configuring from scratch but rather amend or change pieces of the configuration. It is also useful when you are dealing with dynamically generated HTTP-based protocol configurations. For example, consider the simple sample that we started with. It is completely identical with this one, which uses a configuration object and provides it to the service function: rs . service ({ \"\" : { \"get\" : [{ \"serve\" : function ( ctx , request , response ){ response . println ( \"Hello there!\" ); } }] } }). execute (); It is also completely identical with this one: rs . service () . resource ( \"\" , { \"get\" : [{ \"serve\" : function ( ctx , request , response ){ response . println ( \"Hello there!\" ); } }] }). execute (); or this one: rs . service () . resource ( \"\" ) . get ([{ \"serve\" : function ( ctx , request , response ){ response . println ( \"Hello there!\" ); } }]). execute (); In fact, here is a sample how to define a whole API providing configuration directly to the service method and then enhance it. rs . service ({ \"\" : { \"get\" : [{ \"serve\" : function ( ctx , request , response ){ response . println ( \"Hello there!\" ); } }] } }) . resource ( \"\" ) . post () . serve ( function ( ctx , request , response ){ console . info ( request . readText ()); }) . execute (); In this way we essentially are exploiting the fluent API to configure a service but we will not start from scratch. Many of the API methods accept as a second argument configuration object and this doesn't prevent you to continue the API design with fluent API to enhance or override it.","title":"Using configuration objects"},{"location":"development/concepts/rest/#the-senderror-method-in-httpcontroller","text":"The HttpController class instances that we receive when rs.service() is invoked, features a sendError method. It implements the logic for formatting errors and returning them back to the client taking into account its type and content type preferences. Should you require to change this behavior globally you can redefine the function. If you require different behavior for particular resources or resource method handlers, then using the catch callback is the better approach. Sometimes it's useful to reuse the method and send error in your handler functions. The standard request processing mechanism in HttpController does not account for logical errors. It doesn't know for example that a parameter form a client input is out of valid range. For such cases you would normally implement validation either in before event handler or in serve. And if you need tighter control on what is sent back, e.g. the HTTP code you wouldn't simply throw an Error but invoke the sendError function with the right parameters yourself. For these purposes the last argument of each event handler function is conveniently the controller instance. rs . service (). resource ( \"\" ) . get () . before ( function ( ctx , request , response , methodHandler , controller ){ //check if requested file exists if ( ! file . exists ()){ controller . sendError (); } }) . serve ( function (){ //return file content })","title":"The sendError method in HttpController"},{"location":"development/concepts/rest/#defining-readonly-apis","text":"mappings.readonly() An obvious way of defining readonly APIs is to use only GET resource methods definitions. In some cases though APIs can be created from external configuration that also contains other resource method handlers, or we can receive an API instance from another module factory, or we want to support two instances of the same API, one readonly and one with edit capabilities, with minimal code. In such cases, we already have non-GET resource methods that we have to get rid of somehow. Here the readonly method steps in and does exactly this - removes all but the GET resource handlers if any. Example: rs . service () . resource ( \"\" ) . post () . serve ( function (){}); . get () . serve ( function (){}); . readonly () . execute (); If you inspect the configuration after .readonly() is invoked (use resource(\"\").configuration() ) you will notice that the post verb definition is gone. Consecutively, POST requests to this resource will end up in Bad Request (400). Note that for this to work, this must be the last configuration action for a resource. Otherwise, you are resetting the resource configuration to readonly, only to define write methods again. The readonly method is available both for ResourceMapping and Resource objects returned by either invocations of service mappings() method or retained references from configuration API invocations.","title":"Defining readonly APIs"},{"location":"development/concepts/rest/#disabling-a-resourcemethod-handler","text":"api.disable(sPath, sVerb, arrConsumesTypes, arrProducesTypes) Similar to the use cases explored for the readonly method above yo might not be in full control of the definition of the API, but rather takeover at some point. Similar to the readonly method, this one will remove the handler definition identified by the four parameters - resource path , resource verb , consumes constraint array (not necessarily in same order), produces constraint array (not necessarily in same order), but it will do it for any verb, not only 'GET'. In that sense readonly is a specialization of this one only for GET verbs. Example: var mappings = rs . service ({ \"\" : { \"post\" : [{ serve : function (){} }], \"get\" : [{ serve : function (){} }] } }). mappings (); mappings . disable ( \"\" , \"post\" ); With this API definition, invoking mappings.find(\"\",\"get\") will return a reference to the only get handler defined there and you can manage it. Note that you get a reference to the configuration and not an API. Example: // add produces constraint and redefine the serve callback var mappings = rs . service (). get ( function (){}). mappings (); //later in code var handler = mappings . find ( \"\" , \"get\" ); handler . produces = [ \"application/json\" ] handler . serve = function (){ console . info ( \"I was redefined\" ); }","title":"Disabling a ResourceMethod Handler"},{"location":"development/concepts/rest/#executing-service-with-explicit-requestresponse-arguments","text":"The request and response parameters of the execute method are optional. If you don't supply them, the service will take the request/response objects that were used to request the script. Most of the time this is what you want. However, supplying your own request and response arguments can be very handy for testing as you can easily mock and inspect them.","title":"Executing service with explicit request/response arguments"},{"location":"development/concepts/rest/#fluency-for-execute-method","text":"The execute method is defined by the service instance ( HttpController ) obtained with rs.service() and can be executed with: rs.service().execute() . The fluent configuration API also provides references to the method, so you can actually invoke it on any stage. Examples: rs . service (). resource ( \"\" ). get ( function (){}). execute () rs . service (). resource ( \"\" ). get (). serve ( function (){}). execute () rs . service (). resource ( \"\" ). get (). produces ([ \"text/json\" ]). serve ( function (){}). execute () rs . service () . resource ( \"\" ) . produces ([ \"application/json\" ]) . get ( function (){}) . resource ( \"\" ) . consumes ([ \"*/json\" ]) . post ( function (){}) . execute ()","title":"Fluency for execute method"},{"location":"development/concepts/rest/#mappings-vs-configurations","text":"The API supplies two methods mappings() and configuration() that provide configuration in two forms. The mappings method supplies typed API objects such as Resource aggregating ResourceMethod instances. To get a reference to a service mappings, invoke mappings on the service instance: rs.service().mappings() With a reference to mappings you have their fluent API at disposal. This is useful when extending and enhancing the core rs functionality to build dedicated services. For example the HttpController constructor function is designed to accept mappings and if you extend or initialize it internally in another API you will likely need this form of configuration. An invocation of the configuration method on the other hand provides the underlying JS configuration object. It can be used to supply generic configurations that are used to initialize new types of services as the public fluent API is designed to accept this form of configuration. Both are represent configuration but while the mappings are sort of internal, parsed version, the configuration object is the version that the public api accepts and is also therefore kind of advanced public form of the internal configuration. It is also possible to convert between the two: rs . service ( jsConfig ). mappings () rs . service (). resource (). configuration ()","title":"Mappings vs Configurations"},{"location":"development/concepts/rest/#finding-a-resourcemethod","text":"rs.service().mappings().find(sPath, sMethod, arrConsumesTypes, arrProducesTypes) Suppose you want to redefine a handler definition to e.g. change the serve callback, add a before handler, change or add to the consumes media types constraint etc. To do that you need a reference to the handler, which is identified by the four parameters - resource path , resource method , consumes constraint array (not necessarily in same order), produces constraint array (not necessarily in same order). On a successful search hit you get a reference to the handler definition and can perform changes on it. Example: rs . service () . resource ( \"\" ) . get ( function (){}); With this API definition, invoking rs.service().mappings().find(\"\",\"get\") will return a reference to the only get handler defined there and you can manage it. Note that you get a reference to the configuration and not an API. Example: // add produces constraint and redefine the serve callback var handler = svc . mappings (). find ( \"\" , \"get\" ); handler . produces = [ \"application/json\" ] handler . serve = function (){ console . info ( \"I was redefined\" ); } With consumes and produces constraints on a resource method handler, getting a reference will require them specified too. Example: var svc = rs . service (); svc . mapings () . resource ( \"\" ) . post () . consumes ([ 'application/json' , 'text/json' ]) . produces ([ 'application/json' ]) . serve ( function (){}); var handler = svc . mapings (). find ( \"\" , \"post\" , [ 'text/json' , 'application/json' ], [ 'application/json' ]); Note, that the order of the MIME type string values in the consumes/produces array parameters is not significant. They will be sorted before matching the sorted corresponding arrays in the definition.","title":"Finding a ResourceMethod"},{"location":"development/concepts/rest/#configuring-resource-with-js-object","text":"Having defined a resource with path we have two options for configuring it. We can proceed using its fluent API or we can provision a configuration JS object as second argument to the resource method and have it done in one step. Considering the latter, we will be provisioning configuration for this resource only, so it should be an object with method definitions as root members. rs . service () . resource ( \"\" , { \"get\" : [{ \"serve\" : function ( ctx , request , response ){ response . println ( \"Hello there!\" ); } }] }). execute (); Refer to the next sections for comparison how to achieve the same, using fluent API and/or configuration objects on the lower levels.","title":"Configuring resource with JS object"},{"location":"development/concepts/rest/#js-configuration-object-schema","text":"In progress. Check back later. Schema: { pathString : { methodString : [{ \"consumes\" : [ \"types/subtype|*/subtype|type/*|*/*\" ] \"produces\" : [ \"types/subtype|*/subtype|type/*|*/*\" ] \"before\" : Function \"serve\" : Function \"catch\" : Function \"finally\" : Function }] } } pathString is a string that represents the resource path. There could be 0 or more such non-overlapping members. methodString is a string for the HTTP resource method. There could be 0 or more such non-overlapping members. The value of methodString is an array of 0 or more objects, each defining a request method processing that will be executed under unique conditions (constraints) that match the request. A component in the methodString array, can consist of constraints (consumes, produces) and request processing flow event handlers (before, serve, catch, finally) consumes value is an array of 0 or more strings, each a valid MIME type string formatted as types/subtype . Can be undefined. produces value is an array of 0 or more strings, each a valid MIME type string formatted as types/subtype . Can be undefined. before , serve , catch and finally values are functions. Except for the serve function, the rest can be undefined .","title":"JS Configuration object schema"},{"location":"development/concepts/rest/#building-a-crud-rest-service","text":"The code snippet below shows a sample design for a REST API for simple CRUD file operations. It has illustrative purposes. The service design is to work with files in the HOME directory of the user that runs the dirigible instance currently. Users can create, read, update and delete files by sending corresponding POST, GET, PUT and DELETE requests using the file name as path segment (e.g. /services/js/file-serivce.js/test.json ) and they can also upload files if they don't specify file name but send multipart-form-data POST request directly to the service (e.g. /services/js/file-serivce.js ). Note how the before handler is used to validate user has permissions on resources and how it makes use of controller's sendError method. var LOGGER = require ( \"log/v4/logging\" ). getLogger ( 'http.filesvc' ); var rs = require ( \"http/v4/rs\" ); var upload = require ( 'http/v4/upload' ); var files = require ( 'io/v4/files' ); var user = require ( 'security/v4/user' ); var env = require ( 'core/v4/env' ); var validateRequest = function ( permissions , ctx , request , response , methodHandler , controller ){ var filePath = env . get ( 'HOME' ) + '/' + ctx . pathParameters . fileName ; if ( ! files . exists ( filePath )){ LOGGER . info ( \"Requested file \" + filePath + \" does not exist.\" ); controller . sendError ( response . NOT_FOUND , undefined , response . HttpCodesReasons . getReason ( String ( response . NOT_FOUND )), ctx . pathParameters . fileName + \" does not exist.\" ); return ; } if ( permissions ){ var resourcePermissions = files . getPermissions ( filePath ); if ( resourcePermissions !== null && resourcePermissions . indexOf ( permissions ) >- 1 ){ var loggedUser = user . getName (); LOGGER . error ( \"User {} does not have sufficient permissions[{}] for {}\" , loggedUser , files . getPermissions ( filePath ), filePath ); controller . sendError ( response . UNAUTHORIZED , undefined , response . HttpCodesReasons . getReason ( String ( response . UNAUTHORIZED )), \"User \" + loggedUser + \" does not have sufficient permissions for \" + ctx . pathParameters . fileName ); return ; } } LOGGER . error ( 'validation successfull' ); }; var postProcess = function ( operationName ){ LOGGER . info ( \"{} operation finished\" , operationName ); }; rs . service () . resource ( \"\" ) . post ( function ( ctx , request , response ){ var fileItems = upload . parseRequest (); for ( var i = 0 ; i < fileItems . size (); i ++ ) { var filePath = env . get ( 'HOME' ) + '/' ; var content ; var fileItem = fileItems . get ( i ); if ( ! fileItem . isFormField ()) { filePath += fileItem . getName (); content = String . fromCharCode . apply ( null , fileItem . getBytes ()); } else { filePath += fileItem . getFieldName (); content = fileItem . getText (); } LOGGER . debug ( \"Creating file\" + filePath ); files . writeText ( filePath , content ); } response . setStatus ( response . CREATED ); }) . before ( function ( ctx , request , response , methodHandler , controller ){ var loggedUser = user . getName (); if ( files . getOwner ( ctx . pathParameters . fileName ) !== loggedUser ) controller . sendError ( response . UNAUTHORIZED , undefined , response . HttpCodesReasons . getReason ( String ( response . UNAUTHORIZED )), loggedUser + \" is not owner of \" + ctx . pathParameters . fileName ); }) . finally ( postProcess . bind ( this , \"Upload\" )) . consumes ([ \"multipart/form-data\" ]) . resource ( \"{fileName}\" ) . post ( function ( ctx , request , response ){ var content = request . getText (); var filePath = env . get ( 'HOME' ) + '/' + ctx . pathParameters . fileName ; LOGGER . debug ( \"Creating file \" + filePath ); files . writeText ( filePath , content ); files . setPermissions ( filePath , 'rw' ); response . setStatus ( response . CREATED ); }) . finally ( postProcess . bind ( this , \"Create\" )) . consumes ([ \"application/json\" ]) . get ( function ( ctx , request , response ){ var filePath = env . get ( 'HOME' ) + '/' + ctx . pathParameters . fileName ; LOGGER . error ( \"Reading file \" + filePath ); var content = files . readText ( filePath ); response . setStatus ( response . OK ); response . print ( content ); }) . before ( validateRequest . bind ( this , 'r' )) . finally ( postProcess . bind ( this , \"Read\" )) . produces ([ \"application/json\" ]) . put ( function ( ctx , request , response ){ var filePath = env . get ( 'HOME' ) + '/' + ctx . pathParameters . fileName ; LOGGER . debug ( \"Updating file \" + filePath ); var content = request . getJSON (); files . deleteFile ( filePath ); files . writeText ( filePath , content ); response . setStatus ( response . ACCEPTED ); }) . finally ( postProcess . bind ( this , \"Update\" )) . before ( validateRequest . bind ( this , 'rw' )) . consumes ([ \"application/json\" ]) . remove ( function ( ctx , request , response ){ var filePath = env . get ( 'HOME' ) + '/' + ctx . pathParameters . fileName ; LOGGER . debug ( \"Removing file \" + filePath ); files . deleteFile ( filePath ); response . setStatus ( response . NO_CONTENT ); }) . before ( validateRequest . bind ( this , 'w' )) . finally ( postProcess . bind ( this , \"Delete\" )) . execute (); You can find the complete documentation for http/rs and http/rs-data under the API page .","title":"Building a CRUD rest service"},{"location":"development/concepts/web-content/","text":"Web Content Overview The Web content includes all the static client-side resources, such as HTML files, CSS, and related theme ingredients, as well as the dynamic scripts and the images. In general, a Web content adapter plays the role of a tunnel that takes the desired resource location from the request path, loads the corresponding content from the repository, and sends it back without any modification. By default, the Web content adapter accepts requests to particular resources and responds with an error code to requests to whole collections. This way, the Web content adapter indicates that folder listing is forbidden. If the specific application/json Accept header is supplied with the request itself, then a JSON formatted array with sub-folders and resources will be returned. To boost developer productivity in the most common cases, we provide a set of templates that can help during UI creation. There is a set of templates that can be used with the entity services , a list of entities, master-detail, input form, and so on. The other templates can be used as utilities for the creation an application shell in index.html with main menu or as samples that show the most common controls on different AJAX UI frameworks, such as jQuery , Bootstrap , AngularJS , and OpenUI5 .","title":"Web Content"},{"location":"development/concepts/web-content/#web-content","text":"","title":"Web Content"},{"location":"development/concepts/web-content/#overview","text":"The Web content includes all the static client-side resources, such as HTML files, CSS, and related theme ingredients, as well as the dynamic scripts and the images. In general, a Web content adapter plays the role of a tunnel that takes the desired resource location from the request path, loads the corresponding content from the repository, and sends it back without any modification. By default, the Web content adapter accepts requests to particular resources and responds with an error code to requests to whole collections. This way, the Web content adapter indicates that folder listing is forbidden. If the specific application/json Accept header is supplied with the request itself, then a JSON formatted array with sub-folders and resources will be returned. To boost developer productivity in the most common cases, we provide a set of templates that can help during UI creation. There is a set of templates that can be used with the entity services , a list of entities, master-detail, input form, and so on. The other templates can be used as utilities for the creation an application shell in index.html with main menu or as samples that show the most common controls on different AJAX UI frameworks, such as jQuery , Bootstrap , AngularJS , and OpenUI5 .","title":"Overview"},{"location":"development/concepts/workspace/","text":"Workspace The workspace is the developer's place where you create and manage the application artifacts. The first-level citizens of the workspace are the projects . Each project can contain multiple folders and files (artifacts). A single user can have multiple workspaces that contain different sets of projects. The artifacts, i.e. the project management, can be done via the views and editors in the Workbench perspective .","title":"Workspace"},{"location":"development/concepts/workspace/#workspace","text":"The workspace is the developer's place where you create and manage the application artifacts. The first-level citizens of the workspace are the projects . Each project can contain multiple folders and files (artifacts). A single user can have multiple workspaces that contain different sets of projects. The artifacts, i.e. the project management, can be done via the views and editors in the Workbench perspective .","title":"Workspace"},{"location":"development/extensions/","text":"Extensions Extensibility Extensibility is an important requirement for business applications built to follow custom processes in Line of Business(LoB) areas. In the cloud toolkit, a generic description of the extension points and extensions is provided without explicitly defining the contract. This a simple but powerful way to define extensions. To learn more about the Extensions concept, click here Extension Points ide-perspective ide-view ide-editor ide-template ide-menu ide-themes ide-workspace-menu-new-template api-modules ide-operations-menu ide-documents-content-type ide-documents-menu ide-git-menu ide-terminal-menu ide-discussions-menu ide-database-menu ide-repository-menu Events editor.file.saved editor.file.dirty status.message status.caret status.error database.database.selection.changed database.datasource.selection.changed database.sql.execute database.sql.run git.repository.run workspace.file.selected workspace.file.created workspace.file.open workspace.file.pull workspace.file.deleted workspace.file.renamed workspace.file.moved workspace.file.copied workspace.file.properties workspace.file.published workspace.project.exported repository.resource.selected repository.resource.created repository.resource.open repository.resource.deleted","title":"Extensions"},{"location":"development/extensions/#extensions","text":"","title":"Extensions"},{"location":"development/extensions/#extensibility","text":"Extensibility is an important requirement for business applications built to follow custom processes in Line of Business(LoB) areas. In the cloud toolkit, a generic description of the extension points and extensions is provided without explicitly defining the contract. This a simple but powerful way to define extensions. To learn more about the Extensions concept, click here","title":"Extensibility"},{"location":"development/extensions/#extension-points","text":"ide-perspective ide-view ide-editor ide-template ide-menu ide-themes ide-workspace-menu-new-template api-modules ide-operations-menu ide-documents-content-type ide-documents-menu ide-git-menu ide-terminal-menu ide-discussions-menu ide-database-menu ide-repository-menu","title":"Extension Points"},{"location":"development/extensions/#events","text":"editor.file.saved editor.file.dirty status.message status.caret status.error database.database.selection.changed database.datasource.selection.changed database.sql.execute database.sql.run git.repository.run workspace.file.selected workspace.file.created workspace.file.open workspace.file.pull workspace.file.deleted workspace.file.renamed workspace.file.moved workspace.file.copied workspace.file.properties workspace.file.published workspace.project.exported repository.resource.selected repository.resource.created repository.resource.open repository.resource.deleted","title":"Events"},{"location":"development/extensions/editor/","text":"Extension - Editor Descriptors To contribute a new Editor (text-based or form-based) to the Web IDE you need to create one model ( *.extension ) and one descriptor (in *.js ) files in your project: my-editor.extension { \"module\" : \"my-project/services/my-editor.js\" , \"extensionPoint\" : \"ide-editor\" , \"description\" : \"The description of my editor\" } module points to the corresponding view descriptor (see below) extensionPoint is the name of the built-in extension point to which the current plugin will contribute my-editor.js exports . getView = function () { var view = { name : \"My Editor\" , factory : \"frame\" , region : \"center-top\" , link : \"../my-project/index.html\" , contentTypes : [ \"application/json\" ] }; return view ; }; name is the exact name of the view, which will be shown in the e.g. menu factory the type of the factory used during instantiating the view region the region where the view will be placed initially link is the location within the same or external project pointing to the entry HTML file which will be rendered as a view contentTypes the content types array of supported files The project structure in this case should look like this: | my-project |---- extensions |----> my-editor.extension |---- services |----> my-editor.js |---- index.html |---- js |---- css |---- ... Note: The names of the extensions and services can be different following the layout of your project Implementation <!DOCTYPE html> < html lang = \"en\" ng-app = \"editor\" > < head > < meta charset = \"utf-8\" > < meta http-equiv = \"X-UA-Compatible\" content = \"IE=edge\" > < meta name = \"viewport\" content = \"width=device-width, initial-scale=1.0\" > < meta name = \"description\" content = \"\" > < meta name = \"author\" content = \"\" > < link type = \"text/css\" rel = \"stylesheet\" href = \"../../../../../services/v4/js/theme/resources.js/bootstrap.min.css\" > < link type = \"text/css\" rel = \"stylesheet\" href = \"../../../../../services/v4/web/resources/font-awesome-4.7.0/css/font-awesome.min.css\" > < link type = \"image/png\" rel = \"shortcut icon\" href = \"../../../../../services/v4/web/resources/images/favicon.png\" /> <!-- Custom IDE Styles --> < link type = \"text/css\" rel = \"stylesheet\" href = \"../../../../../services/v4/js/theme/resources.js/ide.css\" /> </ head > < body ng-controller = \"EditorController\" > < div class = \"container\" > < div class = \"page-header\" > < h1 > My Editor Description: {{file}} </ h1 > </ div > < form > < div class = \"form-group\" > < label > Group </ label > < input type = \"text\" class = \"form-control\" ng-model = \"myModel.group\" value = \"\" > </ div > ... < button type = \"button\" class = \"btn btn-primary\" ng-click = \"save()\" > Save </ button > </ form > </ div > < script type = \"text/javascript\" src = \"../../../../../services/v4/web/resources/jquery/2.0.3/jquery.min.js\" ></ script > < script type = \"text/javascript\" src = \"../../../../../services/v4/web/resources/bootstrap/3.3.7/bootstrap.min.js\" async ></ script > < script type = \"text/javascript\" src = \"../../../../../services/v4/web/resources/angular/1.4.7/angular.min.js\" ></ script > < script type = \"text/javascript\" src = \"../../../../../services/v4/web/resources/angular/1.4.7/angular-resource.min.js\" ></ script > < script src = \"../../../../../services/v4/web/ide-core/ui/message-hub.js\" ></ script > < script type = \"text/javascript\" src = \"editor.js\" ></ script > </ body > </ html > For \u0430 real world example you can look at Jobs Plugin or Monaco Editor","title":"Editor"},{"location":"development/extensions/editor/#extension-editor","text":"","title":"Extension - Editor"},{"location":"development/extensions/editor/#descriptors","text":"To contribute a new Editor (text-based or form-based) to the Web IDE you need to create one model ( *.extension ) and one descriptor (in *.js ) files in your project: my-editor.extension { \"module\" : \"my-project/services/my-editor.js\" , \"extensionPoint\" : \"ide-editor\" , \"description\" : \"The description of my editor\" } module points to the corresponding view descriptor (see below) extensionPoint is the name of the built-in extension point to which the current plugin will contribute my-editor.js exports . getView = function () { var view = { name : \"My Editor\" , factory : \"frame\" , region : \"center-top\" , link : \"../my-project/index.html\" , contentTypes : [ \"application/json\" ] }; return view ; }; name is the exact name of the view, which will be shown in the e.g. menu factory the type of the factory used during instantiating the view region the region where the view will be placed initially link is the location within the same or external project pointing to the entry HTML file which will be rendered as a view contentTypes the content types array of supported files The project structure in this case should look like this: | my-project |---- extensions |----> my-editor.extension |---- services |----> my-editor.js |---- index.html |---- js |---- css |---- ... Note: The names of the extensions and services can be different following the layout of your project","title":"Descriptors"},{"location":"development/extensions/editor/#implementation","text":"<!DOCTYPE html> < html lang = \"en\" ng-app = \"editor\" > < head > < meta charset = \"utf-8\" > < meta http-equiv = \"X-UA-Compatible\" content = \"IE=edge\" > < meta name = \"viewport\" content = \"width=device-width, initial-scale=1.0\" > < meta name = \"description\" content = \"\" > < meta name = \"author\" content = \"\" > < link type = \"text/css\" rel = \"stylesheet\" href = \"../../../../../services/v4/js/theme/resources.js/bootstrap.min.css\" > < link type = \"text/css\" rel = \"stylesheet\" href = \"../../../../../services/v4/web/resources/font-awesome-4.7.0/css/font-awesome.min.css\" > < link type = \"image/png\" rel = \"shortcut icon\" href = \"../../../../../services/v4/web/resources/images/favicon.png\" /> <!-- Custom IDE Styles --> < link type = \"text/css\" rel = \"stylesheet\" href = \"../../../../../services/v4/js/theme/resources.js/ide.css\" /> </ head > < body ng-controller = \"EditorController\" > < div class = \"container\" > < div class = \"page-header\" > < h1 > My Editor Description: {{file}} </ h1 > </ div > < form > < div class = \"form-group\" > < label > Group </ label > < input type = \"text\" class = \"form-control\" ng-model = \"myModel.group\" value = \"\" > </ div > ... < button type = \"button\" class = \"btn btn-primary\" ng-click = \"save()\" > Save </ button > </ form > </ div > < script type = \"text/javascript\" src = \"../../../../../services/v4/web/resources/jquery/2.0.3/jquery.min.js\" ></ script > < script type = \"text/javascript\" src = \"../../../../../services/v4/web/resources/bootstrap/3.3.7/bootstrap.min.js\" async ></ script > < script type = \"text/javascript\" src = \"../../../../../services/v4/web/resources/angular/1.4.7/angular.min.js\" ></ script > < script type = \"text/javascript\" src = \"../../../../../services/v4/web/resources/angular/1.4.7/angular-resource.min.js\" ></ script > < script src = \"../../../../../services/v4/web/ide-core/ui/message-hub.js\" ></ script > < script type = \"text/javascript\" src = \"editor.js\" ></ script > </ body > </ html > For \u0430 real world example you can look at Jobs Plugin or Monaco Editor","title":"Implementation"},{"location":"development/extensions/perspective/","text":"Extension - Perspective Descriptors To contribute a new Perspective to the Web IDE you need to create one model ( *.extension ) and one descriptor (in *.js ) files in your project: my-perspective.extension { \"module\" : \"my-project/services/my-perspective.js\" , \"extensionPoint\" : \"ide-perspective\" , \"description\" : \"The description of my perspective\" } module points to the corresponding perspective descriptor (see below) extensionPoint is the name of the built-in extension point to which the current plugin will contribute my-perspective.js exports . getPerspective = function () { var perspective = { name : \"My Perspective\" , link : \"../my-project/index.html\" , order : \"901\" , image : \"files-o\" }; return perspective ; }; name is the exact name of the perspective, which will be shown in the e.g. menu link is the location within the same or external project pointing to the entry HTML file which will be rendered as a perspective order a number used in sorting of the perspectives image is the name of the image which will be used for this perspective The project structure in this case should look like this: | my-project |---- extensions |----> my-perspective.extension |---- services |----> my-perspective.js |---- index.html |---- js |---- css |---- ... Note: The names of the extensions and services can be different following the layout of your project. Implementation In general you can embed any valid HTML in the index.html file above and will will be rendered in the place where the perspective should be embedded. In case you would like to align with the overall styling of the Web IDE as well to enable the messaging between your perspective and the Web IDE core, status bar, side bar, etc., you may want to use the template below: <!DOCTYPE html> < html lang = \"en\" ng-app = \"my-perspective\" ng-controller = \"MyPerspectiveController as controller\" > < head > < meta charset = \"utf-8\" > < meta http-equiv = \"X-UA-Compatible\" content = \"IE=edge\" > < meta name = \"viewport\" content = \"width=device-width, initial-scale=1\" > < title brandtitle perspective-name = \"My Perspective\" ></ title > < link brandicon /> <!-- FontAwesome icon set --> < link type = \"text/css\" href = \"../../../../services/v4/web/resources/font-awesome-4.7.0/css/font-awesome.min.css\" rel = \"stylesheet\" > <!-- Twitter Bootstrap with Theme Support --> < link type = \"text/css\" rel = \"stylesheet\" href = \"../../../../services/v4/js/theme/resources.js/bootstrap.min.css\" > <!-- GoldenLayout with Theme Support --> < link type = \"text/css\" rel = \"stylesheet\" href = \"../../../../services/v4/web/resources/goldenlayout/1.5.9/goldenlayout-base.css\" /> < link type = \"text/css\" rel = \"stylesheet\" href = \"../../../../services/v4/js/theme/resources.js/goldenlayout-theme.css\" /> <!-- Custom IDE Styles --> < link type = \"text/css\" rel = \"stylesheet\" href = \"../../../../services/v4/js/theme/resources.js/ide.css\" /> </ head > < body > < div menu menu-data-url = \"../../js/my-project/services/menu-my-perspective.js\" ></ div > < div class = \"shell\" > < div class = \"sidebar list-group\" sidebar active = \"my-perspective\" ></ div > < div id = \"my-perspective\" class = \"plane\" views-layout views-layout-model = \"controller.layoutModel\" ></ div > </ div > < div class = \"statusbar\" status-bar > {{message}} </ div > <!-- jQuery --> < script type = \"text/javascript\" src = \"../../../../services/v4/web/resources/jquery/2.0.3/jquery.min.js\" ></ script > <!-- Twitter Bootstrap with Theme Support --> < script type = \"text/javascript\" src = \"../../../../services/v4/web/resources/bootstrap/3.3.7/bootstrap.min.js\" ></ script > <!-- AngularJS --> < script type = \"text/javascript\" src = \"../../../../services/v4/web/resources/angular/1.4.7/angular.min.js\" ></ script > < script type = \"text/javascript\" src = \"../../../../services/v4/web/resources/angular/1.4.7/angular-resource.min.js\" ></ script > <!-- GoldenLayout with Theme Support --> < script type = \"text/javascript\" src = \"../../../../services/v4/web/resources/goldenlayout/1.5.9/goldenlayout.min.js\" ></ script > < script type = \"text/javascript\" src = \"../../../../services/v4/web/ide-core/ui/message-hub.js\" ></ script > < script type = \"text/javascript\" src = \"../../../../services/v4/web/ide-core/ui/ui-layout.js\" ></ script > < script type = \"text/javascript\" src = \"../../../../services/v4/web/ide-core/ui/ui-core-ng-modules.js\" ></ script > < script type = \"text/javascript\" > angular . module ( 'controller' , [ 'ngResource' , 'ideUiCore' ]) . config ([ \"messageHubProvider\" , function ( messageHubProvider ) { messageHubProvider . evtNamePrefix = 'my-perspective' ; }]) . controller ( 'MyPerspectiveController' , [ 'Layouts' , function ( Layouts ) { this . layoutModel = { views : [ 'console' ], }; var messageHub = new FramesMessageHub (); var send = function ( evtName , data , absolute ){ messageHub . post ({ data : data }, ( absolute ? '' : 'my-perspective.' ) + evtName ); }; var run = function () { send ( \"repository.run\" , metadata , false ); } }]); window . addEventListener ( 'beforeunload' , function ( e ) { e . preventDefault (); e . returnValue = '' ; }); </ script > </ body > </ html > For \u0430 real world example you can look at Database Perspective Project","title":"Perspective"},{"location":"development/extensions/perspective/#extension-perspective","text":"","title":"Extension - Perspective"},{"location":"development/extensions/perspective/#descriptors","text":"To contribute a new Perspective to the Web IDE you need to create one model ( *.extension ) and one descriptor (in *.js ) files in your project: my-perspective.extension { \"module\" : \"my-project/services/my-perspective.js\" , \"extensionPoint\" : \"ide-perspective\" , \"description\" : \"The description of my perspective\" } module points to the corresponding perspective descriptor (see below) extensionPoint is the name of the built-in extension point to which the current plugin will contribute my-perspective.js exports . getPerspective = function () { var perspective = { name : \"My Perspective\" , link : \"../my-project/index.html\" , order : \"901\" , image : \"files-o\" }; return perspective ; }; name is the exact name of the perspective, which will be shown in the e.g. menu link is the location within the same or external project pointing to the entry HTML file which will be rendered as a perspective order a number used in sorting of the perspectives image is the name of the image which will be used for this perspective The project structure in this case should look like this: | my-project |---- extensions |----> my-perspective.extension |---- services |----> my-perspective.js |---- index.html |---- js |---- css |---- ... Note: The names of the extensions and services can be different following the layout of your project.","title":"Descriptors"},{"location":"development/extensions/perspective/#implementation","text":"In general you can embed any valid HTML in the index.html file above and will will be rendered in the place where the perspective should be embedded. In case you would like to align with the overall styling of the Web IDE as well to enable the messaging between your perspective and the Web IDE core, status bar, side bar, etc., you may want to use the template below: <!DOCTYPE html> < html lang = \"en\" ng-app = \"my-perspective\" ng-controller = \"MyPerspectiveController as controller\" > < head > < meta charset = \"utf-8\" > < meta http-equiv = \"X-UA-Compatible\" content = \"IE=edge\" > < meta name = \"viewport\" content = \"width=device-width, initial-scale=1\" > < title brandtitle perspective-name = \"My Perspective\" ></ title > < link brandicon /> <!-- FontAwesome icon set --> < link type = \"text/css\" href = \"../../../../services/v4/web/resources/font-awesome-4.7.0/css/font-awesome.min.css\" rel = \"stylesheet\" > <!-- Twitter Bootstrap with Theme Support --> < link type = \"text/css\" rel = \"stylesheet\" href = \"../../../../services/v4/js/theme/resources.js/bootstrap.min.css\" > <!-- GoldenLayout with Theme Support --> < link type = \"text/css\" rel = \"stylesheet\" href = \"../../../../services/v4/web/resources/goldenlayout/1.5.9/goldenlayout-base.css\" /> < link type = \"text/css\" rel = \"stylesheet\" href = \"../../../../services/v4/js/theme/resources.js/goldenlayout-theme.css\" /> <!-- Custom IDE Styles --> < link type = \"text/css\" rel = \"stylesheet\" href = \"../../../../services/v4/js/theme/resources.js/ide.css\" /> </ head > < body > < div menu menu-data-url = \"../../js/my-project/services/menu-my-perspective.js\" ></ div > < div class = \"shell\" > < div class = \"sidebar list-group\" sidebar active = \"my-perspective\" ></ div > < div id = \"my-perspective\" class = \"plane\" views-layout views-layout-model = \"controller.layoutModel\" ></ div > </ div > < div class = \"statusbar\" status-bar > {{message}} </ div > <!-- jQuery --> < script type = \"text/javascript\" src = \"../../../../services/v4/web/resources/jquery/2.0.3/jquery.min.js\" ></ script > <!-- Twitter Bootstrap with Theme Support --> < script type = \"text/javascript\" src = \"../../../../services/v4/web/resources/bootstrap/3.3.7/bootstrap.min.js\" ></ script > <!-- AngularJS --> < script type = \"text/javascript\" src = \"../../../../services/v4/web/resources/angular/1.4.7/angular.min.js\" ></ script > < script type = \"text/javascript\" src = \"../../../../services/v4/web/resources/angular/1.4.7/angular-resource.min.js\" ></ script > <!-- GoldenLayout with Theme Support --> < script type = \"text/javascript\" src = \"../../../../services/v4/web/resources/goldenlayout/1.5.9/goldenlayout.min.js\" ></ script > < script type = \"text/javascript\" src = \"../../../../services/v4/web/ide-core/ui/message-hub.js\" ></ script > < script type = \"text/javascript\" src = \"../../../../services/v4/web/ide-core/ui/ui-layout.js\" ></ script > < script type = \"text/javascript\" src = \"../../../../services/v4/web/ide-core/ui/ui-core-ng-modules.js\" ></ script > < script type = \"text/javascript\" > angular . module ( 'controller' , [ 'ngResource' , 'ideUiCore' ]) . config ([ \"messageHubProvider\" , function ( messageHubProvider ) { messageHubProvider . evtNamePrefix = 'my-perspective' ; }]) . controller ( 'MyPerspectiveController' , [ 'Layouts' , function ( Layouts ) { this . layoutModel = { views : [ 'console' ], }; var messageHub = new FramesMessageHub (); var send = function ( evtName , data , absolute ){ messageHub . post ({ data : data }, ( absolute ? '' : 'my-perspective.' ) + evtName ); }; var run = function () { send ( \"repository.run\" , metadata , false ); } }]); window . addEventListener ( 'beforeunload' , function ( e ) { e . preventDefault (); e . returnValue = '' ; }); </ script > </ body > </ html > For \u0430 real world example you can look at Database Perspective Project","title":"Implementation"},{"location":"development/extensions/template/","text":"Extension - Template Descriptors To contribute a new Template to the Web IDE you need to create one model ( *.extension ) and one descriptor (in *.js ) files in your project: my-template.extension { \"module\" : \"my-project/services/my-template.js\" , \"extensionPoint\" : \"ide-template\" , \"description\" : \"The description of my template\" } module points to the corresponding template descriptor (see below) extensionPoint is the name of the built-in extension point to which the current plugin will contribute my-template.js exports . getTemplate = function () { var template = { name : \"My Template\" , description : \"My cool template\" , extension : \"myfile\" , sources : [ { location : \"/my-project/my-source.template\" , action : \"generate\" , rename : \"{{fileName}}.\" , engine : \"velocity\" , start : \"[[\" , end : \"]]\" } ], parameters : [] }; return template ; }; name is the exact name of the template, which will be shown in drop-down boxes description text associated with the template extension optional , if present the template will be shown only if a given file with the specified extension is selected sources the list of the templates which will be used during the generation phase location the relative path to the template action the type of the processing which will be used for this templates rename if renaming of the target artefact will be needed engine the template engine which will be used for this template - mustache (default), velocity and javascript start and end tags if the default {{ \"{{\" }} and {{ \"}}\" }} are not applicable handler the javascript transformation service, in case of javascript engine parameters the list of parameters if any which will be passed to the generator The project structure in this case should look like this: | my-project |---- extensions |----> my-template.extension |---- services |----> my-template.js |---- index.html |---- js |---- css |---- ... Note: The names of the extensions and services can be different following the layout of your project Implementation <!DOCTYPE HTML> < html xmlns = \"http://www.w3.org/1999/xhtml\" > < head > < meta charset = \"utf-8\" /> < title > ${fileName} </ title > </ head > < body ng-app = \"my-view\" ng-controller = \"MyController as controller\" class = \"view\" > < form class = \"input-group\" name = \"myForm\" > < span class = \"input-group-btn\" > < button class = \"btn btn-default\" type = \"button\" ng-click = \"myClick()\" >< i class = \"fa fa-bolt\" ></ i ></ button > </ span > </ form > </ body > </ html > For \u0430 real world example you can look at Bookstore Template","title":"Template"},{"location":"development/extensions/template/#extension-template","text":"","title":"Extension - Template"},{"location":"development/extensions/template/#descriptors","text":"To contribute a new Template to the Web IDE you need to create one model ( *.extension ) and one descriptor (in *.js ) files in your project: my-template.extension { \"module\" : \"my-project/services/my-template.js\" , \"extensionPoint\" : \"ide-template\" , \"description\" : \"The description of my template\" } module points to the corresponding template descriptor (see below) extensionPoint is the name of the built-in extension point to which the current plugin will contribute my-template.js exports . getTemplate = function () { var template = { name : \"My Template\" , description : \"My cool template\" , extension : \"myfile\" , sources : [ { location : \"/my-project/my-source.template\" , action : \"generate\" , rename : \"{{fileName}}.\" , engine : \"velocity\" , start : \"[[\" , end : \"]]\" } ], parameters : [] }; return template ; }; name is the exact name of the template, which will be shown in drop-down boxes description text associated with the template extension optional , if present the template will be shown only if a given file with the specified extension is selected sources the list of the templates which will be used during the generation phase location the relative path to the template action the type of the processing which will be used for this templates rename if renaming of the target artefact will be needed engine the template engine which will be used for this template - mustache (default), velocity and javascript start and end tags if the default {{ \"{{\" }} and {{ \"}}\" }} are not applicable handler the javascript transformation service, in case of javascript engine parameters the list of parameters if any which will be passed to the generator The project structure in this case should look like this: | my-project |---- extensions |----> my-template.extension |---- services |----> my-template.js |---- index.html |---- js |---- css |---- ... Note: The names of the extensions and services can be different following the layout of your project","title":"Descriptors"},{"location":"development/extensions/template/#implementation","text":"<!DOCTYPE HTML> < html xmlns = \"http://www.w3.org/1999/xhtml\" > < head > < meta charset = \"utf-8\" /> < title > ${fileName} </ title > </ head > < body ng-app = \"my-view\" ng-controller = \"MyController as controller\" class = \"view\" > < form class = \"input-group\" name = \"myForm\" > < span class = \"input-group-btn\" > < button class = \"btn btn-default\" type = \"button\" ng-click = \"myClick()\" >< i class = \"fa fa-bolt\" ></ i ></ button > </ span > </ form > </ body > </ html > For \u0430 real world example you can look at Bookstore Template","title":"Implementation"},{"location":"development/extensions/view/","text":"Extension - View Descriptors To contribute a new View to the Web IDE you need to create one model ( *.extension ) and one descriptor (in *.js ) files in your project: my-view.extension { \"module\" : \"my-project/services/my-view.js\" , \"extensionPoint\" : \"ide-view\" , \"description\" : \"The description of my view\" } module points to the corresponding view descriptor (see below) extensionPoint is the name of the built-in extension point to which the current plugin will contribute my-view.js exports . getView = function () { var view = { name : \"My View\" , factory : \"frame\" , region : \"center-bottom\" , label : \"My View\" , link : \"../my-project/index.html\" }; return view ; }; name is the exact name of the view, which will be shown in the e.g. menu factory the type of the factory used during instantiating the view region the region where the view will be placed initially label the name which will be used in the heading bar link is the location within the same or external project pointing to the entry HTML file which will be rendered as a view The project structure in this case should look like this: | my-project |---- extensions |----> my-view.extension |---- services |----> my-view.js |---- index.html |---- js |---- css |---- ... Note: The names of the extensions and services can be different following the layout of your project. Implementation <!DOCTYPE HTML> < html xmlns = \"http://www.w3.org/1999/xhtml\" > < head > < meta charset = \"utf-8\" /> < title > My View </ title > < link href = \"../../../../services/v4/web/resources/font-awesome-4.7.0/css/font-awesome.min.css\" type = \"text/css\" rel = \"stylesheet\" > <!-- AngularJS --> < script src = \"../../../../services/v4/web/resources/angular/1.4.7/angular.min.js\" ></ script > < script src = \"../../../../services/v4/web/resources/angular/1.4.7/angular-resource.min.js\" ></ script > <!-- jQuery --> < script src = \"../../../../services/v4/web/resources/jquery/2.0.3/jquery.min.js\" ></ script > <!-- Twitter Bootstrap with Theme Support --> < link rel = \"stylesheet\" href = \"../../../../services/v4/js/theme/resources.js/bootstrap.min.css\" > < script src = \"../../../../services/v4/web/resources/bootstrap/3.3.7/bootstrap.min.js\" ></ script > < script src = \"../../../../services/v4/web/ide-core/ui/message-hub.js\" ></ script > < script src = \"controller.js\" ></ script > <!-- Custom IDE Styles --> < link type = \"text/css\" rel = \"stylesheet\" href = \"../../../../services/v4/js/theme/resources.js/ide.css\" /> </ head > < body ng-app = \"my-view\" ng-controller = \"MyViewController as myview\" class = \"view\" > < form class = \"input-group\" name = \"viewForm\" > < span class = \"input-group-btn\" > < button class = \"btn btn-default\" type = \"button\" ng-click = \"myViewClick()\" >< i class = \"fa fa-bolt\" ></ i ></ button > </ span > </ form > </ body > </ html > For \u0430 real world example you can look at Preview View","title":"View"},{"location":"development/extensions/view/#extension-view","text":"","title":"Extension - View"},{"location":"development/extensions/view/#descriptors","text":"To contribute a new View to the Web IDE you need to create one model ( *.extension ) and one descriptor (in *.js ) files in your project: my-view.extension { \"module\" : \"my-project/services/my-view.js\" , \"extensionPoint\" : \"ide-view\" , \"description\" : \"The description of my view\" } module points to the corresponding view descriptor (see below) extensionPoint is the name of the built-in extension point to which the current plugin will contribute my-view.js exports . getView = function () { var view = { name : \"My View\" , factory : \"frame\" , region : \"center-bottom\" , label : \"My View\" , link : \"../my-project/index.html\" }; return view ; }; name is the exact name of the view, which will be shown in the e.g. menu factory the type of the factory used during instantiating the view region the region where the view will be placed initially label the name which will be used in the heading bar link is the location within the same or external project pointing to the entry HTML file which will be rendered as a view The project structure in this case should look like this: | my-project |---- extensions |----> my-view.extension |---- services |----> my-view.js |---- index.html |---- js |---- css |---- ... Note: The names of the extensions and services can be different following the layout of your project.","title":"Descriptors"},{"location":"development/extensions/view/#implementation","text":"<!DOCTYPE HTML> < html xmlns = \"http://www.w3.org/1999/xhtml\" > < head > < meta charset = \"utf-8\" /> < title > My View </ title > < link href = \"../../../../services/v4/web/resources/font-awesome-4.7.0/css/font-awesome.min.css\" type = \"text/css\" rel = \"stylesheet\" > <!-- AngularJS --> < script src = \"../../../../services/v4/web/resources/angular/1.4.7/angular.min.js\" ></ script > < script src = \"../../../../services/v4/web/resources/angular/1.4.7/angular-resource.min.js\" ></ script > <!-- jQuery --> < script src = \"../../../../services/v4/web/resources/jquery/2.0.3/jquery.min.js\" ></ script > <!-- Twitter Bootstrap with Theme Support --> < link rel = \"stylesheet\" href = \"../../../../services/v4/js/theme/resources.js/bootstrap.min.css\" > < script src = \"../../../../services/v4/web/resources/bootstrap/3.3.7/bootstrap.min.js\" ></ script > < script src = \"../../../../services/v4/web/ide-core/ui/message-hub.js\" ></ script > < script src = \"controller.js\" ></ script > <!-- Custom IDE Styles --> < link type = \"text/css\" rel = \"stylesheet\" href = \"../../../../services/v4/js/theme/resources.js/ide.css\" /> </ head > < body ng-app = \"my-view\" ng-controller = \"MyViewController as myview\" class = \"view\" > < form class = \"input-group\" name = \"viewForm\" > < span class = \"input-group-btn\" > < button class = \"btn btn-default\" type = \"button\" ng-click = \"myViewClick()\" >< i class = \"fa fa-bolt\" ></ i ></ button > </ span > </ form > </ body > </ html > For \u0430 real world example you can look at Preview View","title":"Implementation"},{"location":"development/ide/","text":"IDE Web IDE The Web-based integrated development environment (Web IDE) runs directly in a browser and, therefore, does not require additional downloads and installations. It has a rich set of editors, viewers, wizards, DevOps productivity tools, and a new Web IDE for in-system application development. The Web IDE is a composition of perspectives, each consisting of the necessary tools to accomplish a certain goal. Three of the UI elements retain their positions in all perpectives: top-area toolbar for the menus, theme selection, and user control sidebar on the left with shortcuts to the perspectives status bar at the bottom, for notifications and other use by the tools The tools that constitute the perspectives are laid out in predefined regions of the work plot, but you can change their position using drag and drop. The perspectives are simply predefined configurations, hence you can open, move, or close different tools on the work plot of a perspective for your convenience. You can also be maximize, minimize, or even pop out any of the tools in a separate window. The tools are the smallest atomic parts in the Web IDE. They are referred to as views or editors, and each type is handled differently. Perspectives By default, the different views and editors are separated into a few perspectives: Workbench Git Database Repository Terminal Operations Documents Debugger Views Each perspective is comprised of different views. Learn more about them following the list below: Snapshot Debugger Roles Jobs Documents Git Preview Workspace SQL Extensions Terminal Variables Breakpoints Console Logs Data Structures Access Listeners Database Search Import Registry Repository Editors Monaco is the editor integrated into the Eclipse Dirigible Web IDE. Modelers There are some more sophisticated visual editors: BPMN Modeler Database Schema Modeler Entity Data Modeler Form Designer Layouts The Web IDE layout API delegates the layout management to the GoldenLayout framework. Layouts is a convenience bag of functions that significantly simplifies the work with layouts. It takes care of views registry setup, the work plot regions configuration, layout initialization, serialization, control on the layout manager, open view and open editor functions, global notifications, and others. The top-area toolbar is a composite that aggregates the drop-down menus, the theme selection, the user name, and sign-out control. It uses the corresponding UI microservices available in the ideUiCore module as Menu , User , and Theme . By convention, all UI components are built with Bootstrap 3.x CSS and the themes in the Web IDE are actually custom Bootstrap CSS. A UI microservice enables dynamic change of the CSS upon change of the theme automatically. It is available as Angular factory theme. The Angular service User provides the details for the user that are rendered by the Menu directive, such as the user name. The sidebar is Angular directive that takes care of rendering a standard sidebar in the framework template. It works with the perspectives.js service to populate the registered perspectives as shortcuts. The status bar is an Angular directive that renders a standard, fixed-position footer. The component is subscribed to listen to message types configured as value of the status-bar-topic attribute, or by default to status-message messages.","title":"IDE"},{"location":"development/ide/#ide","text":"","title":"IDE"},{"location":"development/ide/#web-ide","text":"The Web-based integrated development environment (Web IDE) runs directly in a browser and, therefore, does not require additional downloads and installations. It has a rich set of editors, viewers, wizards, DevOps productivity tools, and a new Web IDE for in-system application development. The Web IDE is a composition of perspectives, each consisting of the necessary tools to accomplish a certain goal. Three of the UI elements retain their positions in all perpectives: top-area toolbar for the menus, theme selection, and user control sidebar on the left with shortcuts to the perspectives status bar at the bottom, for notifications and other use by the tools The tools that constitute the perspectives are laid out in predefined regions of the work plot, but you can change their position using drag and drop. The perspectives are simply predefined configurations, hence you can open, move, or close different tools on the work plot of a perspective for your convenience. You can also be maximize, minimize, or even pop out any of the tools in a separate window. The tools are the smallest atomic parts in the Web IDE. They are referred to as views or editors, and each type is handled differently.","title":"Web IDE"},{"location":"development/ide/#perspectives","text":"By default, the different views and editors are separated into a few perspectives: Workbench Git Database Repository Terminal Operations Documents Debugger","title":"Perspectives"},{"location":"development/ide/#views","text":"Each perspective is comprised of different views. Learn more about them following the list below: Snapshot Debugger Roles Jobs Documents Git Preview Workspace SQL Extensions Terminal Variables Breakpoints Console Logs Data Structures Access Listeners Database Search Import Registry Repository","title":"Views"},{"location":"development/ide/#editors","text":"Monaco is the editor integrated into the Eclipse Dirigible Web IDE.","title":"Editors"},{"location":"development/ide/#modelers","text":"There are some more sophisticated visual editors: BPMN Modeler Database Schema Modeler Entity Data Modeler Form Designer","title":"Modelers"},{"location":"development/ide/#layouts","text":"The Web IDE layout API delegates the layout management to the GoldenLayout framework. Layouts is a convenience bag of functions that significantly simplifies the work with layouts. It takes care of views registry setup, the work plot regions configuration, layout initialization, serialization, control on the layout manager, open view and open editor functions, global notifications, and others. The top-area toolbar is a composite that aggregates the drop-down menus, the theme selection, the user name, and sign-out control. It uses the corresponding UI microservices available in the ideUiCore module as Menu , User , and Theme . By convention, all UI components are built with Bootstrap 3.x CSS and the themes in the Web IDE are actually custom Bootstrap CSS. A UI microservice enables dynamic change of the CSS upon change of the theme automatically. It is available as Angular factory theme. The Angular service User provides the details for the user that are rendered by the Menu directive, such as the user name. The sidebar is Angular directive that takes care of rendering a standard sidebar in the framework template. It works with the perspectives.js service to populate the registered perspectives as shortcuts. The status bar is an Angular directive that renders a standard, fixed-position footer. The component is subscribed to listen to message types configured as value of the status-bar-topic attribute, or by default to status-message messages.","title":"Layouts"},{"location":"development/ide/editor-monaco/","text":"Monaco Editor Monaco Editor is the code editor that powers VS Code . It is not supported in mobile browsers or mobile web frameworks. The Editor supports syntax highlighting for XML, PHP, C#, C++, Razor, Markdown, Diff, Java, VB, CoffeeScript, Handlebars, Batch, Pug, F#, Lua, Powershell, Python, SASS, R, Objective-C and side by side live comparison for all languages out of the box. Monaco has a rich set of default keyboard shortcuts as well as allowing you to customize them. Monaco supports multiple cursors for fast simultaneous edits. You can also add secondary cursors.","title":"Monaco Editor"},{"location":"development/ide/editor-monaco/#monaco-editor","text":"Monaco Editor is the code editor that powers VS Code . It is not supported in mobile browsers or mobile web frameworks. The Editor supports syntax highlighting for XML, PHP, C#, C++, Razor, Markdown, Diff, Java, VB, CoffeeScript, Handlebars, Batch, Pug, F#, Lua, Powershell, Python, SASS, R, Objective-C and side by side live comparison for all languages out of the box. Monaco has a rich set of default keyboard shortcuts as well as allowing you to customize them. Monaco supports multiple cursors for fast simultaneous edits. You can also add secondary cursors.","title":"Monaco Editor"},{"location":"development/ide/modelers/bpmn/","text":"BPMN Modeler The BPMN Modeler provides capabilities for visual design of a business process. Such business processes can include Dirigible services.","title":"BPMN"},{"location":"development/ide/modelers/bpmn/#bpmn-modeler","text":"The BPMN Modeler provides capabilities for visual design of a business process. Such business processes can include Dirigible services.","title":"BPMN Modeler"},{"location":"development/ide/modelers/database-schema/","text":"Database Schema Modeler The Database Schema Modeler provides capabilities for visual design of a database schema.","title":"Database Schema"},{"location":"development/ide/modelers/database-schema/#database-schema-modeler","text":"The Database Schema Modeler provides capabilities for visual design of a database schema.","title":"Database Schema Modeler"},{"location":"development/ide/modelers/entity-data/","text":"Entity Data Modeler The Entity Data Modeler provides capabilities for visual design of a domain model. After that you can generate a full-stack applications for basic operations over the defined entities.","title":"Entity Data"},{"location":"development/ide/modelers/entity-data/#entity-data-modeler","text":"The Entity Data Modeler provides capabilities for visual design of a domain model. After that you can generate a full-stack applications for basic operations over the defined entities.","title":"Entity Data Modeler"},{"location":"development/ide/modelers/form-designer/","text":"Form Designer The Form Designer provides capabilities for visual design of a Web form. You can drag and drop UI controls from a predefined list and edit their properties.","title":"Form Designer"},{"location":"development/ide/modelers/form-designer/#form-designer","text":"The Form Designer provides capabilities for visual design of a Web form. You can drag and drop UI controls from a predefined list and edit their properties.","title":"Form Designer"},{"location":"development/ide/perspectives/database/","text":"Database Perspective The Database perspective contains tools for inspection and manipulation of the artifacts within the underlying relational database. It is comprised of Database, SQL, Console and Result views. The Database perspective features a database explorer, a console to execute SQL statements and to preview results in table format.","title":"Database"},{"location":"development/ide/perspectives/database/#database-perspective","text":"The Database perspective contains tools for inspection and manipulation of the artifacts within the underlying relational database. It is comprised of Database, SQL, Console and Result views. The Database perspective features a database explorer, a console to execute SQL statements and to preview results in table format.","title":"Database Perspective"},{"location":"development/ide/perspectives/debugger/","text":"Debugger Perspective The Web IDE includes a Debugger perspective which is comprised of the following views: Debugger Variables Breakpoints Console Preview The Debugger perspective enables you to monitor the execution of your code, stop it, restart it or set breakpoints, and change values in memory.","title":"Debugger"},{"location":"development/ide/perspectives/debugger/#debugger-perspective","text":"The Web IDE includes a Debugger perspective which is comprised of the following views: Debugger Variables Breakpoints Console Preview The Debugger perspective enables you to monitor the execution of your code, stop it, restart it or set breakpoints, and change values in memory.","title":"Debugger Perspective"},{"location":"development/ide/perspectives/documents/","text":"Documents Perspective The Documents perspective is the place where the user manages the binary artifacts such as pictures, spreadsheets, PDF files, etc. It enables him/her to upload, overwrite, download, delete and search for artifacts. At the moment the Documents perspective consists of only one view, which is also called Documents.","title":"Documents"},{"location":"development/ide/perspectives/documents/#documents-perspective","text":"The Documents perspective is the place where the user manages the binary artifacts such as pictures, spreadsheets, PDF files, etc. It enables him/her to upload, overwrite, download, delete and search for artifacts. At the moment the Documents perspective consists of only one view, which is also called Documents.","title":"Documents Perspective"},{"location":"development/ide/perspectives/git/","text":"Git Perspective The Git perspective aims at presenting a simplified interface for the most common Git operations. It is built from tools that support Git client operations. The Git perspective is comprised of Git and Console views, a and workspace menu. It enables the users to perform simple Git operations such as cloning a repository to a workspace, pulling changes, and pushing commits. The user can create, manage, and switch between multiple workspaces through the workspace menu. Note: In case of merge conflict on Push operation, a new branch with your local changes will be created in the remote repository. From this point, you can use your preferred tooling to apply the actual merge between the two branches. Video","title":"Git"},{"location":"development/ide/perspectives/git/#git-perspective","text":"The Git perspective aims at presenting a simplified interface for the most common Git operations. It is built from tools that support Git client operations. The Git perspective is comprised of Git and Console views, a and workspace menu. It enables the users to perform simple Git operations such as cloning a repository to a workspace, pulling changes, and pushing commits. The user can create, manage, and switch between multiple workspaces through the workspace menu. Note: In case of merge conflict on Push operation, a new branch with your local changes will be created in the remote repository. From this point, you can use your preferred tooling to apply the actual merge between the two branches. Video","title":"Git Perspective"},{"location":"development/ide/perspectives/operations/","text":"Operations Perspective The Web IDE includes an Operations perspective, which is comprised of the following views: Registry Repository Extension Jobs Listeners Data Structures Access Roles Console Terminal Logs The Operations perspective enables you to monitor the ongoing processes and operation activities.","title":"Operations"},{"location":"development/ide/perspectives/operations/#operations-perspective","text":"The Web IDE includes an Operations perspective, which is comprised of the following views: Registry Repository Extension Jobs Listeners Data Structures Access Roles Console Terminal Logs The Operations perspective enables you to monitor the ongoing processes and operation activities.","title":"Operations Perspective"},{"location":"development/ide/perspectives/repository/","text":"Repository Perspective The Repository perspective gives access to the raw structure of the Dirigible instance. It is comprised of Repository, Snapshot , Preview and Console views. There the user can inspect at low level the project and folder structure, as well as the artifacts content. The user is able to import/export snapshots via the Snapshot view. Caution: Editing of the file contents via the Repository perspective is not recommended as it can lead to inconsistencies!","title":"Repository"},{"location":"development/ide/perspectives/repository/#repository-perspective","text":"The Repository perspective gives access to the raw structure of the Dirigible instance. It is comprised of Repository, Snapshot , Preview and Console views. There the user can inspect at low level the project and folder structure, as well as the artifacts content. The user is able to import/export snapshots via the Snapshot view. Caution: Editing of the file contents via the Repository perspective is not recommended as it can lead to inconsistencies!","title":"Repository Perspective"},{"location":"development/ide/perspectives/terminal/","text":"Terminal Perspective The key view in the perspective is a terminal that emulates console client connected to the environment of the Dirigible that can execute commands. The difference here is that the whole communication goes via HTTP(S) only and does not require the SSH port to be opened.","title":"Terminal"},{"location":"development/ide/perspectives/terminal/#terminal-perspective","text":"The key view in the perspective is a terminal that emulates console client connected to the environment of the Dirigible that can execute commands. The difference here is that the whole communication goes via HTTP(S) only and does not require the SSH port to be opened.","title":"Terminal Perspective"},{"location":"development/ide/perspectives/workbench/","text":"Workbench Perspective This is the place where the user develops the dynamic applications. This perspective contains all views and editors that may help in the overall implementation, from domain models via services to the user interface. The Workbench perspective is comprised of Workspace , Import , Properties , Console , and Preview views, plus the editors registered for each file type. In other words, the minimal toolset for file management, preview, and editing operations. The main view opened by default in this perspective is the Workspace view, a standard view with the projects in your workspace .","title":"Workbench"},{"location":"development/ide/perspectives/workbench/#workbench-perspective","text":"This is the place where the user develops the dynamic applications. This perspective contains all views and editors that may help in the overall implementation, from domain models via services to the user interface. The Workbench perspective is comprised of Workspace , Import , Properties , Console , and Preview views, plus the editors registered for each file type. In other words, the minimal toolset for file management, preview, and editing operations. The main view opened by default in this perspective is the Workspace view, a standard view with the projects in your workspace .","title":"Workbench Perspective"},{"location":"development/ide/views/access/","text":"Access View The Access view displays the defined security constraints on HTTP servers access or paths to the document repository. These constraints are defined in *.access files. More info about the type of the artifacts you can find here","title":"Access"},{"location":"development/ide/views/access/#access-view","text":"The Access view displays the defined security constraints on HTTP servers access or paths to the document repository. These constraints are defined in *.access files. More info about the type of the artifacts you can find here","title":"Access View"},{"location":"development/ide/views/breakpoints/","text":"Breakpoint View The Breakpoints view enables you to follow the breakpoints you have created in the course of the debugging process. The first column of the view displays the path to the file in the document repository and the second one - the row where the breakpoint is situated.","title":"Breakpoints"},{"location":"development/ide/views/breakpoints/#breakpoint-view","text":"The Breakpoints view enables you to follow the breakpoints you have created in the course of the debugging process. The first column of the view displays the path to the file in the document repository and the second one - the row where the breakpoint is situated.","title":"Breakpoint View"},{"location":"development/ide/views/console/","text":"Console View The Console view is a major debugging tool. It displays the output of the code that you are executing.","title":"Console"},{"location":"development/ide/views/console/#console-view","text":"The Console view is a major debugging tool. It displays the output of the code that you are executing.","title":"Console View"},{"location":"development/ide/views/database/","text":"Database View The Database view gives you direct access to the default target schema assigned to your account in the Web IDE. It enables you to expand the schema item and see the list of all tables and views created either via the data structures models or directly via SQL script.","title":"Database"},{"location":"development/ide/views/database/#database-view","text":"The Database view gives you direct access to the default target schema assigned to your account in the Web IDE. It enables you to expand the schema item and see the list of all tables and views created either via the data structures models or directly via SQL script.","title":"Database View"},{"location":"development/ide/views/datastructures/","text":"Data Structures View The Data Structures view lists all data structures defined in the following files: *.table - the table layout definition in JSON *.view - the view layout definition in JSON *.schema - the schema layout definition in JSON *.append - append mode data file in DSV *.delete - delete mode data file in DSV *.update - update mode data file in DSV *.replace - replace mode data file in DSV More info about the type of the artifacts you can find here","title":"Data Structures"},{"location":"development/ide/views/datastructures/#data-structures-view","text":"The Data Structures view lists all data structures defined in the following files: *.table - the table layout definition in JSON *.view - the view layout definition in JSON *.schema - the schema layout definition in JSON *.append - append mode data file in DSV *.delete - delete mode data file in DSV *.update - update mode data file in DSV *.replace - replace mode data file in DSV More info about the type of the artifacts you can find here","title":"Data Structures View"},{"location":"development/ide/views/debugger/","text":"Debuggeer View The Debugger view enables you to navigate the debugging of your code: to start it, pause it, restart it or proceed step by step.","title":"Debugger"},{"location":"development/ide/views/debugger/#debuggeer-view","text":"The Debugger view enables you to navigate the debugging of your code: to start it, pause it, restart it or proceed step by step.","title":"Debuggeer View"},{"location":"development/ide/views/documents/","text":"Documents View The Documents view enables the user to manage the binary artifacts such as pictures, spreadsheets, PDF, etc. It enables him/her to upload, overwrite, download, delete and search for artifacts.","title":"Documents"},{"location":"development/ide/views/documents/#documents-view","text":"The Documents view enables the user to manage the binary artifacts such as pictures, spreadsheets, PDF, etc. It enables him/her to upload, overwrite, download, delete and search for artifacts.","title":"Documents View"},{"location":"development/ide/views/extensions/","text":"Extensions View The Extensions view lists all defined extensions and extension points through *.extension and *.extensionpoint descriptor. More info about the type of the artifacts you can find here","title":"Extensions"},{"location":"development/ide/views/extensions/#extensions-view","text":"The Extensions view lists all defined extensions and extension points through *.extension and *.extensionpoint descriptor. More info about the type of the artifacts you can find here","title":"Extensions View"},{"location":"development/ide/views/git/","text":"Git View The Git view enables the users to perform simple git operations such as cloning a repository to a workspace, pulling changes, and pushing commits. The user can create, manage, and switch between multiple workspaces through the Workspace menu.","title":"Git"},{"location":"development/ide/views/git/#git-view","text":"The Git view enables the users to perform simple git operations such as cloning a repository to a workspace, pulling changes, and pushing commits. The user can create, manage, and switch between multiple workspaces through the Workspace menu.","title":"Git View"},{"location":"development/ide/views/import/","text":"Import View The Import view enables the user to upload a *.zip file, containing one or more projects, to the selected Workspace . The view includes a progress bar for navigation of the process. The user can manage and switch between multiple workspaces through the Workspace menu.","title":"Import"},{"location":"development/ide/views/import/#import-view","text":"The Import view enables the user to upload a *.zip file, containing one or more projects, to the selected Workspace . The view includes a progress bar for navigation of the process. The user can manage and switch between multiple workspaces through the Workspace menu.","title":"Import View"},{"location":"development/ide/views/jobs/","text":"Jobs View The Jobs view lists all registered custom jobs scheduled for execution in a *.job file. More info about the type of the artifacts you can find here","title":"Jobs"},{"location":"development/ide/views/jobs/#jobs-view","text":"The Jobs view lists all registered custom jobs scheduled for execution in a *.job file. More info about the type of the artifacts you can find here","title":"Jobs View"},{"location":"development/ide/views/listeners/","text":"Listeners View The Listeners view shows all message listeners registered by the *.listener files. Their type depends on the type of the message hub - topic or queue. More info about the type of the artifacts you can find here","title":"Listeners"},{"location":"development/ide/views/listeners/#listeners-view","text":"The Listeners view shows all message listeners registered by the *.listener files. Their type depends on the type of the message hub - topic or queue. More info about the type of the artifacts you can find here","title":"Listeners View"},{"location":"development/ide/views/logs/","text":"Logs View The Logs view lists all available log files.","title":"Logs"},{"location":"development/ide/views/logs/#logs-view","text":"The Logs view lists all available log files.","title":"Logs View"},{"location":"development/ide/views/preview/","text":"Preview View The Preview view displays the result of executing the selected file. It refreshes automatically during Workspace change events e.g. Save .","title":"Preview"},{"location":"development/ide/views/preview/#preview-view","text":"The Preview view displays the result of executing the selected file. It refreshes automatically during Workspace change events e.g. Save .","title":"Preview View"},{"location":"development/ide/views/registry/","text":"Registry View Technically, the Registry is a space within the Repository where all the published artifacts are placed. Caution: Editing of the file contents via the Registry perspective is not recommended as it can lead to inconsistencies!","title":"Registry"},{"location":"development/ide/views/registry/#registry-view","text":"Technically, the Registry is a space within the Repository where all the published artifacts are placed. Caution: Editing of the file contents via the Registry perspective is not recommended as it can lead to inconsistencies!","title":"Registry View"},{"location":"development/ide/views/repository/","text":"Repository View The Repository view gives access to the raw structure of the underlying Repository content. There you can inspect at low level the project and folder structure, as well as the artifacts content. The view enables the user to create new collections and resources, to delete existing ones, or to export them. Caution: Editing of the file contents via the Repository perspective is not recommended as it can lead to inconsistencies!","title":"Repository"},{"location":"development/ide/views/repository/#repository-view","text":"The Repository view gives access to the raw structure of the underlying Repository content. There you can inspect at low level the project and folder structure, as well as the artifacts content. The view enables the user to create new collections and resources, to delete existing ones, or to export them. Caution: Editing of the file contents via the Repository perspective is not recommended as it can lead to inconsistencies!","title":"Repository View"},{"location":"development/ide/views/roles/","text":"Roles View The Roles view lists all roles defined in the roles descriptor *.roles . More info about the type of the artifacts you can find here","title":"Roles"},{"location":"development/ide/views/roles/#roles-view","text":"The Roles view lists all roles defined in the roles descriptor *.roles . More info about the type of the artifacts you can find here","title":"Roles View"},{"location":"development/ide/views/search/","text":"Search View The Search view enables the user to make a free-text search in the selected workspace. The user can switch between multiple workspaces through the Workspace menu.","title":"Search"},{"location":"development/ide/views/search/#search-view","text":"The Search view enables the user to make a free-text search in the selected workspace. The user can switch between multiple workspaces through the Workspace menu.","title":"Search View"},{"location":"development/ide/views/snapshot/","text":"Snapshot View The Snapshot view enables the user to upload the whole repository (including all users Workspaces) and all registry public contents. It includes a progress bar for navigation of the process.","title":"Snapshot"},{"location":"development/ide/views/snapshot/#snapshot-view","text":"The Snapshot view enables the user to upload the whole repository (including all users Workspaces) and all registry public contents. It includes a progress bar for navigation of the process.","title":"Snapshot View"},{"location":"development/ide/views/sql/","text":"SQL View The SQL view is one of the most powerful and dangerous tool for database management. In the SQL console you can enter the SQL script compliant to the underlying database system. You get the result of the execution in the Results view below.","title":"SQL"},{"location":"development/ide/views/sql/#sql-view","text":"The SQL view is one of the most powerful and dangerous tool for database management. In the SQL console you can enter the SQL script compliant to the underlying database system. You get the result of the execution in the Results view below.","title":"SQL View"},{"location":"development/ide/views/terminal/","text":"Terminal View Via the Terminal view, you can execute OS commands. Examples: Linux OS: ls -al Microsoft Windows OS: dir","title":"Terminal"},{"location":"development/ide/views/terminal/#terminal-view","text":"Via the Terminal view, you can execute OS commands. Examples: Linux OS: ls -al Microsoft Windows OS: dir","title":"Terminal View"},{"location":"development/ide/views/variables/","text":"Variables View The Variables view displays the defined values of the variables when the code is executed. During the debugging process they may be displayed step by step or all at once, depending on the existing breakpoints.","title":"Variables"},{"location":"development/ide/views/variables/#variables-view","text":"The Variables view displays the defined values of the variables when the code is executed. During the debugging process they may be displayed step by step or all at once, depending on the existing breakpoints.","title":"Variables View"},{"location":"development/ide/views/workspace/","text":"Workspace View The Workspace is the developer's place where he/she creates and manages the application artifacts. The first-level citizens of the workspace are the projects . With Eclipse Dirigible the users can create , manage , and switch between multiple workspaces through the Workspace view. Each project can contain multiple folders and files (artifacts). The new template-based project and artifacts scaffolding generators features are worthy of mention. The projects file organization is now non-normative and entirely up-to the preferences of the users. The IDE supports multiple editors registered for different file (MIME) types. More than one editor can be registered for one file type and in this case a Open with\u2026 context menu entry is rendered for the user to select, which one to use. The Workspace explorer displays a standard view on the projects in your workspace . It shows the folder structure along with the files. There is a context menu assigned to the project node: Via this context menu, you can create new artifacts such as: Database Table Database View Database Schema Model Entity Data Model JavaScript Service HTML5 Page Scheduled Job Message Listener Business Process Model Access Constraints Roles Definitions or just regular ones: File Folder More info about the type of the artifacts you can find here . When selecting an artifact, you can use the Open or Open With actions to load its content in the corresponding editor, for example, Monaco Editor . A single user can have multiple workspaces, containing different set of projects. The artifacts i.e. the project management, can be done via the views and editors in the Workbench Perspective .","title":"Workspace"},{"location":"development/ide/views/workspace/#workspace-view","text":"The Workspace is the developer's place where he/she creates and manages the application artifacts. The first-level citizens of the workspace are the projects . With Eclipse Dirigible the users can create , manage , and switch between multiple workspaces through the Workspace view. Each project can contain multiple folders and files (artifacts). The new template-based project and artifacts scaffolding generators features are worthy of mention. The projects file organization is now non-normative and entirely up-to the preferences of the users. The IDE supports multiple editors registered for different file (MIME) types. More than one editor can be registered for one file type and in this case a Open with\u2026 context menu entry is rendered for the user to select, which one to use. The Workspace explorer displays a standard view on the projects in your workspace . It shows the folder structure along with the files. There is a context menu assigned to the project node: Via this context menu, you can create new artifacts such as: Database Table Database View Database Schema Model Entity Data Model JavaScript Service HTML5 Page Scheduled Job Message Listener Business Process Model Access Constraints Roles Definitions or just regular ones: File Folder More info about the type of the artifacts you can find here . When selecting an artifact, you can use the Open or Open With actions to load its content in the corresponding editor, for example, Monaco Editor . A single user can have multiple workspaces, containing different set of projects. The artifacts i.e. the project management, can be done via the views and editors in the Workbench Perspective .","title":"Workspace View"},{"location":"overview/","text":"Project Eclipse Dirigible is an open source project that provides Integrated Development Environment as a Service (IDEaaS), as well as integrated runtime execution engines. The applications created with Eclipse Dirigible comply with the Dynamic Applications concept and structure. The main project goal is to provide all required capabilities needed to develop and run end-to-end vertical applications in the cloud in the shortest time ever. The environment itself runs directly in a browser, therefore does not require additional downloads and installations. It packs all the needed components, which makes it a self-contained and well-integrated software stack that can be deployed on any Java based Web server, such as Tomcat, Jetty, JBoss, etc. Eclipse Dirigible project came out of an internal SAP initiative to address the extension and adaptation use cases related to SOA and Enterprise Services. On one hand, in this project were implied the lessons learned from the standard tools and approaches so far. On the other hand, there were added features aligned with the most recent technologies and architectural patterns related to Web 2.0 and HTML5 . This made it complete enough to be used as the only environment needed for building and running applications in the cloud. From the beginning, the project follows the principles of Simplicity , Openness , Agility , Completeness , and Perfection , which provide a sustainable environment where maximum impact is achieved with minimal effort. Features section describes in detail what is included in the project. Concepts section gives you an overview about the internal and the chosen patterns. Samples section shows you how to start and build your first dynamic Web application in seconds.","title":"Project"},{"location":"overview/#project","text":"Eclipse Dirigible is an open source project that provides Integrated Development Environment as a Service (IDEaaS), as well as integrated runtime execution engines. The applications created with Eclipse Dirigible comply with the Dynamic Applications concept and structure. The main project goal is to provide all required capabilities needed to develop and run end-to-end vertical applications in the cloud in the shortest time ever. The environment itself runs directly in a browser, therefore does not require additional downloads and installations. It packs all the needed components, which makes it a self-contained and well-integrated software stack that can be deployed on any Java based Web server, such as Tomcat, Jetty, JBoss, etc. Eclipse Dirigible project came out of an internal SAP initiative to address the extension and adaptation use cases related to SOA and Enterprise Services. On one hand, in this project were implied the lessons learned from the standard tools and approaches so far. On the other hand, there were added features aligned with the most recent technologies and architectural patterns related to Web 2.0 and HTML5 . This made it complete enough to be used as the only environment needed for building and running applications in the cloud. From the beginning, the project follows the principles of Simplicity , Openness , Agility , Completeness , and Perfection , which provide a sustainable environment where maximum impact is achieved with minimal effort. Features section describes in detail what is included in the project. Concepts section gives you an overview about the internal and the chosen patterns. Samples section shows you how to start and build your first dynamic Web application in seconds.","title":"Project"},{"location":"overview/architecture/","text":"Architecture The Eclipse Dirigible architecture follows the well-proved principles of simplicity and scalability in the classical service-oriented architecture. The components are separated between the design time (definition work, modeling, scripting) and the runtime (execution of services, content provisioning, and monitoring). The transition between design time and runtime is achieved with a repository component. The only linking part is the content itself. At design time, the programmers and designers use the Web-based integrated development environment Web IDE . This tooling is based on the most popular client side JavaScript framework - AngularJS, as well as Bootstrap for theme-ing and GoldenLayout for windows management. The runtime components provide the cloud application after you create it. The underlying technology platform is a Java-Web-Profile-compliant application server (such as Tomcat). On top are the Eclipse Dirigible containers for service execution. Depending on the scripting language and purpose, they can be: GraalVM JS Mylyn Lucene Quartz ActiveMQ Flowable Mustache Chemistry The runtime can be scaled independently from the design time and can be deployed without the design time at all (for productive landscapes). Depending on the target cloud platform, you can integrate the services provided by the underlying technology platform in Eclipse Dirigible.","title":"Architecture"},{"location":"overview/architecture/#architecture","text":"The Eclipse Dirigible architecture follows the well-proved principles of simplicity and scalability in the classical service-oriented architecture. The components are separated between the design time (definition work, modeling, scripting) and the runtime (execution of services, content provisioning, and monitoring). The transition between design time and runtime is achieved with a repository component. The only linking part is the content itself. At design time, the programmers and designers use the Web-based integrated development environment Web IDE . This tooling is based on the most popular client side JavaScript framework - AngularJS, as well as Bootstrap for theme-ing and GoldenLayout for windows management. The runtime components provide the cloud application after you create it. The underlying technology platform is a Java-Web-Profile-compliant application server (such as Tomcat). On top are the Eclipse Dirigible containers for service execution. Depending on the scripting language and purpose, they can be: GraalVM JS Mylyn Lucene Quartz ActiveMQ Flowable Mustache Chemistry The runtime can be scaled independently from the design time and can be deployed without the design time at all (for productive landscapes). Depending on the target cloud platform, you can integrate the services provided by the underlying technology platform in Eclipse Dirigible.","title":"Architecture"},{"location":"overview/credits/","text":"Credits and Special Thanks We would like to say a big THANK YOU! to all the open source projects that we use as components of our platform: GraalJS Rhino Eclipse Equinox Eclipse OSGi Remote Application Platfrom Mylyn Camel CXF Ant Derby Commons Geronimo HttpClient Xerces Xalan WS Felix Log4j Batik Avalon Velocity Quartz Spring Framework StaX Woodstox Jettison Groovy CyberNeko HTML Gson EZMorph ACE Editor JCraft JLine ASM Antlr Hamcrest JUnit jRuby wsdl4j Slf4j jsoap ICU Mockito JAF AOP Alliance jQuery Bootstrap AngularJS GoldenLayout Flowable Monaco Xtermjs ttyd acorn","title":"Credits"},{"location":"overview/credits/#credits-and-special-thanks","text":"We would like to say a big THANK YOU! to all the open source projects that we use as components of our platform: GraalJS Rhino Eclipse Equinox Eclipse OSGi Remote Application Platfrom Mylyn Camel CXF Ant Derby Commons Geronimo HttpClient Xerces Xalan WS Felix Log4j Batik Avalon Velocity Quartz Spring Framework StaX Woodstox Jettison Groovy CyberNeko HTML Gson EZMorph ACE Editor JCraft JLine ASM Antlr Hamcrest JUnit jRuby wsdl4j Slf4j jsoap ICU Mockito JAF AOP Alliance jQuery Bootstrap AngularJS GoldenLayout Flowable Monaco Xtermjs ttyd acorn","title":"Credits and Special Thanks"},{"location":"overview/editors-modelers/","text":"Editors & Modelers Editors List Monaco - the editor that powers VS Code . Modelers List Entity Data Modeler - design a domain model. Database Schema Modeler - desing a database schema. BPMN Modeler - design a business process. Form Designer - design a Web form.","title":"Editors & Modelers"},{"location":"overview/editors-modelers/#editors-modelers","text":"","title":"Editors &amp; Modelers"},{"location":"overview/editors-modelers/#editors-list","text":"Monaco - the editor that powers VS Code .","title":"Editors List"},{"location":"overview/editors-modelers/#modelers-list","text":"Entity Data Modeler - design a domain model. Database Schema Modeler - desing a database schema. BPMN Modeler - design a business process. Form Designer - design a Web form.","title":"Modelers List"},{"location":"overview/engines/","text":"Engines Engines List Javascript GraalVM JS - a Javascript module based on the GraalVM JS engine. Web - serving the static content via the underlying web container's capabilities e.g. Apache Tomcat . Wiki Markdown - a Wiki engine supporting Markdown markup language and uses the Mylyn underlying framework. BPM - a BPMN specification supporting engine Flowable . OData - expose OData services from database tables/views. Command - execute shell commands and bash scripts. Deprecated Javascript Rhino - a Javascript module based on the Mozilla Rhino engine. Javascript Nashorn - a Javascript module based on the built-in Java Nashorn engine. Javascript V8 - a Javascript module based on the Chrome V8 engine.","title":"Engines"},{"location":"overview/engines/#engines","text":"","title":"Engines"},{"location":"overview/engines/#engines-list","text":"Javascript GraalVM JS - a Javascript module based on the GraalVM JS engine. Web - serving the static content via the underlying web container's capabilities e.g. Apache Tomcat . Wiki Markdown - a Wiki engine supporting Markdown markup language and uses the Mylyn underlying framework. BPM - a BPMN specification supporting engine Flowable . OData - expose OData services from database tables/views. Command - execute shell commands and bash scripts.","title":"Engines List"},{"location":"overview/engines/#deprecated","text":"Javascript Rhino - a Javascript module based on the Mozilla Rhino engine. Javascript Nashorn - a Javascript module based on the built-in Java Nashorn engine. Javascript V8 - a Javascript module based on the Chrome V8 engine.","title":"Deprecated"},{"location":"overview/faq/","text":"If you have a question that is not covered here, but it should be, please let us know . Concepts In-System Development In-System Development is a programming model used when you work directly on a live system . Avoid side-effects of a simulated (local) environment by working on a live system. Access live data via the same channel which will be used in production. All the dependencies and integrations are on place as they will be in production. Shortest development turn-around time . Short life-cycle management process. Vertical Scenarios & Horizontal Scaling Covering end-to-end scenarios including all the application layers from architecture perspective as well as all the development process phases from project management perspective. All or nothing \u2013 partial doesn't count. Equal runtime instances based on a single content package for simple and reliable management. Content-Centric & Centralized Repository All application artifacts are in a single repository. Operational repository vs SCM repository. During development process is used IO optimized repository. After the code is ready it is committed to SCM - version, inspection and support optimized repository.. Simple life-cycle management and transport. Workspace, Public Registry separation based on the development life-cycle phases. Dynamic Languages Perfect match to Dynamic Applications - built for change. Can interpret (rather than compile) the execution of tasks. Existing smooth integration within the web servers. No restart required. Java is used for the core components of the platform, while JavaScript is for the application business logic (the glue code). Injected Services Available out-of-the-box for developers \u2013 request , response , datasource , http , CMIS storage , BPMN engine , wiki , indexer , user , etc. Standardized API for cloud developers. Different language's implementations are possible integrated via the extension point. Different provider's implementations can be exposed to developers on their cloud. Integration Services Why integration services are part of the core? Cloud applications usually are extensions to a packaged software (on-premise or on-demand). Re-use of 3-thd party services is very often in this context. Replication use-case - major scenario for on-premise to on-demand cross-platform applications. Scheduled jobs as asynchronous activities usually needed. Semantic separation of integration and orchestration services from the other general purpose services. Extensibility Why is the extensibility important and for whom? Software vendor's code vs customer's specific extension's code. Update and Upgrade issues. Business agility depends on the process change -ability. Bilateral extension-points and extensions descriptors. Web IDE Why it looks like Eclipse in a web browser? Why not more webby style? Lower barrier for Eclipse developers. Overall experience comfortable for developers proven for years from on-premise tools. Using of Resource like API and concepts. There are some themes you can choose from the menu for more \"webby\" look and feel. Decisions GraalJS Why GraalJS ? What about Rhino, Nashorn and V8? Mature engine with the best performance. Supports CommonJS for dynamic loading of modules. Built-in debugger with simple API. Possibility to invoke standard Java objects directly, which is not recommended of course. Angular, Bootstrap & GoldenLayout Why moved from RAP to Angular, Bootstrap, GoldenLayout web frameworks? RAP is an Eclipse framework providing a rendering of the user interface for standard SWT/JFace widgets remotely e.g. in a browser. It brings for us: RAP is a mature framework and depends on a reliable API, but not so attractive for pure web developers (HTML, JavaScript, etc.). RAP is a stable framework with great support, but also it could be said for Angular 1.x and Bootstrap 3.x RAP rely on the standard modularization \u2013 OSGi, plugins, but comes with the complexity of Maven, Tycho, OSGi, Orbit, etc. integration. In RAP developers can write mostly in pure Java with all the benefits it brings by itself, but for web developers it turns out it is not a benefit, but a drawback. In RAP one can have a single sourcing components - reuse of existing functionality written as Eclipse plugins, which has never happen in the reality. RAP has possibility to integrate non-Java modules as well (pure client side HTML and JavaScript) via the browser component, but it is much more complex than pure web coding. JSON Models Why JSON for models? JSON is very simple data exchange format. We have chosen it for the standard format for all the models. Simple enough and human readable/writable. Support by mature frameworks for parsing/serializing. Quite popular and proved in web applications context. Flat Data Models Why flat data models? Proved by many business applications for years. Straight forward implementation on relational-database. Easy to be understood and used by the developers. Tools for it are also simple and easy to use. REST Why REST instead of server-side generation? We leverage the use of REST paradigm for the cloud applications created with the toolkit. There are quite enough reasons for these already well described in blogs related to Web 2.0. Clean separation of the data services from the user interface. Independent development of both including easy mocking. Possibility of reuse and/or composition of services in different user interfaces. Possibility of UI-less integration if needed. Better operations and support. Publish Why Publish? Developers can work safely on multiple workspaces. \"Publish\" transfers the artifacts to the central registry space for public use. One-Time-Generation Why one-time-generation? It is enough to boost productivity in some cases. MDA is also supported via Entity Data Modeler. No OSGi OSGi is the only real modularization framework for Java, but comes with much more complexity than needed for our case. We moved from OSGi to build only simple Maven dependency management with Java Services and Guice for runtime injections for the backend. How to How to build my own Dirigible? It is a standard Maven based project, so: git clone cd dirigible mvn clean install should work. How to add my own templates? It is quite easy - create a project with layout similar to ones from DirigibleLabs How to integrate my Java framework? It is even simpler - add it during the packaging phase as a regular Maven module to be packaged in the WAR or the executable JAR files. How to register my Enterprise JavaScript API ? Once you make the your core framework available as a Maven module packaged into your WAR file, you can implement your own Enterprise JavaScript API facade. How to integrate my non-Java framework? It depends on the particular framework. Usually, it is via the Command feature. Please, contact us in case of interest. How to integrate my dynamic language? There is an Engine API which can be implemented, as well as a REST service which can execute the code. Please, contact us if you plan such an integration.","title":"FAQ"},{"location":"overview/faq/#concepts","text":"In-System Development In-System Development is a programming model used when you work directly on a live system . Avoid side-effects of a simulated (local) environment by working on a live system. Access live data via the same channel which will be used in production. All the dependencies and integrations are on place as they will be in production. Shortest development turn-around time . Short life-cycle management process. Vertical Scenarios & Horizontal Scaling Covering end-to-end scenarios including all the application layers from architecture perspective as well as all the development process phases from project management perspective. All or nothing \u2013 partial doesn't count. Equal runtime instances based on a single content package for simple and reliable management. Content-Centric & Centralized Repository All application artifacts are in a single repository. Operational repository vs SCM repository. During development process is used IO optimized repository. After the code is ready it is committed to SCM - version, inspection and support optimized repository.. Simple life-cycle management and transport. Workspace, Public Registry separation based on the development life-cycle phases. Dynamic Languages Perfect match to Dynamic Applications - built for change. Can interpret (rather than compile) the execution of tasks. Existing smooth integration within the web servers. No restart required. Java is used for the core components of the platform, while JavaScript is for the application business logic (the glue code). Injected Services Available out-of-the-box for developers \u2013 request , response , datasource , http , CMIS storage , BPMN engine , wiki , indexer , user , etc. Standardized API for cloud developers. Different language's implementations are possible integrated via the extension point. Different provider's implementations can be exposed to developers on their cloud. Integration Services Why integration services are part of the core? Cloud applications usually are extensions to a packaged software (on-premise or on-demand). Re-use of 3-thd party services is very often in this context. Replication use-case - major scenario for on-premise to on-demand cross-platform applications. Scheduled jobs as asynchronous activities usually needed. Semantic separation of integration and orchestration services from the other general purpose services. Extensibility Why is the extensibility important and for whom? Software vendor's code vs customer's specific extension's code. Update and Upgrade issues. Business agility depends on the process change -ability. Bilateral extension-points and extensions descriptors. Web IDE Why it looks like Eclipse in a web browser? Why not more webby style? Lower barrier for Eclipse developers. Overall experience comfortable for developers proven for years from on-premise tools. Using of Resource like API and concepts. There are some themes you can choose from the menu for more \"webby\" look and feel.","title":"Concepts"},{"location":"overview/faq/#decisions","text":"GraalJS Why GraalJS ? What about Rhino, Nashorn and V8? Mature engine with the best performance. Supports CommonJS for dynamic loading of modules. Built-in debugger with simple API. Possibility to invoke standard Java objects directly, which is not recommended of course. Angular, Bootstrap & GoldenLayout Why moved from RAP to Angular, Bootstrap, GoldenLayout web frameworks? RAP is an Eclipse framework providing a rendering of the user interface for standard SWT/JFace widgets remotely e.g. in a browser. It brings for us: RAP is a mature framework and depends on a reliable API, but not so attractive for pure web developers (HTML, JavaScript, etc.). RAP is a stable framework with great support, but also it could be said for Angular 1.x and Bootstrap 3.x RAP rely on the standard modularization \u2013 OSGi, plugins, but comes with the complexity of Maven, Tycho, OSGi, Orbit, etc. integration. In RAP developers can write mostly in pure Java with all the benefits it brings by itself, but for web developers it turns out it is not a benefit, but a drawback. In RAP one can have a single sourcing components - reuse of existing functionality written as Eclipse plugins, which has never happen in the reality. RAP has possibility to integrate non-Java modules as well (pure client side HTML and JavaScript) via the browser component, but it is much more complex than pure web coding. JSON Models Why JSON for models? JSON is very simple data exchange format. We have chosen it for the standard format for all the models. Simple enough and human readable/writable. Support by mature frameworks for parsing/serializing. Quite popular and proved in web applications context. Flat Data Models Why flat data models? Proved by many business applications for years. Straight forward implementation on relational-database. Easy to be understood and used by the developers. Tools for it are also simple and easy to use. REST Why REST instead of server-side generation? We leverage the use of REST paradigm for the cloud applications created with the toolkit. There are quite enough reasons for these already well described in blogs related to Web 2.0. Clean separation of the data services from the user interface. Independent development of both including easy mocking. Possibility of reuse and/or composition of services in different user interfaces. Possibility of UI-less integration if needed. Better operations and support. Publish Why Publish? Developers can work safely on multiple workspaces. \"Publish\" transfers the artifacts to the central registry space for public use. One-Time-Generation Why one-time-generation? It is enough to boost productivity in some cases. MDA is also supported via Entity Data Modeler. No OSGi OSGi is the only real modularization framework for Java, but comes with much more complexity than needed for our case. We moved from OSGi to build only simple Maven dependency management with Java Services and Guice for runtime injections for the backend.","title":"Decisions"},{"location":"overview/faq/#how-to","text":"How to build my own Dirigible? It is a standard Maven based project, so: git clone cd dirigible mvn clean install should work. How to add my own templates? It is quite easy - create a project with layout similar to ones from DirigibleLabs How to integrate my Java framework? It is even simpler - add it during the packaging phase as a regular Maven module to be packaged in the WAR or the executable JAR files. How to register my Enterprise JavaScript API ? Once you make the your core framework available as a Maven module packaged into your WAR file, you can implement your own Enterprise JavaScript API facade. How to integrate my non-Java framework? It depends on the particular framework. Usually, it is via the Command feature. Please, contact us in case of interest. How to integrate my dynamic language? There is an Engine API which can be implemented, as well as a REST service which can execute the code. Please, contact us if you plan such an integration.","title":"How to"},{"location":"overview/features/","text":"Features Note: The feature set listed bellow contains only the major part of what is currently available. For more insights on what can be done with Eclipse Dirigible, we recommend to try it out . Data Structures Creation of table model (JSON formatted *.table descriptor) and actual creation of the corresponding database table during publishing. Creation of view model (JSON formatted *.view descriptor) and actual creation of the corresponding database view during publishing. Creation of delimiter separated values ( *.append , *.update , *.delete , *.replace ) data files and populating the corresponding database table during publishing. Automatic altering of existing tables from the models on compatible changes (new columns added). Modeling of the database schema ( *.dsm and *.schema ) files and creation of the tables, views, and constraints during publishing. Scripting Services Support of JavaScript language by using GraalVM JS as runtime execution engine ( *.js ). Support of CommonJS based modularization of JavaScript services ( *.js ). Support of strictly defined enterprise API for JavaScript to be used by the business application developers. Web Content Support of client-side Web related artifacts, such as HTML, CSS, JS, pictures, etc. Wiki Content Support of Markdown format for Wiki pages. Integration Services Support of listeners for messages from the built-in message bus ( *.listener ). Support of scheduled jobs as triggers for backend services invocation ( *.job ). Support of business processes defined in BPMN 2.0 and executed by the underlying BPM process engine ( *.bpmn ). Support of shell commands execution ( *.command ). Support of OData 2.0 ( *.odata ). Support of websockets ( *.websocket ). Mobile Applications Support of native mobile application development via Tabris.js . Extension Definitions Creation of extension points (JSON formatted descriptor - *.extensionpoint ). Creation of extensions by a given extension point (JSON formatted descriptor - *.extension ). Tooling Workbench perspective for full support of project management (New, Cut, Copy, Paste, Delete, Refresh, Import, Export, etc.) Database perspective for RDBMS management including SQL Console Enhanced code editor with highlight support for JavaScript, HTML, JSON, XML, etc. Preview view for easy testing of changes in Web, Wiki, and Scripting Services Configurable Logs view , which provides server-side logs and traces Lots of template-based wizards for creating new content and services Import and export of project content Documents perspective for import of binary files for external documents and pictures Repository perspective for low-level repository content management Debugger perspective for debugging backend JavaScript services Terminal perspective with the corresponding main view for execution of shell commands on the target instance's OS Modeling Modeling of database schema ( *.dsm and *.schema ) files with Database Schema Modeler Modeling of entity data model ( *.edm and *.model ) files with Entity Data Modeler Modeling of BPMN process ( *.bpmn ) files with BPMN Modeler Modeling of Web form layout ( *.form ) files with Form Designer Security Role-based access management for Web services as well as the document repository Security constraints model (JSON formatted *.access ) support Several predefined roles, which can be used out-of-the-box ( Everyone , Administrator , Manager , PowerUser , User , ReadWrite , ReadOnly ) Registry Publishing support - exposing the artifacts from the user's workspace publicly Auto-publishing support for better usability User interface for browsing and searching within the published content Separate lists of endpoints and viewers per type of services - JavaScript, Web, wiki, etc. Separate browse user interface for Web and wiki content","title":"Features"},{"location":"overview/features/#features","text":"Note: The feature set listed bellow contains only the major part of what is currently available. For more insights on what can be done with Eclipse Dirigible, we recommend to try it out .","title":"Features"},{"location":"overview/features/#data-structures","text":"Creation of table model (JSON formatted *.table descriptor) and actual creation of the corresponding database table during publishing. Creation of view model (JSON formatted *.view descriptor) and actual creation of the corresponding database view during publishing. Creation of delimiter separated values ( *.append , *.update , *.delete , *.replace ) data files and populating the corresponding database table during publishing. Automatic altering of existing tables from the models on compatible changes (new columns added). Modeling of the database schema ( *.dsm and *.schema ) files and creation of the tables, views, and constraints during publishing.","title":"Data Structures"},{"location":"overview/features/#scripting-services","text":"Support of JavaScript language by using GraalVM JS as runtime execution engine ( *.js ). Support of CommonJS based modularization of JavaScript services ( *.js ). Support of strictly defined enterprise API for JavaScript to be used by the business application developers.","title":"Scripting Services"},{"location":"overview/features/#web-content","text":"Support of client-side Web related artifacts, such as HTML, CSS, JS, pictures, etc.","title":"Web Content"},{"location":"overview/features/#wiki-content","text":"Support of Markdown format for Wiki pages.","title":"Wiki Content"},{"location":"overview/features/#integration-services","text":"Support of listeners for messages from the built-in message bus ( *.listener ). Support of scheduled jobs as triggers for backend services invocation ( *.job ). Support of business processes defined in BPMN 2.0 and executed by the underlying BPM process engine ( *.bpmn ). Support of shell commands execution ( *.command ). Support of OData 2.0 ( *.odata ). Support of websockets ( *.websocket ).","title":"Integration Services"},{"location":"overview/features/#mobile-applications","text":"Support of native mobile application development via Tabris.js .","title":"Mobile Applications"},{"location":"overview/features/#extension-definitions","text":"Creation of extension points (JSON formatted descriptor - *.extensionpoint ). Creation of extensions by a given extension point (JSON formatted descriptor - *.extension ).","title":"Extension Definitions"},{"location":"overview/features/#tooling","text":"Workbench perspective for full support of project management (New, Cut, Copy, Paste, Delete, Refresh, Import, Export, etc.) Database perspective for RDBMS management including SQL Console Enhanced code editor with highlight support for JavaScript, HTML, JSON, XML, etc. Preview view for easy testing of changes in Web, Wiki, and Scripting Services Configurable Logs view , which provides server-side logs and traces Lots of template-based wizards for creating new content and services Import and export of project content Documents perspective for import of binary files for external documents and pictures Repository perspective for low-level repository content management Debugger perspective for debugging backend JavaScript services Terminal perspective with the corresponding main view for execution of shell commands on the target instance's OS","title":"Tooling"},{"location":"overview/features/#modeling","text":"Modeling of database schema ( *.dsm and *.schema ) files with Database Schema Modeler Modeling of entity data model ( *.edm and *.model ) files with Entity Data Modeler Modeling of BPMN process ( *.bpmn ) files with BPMN Modeler Modeling of Web form layout ( *.form ) files with Form Designer","title":"Modeling"},{"location":"overview/features/#security","text":"Role-based access management for Web services as well as the document repository Security constraints model (JSON formatted *.access ) support Several predefined roles, which can be used out-of-the-box ( Everyone , Administrator , Manager , PowerUser , User , ReadWrite , ReadOnly )","title":"Security"},{"location":"overview/features/#registry","text":"Publishing support - exposing the artifacts from the user's workspace publicly Auto-publishing support for better usability User interface for browsing and searching within the published content Separate lists of endpoints and viewers per type of services - JavaScript, Web, wiki, etc. Separate browse user interface for Web and wiki content","title":"Registry"},{"location":"overview/license/","text":"License The Dirigible project source code base is provided under the Eclipse Public License - v 2.0 Eclipse Public License - v 2.0 THE ACCOMPANYING PROGRAM IS PROVIDED UNDER THE TERMS OF THIS ECLIPSE PUBLIC LICENSE (\"AGREEMENT\"). ANY USE, REPRODUCTION OR DISTRIBUTION OF THE PROGRAM CONSTITUTES RECIPIENT'S ACCEPTANCE OF THIS AGREEMENT. 1. DEFINITIONS \"Contribution\" means: a) in the case of the initial Contributor, the initial code and documentation distributed under this Agreement, and b) in the case of each subsequent Contributor: i) changes to the Program, and ii) additions to the Program; where such changes and/or additions to the Program originate from and are distributed by that particular Contributor. A Contribution 'originates' from a Contributor if it was added to the Program by such Contributor itself or anyone acting on such Contributor's behalf. Contributions do not include additions to the Program which: (i) are separate modules of software distributed in conjunction with the Program under their own license agreement, and (ii) are not derivative works of the Program. \"Contributor\" means any person or entity that distributes the Program. \"Licensed Patents\" mean patent claims licensable by a Contributor which are necessarily infringed by the use or sale of its Contribution alone or when combined with the Program. \"Program\" means the Contributions distributed in accordance with this Agreement. \"Recipient\" means anyone who receives the Program under this Agreement, including all Contributors. 2. GRANT OF RIGHTS a) Subject to the terms of this Agreement, each Contributor hereby grants Recipient a non-exclusive, worldwide, royalty-free copyright license to reproduce, prepare derivative works of, publicly display, publicly perform, distribute and sublicense the Contribution of such Contributor, if any, and such derivative works, in source code and object code form. b) Subject to the terms of this Agreement, each Contributor hereby grants Recipient a non-exclusive, worldwide, royalty-free patent license under Licensed Patents to make, use, sell, offer to sell, import and otherwise transfer the Contribution of such Contributor, if any, in source code and object code form. This patent license shall apply to the combination of the Contribution and the Program if, at the time the Contribution is added by the Contributor, such addition of the Contribution causes such combination to be covered by the Licensed Patents. The patent license shall not apply to any other combinations which include the Contribution. No hardware per se is licensed hereunder. c) Recipient understands that although each Contributor grants the licenses to its Contributions set forth herein, no assurances are provided by any Contributor that the Program does not infringe the patent or other intellectual property rights of any other entity. Each Contributor disclaims any liability to Recipient for claims brought by any other entity based on infringement of intellectual property rights or otherwise. As a condition to exercising the rights and licenses granted hereunder, each Recipient hereby assumes sole responsibility to secure any other intellectual property rights needed, if any. For example, if a third party patent license is required to allow Recipient to distribute the Program, it is Recipient's responsibility to acquire that license before distributing the Program. d) Each Contributor represents that to its knowledge it has sufficient copyright rights in its Contribution, if any, to grant the copyright license set forth in this Agreement. 3. REQUIREMENTS A Contributor may choose to distribute the Program in object code form under its own license agreement, provided that: a) it complies with the terms and conditions of this Agreement; and b) its license agreement: i) effectively disclaims on behalf of all Contributors all warranties and conditions, express and implied, including warranties or conditions of title and non-infringement, and implied warranties or conditions of merchantability and fitness for a particular purpose; ii) effectively excludes on behalf of all Contributors all liability for damages, including direct, indirect, special, incidental and consequential damages, such as lost profits; iii) states that any provisions which differ from this Agreement are offered by that Contributor alone and not by any other party; and iv) states that source code for the Program is available from such Contributor, and informs licensees how to obtain it in a reasonable manner on or through a medium customarily used for software exchange. When the Program is made available in source code form: a) it must be made available under this Agreement; and b) a copy of this Agreement must be included with each copy of the Program. Contributors may not remove or alter any copyright notices contained within the Program. Each Contributor must identify itself as the originator of its Contribution, if any, in a manner that reasonably allows subsequent Recipients to identify the originator of the Contribution. 4. COMMERCIAL DISTRIBUTION Commercial distributors of software may accept certain responsibilities with respect to end users, business partners and the like. While this license is intended to facilitate the commercial use of the Program, the Contributor who includes the Program in a commercial product offering should do so in a manner which does not create potential liability for other Contributors. Therefore, if a Contributor includes the Program in a commercial product offering, such Contributor (\"Commercial Contributor\") hereby agrees to defend and indemnify every other Contributor (\"Indemnified Contributor\") against any losses, damages and costs (collectively \"Losses\") arising from claims, lawsuits and other legal actions brought by a third party against the Indemnified Contributor to the extent caused by the acts or omissions of such Commercial Contributor in connection with its distribution of the Program in a commercial product offering. The obligations in this section do not apply to any claims or Losses relating to any actual or alleged intellectual property infringement. In order to qualify, an Indemnified Contributor must: a) promptly notify the Commercial Contributor in writing of such claim, and b) allow the Commercial Contributor to control, and cooperate with the Commercial Contributor in, the defense and any related settlement negotiations. The Indemnified Contributor may participate in any such claim at its own expense. For example, a Contributor might include the Program in a commercial product offering, Product X. That Contributor is then a Commercial Contributor. If that Commercial Contributor then makes performance claims, or offers warranties related to Product X, those performance claims and warranties are such Commercial Contributor's responsibility alone. Under this section, the Commercial Contributor would have to defend claims against the other Contributors related to those performance claims and warranties, and if a court requires any other Contributor to pay any damages as a result, the Commercial Contributor must pay those damages. 5. NO WARRANTY EXCEPT AS EXPRESSLY SET FORTH IN THIS AGREEMENT, THE PROGRAM IS PROVIDED ON AN \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, EITHER EXPRESS OR IMPLIED INCLUDING, WITHOUT LIMITATION, ANY WARRANTIES OR CONDITIONS OF TITLE, NON-INFRINGEMENT, MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE. Each Recipient is solely responsible for determining the appropriateness of using and distributing the Program and assumes all risks associated with its exercise of rights under this Agreement , including but not limited to the risks and costs of program errors, compliance with applicable laws, damage to or loss of data, programs or equipment, and unavailability or interruption of operations. 6. DISCLAIMER OF LIABILITY EXCEPT AS EXPRESSLY SET FORTH IN THIS AGREEMENT, NEITHER RECIPIENT NOR ANY CONTRIBUTORS SHALL HAVE ANY LIABILITY FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING WITHOUT LIMITATION LOST PROFITS), HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OR DISTRIBUTION OF THE PROGRAM OR THE EXERCISE OF ANY RIGHTS GRANTED HEREUNDER, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGES. 7. GENERAL If any provision of this Agreement is invalid or unenforceable under applicable law, it shall not affect the validity or enforceability of the remainder of the terms of this Agreement, and without further action by the parties hereto, such provision shall be reformed to the minimum extent necessary to make such provision valid and enforceable. If Recipient institutes patent litigation against any entity (including a cross-claim or counterclaim in a lawsuit) alleging that the Program itself (excluding combinations of the Program with other software or hardware) infringes such Recipient's patent(s), then such Recipient's rights granted under Section 2(b) shall terminate as of the date such litigation is filed. All Recipient's rights under this Agreement shall terminate if it fails to comply with any of the material terms or conditions of this Agreement and does not cure such failure in a reasonable period of time after becoming aware of such noncompliance. If all Recipient's rights under this Agreement terminate, Recipient agrees to cease use and distribution of the Program as soon as reasonably practicable. However, Recipient's obligations under this Agreement and any licenses granted by Recipient relating to the Program shall continue and survive. Everyone is permitted to copy and distribute copies of this Agreement, but in order to avoid inconsistency the Agreement is copyrighted and may only be modified in the following manner. The Agreement Steward reserves the right to publish new versions (including revisions) of this Agreement from time to time. No one other than the Agreement Steward has the right to modify this Agreement. The Eclipse Foundation is the initial Agreement Steward. The Eclipse Foundation may assign the responsibility to serve as the Agreement Steward to a suitable separate entity. Each new version of the Agreement will be given a distinguishing version number. The Program (including Contributions) may always be distributed subject to the version of the Agreement under which it was received. In addition, after a new version of the Agreement is published, Contributor may elect to distribute the Program (including its Contributions) under the new version. Except as expressly stated in Sections 2(a) and 2(b) above, Recipient receives no rights or licenses to the intellectual property of any Contributor under this Agreement, whether expressly, by implication, estoppel or otherwise. All rights in the Program not expressly granted under this Agreement are reserved. This Agreement is governed by the laws of the State of New York and the intellectual property laws of the United States of America. No party to this Agreement will bring a legal action under this Agreement more than one year after the cause of action arose. Each party waives its rights to a jury trial in any resulting litigation.","title":"License"},{"location":"overview/license/#license","text":"The Dirigible project source code base is provided under the Eclipse Public License - v 2.0","title":"License"},{"location":"overview/license/#eclipse-public-license-v-20","text":"THE ACCOMPANYING PROGRAM IS PROVIDED UNDER THE TERMS OF THIS ECLIPSE PUBLIC LICENSE (\"AGREEMENT\"). ANY USE, REPRODUCTION OR DISTRIBUTION OF THE PROGRAM CONSTITUTES RECIPIENT'S ACCEPTANCE OF THIS AGREEMENT.","title":"Eclipse Public License - v 2.0"},{"location":"overview/license/#1-definitions","text":"\"Contribution\" means: a) in the case of the initial Contributor, the initial code and documentation distributed under this Agreement, and b) in the case of each subsequent Contributor: i) changes to the Program, and ii) additions to the Program; where such changes and/or additions to the Program originate from and are distributed by that particular Contributor. A Contribution 'originates' from a Contributor if it was added to the Program by such Contributor itself or anyone acting on such Contributor's behalf. Contributions do not include additions to the Program which: (i) are separate modules of software distributed in conjunction with the Program under their own license agreement, and (ii) are not derivative works of the Program. \"Contributor\" means any person or entity that distributes the Program. \"Licensed Patents\" mean patent claims licensable by a Contributor which are necessarily infringed by the use or sale of its Contribution alone or when combined with the Program. \"Program\" means the Contributions distributed in accordance with this Agreement. \"Recipient\" means anyone who receives the Program under this Agreement, including all Contributors.","title":"1. DEFINITIONS"},{"location":"overview/license/#2-grant-of-rights","text":"a) Subject to the terms of this Agreement, each Contributor hereby grants Recipient a non-exclusive, worldwide, royalty-free copyright license to reproduce, prepare derivative works of, publicly display, publicly perform, distribute and sublicense the Contribution of such Contributor, if any, and such derivative works, in source code and object code form. b) Subject to the terms of this Agreement, each Contributor hereby grants Recipient a non-exclusive, worldwide, royalty-free patent license under Licensed Patents to make, use, sell, offer to sell, import and otherwise transfer the Contribution of such Contributor, if any, in source code and object code form. This patent license shall apply to the combination of the Contribution and the Program if, at the time the Contribution is added by the Contributor, such addition of the Contribution causes such combination to be covered by the Licensed Patents. The patent license shall not apply to any other combinations which include the Contribution. No hardware per se is licensed hereunder. c) Recipient understands that although each Contributor grants the licenses to its Contributions set forth herein, no assurances are provided by any Contributor that the Program does not infringe the patent or other intellectual property rights of any other entity. Each Contributor disclaims any liability to Recipient for claims brought by any other entity based on infringement of intellectual property rights or otherwise. As a condition to exercising the rights and licenses granted hereunder, each Recipient hereby assumes sole responsibility to secure any other intellectual property rights needed, if any. For example, if a third party patent license is required to allow Recipient to distribute the Program, it is Recipient's responsibility to acquire that license before distributing the Program. d) Each Contributor represents that to its knowledge it has sufficient copyright rights in its Contribution, if any, to grant the copyright license set forth in this Agreement.","title":"2. GRANT OF RIGHTS"},{"location":"overview/license/#3-requirements","text":"A Contributor may choose to distribute the Program in object code form under its own license agreement, provided that: a) it complies with the terms and conditions of this Agreement; and b) its license agreement: i) effectively disclaims on behalf of all Contributors all warranties and conditions, express and implied, including warranties or conditions of title and non-infringement, and implied warranties or conditions of merchantability and fitness for a particular purpose; ii) effectively excludes on behalf of all Contributors all liability for damages, including direct, indirect, special, incidental and consequential damages, such as lost profits; iii) states that any provisions which differ from this Agreement are offered by that Contributor alone and not by any other party; and iv) states that source code for the Program is available from such Contributor, and informs licensees how to obtain it in a reasonable manner on or through a medium customarily used for software exchange. When the Program is made available in source code form: a) it must be made available under this Agreement; and b) a copy of this Agreement must be included with each copy of the Program. Contributors may not remove or alter any copyright notices contained within the Program. Each Contributor must identify itself as the originator of its Contribution, if any, in a manner that reasonably allows subsequent Recipients to identify the originator of the Contribution.","title":"3. REQUIREMENTS"},{"location":"overview/license/#4-commercial-distribution","text":"Commercial distributors of software may accept certain responsibilities with respect to end users, business partners and the like. While this license is intended to facilitate the commercial use of the Program, the Contributor who includes the Program in a commercial product offering should do so in a manner which does not create potential liability for other Contributors. Therefore, if a Contributor includes the Program in a commercial product offering, such Contributor (\"Commercial Contributor\") hereby agrees to defend and indemnify every other Contributor (\"Indemnified Contributor\") against any losses, damages and costs (collectively \"Losses\") arising from claims, lawsuits and other legal actions brought by a third party against the Indemnified Contributor to the extent caused by the acts or omissions of such Commercial Contributor in connection with its distribution of the Program in a commercial product offering. The obligations in this section do not apply to any claims or Losses relating to any actual or alleged intellectual property infringement. In order to qualify, an Indemnified Contributor must: a) promptly notify the Commercial Contributor in writing of such claim, and b) allow the Commercial Contributor to control, and cooperate with the Commercial Contributor in, the defense and any related settlement negotiations. The Indemnified Contributor may participate in any such claim at its own expense. For example, a Contributor might include the Program in a commercial product offering, Product X. That Contributor is then a Commercial Contributor. If that Commercial Contributor then makes performance claims, or offers warranties related to Product X, those performance claims and warranties are such Commercial Contributor's responsibility alone. Under this section, the Commercial Contributor would have to defend claims against the other Contributors related to those performance claims and warranties, and if a court requires any other Contributor to pay any damages as a result, the Commercial Contributor must pay those damages.","title":"4. COMMERCIAL DISTRIBUTION"},{"location":"overview/license/#5-no-warranty","text":"EXCEPT AS EXPRESSLY SET FORTH IN THIS AGREEMENT, THE PROGRAM IS PROVIDED ON AN \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, EITHER EXPRESS OR IMPLIED INCLUDING, WITHOUT LIMITATION, ANY WARRANTIES OR CONDITIONS OF TITLE, NON-INFRINGEMENT, MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE. Each Recipient is solely responsible for determining the appropriateness of using and distributing the Program and assumes all risks associated with its exercise of rights under this Agreement , including but not limited to the risks and costs of program errors, compliance with applicable laws, damage to or loss of data, programs or equipment, and unavailability or interruption of operations.","title":"5. NO WARRANTY"},{"location":"overview/license/#6-disclaimer-of-liability","text":"EXCEPT AS EXPRESSLY SET FORTH IN THIS AGREEMENT, NEITHER RECIPIENT NOR ANY CONTRIBUTORS SHALL HAVE ANY LIABILITY FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING WITHOUT LIMITATION LOST PROFITS), HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OR DISTRIBUTION OF THE PROGRAM OR THE EXERCISE OF ANY RIGHTS GRANTED HEREUNDER, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGES.","title":"6. DISCLAIMER OF LIABILITY"},{"location":"overview/license/#7-general","text":"If any provision of this Agreement is invalid or unenforceable under applicable law, it shall not affect the validity or enforceability of the remainder of the terms of this Agreement, and without further action by the parties hereto, such provision shall be reformed to the minimum extent necessary to make such provision valid and enforceable. If Recipient institutes patent litigation against any entity (including a cross-claim or counterclaim in a lawsuit) alleging that the Program itself (excluding combinations of the Program with other software or hardware) infringes such Recipient's patent(s), then such Recipient's rights granted under Section 2(b) shall terminate as of the date such litigation is filed. All Recipient's rights under this Agreement shall terminate if it fails to comply with any of the material terms or conditions of this Agreement and does not cure such failure in a reasonable period of time after becoming aware of such noncompliance. If all Recipient's rights under this Agreement terminate, Recipient agrees to cease use and distribution of the Program as soon as reasonably practicable. However, Recipient's obligations under this Agreement and any licenses granted by Recipient relating to the Program shall continue and survive. Everyone is permitted to copy and distribute copies of this Agreement, but in order to avoid inconsistency the Agreement is copyrighted and may only be modified in the following manner. The Agreement Steward reserves the right to publish new versions (including revisions) of this Agreement from time to time. No one other than the Agreement Steward has the right to modify this Agreement. The Eclipse Foundation is the initial Agreement Steward. The Eclipse Foundation may assign the responsibility to serve as the Agreement Steward to a suitable separate entity. Each new version of the Agreement will be given a distinguishing version number. The Program (including Contributions) may always be distributed subject to the version of the Agreement under which it was received. In addition, after a new version of the Agreement is published, Contributor may elect to distribute the Program (including its Contributions) under the new version. Except as expressly stated in Sections 2(a) and 2(b) above, Recipient receives no rights or licenses to the intellectual property of any Contributor under this Agreement, whether expressly, by implication, estoppel or otherwise. All rights in the Program not expressly granted under this Agreement are reserved. This Agreement is governed by the laws of the State of New York and the intellectual property laws of the United States of America. No party to this Agreement will bring a legal action under this Agreement more than one year after the cause of action arose. Each party waives its rights to a jury trial in any resulting litigation.","title":"7. GENERAL"},{"location":"overview/runtime-services/","text":"Runtime Services There are several REST services available at runtime, which can give you another communication channel with Dirigible containers.","title":"Runtime Services"},{"location":"overview/runtime-services/#runtime-services","text":"There are several REST services available at runtime, which can give you another communication channel with Dirigible containers.","title":"Runtime Services"},{"location":"setup/","text":"Setup in Tomcat The Tomcat specific WAR files can be deployed on a Apache Tomcat web container. In this case the built-in H2 database is used. More information about how to deploy on Tomcat can be found here . Prerequisites JDK 11 or later - OpenJDK versions can be found here . macOS brew install ttyd Linux Linux support is built-in More info about ttyd can be found at: ttyd Windows You may experience certain functional limitations if you decide to run the Web IDE locally on Windows using Tomcat. In this case, we recommend that you perform the setup using Docker. See Setup as a Docker Image . Steps Download ROOT.war for Tomcat from: download.dirigible.io Configure the Users store under $CATALINA_HOME/conf/tomcat-users.xml : <tomcat-users> <role rolename= \"Developer\" /> <role rolename= \"Operator\" /> <role rolename= \"Everyone\" /> <user username= \"dirigible\" password= \"dirigible\" roles= \"Developer,Operator,Everyone\" /> </tomcat-users> Copy the Dirigible's ROOT.war to $TOMCAT/webapps folder. Configure the target Database setup, if needed: Local (H2) No additional setup is needed. PostgreSQL Install postgresql on Linux (Debian-based) with: sudo apt-get update sudo apt-get install postgresql postgresql-contrib Create the default database for Eclipse Dirigible: sudo -i -u postgres createdb dirigible_database Create System User for the Eclipse Dirigible database: psql dirigible_database create user dirigible_system with password 'dirigible1234'; grant all on database dirigible_database to dirigible_system; Datasource configuration: Download the postgresql JDBC driver version 4.1 from here . Copy the postgresql-*.jar file to the <TOMCAT_HOME>/lib directory. Set the environment variables: export DIRIGIBLE_DATABASE_PROVIDER=custom export DIRIGIBLE_DATABASE_CUSTOM_DATASOURCES=POSTGRES export DIRIGIBLE_DATABASE_DATASOURCE_NAME_DEFAULT=POSTGRES export POSTGRES_DRIVER=org.postgresql.Driver export POSTGRES_URL=jdbc:postgresql://localhost:5432/dirigible_database export POSTGRES_USERNAME=dirigible_system export POSTGRES_PASSWORD=dirigible1234 export DIRIGIBLE_SCHEDULER_DATABASE_DRIVER=org.postgresql.Driver export DIRIGIBLE_SCHEDULER_DATABASE_URL=jdbc:postgresql://localhost:5432/dirigible_database export DIRIGIBLE_SCHEDULER_DATABASE_USER=dirigible_system export DIRIGIBLE_SCHEDULER_DATABASE_PASSWORD=dirigible1234 export DIRIGIBLE_SCHEDULER_DATABASE_DELEGATE=org.quartz.impl.jdbcjobstore.PostgreSQLDelegate export DIRIGIBLE_MESSAGING_USE_DEFAULT_DATABASE=true export DIRIGIBLE_FLOWABLE_USE_DEFAULT_DATABASE=true export DIRIGIBLE_DATABASE_NAMES_CASE_SENSITIVE=true MySQL Install mysql on Linux (Debian-based) with: sudo apt-get update sudo apt-get install mysql-server sudo mysql\\_install\\_db sudo /usr/bin/mysql\\_secure\\_installation Create the default database for Dirigible: sudo -i -u postgres createdb dirigible_database Create System User for the Eclipse Dirigible database: mysql -u root -p CREATE DATABASE dirigible_database; CREATE USER 'dirigible_system'@'localhost' IDENTIFIED BY 'dirigible1234'; GRANT ALL PRIVILEGES ON dirigible_database.* TO 'dirigible_system'@'localhost' WITH GRANT OPTION; Datasource configuration: Download the mysql JDBC driver version 5.1 from here . Copy the mysql-*.jar file to the <TOMCAT_HOME>/lib directory. Open the file <TOMCAT_HOME>/conf/context.xml and add the following within the context: <Resource name= \"jdbc/DefaultDB\" auth= \"Container\" type= \"javax.sql.DataSource\" maxActive= \"100\" maxIdle= \"30\" maxWait= \"10000\" username= \"dirigible_system\" password= \"dirigible1234\" driverClassName= \"com.mysql.jdbc.Driver\" url= \"jdbc:mysql://localhost:3306/dirigible_database?useUnicode=true&amp;characterEncoding=UTF-8\" /> web.xml - make sure the initial parameter jndiDefaultDataSource is uncommented: <init-param> <param-name> jndiDefaultDataSource </param-name> <param-value> java:comp/env/jdbc/DefaultDB </param-value> </init-param> Also, the initial parameter jdbcAutoCommit must be set to false (by default). <init-param> <param-name> jdbcAutoCommit </param-name> <param-value> false </param-value> </init-param> The type of the datasource is jndi instead of local . <init-param> <param-name> defaultDataSourceType </param-name> <param-value> jndi </param-value> </init-param> Lastly, the resource reference for the datasource has to be uncommented. <resource-ref> <res-ref-name> jdbc/DefaultDB </res-ref-name> <res-type> javax.sql.DataSource </res-type> <res-auth> Container </res-auth> </resource-ref> HANA Install HANA Express . Set the environment variables: export DIRIGIBLE_DATABASE_PROVIDER=custom export DIRIGIBLE_DATABASE_CUSTOM_DATASOURCES=HANA export DIRIGIBLE_DATABASE_DATASOURCE_NAME_DEFAULT=HANA export HANA_DRIVER=com.sap.db.jdbc.Driver export HANA_URL=jdbc:sap://<host>:<port> export HANA_USERNAME=<user> export HANA_PASSWORD=<password> export DIRIGIBLE_SCHEDULER_DATABASE_DRIVER=com.sap.db.jdbc.Driver export DIRIGIBLE_SCHEDULER_DATABASE_URL=jdbc:sap://<host>:<port> export DIRIGIBLE_SCHEDULER_DATABASE_USER=<user> export DIRIGIBLE_SCHEDULER_DATABASE_PASSWORD=<password> export DIRIGIBLE_MESSAGING_USE_DEFAULT_DATABASE=false export DIRIGIBLE_FLOWABLE_USE_DEFAULT_DATABASE=false Note: Remember to replace the <host> , <port> , <user> , <password> placeholders. Sybase ASE How to setup a test environment on Amazon: Select Image Size: t2.medium Security Group: TCP Custom, 5000 Download Sybase ASE Express from here . Transfer: scp -i dirigible-aws.pem ASE_Suite.linuxamd64.tgz ec2-user@<ip-address>:~ scp -i dirigible-aws.pem apache-tomcat-XXX.zip ec2-user@<ip-address>:~ scp -i dirigible-aws.pem ROOT.war ec2-user@<ip-address>:~ scp -i dirigible-aws.pem jdk-8u144-linux-x64.tar.gz ec2-user@<ip-address>:~ Prepare OS: sudo mkdir -p /opt/sybase sudo mkdir -p /var/sybase sudo groupadd sybase sudo useradd -g sybase -d /opt/sybase sybase sudo passwd sybase sudo chown sybase:sybase /opt/sybase sudo chown sybase:sybase /var/sybase Login: ssh ec2-user@<ip-address> -i dirigible-aws.pem Setup: su - sybase mkdir install cd install cp /home/ec2-user/ASE_Suite.linuxamd64.tgz . tar -xvf ASE_Suite.linuxamd64.tgz ./setup.bin -i console Parameters: Choose Install Folder -> use: /opt/sybase Choose Install Set -> 1- Typical Software License Type Selection -> 2- Install Express Edition of SAP Adaptive Server Enterprise End-user License Agreement -> 1) All regions Configure New Servers -> [X] 1 - Configure new SAP ASE Configure Servers with Different User Account -> 2- No SAP ASE Name ASE160 System Administrator's Password ****** Enable SAP ASE for SAP ASE Cockpit monitoring false Technical user tech_user Technical user password ******** Host Name ip-<internal-ip-address>.eu-central-1.comp Port Number 5000 Application Type Mixed (OLTP/DSS) Create sample databases false Page Size 4k Error Log /opt/sybase/ASE-16_0/install/ASE1 Default Language <use default> Default Character Set <use default> Default Sort Order <use default> Master Device /opt/sybase/data/master.dat Master Device Size (MB) 500 Master Database Size (MB) 250 System Procedure Device /opt/sybase/data/sysprocs.dat System Procedure Device Size (MB) 500 System Procedure Database Size (MB) 500 System Device /opt/sybase/data/sybsysdb.dat System Device Size (MB) 100 System Database Size (MB) 100 Tempdb Device /opt/sybase/data/tempdbdev.dat Tempdb Device Size (MB) 1000 Tempdb Database Size (MB) 1000 Enable PCI false Optimize SAP ASE Configuration false Show Servers: /opt/sybase/ASE-16_0/install/showserver Prepare Test Environment: cd /opt/sybase/install cp /home/ec2-user/apache-tomcat-XXX.zip . cp /home/ec2-user/jdk-8u144-linux-x64.tar.gz . unzip apache-tomcat-XXX.zip tar -xvf jdk-8u144-linux-x64.tar.gz export JAVA_HOME=/opt/sybase/install/jdk1.8.0_144 Add the provided JDBC driver to the lib folder: cp /opt/sybase/shared/lib/jconn4.jar /home/ec2-user/apache-tomcat-XXX/lib Useful actions in case of issues: Start Server: export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/opt/sybase/OCS-16_0/lib3p64 export LANG=C cd /opt/sybase/ASE-16_0/bin ./startserver -f /opt/sybase/ASE-16_0/install/RUN_ASE160 Stop Server: cd /opt/sybase/OCS-16_0/bin export LANG=C ./isql -Usa -SASE160 shutdown with nowait go Kill Hanging Requests: cd /opt/sybase/OCS-16_0/bin export LANG=C ./isql -Usa -SASE160 sp_who go kill spid Uninstall: cd /opt/sybase/sybuninstall/ASESuite ./uninstall -i console Set the environment variables export DIRIGIBLE_DATABASE_PROVIDER=custom export DIRIGIBLE_DATABASE_CUSTOM_DATASOURCES=SYBASE export DIRIGIBLE_DATABASE_DATASOURCE_NAME_DEFAULT=SYBASE export SYBASE_DRIVER=com.sybase.jdbc4.jdbc.SybDriver export SYBASE_URL=jdbc:sybase:Tds:<host>:<port>?ServiceName=<database> export SYBASE_USERNAME=<user> export SYBASE_PASSWORD=<password> export SYBASE_CONNECTION_PROPERTIES=\"DYNAMIC_PREPARE=true;SSL_TRUST_ALL_CERTS=true;JCONNECT_VERSION=0;ENABLE_SSL=true;\" export DIRIGIBLE_MESSAGING_USE_DEFAULT_DATABASE=false export DIRIGIBLE_SCHEDULER_DATABASE_DRIVER=com.sybase.jdbc4.jdbc.SybDriver export DIRIGIBLE_SCHEDULER_DATABASE_URL=\"jdbc:sybase:Tds:<host>:<port>?ServiceName=<database>&DYNAMIC_PREPARE=true&JCONNECT_VERSION=0&ENABLE_SSL=true&SSL_TRUST_ALL_CERTS=true\" export DIRIGIBLE_SCHEDULER_DATABASE_USER=<user> export DIRIGIBLE_SCHEDULER_DATABASE_PASSWORD=<password> export DIRIGIBLE_SCHEDULER_DATABASE_DELEGATE=org.quartz.impl.jdbcjobstore.SybaseDelegate Note: Remember to replace the <host> , <port> , <user> , <password> placeholders. Start the Tomcat server. Open a web browser and go to: http://localhost:8080/ Login with user dirigible and password dirigible . Manager App In case you want to use Apache Tomcat's Manager App to deploy the ROOT.war file, you have to increase the file size limit for upload (e.g. to 200MB): conf\\server.xml <Connector port= \"8080\" protocol= \"HTTP/1.1\" connectionTimeout= \"20000\" redirectPort= \"8443\" maxPostSize= \"209715200\" /> webapps\\manager\\WEB-INF\\web.xml <web-app> ... <servlet> ... <multipart-config> <file-size-threshold> 0 </file-size-threshold> <max-file-size> 209715200 </max-file-size> <max-request-size> 209715200 </max-request-size> </multipart-config> ... </servlet> ... </web-app>","title":"Tomcat"},{"location":"setup/#setup-in-tomcat","text":"The Tomcat specific WAR files can be deployed on a Apache Tomcat web container. In this case the built-in H2 database is used. More information about how to deploy on Tomcat can be found here .","title":"Setup in Tomcat"},{"location":"setup/#prerequisites","text":"JDK 11 or later - OpenJDK versions can be found here . macOS brew install ttyd Linux Linux support is built-in More info about ttyd can be found at: ttyd Windows You may experience certain functional limitations if you decide to run the Web IDE locally on Windows using Tomcat. In this case, we recommend that you perform the setup using Docker. See Setup as a Docker Image .","title":"Prerequisites"},{"location":"setup/#steps","text":"Download ROOT.war for Tomcat from: download.dirigible.io Configure the Users store under $CATALINA_HOME/conf/tomcat-users.xml : <tomcat-users> <role rolename= \"Developer\" /> <role rolename= \"Operator\" /> <role rolename= \"Everyone\" /> <user username= \"dirigible\" password= \"dirigible\" roles= \"Developer,Operator,Everyone\" /> </tomcat-users> Copy the Dirigible's ROOT.war to $TOMCAT/webapps folder. Configure the target Database setup, if needed: Local (H2) No additional setup is needed. PostgreSQL Install postgresql on Linux (Debian-based) with: sudo apt-get update sudo apt-get install postgresql postgresql-contrib Create the default database for Eclipse Dirigible: sudo -i -u postgres createdb dirigible_database Create System User for the Eclipse Dirigible database: psql dirigible_database create user dirigible_system with password 'dirigible1234'; grant all on database dirigible_database to dirigible_system; Datasource configuration: Download the postgresql JDBC driver version 4.1 from here . Copy the postgresql-*.jar file to the <TOMCAT_HOME>/lib directory. Set the environment variables: export DIRIGIBLE_DATABASE_PROVIDER=custom export DIRIGIBLE_DATABASE_CUSTOM_DATASOURCES=POSTGRES export DIRIGIBLE_DATABASE_DATASOURCE_NAME_DEFAULT=POSTGRES export POSTGRES_DRIVER=org.postgresql.Driver export POSTGRES_URL=jdbc:postgresql://localhost:5432/dirigible_database export POSTGRES_USERNAME=dirigible_system export POSTGRES_PASSWORD=dirigible1234 export DIRIGIBLE_SCHEDULER_DATABASE_DRIVER=org.postgresql.Driver export DIRIGIBLE_SCHEDULER_DATABASE_URL=jdbc:postgresql://localhost:5432/dirigible_database export DIRIGIBLE_SCHEDULER_DATABASE_USER=dirigible_system export DIRIGIBLE_SCHEDULER_DATABASE_PASSWORD=dirigible1234 export DIRIGIBLE_SCHEDULER_DATABASE_DELEGATE=org.quartz.impl.jdbcjobstore.PostgreSQLDelegate export DIRIGIBLE_MESSAGING_USE_DEFAULT_DATABASE=true export DIRIGIBLE_FLOWABLE_USE_DEFAULT_DATABASE=true export DIRIGIBLE_DATABASE_NAMES_CASE_SENSITIVE=true MySQL Install mysql on Linux (Debian-based) with: sudo apt-get update sudo apt-get install mysql-server sudo mysql\\_install\\_db sudo /usr/bin/mysql\\_secure\\_installation Create the default database for Dirigible: sudo -i -u postgres createdb dirigible_database Create System User for the Eclipse Dirigible database: mysql -u root -p CREATE DATABASE dirigible_database; CREATE USER 'dirigible_system'@'localhost' IDENTIFIED BY 'dirigible1234'; GRANT ALL PRIVILEGES ON dirigible_database.* TO 'dirigible_system'@'localhost' WITH GRANT OPTION; Datasource configuration: Download the mysql JDBC driver version 5.1 from here . Copy the mysql-*.jar file to the <TOMCAT_HOME>/lib directory. Open the file <TOMCAT_HOME>/conf/context.xml and add the following within the context: <Resource name= \"jdbc/DefaultDB\" auth= \"Container\" type= \"javax.sql.DataSource\" maxActive= \"100\" maxIdle= \"30\" maxWait= \"10000\" username= \"dirigible_system\" password= \"dirigible1234\" driverClassName= \"com.mysql.jdbc.Driver\" url= \"jdbc:mysql://localhost:3306/dirigible_database?useUnicode=true&amp;characterEncoding=UTF-8\" /> web.xml - make sure the initial parameter jndiDefaultDataSource is uncommented: <init-param> <param-name> jndiDefaultDataSource </param-name> <param-value> java:comp/env/jdbc/DefaultDB </param-value> </init-param> Also, the initial parameter jdbcAutoCommit must be set to false (by default). <init-param> <param-name> jdbcAutoCommit </param-name> <param-value> false </param-value> </init-param> The type of the datasource is jndi instead of local . <init-param> <param-name> defaultDataSourceType </param-name> <param-value> jndi </param-value> </init-param> Lastly, the resource reference for the datasource has to be uncommented. <resource-ref> <res-ref-name> jdbc/DefaultDB </res-ref-name> <res-type> javax.sql.DataSource </res-type> <res-auth> Container </res-auth> </resource-ref> HANA Install HANA Express . Set the environment variables: export DIRIGIBLE_DATABASE_PROVIDER=custom export DIRIGIBLE_DATABASE_CUSTOM_DATASOURCES=HANA export DIRIGIBLE_DATABASE_DATASOURCE_NAME_DEFAULT=HANA export HANA_DRIVER=com.sap.db.jdbc.Driver export HANA_URL=jdbc:sap://<host>:<port> export HANA_USERNAME=<user> export HANA_PASSWORD=<password> export DIRIGIBLE_SCHEDULER_DATABASE_DRIVER=com.sap.db.jdbc.Driver export DIRIGIBLE_SCHEDULER_DATABASE_URL=jdbc:sap://<host>:<port> export DIRIGIBLE_SCHEDULER_DATABASE_USER=<user> export DIRIGIBLE_SCHEDULER_DATABASE_PASSWORD=<password> export DIRIGIBLE_MESSAGING_USE_DEFAULT_DATABASE=false export DIRIGIBLE_FLOWABLE_USE_DEFAULT_DATABASE=false Note: Remember to replace the <host> , <port> , <user> , <password> placeholders. Sybase ASE How to setup a test environment on Amazon: Select Image Size: t2.medium Security Group: TCP Custom, 5000 Download Sybase ASE Express from here . Transfer: scp -i dirigible-aws.pem ASE_Suite.linuxamd64.tgz ec2-user@<ip-address>:~ scp -i dirigible-aws.pem apache-tomcat-XXX.zip ec2-user@<ip-address>:~ scp -i dirigible-aws.pem ROOT.war ec2-user@<ip-address>:~ scp -i dirigible-aws.pem jdk-8u144-linux-x64.tar.gz ec2-user@<ip-address>:~ Prepare OS: sudo mkdir -p /opt/sybase sudo mkdir -p /var/sybase sudo groupadd sybase sudo useradd -g sybase -d /opt/sybase sybase sudo passwd sybase sudo chown sybase:sybase /opt/sybase sudo chown sybase:sybase /var/sybase Login: ssh ec2-user@<ip-address> -i dirigible-aws.pem Setup: su - sybase mkdir install cd install cp /home/ec2-user/ASE_Suite.linuxamd64.tgz . tar -xvf ASE_Suite.linuxamd64.tgz ./setup.bin -i console Parameters: Choose Install Folder -> use: /opt/sybase Choose Install Set -> 1- Typical Software License Type Selection -> 2- Install Express Edition of SAP Adaptive Server Enterprise End-user License Agreement -> 1) All regions Configure New Servers -> [X] 1 - Configure new SAP ASE Configure Servers with Different User Account -> 2- No SAP ASE Name ASE160 System Administrator's Password ****** Enable SAP ASE for SAP ASE Cockpit monitoring false Technical user tech_user Technical user password ******** Host Name ip-<internal-ip-address>.eu-central-1.comp Port Number 5000 Application Type Mixed (OLTP/DSS) Create sample databases false Page Size 4k Error Log /opt/sybase/ASE-16_0/install/ASE1 Default Language <use default> Default Character Set <use default> Default Sort Order <use default> Master Device /opt/sybase/data/master.dat Master Device Size (MB) 500 Master Database Size (MB) 250 System Procedure Device /opt/sybase/data/sysprocs.dat System Procedure Device Size (MB) 500 System Procedure Database Size (MB) 500 System Device /opt/sybase/data/sybsysdb.dat System Device Size (MB) 100 System Database Size (MB) 100 Tempdb Device /opt/sybase/data/tempdbdev.dat Tempdb Device Size (MB) 1000 Tempdb Database Size (MB) 1000 Enable PCI false Optimize SAP ASE Configuration false Show Servers: /opt/sybase/ASE-16_0/install/showserver Prepare Test Environment: cd /opt/sybase/install cp /home/ec2-user/apache-tomcat-XXX.zip . cp /home/ec2-user/jdk-8u144-linux-x64.tar.gz . unzip apache-tomcat-XXX.zip tar -xvf jdk-8u144-linux-x64.tar.gz export JAVA_HOME=/opt/sybase/install/jdk1.8.0_144 Add the provided JDBC driver to the lib folder: cp /opt/sybase/shared/lib/jconn4.jar /home/ec2-user/apache-tomcat-XXX/lib Useful actions in case of issues: Start Server: export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/opt/sybase/OCS-16_0/lib3p64 export LANG=C cd /opt/sybase/ASE-16_0/bin ./startserver -f /opt/sybase/ASE-16_0/install/RUN_ASE160 Stop Server: cd /opt/sybase/OCS-16_0/bin export LANG=C ./isql -Usa -SASE160 shutdown with nowait go Kill Hanging Requests: cd /opt/sybase/OCS-16_0/bin export LANG=C ./isql -Usa -SASE160 sp_who go kill spid Uninstall: cd /opt/sybase/sybuninstall/ASESuite ./uninstall -i console Set the environment variables export DIRIGIBLE_DATABASE_PROVIDER=custom export DIRIGIBLE_DATABASE_CUSTOM_DATASOURCES=SYBASE export DIRIGIBLE_DATABASE_DATASOURCE_NAME_DEFAULT=SYBASE export SYBASE_DRIVER=com.sybase.jdbc4.jdbc.SybDriver export SYBASE_URL=jdbc:sybase:Tds:<host>:<port>?ServiceName=<database> export SYBASE_USERNAME=<user> export SYBASE_PASSWORD=<password> export SYBASE_CONNECTION_PROPERTIES=\"DYNAMIC_PREPARE=true;SSL_TRUST_ALL_CERTS=true;JCONNECT_VERSION=0;ENABLE_SSL=true;\" export DIRIGIBLE_MESSAGING_USE_DEFAULT_DATABASE=false export DIRIGIBLE_SCHEDULER_DATABASE_DRIVER=com.sybase.jdbc4.jdbc.SybDriver export DIRIGIBLE_SCHEDULER_DATABASE_URL=\"jdbc:sybase:Tds:<host>:<port>?ServiceName=<database>&DYNAMIC_PREPARE=true&JCONNECT_VERSION=0&ENABLE_SSL=true&SSL_TRUST_ALL_CERTS=true\" export DIRIGIBLE_SCHEDULER_DATABASE_USER=<user> export DIRIGIBLE_SCHEDULER_DATABASE_PASSWORD=<password> export DIRIGIBLE_SCHEDULER_DATABASE_DELEGATE=org.quartz.impl.jdbcjobstore.SybaseDelegate Note: Remember to replace the <host> , <port> , <user> , <password> placeholders. Start the Tomcat server. Open a web browser and go to: http://localhost:8080/ Login with user dirigible and password dirigible .","title":"Steps"},{"location":"setup/#manager-app","text":"In case you want to use Apache Tomcat's Manager App to deploy the ROOT.war file, you have to increase the file size limit for upload (e.g. to 200MB): conf\\server.xml <Connector port= \"8080\" protocol= \"HTTP/1.1\" connectionTimeout= \"20000\" redirectPort= \"8443\" maxPostSize= \"209715200\" /> webapps\\manager\\WEB-INF\\web.xml <web-app> ... <servlet> ... <multipart-config> <file-size-threshold> 0 </file-size-threshold> <max-file-size> 209715200 </max-file-size> <max-request-size> 209715200 </max-request-size> </multipart-config> ... </servlet> ... </web-app>","title":"Manager App"},{"location":"setup/cloud-foundry/","text":"Setup in Cloud Foundry Deploy Eclipse Dirigible in the Cloud Foundry environment of SAP Cloud Platform with the Cloud Foundry Command Line Interface . Prerequisites Install Cloud Foundry Command Line Interface Steps Login to the SAP Cloud Platform Cloud Foundry environment with: cf login -a <cloud-foundry-api-host> Clone the dirigiblelabs\\deployment-sap-cloud-foundry repository: git clone https://github.com/dirigiblelabs/deployment-sap-cloud-foundry Follow the README.md steps. Login with user which has assigned the Developer and Operator roles. Tutorial Step by step tutorial can be found here .","title":"Cloud Foundry"},{"location":"setup/cloud-foundry/#setup-in-cloud-foundry","text":"Deploy Eclipse Dirigible in the Cloud Foundry environment of SAP Cloud Platform with the Cloud Foundry Command Line Interface .","title":"Setup in Cloud Foundry"},{"location":"setup/cloud-foundry/#prerequisites","text":"Install Cloud Foundry Command Line Interface","title":"Prerequisites"},{"location":"setup/cloud-foundry/#steps","text":"Login to the SAP Cloud Platform Cloud Foundry environment with: cf login -a <cloud-foundry-api-host> Clone the dirigiblelabs\\deployment-sap-cloud-foundry repository: git clone https://github.com/dirigiblelabs/deployment-sap-cloud-foundry Follow the README.md steps. Login with user which has assigned the Developer and Operator roles.","title":"Steps"},{"location":"setup/cloud-foundry/#tutorial","text":"Step by step tutorial can be found here .","title":"Tutorial"},{"location":"setup/docker/","text":"Setup as a Docker Image Prerequisites Install Docker Steps Pull the already built container from Docker Hub : docker pull dirigiblelabs/dirigible-all:latest Start the container: Run docker run --name dirigible \\ --rm -p 8080:8080 -p 8081:8081 \\ dirigiblelabs/dirigible-all:latest with Mounted Volume docker run --name dirigible \\ --rm -p 8080:8080 -p 8081:8081 \\ -v <your-local-directory>:/usr/local/tomcat/target \\ dirigiblelabs/dirigible-all:latest with Java Debugging Options docker run --name dirigible \\ --rm -e JPDA_ADDRESS=0.0.0.0:8000 -e JPDA_TRANSPORT=dt_socket \\ -p 8000:8000 -p 8080:8080 -p 8081:8081 \\ dirigiblelabs/dirigible-all:latest Open a web browser and go to: http://localhost:8080/ Note: The default user name and password are dirigible/dirigible Stop the container: docker stop dirigible Contribution Optionally, you can enhance and customize the Dockerfile artifacts from here , or any of the other Docker releases: anonymous-all anonymous-runtime openshift-all sap-cf-all sap-cf-runtime sap-kyma-all sap-kyma-runtime server-all server-runtime server-keycloak-all server-runtime-keycloak trial-all Note: Most of the packages contains two files: Dockerfile-base and Dockerfile . Usually you would want to extend the Dockerfile , except in some special cases.","title":"Docker"},{"location":"setup/docker/#setup-as-a-docker-image","text":"","title":"Setup as a Docker Image"},{"location":"setup/docker/#prerequisites","text":"Install Docker","title":"Prerequisites"},{"location":"setup/docker/#steps","text":"Pull the already built container from Docker Hub : docker pull dirigiblelabs/dirigible-all:latest Start the container: Run docker run --name dirigible \\ --rm -p 8080:8080 -p 8081:8081 \\ dirigiblelabs/dirigible-all:latest with Mounted Volume docker run --name dirigible \\ --rm -p 8080:8080 -p 8081:8081 \\ -v <your-local-directory>:/usr/local/tomcat/target \\ dirigiblelabs/dirigible-all:latest with Java Debugging Options docker run --name dirigible \\ --rm -e JPDA_ADDRESS=0.0.0.0:8000 -e JPDA_TRANSPORT=dt_socket \\ -p 8000:8000 -p 8080:8080 -p 8081:8081 \\ dirigiblelabs/dirigible-all:latest Open a web browser and go to: http://localhost:8080/ Note: The default user name and password are dirigible/dirigible Stop the container: docker stop dirigible","title":"Steps"},{"location":"setup/docker/#contribution","text":"Optionally, you can enhance and customize the Dockerfile artifacts from here , or any of the other Docker releases: anonymous-all anonymous-runtime openshift-all sap-cf-all sap-cf-runtime sap-kyma-all sap-kyma-runtime server-all server-runtime server-keycloak-all server-runtime-keycloak trial-all Note: Most of the packages contains two files: Dockerfile-base and Dockerfile . Usually you would want to extend the Dockerfile , except in some special cases.","title":"Contribution"},{"location":"setup/kubernetes/","text":"Setup in Kubernetes You can deploy Dirigible Docker images, for example dirigiblelabs/dirigible-tomcat , in a Kubernetes cluster. Prerequisites Kubernetes Command Line Interface Kubernetes Cluster on IaaS provider of your choice Steps Create deployment configuration file: deployment.yaml Pod apiVersion : v1 kind : Pod metadata : name : dirigible spec : containers : - name : dirigible image : dirigiblelabs/dirigible-tomcat:latest ports : - name : dirigible containerPort : 8080 Deployment apiVersion : apps/v1 kind : Deployment metadata : name : dirigible spec : replicas : 1 selector : matchLabels : app : dirigible template : metadata : labels : app : dirigible spec : containers : - name : dirigible image : dirigiblelabs/dirigible-tomcat:latest ports : - name : dirigible containerPort : 8080 env : - name : DIRIGIBLE_THEME_DEFAULT value : \"fiori\" Deployment with PVC apiVersion : apps/v1 kind : Deployment metadata : name : dirigible spec : replicas : 1 selector : matchLabels : app : dirigible template : metadata : labels : app : dirigible spec : containers : - name : dirigible image : dirigiblelabs/dirigible-tomcat:latest ports : - name : dirigible containerPort : 8080 env : - name : DIRIGIBLE_THEME_DEFAULT value : \"fiori\" volumeMounts : - name : dirigible-data mountPath : /usr/local/tomcat/dirigible volumes : - name : dirigible-data persistentVolumeClaim : claimName : \"dirigible-data\" -- apiVersion : v1 kind : PersistentVolumeClaim metadata : name : dirigible-data spec : accessModes : - ReadWriteOnce volumeMode : Filesystem resources : requests : storage : 1Gi Create service configuration file: service.yaml Service apiVersion : v1 kind : Service metadata : name : dirigible labels : app : dirigible spec : ports : - name : dirigible port : 8080 type : ClusterIP selector : app : dirigible apiVersion : extensions/v1beta1 Ingress apiVersion : v1 kind : Service metadata : name : dirigible labels : app : dirigible spec : ports : - name : dirigible port : 8080 type : ClusterIP selector : app : dirigible --- apiVersion : extensions/v1beta1 kind : Ingress metadata : name : dirigible spec : rules : - host : dirigible.<kubernetes-ingress-host> http : paths : - path : / backend : serviceName : dirigible servicePort : 8080 Note: Replace <kubernetes-ingress-host> with your Ingress host Deploy to the Kubernetes Cluster with: kubectl apply -f deployment.yml kubectl apply -f service.yml Open a web browser and go to: http://dirigible.<kubernetes-ingress-host> Login with user dirigible and password dirigible , which are set by default in the Docker image ( dirigiblelabs/dirigible-tomcat ) used above.","title":"Kubernetes"},{"location":"setup/kubernetes/#setup-in-kubernetes","text":"You can deploy Dirigible Docker images, for example dirigiblelabs/dirigible-tomcat , in a Kubernetes cluster.","title":"Setup in Kubernetes"},{"location":"setup/kubernetes/#prerequisites","text":"Kubernetes Command Line Interface Kubernetes Cluster on IaaS provider of your choice","title":"Prerequisites"},{"location":"setup/kubernetes/#steps","text":"Create deployment configuration file: deployment.yaml Pod apiVersion : v1 kind : Pod metadata : name : dirigible spec : containers : - name : dirigible image : dirigiblelabs/dirigible-tomcat:latest ports : - name : dirigible containerPort : 8080 Deployment apiVersion : apps/v1 kind : Deployment metadata : name : dirigible spec : replicas : 1 selector : matchLabels : app : dirigible template : metadata : labels : app : dirigible spec : containers : - name : dirigible image : dirigiblelabs/dirigible-tomcat:latest ports : - name : dirigible containerPort : 8080 env : - name : DIRIGIBLE_THEME_DEFAULT value : \"fiori\" Deployment with PVC apiVersion : apps/v1 kind : Deployment metadata : name : dirigible spec : replicas : 1 selector : matchLabels : app : dirigible template : metadata : labels : app : dirigible spec : containers : - name : dirigible image : dirigiblelabs/dirigible-tomcat:latest ports : - name : dirigible containerPort : 8080 env : - name : DIRIGIBLE_THEME_DEFAULT value : \"fiori\" volumeMounts : - name : dirigible-data mountPath : /usr/local/tomcat/dirigible volumes : - name : dirigible-data persistentVolumeClaim : claimName : \"dirigible-data\" -- apiVersion : v1 kind : PersistentVolumeClaim metadata : name : dirigible-data spec : accessModes : - ReadWriteOnce volumeMode : Filesystem resources : requests : storage : 1Gi Create service configuration file: service.yaml Service apiVersion : v1 kind : Service metadata : name : dirigible labels : app : dirigible spec : ports : - name : dirigible port : 8080 type : ClusterIP selector : app : dirigible apiVersion : extensions/v1beta1 Ingress apiVersion : v1 kind : Service metadata : name : dirigible labels : app : dirigible spec : ports : - name : dirigible port : 8080 type : ClusterIP selector : app : dirigible --- apiVersion : extensions/v1beta1 kind : Ingress metadata : name : dirigible spec : rules : - host : dirigible.<kubernetes-ingress-host> http : paths : - path : / backend : serviceName : dirigible servicePort : 8080 Note: Replace <kubernetes-ingress-host> with your Ingress host Deploy to the Kubernetes Cluster with: kubectl apply -f deployment.yml kubectl apply -f service.yml Open a web browser and go to: http://dirigible.<kubernetes-ingress-host> Login with user dirigible and password dirigible , which are set by default in the Docker image ( dirigiblelabs/dirigible-tomcat ) used above.","title":"Steps"},{"location":"setup/setup-environment-variables/","text":"Environment Variables Configuration Parameters Anonymous Access Parameter Description Default* DIRIGIBLE_ANONYMOUS_USER_NAME_PROPERTY_NAME The name of the property, that will be used to retrieve the anonymous user name (e.g. MY_USER_VARIABLE) - Branding Parameter Description Default* DIRIGIBLE_BRANDING_NAME The brand name Eclipse Dirigible DIRIGIBLE_BRANDING_BRAND The branding name Eclipse Dirigible DIRIGIBLE_BRANDING_ICON The branding icon ../../../../services/v4/web/resources/images/favicon.png DIRIGIBLE_BRANDING_WELCOME_PAGE_DEFAULT The branding welcome page ../../../../services/v4/web/ide/welcome.html Git Parameter Description Default* DIRIGIBLE_GIT_ROOT_FOLDER The external folder that will be used for synchronizing git projects - Registry Parameter Description Default* DIRIGIBLE_REGISTRY_SYNCH_ROOT_FOLDER The external folder that will be used for synchronizing the public registry - Repository Parameter Description Default* DIRIGIBLE_REPOSITORY_PROVIDER The name of the repository provider used in this instance local or database Database Repository Parameter Description Default* DIRIGIBLE_REPOSITORY_DATABASE_DATASOURCE_NAME The name of the data source, which will be used to store the repository artifacts DefaultDB Local Repository Parameter Description Default* DIRIGIBLE_REPOSITORY_LOCAL_ROOT_FOLDER The location of the root folder where the repository artifacts will be stored . DIRIGIBLE_REPOSITORY_LOCAL_ROOT_FOLDER_IS_ABSOLUTE Whether the location of the root folder is absolute or context dependent false Master Repository Parameter Description Default* DIRIGIBLE_MASTER_REPOSITORY_PROVIDER The name of the master repository provider used in this instance ( filesystem , zip or jar ) - DIRIGIBLE_MASTER_REPOSITORY_ROOT_FOLDER The location of the root folder where the master repository artifacts will be loaded from . DIRIGIBLE_MASTER_REPOSITORY_ZIP_LOCATION The location of the zip file where the master repository artifacts will be loaded from (e.g. /User/data/my-repo.zip ) - DIRIGIBLE_MASTER_REPOSITORY_JAR_PATH The JAR path location of the zip file where the master repository artifacts will be loaded from (e.g. /org/dirigible/example/my-repo.zip ) - Note: The JAR path is absolute inside the class path Repository Search Parameter Description Default* DIRIGIBLE_REPOSITORY_SEARCH_ROOT_FOLDER The location of the root folder to be used by the indexing engine . DIRIGIBLE_REPOSITORY_SEARCH_ROOT_FOLDER_IS_ABSOLUTE Whether the location of the root folder is absolute or context dependent false DIRIGIBLE_REPOSITORY_SEARCH_INDEX_LOCATION The sub-folder under the root folder where the index files will be stored dirigible/repository/index Database Parameter Description Default* DIRIGIBLE_DATABASE_PROVIDER The name of the database provider which will be used in this instance ( local , managed or custom ) local DIRIGIBLE_DATABASE_DEFAULT_SET_AUTO_COMMIT The AUTO_COMMIT data source parameter true DIRIGIBLE_DATABASE_DEFAULT_MAX_CONNECTIONS_COUNT The MAX_CONNECTIONS_COUNT data source parameter 8 DIRIGIBLE_DATABASE_DEFAULT_WAIT_TIMEOUT The WAIT_TIMEOUT data source parameter 500 DIRIGIBLE_DATABASE_DEFAULT_WAIT_COUNT The WAIT_COUNT data source parameter 5 DIRIGIBLE_DATABASE_CUSTOM_DATASOURCES The list of the custom data sources names used in this instance DIRIGIBLE_DATABASE_DATASOURCE_NAME_DEFAULT The name of the primary data source used in this instance DefaultDB DIRIGIBLE_DATABASE_NAMES_CASE_SENSITIVE The names of the tables, views and columns to be considered as case sensitive false Database - Custom Note: Replace CUSTOME_NAME with the actual name set by DIRIGIBLE_DATABASE_CUSTOM_DATASOURCES e.g. POSTGRES_DRIVER Parameter Description Default* CUSTOM_NAME_DRIVER The Driver name of the custom datasource (e.g. org.postgresql.Driver ) - CUSTOM_NAME_URL The URL of the custom datasource (e.g. jdbc:postgresql://localhost:5432/<database-name> ) - CUSTOM_NAME_USERNAME The User Name of the custom datasource - CUSTOM_NAME_PASSWORD The Password of the custom datasource - CUSTOM_NAME_CONNECTION_PROPERTIES The additional connection properties if any - Database Derby Parameter Description Default* DIRIGIBLE_DATABASE_DERBY_ROOT_FOLDER_DEFAULT The location used by Derby database ./target/dirigible/derby Database H2 Parameter Description Default* DIRIGIBLE_DATABASE_H2_ROOT_FOLDER_DEFAULT The location used by H2 database ./target/dirigible/h2 DIRIGIBLE_DATABASE_H2_DRIVER The Driver used by H2 database org.h2.Driver DIRIGIBLE_DATABASE_H2_URL The URL used by H2 database jdbc:h2:./target/dirigible/h2 DIRIGIBLE_DATABASE_H2_USERNAME The Username used by H2 database sa DIRIGIBLE_DATABASE_H2_PASSWORD The Password used by H2 database - Persistence Parameter Description Default* DIRIGIBLE_PERSISTENCE_CREATE_TABLE_ON_USE Whether the table to be created automatically on use if it does not exist true MongoDB Parameter Description Default* DIRIGIBLE_MONGODB_CLIENT_URI The location used by MongoDB server mongodb://localhost:27017 DIRIGIBLE_MONGODB_DATABASE_DEFAULT The default database name db Scheduler Parameter Description Default* DIRIGIBLE_SCHEDULER_MEMORY_STORE Whether Quartz to use in-memory job store false DIRIGIBLE_SCHEDULER_DATABASE_DATASOURCE_TYPE The type of the custom data-source used by Quartz, if not the default one - DIRIGIBLE_SCHEDULER_DATABASE_DATASOURCE_NAME The name of the custom data-source used by Quartz, if not the default one - DIRIGIBLE_SCHEDULER_DATABASE_DELEGATE The name of the JDBC delegate used by Quartz, if not the default one org.quartz.impl.jdbcjobstore.StdJDBCDelegate org.quartz.impl.jdbcjobstore.StdJDBCDelegate (for fully JDBC-compliant drivers) org.quartz.impl.jdbcjobstore.MSSQLDelegate (for Microsoft SQL Server, and Sybase) org.quartz.impl.jdbcjobstore.PostgreSQLDelegate org.quartz.impl.jdbcjobstore.WebLogicDelegate (for WebLogic drivers) org.quartz.impl.jdbcjobstore.oracle.OracleDelegate org.quartz.impl.jdbcjobstore.oracle.WebLogicOracleDelegate (for Oracle drivers used within Weblogic) org.quartz.impl.jdbcjobstore.oracle.weblogic.WebLogicOracleDelegate (for Oracle drivers used within Weblogic) org.quartz.impl.jdbcjobstore.CloudscapeDelegate org.quartz.impl.jdbcjobstore.DB2v6Delegate org.quartz.impl.jdbcjobstore.DB2v7Delegate org.quartz.impl.jdbcjobstore.DB2v8Delegate org.quartz.impl.jdbcjobstore.HSQLDBDelegate org.quartz.impl.jdbcjobstore.PointbaseDelegate org.quartz.impl.jdbcjobstore.SybaseDelegate Synchronizer Parameter Description Default* DIRIGIBLE_SYNCHRONIZER_IGNORE_DEPENDENCIES Whether to ignore dependencies for synchronizers, e.g. for tests purposes false Job Expression Parameter Description Default* DIRIGIBLE_JOB_EXPRESSION_BPM BPM synchronizer job config 0/50 * * * * ? DIRIGIBLE_JOB_EXPRESSION_DATA_STRUCTURES Data structures job synchronizer config 0/25 * * * * ? DIRIGIBLE_JOB_EXPRESSION_EXTENSIONS Extension synchronizer job config 0/10 * * * * ? DIRIGIBLE_JOB_EXPRESSION_JOBS Jobs synchronizer job config 0/15 * * * * ? DIRIGIBLE_JOB_EXPRESSION_MESSAGING Messaging synchronizer job config 0/25 * * * * ? DIRIGIBLE_JOB_EXPRESSION_MIGRATIONS Migration synchronizer job config 0/55 * * * * ? DIRIGIBLE_JOB_EXPRESSION_ODATA OData synchronizer job config 0/45 * * * * ? DIRIGIBLE_JOB_EXPRESSION_PUBLISHER Publisher synchronizer job config 0/5 * * * * ? DIRIGIBLE_JOB_EXPRESSION_SECURITY Security synchronizer job config 0/20 * * * * ? DIRIGIBLE_JOB_EXPRESSION_REGISTRY Registry synchronizer job config 0/35 * * * * ? DIRIGIBLE_JOB_DEFAULT_TIMEOUT Default timeout in minutes 3 Runtime Core Parameter Description Default* DIRIGIBLE_HOME_URL The home URL where the user to be redirected on access /services/v4/web/ide/index.html CMS Parameter Description Default* DIRIGIBLE_CMS_PROVIDER The type of the CMS provider used in this instance (e.g. internal , managed or database ) internal DIRIGIBLE_CMS_ROLES_ENABLED Whether the RBAC over the CMS content to be enabled false CMS - Internal Parameter Description Default* DIRIGIBLE_CMS_INTERNAL_ROOT_FOLDER The location of the CMS internal repository target DIRIGIBLE_CMS_INTERNAL_ROOT_FOLDER_IS_ABSOLUTE Whether the root folder parameter is absolute or not false CMS - Managed Parameter Description Default* DIRIGIBLE_CMS_MANAGED_CONFIGURATION_JNDI_NAME The JNDI name of the managed CMS repository java:comp/env/EcmService in case of SAP package DIRIGIBLE_CMS_MANAGED_CONFIGURATION_AUTH_METHOD The authentication method (e.g. key or destination ) key DIRIGIBLE_CMS_MANAGED_CONFIGURATION_NAME The name of the repository cmis:dirigible DIRIGIBLE_CMS_MANAGED_CONFIGURATION_KEY The key of the repository cmis:dirigible:key DIRIGIBLE_CMS_MANAGED_CONFIGURATION_DESTINATION The name of the destination where the name and the key for the repository are stored (e.g. CMIS_DESTINATION ) - DIRIGIBLE_CONNECTIVITY_CONFIGURATION_JNDI_NAME The JNDI name of the connectivity configuration serivce java:comp/env/connectivity/Configuration in case of SAP package CMS Database Parameter Description Default* DIRIGIBLE_CMS_DATABASE_DATASOURCE_TYPE Type of the database for CMS repository (e.g. local , managed , custom , dynamic ) managed DIRIGIBLE_CMS_DATABASE_DATASOURCE_NAME The datasource name DefaultDB BPM Parameter Description Default* DIRIGIBLE_BPM_PROVIDER The provider of the BPM engine (e.g. internal , managed , remote ) internal BPM - Flowable Parameter Description Default* DIRIGIBLE_FLOWABLE_DATABASE_DRIVER The driver of the Flowable engine (e.g. org.postgresql.Driver ) - DIRIGIBLE_FLOWABLE_DATABASE_URL The URL of the Flowable engine (e.g. jdbc:postgresql://localhost:5432/<database-name> ) - DIRIGIBLE_FLOWABLE_DATABASE_USER The user of the Flowable engine - DIRIGIBLE_FLOWABLE_DATABASE_PASSWORD The driver of the Flowable engine - DIRIGIBLE_FLOWABLE_DATABASE_DATASOURCE_NAME The datasource name of the Flowable engine, if any configured - DIRIGIBLE_FLOWABLE_DATABASE_SCHEMA_UPDATE Whether to materialize the database layout or not true DIRIGIBLE_FLOWABLE_USE_DEFAULT_DATABASE Whether to use the DefaultDB datasource or built-in H2 (e.g. true (DefaultDB) or false (H2)) true Mail Parameter Description Default* DIRIGIBLE_MAIL_USERNAME Mailbox username - DIRIGIBLE_MAIL_PASSWORD Mailbox password - DIRIGIBLE_MAIL_TRANSPORT_PROTOCOL Mail transport protocol smtps DIRIGIBLE_MAIL_SMTPS_HOST Mailbox SMTPS host - DIRIGIBLE_MAIL_SMTPS_PORT Mailbox SMTPS port - DIRIGIBLE_MAIL_SMTPS_AUTH Enable/disable mailbox SMTPS authentication - DIRIGIBLE_MAIL_SMTP_HOST Mailbox SMTP host - DIRIGIBLE_MAIL_SMTP_PORT Mailbox SMTP port - DIRIGIBLE_MAIL_SMTP_AUTH Enable/disable mailbox SMTP authentication - Messaging Parameter Description Default* DIRIGIBLE_MESSAGING_USE_DEFAULT_DATABASE Whether to use the DefaultDB datasource or built-in KahaDB (e.g. true (DefaultDB) or false (KahaDB)) true Kafka Parameter Description Default* DIRIGIBLE_KAFKA_BOOTSTRAP_SERVER The Kafka server location localhost:9092 DIRIGIBLE_KAFKA_ACKS The number of brokers that must receive the record before considering the write as successful all DIRIGIBLE_KAFKA_KEY_SERIALIZER The Key serializer org.apache.kafka.common.serialization.StringSerializer DIRIGIBLE_KAFKA_VALUE_SERIALIZER The Value serializer org.apache.kafka.common.serialization.StringSerializer DIRIGIBLE_KAFKA_AUTOCOMMIT_ENABLED Whether Auto Commit is enabled true DIRIGIBLE_KAFKA_AUTOCOMMIT_INTERVAL Auto Commit interval in ms 1000 Engines JavaScript Parameter Description Default* DIRIGIBLE_JAVASCRIPT_ENGINE_TYPE_DEFAULT The type of the JavaScript engine provider used in this instance (e.g. graalvm , rhino , nashorn or v8 ) graalvm since 5.0 GraalVM Parameter Description Default* DIRIGBLE_JAVASCRIPT_GRAALVM_DEBUGGER_PORT The GraalVM debugger port 8081 and 0.0.0.0:8081 in Docker environment DIRIGBLE_JAVASCRIPT_GRAALVM_ALLOW_HOST_ACCESS Whether GraalVM can load classes form custom packages true DIRIGBLE_JAVASCRIPT_GRAALVM_ALLOW_CREATE_THREAD Whether GraalVM can create threads true DIRIGBLE_JAVASCRIPT_GRAALVM_ALLOW_CREATE_PROCESS Whether GraalVM can make IO operations true DIRIGBLE_JAVASCRIPT_GRAALVM_ALLOW_IO Whether GraalVM can make IO operations true DIRIGBLE_JAVASCRIPT_GRAALVM_COMPATIBILITY_MODE_NASHORN Whether GraalVM has enabled compatibility mode for Nashorn true DIRIGBLE_JAVASCRIPT_GRAALVM_COMPATIBILITY_MODE_MOZILLA Whether GraalVM has enabled compatibility mode for Mozilla false Operations Logs Parameter Description Default* DIRIGIBLE_OPERATIONS_LOGS_ROOT_FOLDER_DEFAULT The folder where the log files are stored in ../logs Look & Feel Theme Parameter Description Default* DIRIGIBLE_THEME_DEFAULT The name of the default name Default Destinations Parameter Description Default* DIRIGIBLE_DESTINATIONS_PROVIDER The name of the Destinations Service provider used in this instance local or managed DIRIGIBLE_DESTINATIONS_INTERNAL_ROOT_FOLDER The location of the Destinations internal repository target DIRIGIBLE_DESTINATIONS_INTERNAL_ROOT_FOLDER_IS_ABSOLUTE Whether the root folder parameter is absolute or not false The source is here","title":"Environment Variables"},{"location":"setup/setup-environment-variables/#environment-variables","text":"","title":"Environment Variables"},{"location":"setup/setup-environment-variables/#configuration-parameters","text":"","title":"Configuration Parameters"},{"location":"setup/setup-environment-variables/#anonymous-access","text":"Parameter Description Default* DIRIGIBLE_ANONYMOUS_USER_NAME_PROPERTY_NAME The name of the property, that will be used to retrieve the anonymous user name (e.g. MY_USER_VARIABLE) -","title":"Anonymous Access"},{"location":"setup/setup-environment-variables/#branding","text":"Parameter Description Default* DIRIGIBLE_BRANDING_NAME The brand name Eclipse Dirigible DIRIGIBLE_BRANDING_BRAND The branding name Eclipse Dirigible DIRIGIBLE_BRANDING_ICON The branding icon ../../../../services/v4/web/resources/images/favicon.png DIRIGIBLE_BRANDING_WELCOME_PAGE_DEFAULT The branding welcome page ../../../../services/v4/web/ide/welcome.html","title":"Branding"},{"location":"setup/setup-environment-variables/#git","text":"Parameter Description Default* DIRIGIBLE_GIT_ROOT_FOLDER The external folder that will be used for synchronizing git projects -","title":"Git"},{"location":"setup/setup-environment-variables/#registry","text":"Parameter Description Default* DIRIGIBLE_REGISTRY_SYNCH_ROOT_FOLDER The external folder that will be used for synchronizing the public registry -","title":"Registry"},{"location":"setup/setup-environment-variables/#repository","text":"Parameter Description Default* DIRIGIBLE_REPOSITORY_PROVIDER The name of the repository provider used in this instance local or database","title":"Repository"},{"location":"setup/setup-environment-variables/#database-repository","text":"Parameter Description Default* DIRIGIBLE_REPOSITORY_DATABASE_DATASOURCE_NAME The name of the data source, which will be used to store the repository artifacts DefaultDB","title":"Database Repository"},{"location":"setup/setup-environment-variables/#local-repository","text":"Parameter Description Default* DIRIGIBLE_REPOSITORY_LOCAL_ROOT_FOLDER The location of the root folder where the repository artifacts will be stored . DIRIGIBLE_REPOSITORY_LOCAL_ROOT_FOLDER_IS_ABSOLUTE Whether the location of the root folder is absolute or context dependent false","title":"Local Repository"},{"location":"setup/setup-environment-variables/#master-repository","text":"Parameter Description Default* DIRIGIBLE_MASTER_REPOSITORY_PROVIDER The name of the master repository provider used in this instance ( filesystem , zip or jar ) - DIRIGIBLE_MASTER_REPOSITORY_ROOT_FOLDER The location of the root folder where the master repository artifacts will be loaded from . DIRIGIBLE_MASTER_REPOSITORY_ZIP_LOCATION The location of the zip file where the master repository artifacts will be loaded from (e.g. /User/data/my-repo.zip ) - DIRIGIBLE_MASTER_REPOSITORY_JAR_PATH The JAR path location of the zip file where the master repository artifacts will be loaded from (e.g. /org/dirigible/example/my-repo.zip ) - Note: The JAR path is absolute inside the class path","title":"Master Repository"},{"location":"setup/setup-environment-variables/#repository-search","text":"Parameter Description Default* DIRIGIBLE_REPOSITORY_SEARCH_ROOT_FOLDER The location of the root folder to be used by the indexing engine . DIRIGIBLE_REPOSITORY_SEARCH_ROOT_FOLDER_IS_ABSOLUTE Whether the location of the root folder is absolute or context dependent false DIRIGIBLE_REPOSITORY_SEARCH_INDEX_LOCATION The sub-folder under the root folder where the index files will be stored dirigible/repository/index","title":"Repository Search"},{"location":"setup/setup-environment-variables/#database","text":"Parameter Description Default* DIRIGIBLE_DATABASE_PROVIDER The name of the database provider which will be used in this instance ( local , managed or custom ) local DIRIGIBLE_DATABASE_DEFAULT_SET_AUTO_COMMIT The AUTO_COMMIT data source parameter true DIRIGIBLE_DATABASE_DEFAULT_MAX_CONNECTIONS_COUNT The MAX_CONNECTIONS_COUNT data source parameter 8 DIRIGIBLE_DATABASE_DEFAULT_WAIT_TIMEOUT The WAIT_TIMEOUT data source parameter 500 DIRIGIBLE_DATABASE_DEFAULT_WAIT_COUNT The WAIT_COUNT data source parameter 5 DIRIGIBLE_DATABASE_CUSTOM_DATASOURCES The list of the custom data sources names used in this instance DIRIGIBLE_DATABASE_DATASOURCE_NAME_DEFAULT The name of the primary data source used in this instance DefaultDB DIRIGIBLE_DATABASE_NAMES_CASE_SENSITIVE The names of the tables, views and columns to be considered as case sensitive false","title":"Database"},{"location":"setup/setup-environment-variables/#database-custom","text":"Note: Replace CUSTOME_NAME with the actual name set by DIRIGIBLE_DATABASE_CUSTOM_DATASOURCES e.g. POSTGRES_DRIVER Parameter Description Default* CUSTOM_NAME_DRIVER The Driver name of the custom datasource (e.g. org.postgresql.Driver ) - CUSTOM_NAME_URL The URL of the custom datasource (e.g. jdbc:postgresql://localhost:5432/<database-name> ) - CUSTOM_NAME_USERNAME The User Name of the custom datasource - CUSTOM_NAME_PASSWORD The Password of the custom datasource - CUSTOM_NAME_CONNECTION_PROPERTIES The additional connection properties if any -","title":"Database - Custom"},{"location":"setup/setup-environment-variables/#database-derby","text":"Parameter Description Default* DIRIGIBLE_DATABASE_DERBY_ROOT_FOLDER_DEFAULT The location used by Derby database ./target/dirigible/derby","title":"Database Derby"},{"location":"setup/setup-environment-variables/#database-h2","text":"Parameter Description Default* DIRIGIBLE_DATABASE_H2_ROOT_FOLDER_DEFAULT The location used by H2 database ./target/dirigible/h2 DIRIGIBLE_DATABASE_H2_DRIVER The Driver used by H2 database org.h2.Driver DIRIGIBLE_DATABASE_H2_URL The URL used by H2 database jdbc:h2:./target/dirigible/h2 DIRIGIBLE_DATABASE_H2_USERNAME The Username used by H2 database sa DIRIGIBLE_DATABASE_H2_PASSWORD The Password used by H2 database -","title":"Database H2"},{"location":"setup/setup-environment-variables/#persistence","text":"Parameter Description Default* DIRIGIBLE_PERSISTENCE_CREATE_TABLE_ON_USE Whether the table to be created automatically on use if it does not exist true","title":"Persistence"},{"location":"setup/setup-environment-variables/#mongodb","text":"Parameter Description Default* DIRIGIBLE_MONGODB_CLIENT_URI The location used by MongoDB server mongodb://localhost:27017 DIRIGIBLE_MONGODB_DATABASE_DEFAULT The default database name db","title":"MongoDB"},{"location":"setup/setup-environment-variables/#scheduler","text":"Parameter Description Default* DIRIGIBLE_SCHEDULER_MEMORY_STORE Whether Quartz to use in-memory job store false DIRIGIBLE_SCHEDULER_DATABASE_DATASOURCE_TYPE The type of the custom data-source used by Quartz, if not the default one - DIRIGIBLE_SCHEDULER_DATABASE_DATASOURCE_NAME The name of the custom data-source used by Quartz, if not the default one - DIRIGIBLE_SCHEDULER_DATABASE_DELEGATE The name of the JDBC delegate used by Quartz, if not the default one org.quartz.impl.jdbcjobstore.StdJDBCDelegate org.quartz.impl.jdbcjobstore.StdJDBCDelegate (for fully JDBC-compliant drivers) org.quartz.impl.jdbcjobstore.MSSQLDelegate (for Microsoft SQL Server, and Sybase) org.quartz.impl.jdbcjobstore.PostgreSQLDelegate org.quartz.impl.jdbcjobstore.WebLogicDelegate (for WebLogic drivers) org.quartz.impl.jdbcjobstore.oracle.OracleDelegate org.quartz.impl.jdbcjobstore.oracle.WebLogicOracleDelegate (for Oracle drivers used within Weblogic) org.quartz.impl.jdbcjobstore.oracle.weblogic.WebLogicOracleDelegate (for Oracle drivers used within Weblogic) org.quartz.impl.jdbcjobstore.CloudscapeDelegate org.quartz.impl.jdbcjobstore.DB2v6Delegate org.quartz.impl.jdbcjobstore.DB2v7Delegate org.quartz.impl.jdbcjobstore.DB2v8Delegate org.quartz.impl.jdbcjobstore.HSQLDBDelegate org.quartz.impl.jdbcjobstore.PointbaseDelegate org.quartz.impl.jdbcjobstore.SybaseDelegate","title":"Scheduler"},{"location":"setup/setup-environment-variables/#synchronizer","text":"Parameter Description Default* DIRIGIBLE_SYNCHRONIZER_IGNORE_DEPENDENCIES Whether to ignore dependencies for synchronizers, e.g. for tests purposes false","title":"Synchronizer"},{"location":"setup/setup-environment-variables/#job-expression","text":"Parameter Description Default* DIRIGIBLE_JOB_EXPRESSION_BPM BPM synchronizer job config 0/50 * * * * ? DIRIGIBLE_JOB_EXPRESSION_DATA_STRUCTURES Data structures job synchronizer config 0/25 * * * * ? DIRIGIBLE_JOB_EXPRESSION_EXTENSIONS Extension synchronizer job config 0/10 * * * * ? DIRIGIBLE_JOB_EXPRESSION_JOBS Jobs synchronizer job config 0/15 * * * * ? DIRIGIBLE_JOB_EXPRESSION_MESSAGING Messaging synchronizer job config 0/25 * * * * ? DIRIGIBLE_JOB_EXPRESSION_MIGRATIONS Migration synchronizer job config 0/55 * * * * ? DIRIGIBLE_JOB_EXPRESSION_ODATA OData synchronizer job config 0/45 * * * * ? DIRIGIBLE_JOB_EXPRESSION_PUBLISHER Publisher synchronizer job config 0/5 * * * * ? DIRIGIBLE_JOB_EXPRESSION_SECURITY Security synchronizer job config 0/20 * * * * ? DIRIGIBLE_JOB_EXPRESSION_REGISTRY Registry synchronizer job config 0/35 * * * * ? DIRIGIBLE_JOB_DEFAULT_TIMEOUT Default timeout in minutes 3","title":"Job Expression"},{"location":"setup/setup-environment-variables/#runtime-core","text":"Parameter Description Default* DIRIGIBLE_HOME_URL The home URL where the user to be redirected on access /services/v4/web/ide/index.html","title":"Runtime Core"},{"location":"setup/setup-environment-variables/#cms","text":"Parameter Description Default* DIRIGIBLE_CMS_PROVIDER The type of the CMS provider used in this instance (e.g. internal , managed or database ) internal DIRIGIBLE_CMS_ROLES_ENABLED Whether the RBAC over the CMS content to be enabled false","title":"CMS"},{"location":"setup/setup-environment-variables/#cms-internal","text":"Parameter Description Default* DIRIGIBLE_CMS_INTERNAL_ROOT_FOLDER The location of the CMS internal repository target DIRIGIBLE_CMS_INTERNAL_ROOT_FOLDER_IS_ABSOLUTE Whether the root folder parameter is absolute or not false","title":"CMS - Internal"},{"location":"setup/setup-environment-variables/#cms-managed","text":"Parameter Description Default* DIRIGIBLE_CMS_MANAGED_CONFIGURATION_JNDI_NAME The JNDI name of the managed CMS repository java:comp/env/EcmService in case of SAP package DIRIGIBLE_CMS_MANAGED_CONFIGURATION_AUTH_METHOD The authentication method (e.g. key or destination ) key DIRIGIBLE_CMS_MANAGED_CONFIGURATION_NAME The name of the repository cmis:dirigible DIRIGIBLE_CMS_MANAGED_CONFIGURATION_KEY The key of the repository cmis:dirigible:key DIRIGIBLE_CMS_MANAGED_CONFIGURATION_DESTINATION The name of the destination where the name and the key for the repository are stored (e.g. CMIS_DESTINATION ) - DIRIGIBLE_CONNECTIVITY_CONFIGURATION_JNDI_NAME The JNDI name of the connectivity configuration serivce java:comp/env/connectivity/Configuration in case of SAP package","title":"CMS - Managed"},{"location":"setup/setup-environment-variables/#cms-database","text":"Parameter Description Default* DIRIGIBLE_CMS_DATABASE_DATASOURCE_TYPE Type of the database for CMS repository (e.g. local , managed , custom , dynamic ) managed DIRIGIBLE_CMS_DATABASE_DATASOURCE_NAME The datasource name DefaultDB","title":"CMS Database"},{"location":"setup/setup-environment-variables/#bpm","text":"Parameter Description Default* DIRIGIBLE_BPM_PROVIDER The provider of the BPM engine (e.g. internal , managed , remote ) internal","title":"BPM"},{"location":"setup/setup-environment-variables/#bpm-flowable","text":"Parameter Description Default* DIRIGIBLE_FLOWABLE_DATABASE_DRIVER The driver of the Flowable engine (e.g. org.postgresql.Driver ) - DIRIGIBLE_FLOWABLE_DATABASE_URL The URL of the Flowable engine (e.g. jdbc:postgresql://localhost:5432/<database-name> ) - DIRIGIBLE_FLOWABLE_DATABASE_USER The user of the Flowable engine - DIRIGIBLE_FLOWABLE_DATABASE_PASSWORD The driver of the Flowable engine - DIRIGIBLE_FLOWABLE_DATABASE_DATASOURCE_NAME The datasource name of the Flowable engine, if any configured - DIRIGIBLE_FLOWABLE_DATABASE_SCHEMA_UPDATE Whether to materialize the database layout or not true DIRIGIBLE_FLOWABLE_USE_DEFAULT_DATABASE Whether to use the DefaultDB datasource or built-in H2 (e.g. true (DefaultDB) or false (H2)) true","title":"BPM - Flowable"},{"location":"setup/setup-environment-variables/#mail","text":"Parameter Description Default* DIRIGIBLE_MAIL_USERNAME Mailbox username - DIRIGIBLE_MAIL_PASSWORD Mailbox password - DIRIGIBLE_MAIL_TRANSPORT_PROTOCOL Mail transport protocol smtps DIRIGIBLE_MAIL_SMTPS_HOST Mailbox SMTPS host - DIRIGIBLE_MAIL_SMTPS_PORT Mailbox SMTPS port - DIRIGIBLE_MAIL_SMTPS_AUTH Enable/disable mailbox SMTPS authentication - DIRIGIBLE_MAIL_SMTP_HOST Mailbox SMTP host - DIRIGIBLE_MAIL_SMTP_PORT Mailbox SMTP port - DIRIGIBLE_MAIL_SMTP_AUTH Enable/disable mailbox SMTP authentication -","title":"Mail"},{"location":"setup/setup-environment-variables/#messaging","text":"Parameter Description Default* DIRIGIBLE_MESSAGING_USE_DEFAULT_DATABASE Whether to use the DefaultDB datasource or built-in KahaDB (e.g. true (DefaultDB) or false (KahaDB)) true","title":"Messaging"},{"location":"setup/setup-environment-variables/#kafka","text":"Parameter Description Default* DIRIGIBLE_KAFKA_BOOTSTRAP_SERVER The Kafka server location localhost:9092 DIRIGIBLE_KAFKA_ACKS The number of brokers that must receive the record before considering the write as successful all DIRIGIBLE_KAFKA_KEY_SERIALIZER The Key serializer org.apache.kafka.common.serialization.StringSerializer DIRIGIBLE_KAFKA_VALUE_SERIALIZER The Value serializer org.apache.kafka.common.serialization.StringSerializer DIRIGIBLE_KAFKA_AUTOCOMMIT_ENABLED Whether Auto Commit is enabled true DIRIGIBLE_KAFKA_AUTOCOMMIT_INTERVAL Auto Commit interval in ms 1000","title":"Kafka"},{"location":"setup/setup-environment-variables/#engines","text":"","title":"Engines"},{"location":"setup/setup-environment-variables/#javascript","text":"Parameter Description Default* DIRIGIBLE_JAVASCRIPT_ENGINE_TYPE_DEFAULT The type of the JavaScript engine provider used in this instance (e.g. graalvm , rhino , nashorn or v8 ) graalvm since 5.0","title":"JavaScript"},{"location":"setup/setup-environment-variables/#graalvm","text":"Parameter Description Default* DIRIGBLE_JAVASCRIPT_GRAALVM_DEBUGGER_PORT The GraalVM debugger port 8081 and 0.0.0.0:8081 in Docker environment DIRIGBLE_JAVASCRIPT_GRAALVM_ALLOW_HOST_ACCESS Whether GraalVM can load classes form custom packages true DIRIGBLE_JAVASCRIPT_GRAALVM_ALLOW_CREATE_THREAD Whether GraalVM can create threads true DIRIGBLE_JAVASCRIPT_GRAALVM_ALLOW_CREATE_PROCESS Whether GraalVM can make IO operations true DIRIGBLE_JAVASCRIPT_GRAALVM_ALLOW_IO Whether GraalVM can make IO operations true DIRIGBLE_JAVASCRIPT_GRAALVM_COMPATIBILITY_MODE_NASHORN Whether GraalVM has enabled compatibility mode for Nashorn true DIRIGBLE_JAVASCRIPT_GRAALVM_COMPATIBILITY_MODE_MOZILLA Whether GraalVM has enabled compatibility mode for Mozilla false","title":"GraalVM"},{"location":"setup/setup-environment-variables/#operations","text":"","title":"Operations"},{"location":"setup/setup-environment-variables/#logs","text":"Parameter Description Default* DIRIGIBLE_OPERATIONS_LOGS_ROOT_FOLDER_DEFAULT The folder where the log files are stored in ../logs","title":"Logs"},{"location":"setup/setup-environment-variables/#look-feel","text":"","title":"Look &amp; Feel"},{"location":"setup/setup-environment-variables/#theme","text":"Parameter Description Default* DIRIGIBLE_THEME_DEFAULT The name of the default name Default","title":"Theme"},{"location":"setup/setup-environment-variables/#destinations","text":"Parameter Description Default* DIRIGIBLE_DESTINATIONS_PROVIDER The name of the Destinations Service provider used in this instance local or managed DIRIGIBLE_DESTINATIONS_INTERNAL_ROOT_FOLDER The location of the Destinations internal repository target DIRIGIBLE_DESTINATIONS_INTERNAL_ROOT_FOLDER_IS_ABSOLUTE Whether the root folder parameter is absolute or not false The source is here","title":"Destinations"}]}